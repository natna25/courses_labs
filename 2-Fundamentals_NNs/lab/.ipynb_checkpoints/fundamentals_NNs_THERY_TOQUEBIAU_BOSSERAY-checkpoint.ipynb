{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "EPSILON = 1e-8 # small constant to avoid underflow or divide per 0\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This time, the data will correspond to greyscale images. <br> Two different datasets can be used here:\n",
    "- The MNIST dataset, small 8*8 images, corresponding to handwritten digits &rightarrow; 10 classes\n",
    "- The Fashion MNIST dataset, medium 28*28 images, corresponding to clothes pictures &rightarrow; 10 classes\n",
    "\n",
    "#### Starting with the simple MNIST is recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"MNIST\"\n",
    "# dataset = \"FASHION_MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset='MNIST'):\n",
    "    if dataset == 'MNIST':\n",
    "        digits = load_digits()\n",
    "        X, Y = np.asarray(digits['data'], dtype='float32'), np.asarray(digits['target'], dtype='int32')\n",
    "        return X, Y\n",
    "    elif dataset == 'FASHION_MNIST':\n",
    "        import tensorflow as tf\n",
    "        fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "        (X, Y), (_, _) = fashion_mnist.load_data()\n",
    "        X = X.reshape((X.shape[0], X.shape[1] * X.shape[2]))\n",
    "        X, Y = np.asarray(X, dtype='float32'), np.asarray(Y, dtype='int32')\n",
    "        return X, Y\n",
    "X, Y = load_data(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1797\n",
      "Input dimension: 64\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples: {:d}'.format(X.shape[0]))\n",
    "print('Input dimension: {:d}'.format(X.shape[1]))  # images 8x8 or 28*28 actually\n",
    "print('Number of classes: {:d}'.format(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range max-min of greyscale pixel values: (16.0, 0.0)\n",
      "First image sample:\n",
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n",
      "First image label: 0\n",
      "Input design matrix shape: (1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Range max-min of greyscale pixel values: ({0:.1f}, {1:.1f})\".format(np.max(X), np.min(X)))\n",
    "print(\"First image sample:\\n{0}\".format(X[0]))\n",
    "print(\"First image label: {0}\".format(Y[0]))\n",
    "print(\"Input design matrix shape: {0}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does the data look like?\n",
    "Each image in the dataset consists of a 8 x 8 (or 28 x 28) matrix, of greyscale pixels. For the MNIST dataset, the values are between 0 and 16 where 0 represents white, 16 represents black and there are many shades of grey in-between. For the Fashion MNIST dataset, the values are between 0 and 255.<br>Each image is assigned a corresponding numerical label, so the image in ```X[i]``` has its corresponding label stored in ```Y[i]```.\n",
    "\n",
    "The next cells below demonstrate how to visualise the input data. Make sure you understand what's happening, particularly how the indices correspond to individual items in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data_sample(X, Y, nrows=2, ncols=2):\n",
    "    fig, ax = plt.subplots(nrows, ncols)\n",
    "    for row in ax:\n",
    "        for col in row:\n",
    "            index = random.randint(0, X.shape[0])\n",
    "            dim = np.sqrt(X.shape[1]).astype(int)\n",
    "            col.imshow(X[index].reshape((dim, dim)), cmap=plt.cm.gray_r)\n",
    "            col.set_title(\"image label: %d\" % Y[index])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_data_sample(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â II - Multiclass classification MLP with Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II a) - Problem definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/mlp_mnist.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task here will be to implement \"from scratch\" a Multilayer Perceptron for classification.\n",
    "\n",
    "We will define the formal categorical cross entropy loss as follows:\n",
    "$$\n",
    "l(\\mathbf{\\Theta}, \\mathbf{X}, \\mathbf{Y}) = - \\frac{1}{n} \\sum_{i=1}^n \\log \\mathbf{f}(\\mathbf{x}_i ; \\mathbf{\\Theta})^\\top y_i\n",
    "$$\n",
    "<center>with $y_i$ being the one-hot encoded true label for the sample $i$, and $\\Theta = (\\mathbf{W}^h; \\mathbf{b}^h; \\mathbf{W}^o; \\mathbf{b}^o)$</center>\n",
    "<center>In addition, $\\mathbf{f}(\\mathbf{x}) = softmax(\\mathbf{z^o}(\\mathbf{x})) = softmax(\\mathbf{W}^o\\mathbf{h}(\\mathbf{x}) + \\mathbf{b}^o)$</center>\n",
    "<center>and $\\mathbf{h}(\\mathbf{x}) = g(\\mathbf{z^h}(\\mathbf{x})) = g(\\mathbf{W}^h\\mathbf{x} + \\mathbf{b}^h)$, $g$ being the activation function and could be implemented with $sigmoid$ or $relu$</center>\n",
    "\n",
    "## Objectives:\n",
    "- Write the categorical cross entropy loss function\n",
    "- Write the activation functions with their associated gradient\n",
    "- Write the softmax function that is going to be used to output the predicted probabilities\n",
    "- Implement the forward pass through the neural network\n",
    "- Implement the backpropagation according to the used loss: progagate the gradients using the chain rule and return $(\\mathbf{\\nabla_{W^h}}l ; \\mathbf{\\nabla_{b^h}}l ; \\mathbf{\\nabla_{W^o}}l ; \\mathbf{\\nabla_{b^o}}l)$\n",
    "- Implement dropout regularization in the forward pass: be careful to consider both training and prediction cases\n",
    "- Implement the SGD optimization algorithm, and improve it with simple momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple graph function to let you have a global overview:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/function_graph.png\" style=\"width: 750px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) You may find numpy outer products useful: <br>\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.outer.html <br>\n",
    "We have: $outer(u, v) = u \\cdot v^T$, with $u, v$ two vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = np.random.normal(size=(5,)), np.random.normal(size=(10,))\n",
    "assert np.array_equal(\n",
    "    np.outer(u, v),\n",
    "    np.dot(np.reshape(u, (u.size, 1)), np.reshape(v, (1, v.size)))\n",
    ")\n",
    "assert np.outer(u, v).shape == (5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) You also may find numpy matmul function useful: <br>\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html <br>\n",
    "It can be used to perform matrix products along one fixed dimension (i.e. the batch size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = np.random.randint(0, 100, size=(64, 5, 10)), np.random.randint(0, 100, size=(64, 10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(\n",
    "    np.stack([np.dot(A_i, B_i) for A_i, B_i in zip(A, B)]),\n",
    "    np.matmul(A, B)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â II b) - Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron():\n",
    "    \"\"\"MLP with one hidden layer having a hidden activation,\n",
    "    and one output layer having a softmax activation\"\"\"\n",
    "    def __init__(self, X, Y, hidden_size, activation='relu',\n",
    "                 initialization='uniform', dropout=False, dropout_rate=1):\n",
    "        # input, hidden, and output dimensions on the MLP based on X, Y\n",
    "        self.input_size, self.output_size = X.shape[1], len(np.unique(Y))\n",
    "        self.hidden_size = hidden_size\n",
    "        # initialization strategies: avoid a full-0 initialization of the weight matrices\n",
    "        if initialization == 'uniform':\n",
    "            self.W_h = np.random.uniform(size=(self.hidden_size, self.input_size), high=0.01, low=-0.01)\n",
    "            self.W_o = np.random.uniform(size=(self.output_size, self.hidden_size), high=0.01, low=-0.01)\n",
    "        elif initialization == 'normal':\n",
    "            self.W_h = np.random.normal(size=(self.hidden_size, self.input_size), loc=0, scale=0.01)\n",
    "            self.W_o = np.random.normal(size=(self.output_size, self.hidden_size), loc=0, scale=0.01)\n",
    "        # the bias could be initializated to 0 or a random low constant\n",
    "        self.b_h = np.zeros(self.hidden_size)\n",
    "        self.b_o = np.zeros(self.output_size)\n",
    "        # our namedtuple structure of gradients\n",
    "        self.Grads = namedtuple('Grads', ['W_h', 'b_h', 'W_o', 'b_o'])\n",
    "        # and the velocities associated which are going to be useful for the momentum\n",
    "        self.velocities = {'W_h': 0., 'b_h': 0., 'W_o': 0., 'b_o': 0.}\n",
    "        #Â the hidden activation function used\n",
    "        self.activation = activation\n",
    "        #Â arrays to track back the losses and accuracies evolution\n",
    "        self.training_losses_history = []\n",
    "        self.validation_losses_history = []\n",
    "        self.training_acc_history = []\n",
    "        self.validation_acc_history = []\n",
    "        #Â train val split and normalization of the features\n",
    "        self.X_tr, self.X_val, self.Y_tr, self.Y_val = self.split_train_validation(X, Y)\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1), copy=False)\n",
    "        self.X_tr = self.scaler.fit_transform(self.X_tr)\n",
    "        self.X_val = self.scaler.transform(self.X_val)\n",
    "        #Â dropout parameters\n",
    "        self.dropout = dropout\n",
    "        self.dropout_rate = dropout_rate\n",
    "        # step used for the optimization algorithm and setted later\n",
    "        self.step = None\n",
    "    \n",
    "    # One-hot encoding of the target\n",
    "    # Transform the integer represensation to a sparse one\n",
    "    @staticmethod\n",
    "    def one_hot(n_classes, Y):\n",
    "        return np.eye(n_classes)[Y]\n",
    "    \n",
    "    # Reverse one-hot encoding of the target\n",
    "    # Recover the former integer representation\n",
    "    # ex: from (0,0,1,0) to 2\n",
    "    @staticmethod\n",
    "    def reverse_one_hot(Y_one_hot):\n",
    "        return np.asarray(np.where(Y_one_hot==1)[1], dtype='int32')\n",
    "    \n",
    "    \"\"\"\n",
    "    Activation functions and their gradient\n",
    "    \"\"\"\n",
    "    # In implementations below X is a matrix of shape (n_samples, p)\n",
    "    \n",
    "    #Â A max_value value is indicated for the relu and grad_relu functions\n",
    "    # Make sure to clip the output to it to prevent numerical overflow (exploding gradient)\n",
    "    # Make it so the max value reachable is max_value\n",
    "    @staticmethod\n",
    "    def relu(X, max_value=20):\n",
    "        assert max_value > 0\n",
    "        #TODO: (done)\n",
    "        return np.maximum(0,np.clip(X,0,max_value))\n",
    "    \n",
    "    # Make it so the gradient becomes 0 when X becomes greater than max_value\n",
    "    @staticmethod\n",
    "    def grad_relu(X, max_value=20):\n",
    "        assert max_value > 0\n",
    "        # TODO: (done)\n",
    "        return np.where(np.where(X < max_value, X, 0 ) < 0, 0, 1 )\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(X):\n",
    "        # TODO: (done)\n",
    "        return (1/(1+np.exp(-X)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def grad_sigmoid(X,sigmoid):\n",
    "        # TODO: (done)\n",
    "        return (sigmoid(X) * (1- sigmoid(X)))\n",
    "    \n",
    "    # Softmax function to output probabilities\n",
    "    @staticmethod\n",
    "    def softmax(X):\n",
    "        # TODO: (done)\n",
    "        return ( 1/np.sum(np.exp(X),axis=0) ) * np.exp(X) \n",
    "    \n",
    "    #Â Loss function\n",
    "    #Â Consider using EPSILON to prevent numerical issues (log(0) is undefined)\n",
    "    # Y_true and Y_pred are of shape (n_samples,n_classes)\n",
    "    @staticmethod\n",
    "    def categorical_cross_entropy(Y_true, Y_pred):\n",
    "        # TODO: (done)\n",
    "        return -np.sum(Y_true * np.log(Y_pred + EPSILON))\n",
    "    \n",
    "    @staticmethod\n",
    "    def split_train_validation(X, Y, test_size=0.25, seed=False):\n",
    "        random_state = 42 if seed else np.random.randint(1e3)\n",
    "        X_tr, X_val, Y_tr, Y_val = train_test_split(X, Y, test_size=test_size, random_state=random_state)\n",
    "        return X_tr, X_val, Y_tr, Y_val\n",
    "    \n",
    "    # Sample random batch in (X, Y) with a given batch_size for SGD\n",
    "    @staticmethod\n",
    "    def get_random_batch(X, Y, batch_size):\n",
    "        indexes = np.random.choice(X.shape[0], size=batch_size, replace=False)\n",
    "        return X[indexes], Y[indexes]\n",
    "        \n",
    "    #Â Forward pass: compute f(x) as y, and return optionally the hidden states h(x) and z_h(x) for compute_grads\n",
    "    def forward(self, X, return_activation=False, training=False):\n",
    "        if self.activation == 'relu':\n",
    "            g_activation = self.relu\n",
    "        elif self.activation == 'sigmoid':\n",
    "            g_activation = self.sigmoid\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        #z_h = np.zeros((X.shape[0], self.hidden_size)) if len(X.shape) > 1 else np.zeros(self.hidden_size)\n",
    "        #h = np.zeros((X.shape[0], self.hidden_size)) if len(X.shape) > 1 else np.zeros(self.hidden_size)\n",
    "        # TODO: (done)\n",
    "        z_h =  np.dot(X,self.W_h.T) + self.b_h\n",
    "        h = g_activation(z_h)\n",
    "        \n",
    "        if self.dropout:\n",
    "            if training:\n",
    "                # TODO: (done)\n",
    "                keep = np.where(np.random.uniform(size=h.shape) > self.dropout_rate, 1,0)\n",
    "                h *= keep\n",
    "            else:\n",
    "                # TODO: (done)\n",
    "                h *= self.dropout_rate\n",
    "\n",
    "\n",
    "        # TODO: (done)\n",
    "        #y = np.zeros((X.shape[0], self.output_size)) if len(X.shape) > 1 else np.zeros(self.output_size)  \n",
    "        \n",
    "        y = g_activation(np.dot(h,self.W_o.T) + self.b_o)\n",
    "        \n",
    "        #y = self.softmax(y)\n",
    "        \n",
    "        if return_activation:\n",
    "            return y, h, z_h\n",
    "        else:\n",
    "            return y\n",
    "    \n",
    "    #Â Backpropagation: return an instantiation of self.Grads that contains the average gradients for the given batch\n",
    "    def compute_grads(self, X, Y_true, vectorized=False):\n",
    "        if self.activation == 'relu':\n",
    "            g_grad = self.grad_relu\n",
    "        elif self.activation == 'sigmoid':\n",
    "            g_grad = self.grad_sigmoid\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape((1,) + X.shape)\n",
    "        \n",
    "        if not vectorized:\n",
    "            n = X.shape[0]\n",
    "            grad_W_h = np.zeros((self.hidden_size, self.input_size))\n",
    "            grad_b_h = np.zeros((self.hidden_size, )) \n",
    "            grad_W_o = np.zeros((self.output_size, self.hidden_size))\n",
    "            grad_b_o = np.zeros((self.output_size, ))\n",
    "            for x, y_true in zip(X, Y_true):\n",
    "                y_pred, h, z_h = self.forward(x, return_activation=True, training=True)\n",
    "                \n",
    "                #calculate loss\n",
    "                #one hot y true ????\n",
    "                y_true_one_hot = self.one_hot(10,y_true)\n",
    "                loss = self.categorical_cross_entropy(y_true_one_hot,y_pred)\n",
    "                \n",
    "                #calc activation gradients\n",
    "                y_true_one_hot = self.one_hot(10,y_true)\n",
    "                act_grad = y_pred - y_true_one_hot\n",
    "                #print(\"act_grad\",act_grad.shape)\n",
    "                \n",
    "                # TODO: (maybe done)\n",
    "                grad_h   = self.W_o.T.dot(act_grad)\n",
    "                #print(\"grad_h\",grad_h.shape)\n",
    "                grad_z_h = np.multiply(grad_h, self.grad_sigmoid(z_h,self.sigmoid) )\n",
    "                #print(\"grad_z_h\", grad_z_h.shape)\n",
    "                \n",
    "                #grad_W_h = grad_z_h.reshape((self.hidden_size,1)).dot(x.reshape((self.input_size,1)).T) #np.zeros((self.hidden_size, self.input_size))\n",
    "                grad_W_h += np.outer(grad_z_h,x)\n",
    "                #print(\"grad_W_h\",grad_W_h.shape)\n",
    "                grad_b_h += grad_z_h #np.zeros((self.hidden_size, )) \n",
    "                #print(\"grad_b_h\",grad_b_h.shape)\n",
    "                #grad_W_o = act_grad.dot(h.T) #np.zeros((self.output_size, self.hidden_size))\n",
    "                grad_W_o += np.outer(act_grad,h)\n",
    "                #print(\"grad_W_o\",grad_W_o.shape)\n",
    "                grad_b_o += act_grad # np.zeros((self.output_size, ))\n",
    "                #print(\"grad_b_o\",grad_b_o.shape)\n",
    "                \n",
    "            grads = self.Grads(grad_W_h/n, grad_b_h/n, grad_W_o/n, grad_b_o/n)\n",
    "            \n",
    "        else: \n",
    "            #print('doing vectorized grads')\n",
    "            Y_pred, h, z_h = self.forward(X, return_activation=True, training=True)\n",
    "\n",
    "            # TODO (optional), try to do the backprop without Python loops in a vectorized way:\n",
    "              \n",
    "            #calculate loss\n",
    "            #one hot y true ????\n",
    "            Y_true_one_hot = self.one_hot(10,Y_true)\n",
    "            loss = self.categorical_cross_entropy(Y_true_one_hot,Y_pred)\n",
    "\n",
    "            #calc activation gradients\n",
    "            Y_true_one_hot = self.one_hot(10,Y_true)\n",
    "            act_grad = Y_pred - Y_true_one_hot\n",
    "            #print(\"act_grad\",act_grad.shape)\n",
    "\n",
    "            # TODO: (maybe done)\n",
    "            \n",
    "            #grad_h   = self.W_o.T.dot(act_grad)\n",
    "            #print(self.W_o.shape)\n",
    "            #print(act_grad.shape)\n",
    "            grad_h   = np.dot(act_grad,self.W_o)\n",
    "            \n",
    "            #print(\"grad_h\",grad_h.shape)\n",
    "            grad_z_h = np.multiply(grad_h, self.grad_sigmoid(z_h,self.sigmoid) )\n",
    "            #print(\"grad_z_h\", grad_z_h.shape)\n",
    "\n",
    "            #grad_W_h = grad_z_h.reshape((self.hidden_size,1)).dot(x.reshape((self.input_size,1)).T) #np.zeros((self.hidden_size, self.input_size))\n",
    "            grad_W_h = np.outer(grad_z_h,X)\n",
    "            #print(\"grad_W_h\",grad_W_h.shape)\n",
    "            grad_b_h = grad_z_h #np.zeros((self.hidden_size, )) \n",
    "            #print(\"grad_b_h\",grad_b_h.shape)\n",
    "            #grad_W_o = act_grad.dot(h.T) #np.zeros((self.output_size, self.hidden_size))\n",
    "            grad_W_o = np.outer(act_grad,h)\n",
    "            #print(\"grad_W_o\",grad_W_o.shape)\n",
    "            grad_b_o = act_grad # np.zeros((self.output_size, ))\n",
    "            #print(\"grad_b_o\",grad_b_o.shape)\n",
    "\n",
    "            grads = self.Grads(\n",
    "                np.mean(grad_W_h, axis=0), \n",
    "                np.mean(grad_b_h, axis=0), \n",
    "                np.mean(grad_W_o, axis=0), \n",
    "                np.mean(grad_b_o, axis=0))\n",
    "            \n",
    "        return grads\n",
    "    \n",
    "    # Perform the update of the parameters (W_h, b_h, W_o, b_o) based of their gradient\n",
    "    def optimizer_step(self, optimizer='gd', momentum=False, momentum_alpha=0.9, \n",
    "                       batch_size=None, vectorized=False):\n",
    "        if optimizer == 'gd':\n",
    "            grads = self.compute_grads(self.X_tr, self.Y_tr, vectorized=vectorized)\n",
    "        elif optimizer == 'sgd':\n",
    "            batch_X_tr, batch_Y_tr = self.get_random_batch(self.X_tr, self.Y_tr, batch_size)\n",
    "            grads = self.compute_grads(batch_X_tr, batch_Y_tr, vectorized=vectorized)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        if not momentum:\n",
    "            # TODO: (testing?)\n",
    "            #update params\n",
    "            self.W_h -= self.step * grads.W_h\n",
    "            self.b_h -= self.step * grads.b_h\n",
    "            self.W_o -= self.step * grads.W_o\n",
    "            self.b_o -= self.step * grads.b_o\n",
    "            pass\n",
    "        else:\n",
    "            # remember: use the stored velocities self.velocities = {'W_h': 0., 'b_h': 0., 'W_o': 0., 'b_o': 0.}\n",
    "            # TODO: (testing)\n",
    "            #update velocities\n",
    "            \n",
    "            self.velocities[\"W_h\"] = momentum_alpha * self.velocities[\"W_h\"] - self.step * grads.W_h\n",
    "            self.velocities[\"W_o\"] = momentum_alpha * self.velocities[\"W_o\"] - self.step * grads.W_o\n",
    "            self.velocities[\"b_h\"] = momentum_alpha * self.velocities[\"b_h\"] - self.step * grads.b_h\n",
    "            self.velocities[\"b_o\"] = momentum_alpha * self.velocities[\"b_o\"] - self.step * grads.b_o\n",
    "            \n",
    "            #update params\n",
    "            self.W_h += self.velocities[\"W_h\"]\n",
    "            self.b_h += self.velocities[\"b_h\"]\n",
    "            self.W_o += self.velocities[\"W_o\"]\n",
    "            self.b_o += self.velocities[\"b_o\"]\n",
    "            pass\n",
    "    \n",
    "    # Loss wrapper\n",
    "    def loss(self, Y_true, Y_pred):\n",
    "        return self.categorical_cross_entropy(self.one_hot(self.output_size, Y_true), Y_pred)\n",
    "    \n",
    "    def loss_history_flush(self):\n",
    "        self.training_losses_history = []\n",
    "        self.validation_losses_history = []\n",
    "        \n",
    "    # Main function that trains the MLP with a design matrix X and a target vector Y\n",
    "    def train(self, optimizer='sgd', momentum=False, min_iterations=500, max_iterations=2000, initial_step=1e-1,\n",
    "                batch_size=64, early_stopping=True, early_stopping_lookbehind=100, early_stopping_delta=1e-4, \n",
    "                vectorized=False, flush_history=True, verbose=True):\n",
    "        if flush_history:\n",
    "            self.loss_history_flush()\n",
    "        cpt_patience, best_validation_loss = 0, np.inf\n",
    "        iteration_number = 0\n",
    "        self.step = initial_step\n",
    "        while len(self.training_losses_history) < max_iterations:\n",
    "            iteration_number += 1\n",
    "            self.optimizer_step(\n",
    "                optimizer=optimizer, momentum=momentum, batch_size=batch_size, vectorized=vectorized\n",
    "                )\n",
    "            \n",
    "            training_loss = self.loss(self.Y_tr, self.forward(self.X_tr))\n",
    "            self.training_losses_history.append(training_loss)\n",
    "            training_accuracy = self.accuracy_on_train()\n",
    "            self.training_acc_history.append(training_accuracy)\n",
    "            validation_loss = self.loss(self.Y_val, self.forward(self.X_val))\n",
    "            self.validation_losses_history.append(validation_loss)\n",
    "            validation_accuracy = self.accuracy_on_validation()\n",
    "            self.validation_acc_history.append(validation_accuracy)\n",
    "            if iteration_number > min_iterations and early_stopping:\n",
    "                if validation_loss + early_stopping_delta < best_validation_loss:\n",
    "                    best_validation_loss = validation_loss\n",
    "                    cpt_patience = 0\n",
    "                else:\n",
    "                    cpt_patience += 1\n",
    "            if verbose:\n",
    "                msg = \"iteration number: {0}\\t training loss: {1:.4f}\\t\" + \\\n",
    "                \"validation loss: {2:.4f}\\t validation accuracy: {3:.4f}\"\n",
    "                print(msg.format(iteration_number, \n",
    "                                 training_loss, \n",
    "                                 validation_loss,\n",
    "                                 validation_accuracy))\n",
    "            if cpt_patience >= early_stopping_lookbehind:\n",
    "                break\n",
    "    \n",
    "    # Return the predicted class once the MLP has been trained\n",
    "    def predict(self, X, normalize=True):\n",
    "        if normalize:\n",
    "            X = self.scaler.transform(X)\n",
    "        if len(X.shape) == 1:\n",
    "            return np.argmax(self.forward(X))\n",
    "        else:\n",
    "            return np.argmax(self.forward(X), axis=1)\n",
    "        \n",
    "    \"\"\"\n",
    "    Metrics and plots\n",
    "    \"\"\"\n",
    "    def accuracy_on_train(self):\n",
    "        return (self.predict(self.X_tr, normalize=False) == self.Y_tr).mean()\n",
    "\n",
    "    def accuracy_on_validation(self):\n",
    "        return (self.predict(self.X_val, normalize=False) == self.Y_val).mean()\n",
    "\n",
    "    def plot_loss_history(self, add_to_title=None):\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.plot(range(len(self.training_losses_history)), \n",
    "                 self.training_losses_history, label='Training loss evolution')\n",
    "        plt.plot(range(len(self.validation_losses_history)), \n",
    "                 self.validation_losses_history, label='Validation loss evolution')\n",
    "        plt.legend(fontsize=15)\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel(\"iteration number\", fontsize=15)\n",
    "        plt.ylabel(\"Cross entropy loss\", fontsize=15)\n",
    "        base_title = \"Cross entropy loss evolution during training\"\n",
    "        if not self.dropout:\n",
    "            base_title += \", no dropout penalization\"\n",
    "        else:\n",
    "            base_title += \", {:.1f} dropout penalization\"\n",
    "            base_title = base_title.format(self.dropout_rate)\n",
    "        title = base_title + \", \" + add_to_title if add_to_title else base_title\n",
    "        plt.title(title, fontsize=20)\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_validation_prediction(self, sample_id):\n",
    "        fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "        classes = np.unique(self.Y_tr)\n",
    "        dim = np.sqrt(self.X_val.shape[1]).astype(int)\n",
    "        ax0.imshow(self.scaler.inverse_transform([self.X_val[sample_id]]).reshape(dim, dim), cmap=plt.cm.gray_r,\n",
    "                   interpolation='nearest')\n",
    "        ax0.set_title(\"True image label: %d\" % self.Y_val[sample_id]);\n",
    "\n",
    "        ax1.bar(classes, self.one_hot(len(classes), self.Y_val[sample_id]), label='true')\n",
    "        ax1.bar(classes, self.forward(self.X_val[sample_id]), label='prediction', color=\"red\")\n",
    "        ax1.set_xticks(classes)\n",
    "        prediction = self.predict(self.X_val[sample_id], normalize=False)\n",
    "        ax1.set_title('Output probabilities (prediction: %d)' % prediction)\n",
    "        ax1.set_xlabel('Digit class')\n",
    "        ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1\t training loss: 1350.9978\tvalidation loss: 451.5737\t validation accuracy: 0.0956\n",
      "iteration number: 2\t training loss: 2185.9497\tvalidation loss: 730.6288\t validation accuracy: 0.0956\n",
      "iteration number: 3\t training loss: 3268.8478\tvalidation loss: 1092.5570\t validation accuracy: 0.1200\n",
      "iteration number: 4\t training loss: 4327.4979\tvalidation loss: 1446.4505\t validation accuracy: 0.1000\n",
      "iteration number: 5\t training loss: 5173.9630\tvalidation loss: 1729.5451\t validation accuracy: 0.1000\n",
      "iteration number: 6\t training loss: 5718.7387\tvalidation loss: 1911.9330\t validation accuracy: 0.1000\n",
      "iteration number: 7\t training loss: 5937.1542\tvalidation loss: 1985.3404\t validation accuracy: 0.1000\n",
      "iteration number: 8\t training loss: 5848.7596\tvalidation loss: 1956.2482\t validation accuracy: 0.1000\n",
      "iteration number: 9\t training loss: 5506.6192\tvalidation loss: 1842.3237\t validation accuracy: 0.1178\n",
      "iteration number: 10\t training loss: 4988.8011\tvalidation loss: 1669.5888\t validation accuracy: 0.0933\n",
      "iteration number: 11\t training loss: 4387.0388\tvalidation loss: 1468.6477\t validation accuracy: 0.0933\n",
      "iteration number: 12\t training loss: 3790.3188\tvalidation loss: 1269.2216\t validation accuracy: 0.0933\n",
      "iteration number: 13\t training loss: 3266.4021\tvalidation loss: 1093.9816\t validation accuracy: 0.0933\n",
      "iteration number: 14\t training loss: 2850.3110\tvalidation loss: 954.6882\t validation accuracy: 0.0933\n",
      "iteration number: 15\t training loss: 2546.9788\tvalidation loss: 853.0467\t validation accuracy: 0.0933\n",
      "iteration number: 16\t training loss: 2343.9638\tvalidation loss: 784.9353\t validation accuracy: 0.0933\n",
      "iteration number: 17\t training loss: 2223.8990\tvalidation loss: 744.5651\t validation accuracy: 0.0933\n",
      "iteration number: 18\t training loss: 2171.3035\tvalidation loss: 726.7637\t validation accuracy: 0.0933\n",
      "iteration number: 19\t training loss: 2174.5591\tvalidation loss: 727.6438\t validation accuracy: 0.0933\n",
      "iteration number: 20\t training loss: 2225.4765\tvalidation loss: 744.4624\t validation accuracy: 0.1000\n",
      "iteration number: 21\t training loss: 2318.0294\tvalidation loss: 775.2002\t validation accuracy: 0.0956\n",
      "iteration number: 22\t training loss: 2446.9109\tvalidation loss: 818.0798\t validation accuracy: 0.0956\n",
      "iteration number: 23\t training loss: 2606.1417\tvalidation loss: 871.1021\t validation accuracy: 0.0956\n",
      "iteration number: 24\t training loss: 2787.9150\tvalidation loss: 931.6602\t validation accuracy: 0.0956\n",
      "iteration number: 25\t training loss: 2981.9483\tvalidation loss: 996.3225\t validation accuracy: 0.0956\n",
      "iteration number: 26\t training loss: 3175.6321\tvalidation loss: 1060.8828\t validation accuracy: 0.0956\n",
      "iteration number: 27\t training loss: 3355.1022\tvalidation loss: 1120.7167\t validation accuracy: 0.0956\n",
      "iteration number: 28\t training loss: 3507.0266\tvalidation loss: 1171.3775\t validation accuracy: 0.0956\n",
      "iteration number: 29\t training loss: 3620.5988\tvalidation loss: 1209.2608\t validation accuracy: 0.0956\n",
      "iteration number: 30\t training loss: 3689.1513\tvalidation loss: 1232.1425\t validation accuracy: 0.0956\n",
      "iteration number: 31\t training loss: 3710.9650\tvalidation loss: 1239.4481\t validation accuracy: 0.0956\n",
      "iteration number: 32\t training loss: 3689.1417\tvalidation loss: 1232.2107\t validation accuracy: 0.0956\n",
      "iteration number: 33\t training loss: 3630.6750\tvalidation loss: 1212.7611\t validation accuracy: 0.0956\n",
      "iteration number: 34\t training loss: 3545.0239\tvalidation loss: 1184.2520\t validation accuracy: 0.0956\n",
      "iteration number: 35\t training loss: 3442.5522\tvalidation loss: 1150.1381\t validation accuracy: 0.0956\n",
      "iteration number: 36\t training loss: 3333.1583\tvalidation loss: 1113.7189\t validation accuracy: 0.0956\n",
      "iteration number: 37\t training loss: 3225.3109\tvalidation loss: 1077.8175\t validation accuracy: 0.0956\n",
      "iteration number: 38\t training loss: 3125.5605\tvalidation loss: 1044.6178\t validation accuracy: 0.0956\n",
      "iteration number: 39\t training loss: 3038.4687\tvalidation loss: 1015.6403\t validation accuracy: 0.0956\n",
      "iteration number: 40\t training loss: 2966.8184\tvalidation loss: 991.8127\t validation accuracy: 0.0956\n",
      "iteration number: 41\t training loss: 2911.9577\tvalidation loss: 973.5843\t validation accuracy: 0.1178\n",
      "iteration number: 42\t training loss: 2874.1569\tvalidation loss: 961.0447\t validation accuracy: 0.1311\n",
      "iteration number: 43\t training loss: 2852.9102\tvalidation loss: 954.0248\t validation accuracy: 0.1311\n",
      "iteration number: 44\t training loss: 2847.1563\tvalidation loss: 952.1698\t validation accuracy: 0.1089\n",
      "iteration number: 45\t training loss: 2855.4214\tvalidation loss: 954.9875\t validation accuracy: 0.1000\n",
      "iteration number: 46\t training loss: 2875.9019\tvalidation loss: 961.8752\t validation accuracy: 0.1022\n",
      "iteration number: 47\t training loss: 2906.5138\tvalidation loss: 972.1371\t validation accuracy: 0.1022\n",
      "iteration number: 48\t training loss: 2944.9308\tvalidation loss: 984.9961\t validation accuracy: 0.1067\n",
      "iteration number: 49\t training loss: 2988.6324\tvalidation loss: 999.6109\t validation accuracy: 0.1111\n",
      "iteration number: 50\t training loss: 3034.9774\tvalidation loss: 1015.1000\t validation accuracy: 0.1311\n",
      "iteration number: 51\t training loss: 3081.3084\tvalidation loss: 1030.5768\t validation accuracy: 0.1378\n",
      "iteration number: 52\t training loss: 3125.0839\tvalidation loss: 1045.1939\t validation accuracy: 0.1356\n",
      "iteration number: 53\t training loss: 3164.0261\tvalidation loss: 1058.1919\t validation accuracy: 0.1356\n",
      "iteration number: 54\t training loss: 3196.2655\tvalidation loss: 1068.9482\t validation accuracy: 0.1244\n",
      "iteration number: 55\t training loss: 3220.4596\tvalidation loss: 1077.0160\t validation accuracy: 0.1178\n",
      "iteration number: 56\t training loss: 3235.8682\tvalidation loss: 1082.1499\t validation accuracy: 0.1133\n",
      "iteration number: 57\t training loss: 3242.3735\tvalidation loss: 1084.3116\t validation accuracy: 0.1089\n",
      "iteration number: 58\t training loss: 3240.4417\tvalidation loss: 1083.6580\t validation accuracy: 0.1067\n",
      "iteration number: 59\t training loss: 3231.0348\tvalidation loss: 1080.5110\t validation accuracy: 0.1000\n",
      "iteration number: 60\t training loss: 3215.4877\tvalidation loss: 1075.3165\t validation accuracy: 0.1000\n",
      "iteration number: 61\t training loss: 3195.3665\tvalidation loss: 1068.5978\t validation accuracy: 0.1000\n",
      "iteration number: 62\t training loss: 3172.3290\tvalidation loss: 1060.9081\t validation accuracy: 0.1022\n",
      "iteration number: 63\t training loss: 3147.9993\tvalidation loss: 1052.7894\t validation accuracy: 0.1067\n",
      "iteration number: 64\t training loss: 3123.8681\tvalidation loss: 1044.7391\t validation accuracy: 0.1067\n",
      "iteration number: 65\t training loss: 3101.2207\tvalidation loss: 1037.1859\t validation accuracy: 0.1089\n",
      "iteration number: 66\t training loss: 3081.0943\tvalidation loss: 1030.4756\t validation accuracy: 0.1111\n",
      "iteration number: 67\t training loss: 3064.2582\tvalidation loss: 1024.8647\t validation accuracy: 0.1133\n",
      "iteration number: 68\t training loss: 3051.2146\tvalidation loss: 1020.5206\t validation accuracy: 0.1133\n",
      "iteration number: 69\t training loss: 3042.2114\tvalidation loss: 1017.5256\t validation accuracy: 0.1200\n",
      "iteration number: 70\t training loss: 3037.2652\tvalidation loss: 1015.8853\t validation accuracy: 0.1222\n",
      "iteration number: 71\t training loss: 3036.1893\tvalidation loss: 1015.5371\t validation accuracy: 0.1222\n",
      "iteration number: 72\t training loss: 3038.6246\tvalidation loss: 1016.3612\t validation accuracy: 0.1244\n",
      "iteration number: 73\t training loss: 3044.0737\tvalidation loss: 1018.1916\t validation accuracy: 0.1333\n",
      "iteration number: 74\t training loss: 3051.9353\tvalidation loss: 1020.8276\t validation accuracy: 0.1356\n",
      "iteration number: 75\t training loss: 3061.5406\tvalidation loss: 1024.0462\t validation accuracy: 0.1400\n",
      "iteration number: 76\t training loss: 3072.1893\tvalidation loss: 1027.6138\t validation accuracy: 0.1422\n",
      "iteration number: 77\t training loss: 3083.1866\tvalidation loss: 1031.2988\t validation accuracy: 0.1444\n",
      "iteration number: 78\t training loss: 3093.8773\tvalidation loss: 1034.8827\t validation accuracy: 0.1467\n",
      "iteration number: 79\t training loss: 3103.6775\tvalidation loss: 1038.1708\t validation accuracy: 0.1467\n",
      "iteration number: 80\t training loss: 3112.1010\tvalidation loss: 1041.0009\t validation accuracy: 0.1467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 81\t training loss: 3118.7785\tvalidation loss: 1043.2499\t validation accuracy: 0.1489\n",
      "iteration number: 82\t training loss: 3123.4701\tvalidation loss: 1044.8378\t validation accuracy: 0.1511\n",
      "iteration number: 83\t training loss: 3126.0676\tvalidation loss: 1045.7284\t validation accuracy: 0.1556\n",
      "iteration number: 84\t training loss: 3126.5898\tvalidation loss: 1045.9279\t validation accuracy: 0.1578\n",
      "iteration number: 85\t training loss: 3125.1692\tvalidation loss: 1045.4802\t validation accuracy: 0.1667\n",
      "iteration number: 86\t training loss: 3122.0331\tvalidation loss: 1044.4610\t validation accuracy: 0.1711\n",
      "iteration number: 87\t training loss: 3117.4805\tvalidation loss: 1042.9699\t validation accuracy: 0.1756\n",
      "iteration number: 88\t training loss: 3111.8570\tvalidation loss: 1041.1217\t validation accuracy: 0.1756\n",
      "iteration number: 89\t training loss: 3105.5292\tvalidation loss: 1039.0386\t validation accuracy: 0.1822\n",
      "iteration number: 90\t training loss: 3098.8613\tvalidation loss: 1036.8418\t validation accuracy: 0.1889\n",
      "iteration number: 91\t training loss: 3092.1948\tvalidation loss: 1034.6450\t validation accuracy: 0.2022\n",
      "iteration number: 92\t training loss: 3085.8310\tvalidation loss: 1032.5486\t validation accuracy: 0.2089\n",
      "iteration number: 93\t training loss: 3080.0197\tvalidation loss: 1030.6358\t validation accuracy: 0.2089\n",
      "iteration number: 94\t training loss: 3074.9501\tvalidation loss: 1028.9697\t validation accuracy: 0.2133\n",
      "iteration number: 95\t training loss: 3070.7478\tvalidation loss: 1027.5922\t validation accuracy: 0.2133\n",
      "iteration number: 96\t training loss: 3067.4744\tvalidation loss: 1026.5239\t validation accuracy: 0.2156\n",
      "iteration number: 97\t training loss: 3065.1308\tvalidation loss: 1025.7651\t validation accuracy: 0.2178\n",
      "iteration number: 98\t training loss: 3063.6628\tvalidation loss: 1025.2982\t validation accuracy: 0.2222\n",
      "iteration number: 99\t training loss: 3062.9697\tvalidation loss: 1025.0895\t validation accuracy: 0.2244\n",
      "iteration number: 100\t training loss: 3062.9130\tvalidation loss: 1025.0932\t validation accuracy: 0.2222\n",
      "iteration number: 101\t training loss: 3063.3275\tvalidation loss: 1025.2545\t validation accuracy: 0.2244\n",
      "iteration number: 102\t training loss: 3064.0315\tvalidation loss: 1025.5131\t validation accuracy: 0.2244\n",
      "iteration number: 103\t training loss: 3064.8379\tvalidation loss: 1025.8069\t validation accuracy: 0.2244\n",
      "iteration number: 104\t training loss: 3065.5639\tvalidation loss: 1026.0751\t validation accuracy: 0.2267\n",
      "iteration number: 105\t training loss: 3066.0399\tvalidation loss: 1026.2617\t validation accuracy: 0.2289\n",
      "iteration number: 106\t training loss: 3066.1171\tvalidation loss: 1026.3170\t validation accuracy: 0.2333\n",
      "iteration number: 107\t training loss: 3065.6729\tvalidation loss: 1026.2006\t validation accuracy: 0.2333\n",
      "iteration number: 108\t training loss: 3064.6144\tvalidation loss: 1025.8816\t validation accuracy: 0.2311\n",
      "iteration number: 109\t training loss: 3062.8804\tvalidation loss: 1025.3399\t validation accuracy: 0.2378\n",
      "iteration number: 110\t training loss: 3060.4405\tvalidation loss: 1024.5654\t validation accuracy: 0.2422\n",
      "iteration number: 111\t training loss: 3057.2933\tvalidation loss: 1023.5578\t validation accuracy: 0.2400\n",
      "iteration number: 112\t training loss: 3053.4625\tvalidation loss: 1022.3251\t validation accuracy: 0.2444\n",
      "iteration number: 113\t training loss: 3048.9917\tvalidation loss: 1020.8819\t validation accuracy: 0.2467\n",
      "iteration number: 114\t training loss: 3043.9393\tvalidation loss: 1019.2478\t validation accuracy: 0.2511\n",
      "iteration number: 115\t training loss: 3038.3717\tvalidation loss: 1017.4448\t validation accuracy: 0.2511\n",
      "iteration number: 116\t training loss: 3032.3578\tvalidation loss: 1015.4962\t validation accuracy: 0.2578\n",
      "iteration number: 117\t training loss: 3025.9632\tvalidation loss: 1013.4238\t validation accuracy: 0.2600\n",
      "iteration number: 118\t training loss: 3019.2449\tvalidation loss: 1011.2466\t validation accuracy: 0.2600\n",
      "iteration number: 119\t training loss: 3012.2471\tvalidation loss: 1008.9795\t validation accuracy: 0.2667\n",
      "iteration number: 120\t training loss: 3004.9985\tvalidation loss: 1006.6322\t validation accuracy: 0.2711\n",
      "iteration number: 121\t training loss: 2997.5096\tvalidation loss: 1004.2083\t validation accuracy: 0.2756\n",
      "iteration number: 122\t training loss: 2989.7723\tvalidation loss: 1001.7051\t validation accuracy: 0.2800\n",
      "iteration number: 123\t training loss: 2981.7594\tvalidation loss: 999.1138\t validation accuracy: 0.2822\n",
      "iteration number: 124\t training loss: 2973.4262\tvalidation loss: 996.4196\t validation accuracy: 0.2844\n",
      "iteration number: 125\t training loss: 2964.7119\tvalidation loss: 993.6022\t validation accuracy: 0.2822\n",
      "iteration number: 126\t training loss: 2955.5425\tvalidation loss: 990.6372\t validation accuracy: 0.2822\n",
      "iteration number: 127\t training loss: 2945.8338\tvalidation loss: 987.4964\t validation accuracy: 0.2889\n",
      "iteration number: 128\t training loss: 2935.4952\tvalidation loss: 984.1496\t validation accuracy: 0.2933\n",
      "iteration number: 129\t training loss: 2924.4330\tvalidation loss: 980.5656\t validation accuracy: 0.2956\n",
      "iteration number: 130\t training loss: 2912.5547\tvalidation loss: 976.7133\t validation accuracy: 0.3000\n",
      "iteration number: 131\t training loss: 2899.7723\tvalidation loss: 972.5630\t validation accuracy: 0.3111\n",
      "iteration number: 132\t training loss: 2886.0059\tvalidation loss: 968.0879\t validation accuracy: 0.3200\n",
      "iteration number: 133\t training loss: 2871.1872\tvalidation loss: 963.2646\t validation accuracy: 0.3244\n",
      "iteration number: 134\t training loss: 2855.2619\tvalidation loss: 958.0743\t validation accuracy: 0.3333\n",
      "iteration number: 135\t training loss: 2838.1919\tvalidation loss: 952.5037\t validation accuracy: 0.3511\n",
      "iteration number: 136\t training loss: 2819.9573\tvalidation loss: 946.5452\t validation accuracy: 0.3533\n",
      "iteration number: 137\t training loss: 2800.5573\tvalidation loss: 940.1976\t validation accuracy: 0.3533\n",
      "iteration number: 138\t training loss: 2780.0110\tvalidation loss: 933.4661\t validation accuracy: 0.3667\n",
      "iteration number: 139\t training loss: 2758.3569\tvalidation loss: 926.3625\t validation accuracy: 0.3822\n",
      "iteration number: 140\t training loss: 2735.6528\tvalidation loss: 918.9048\t validation accuracy: 0.3867\n",
      "iteration number: 141\t training loss: 2711.9740\tvalidation loss: 911.1171\t validation accuracy: 0.4000\n",
      "iteration number: 142\t training loss: 2687.4122\tvalidation loss: 903.0285\t validation accuracy: 0.4044\n",
      "iteration number: 143\t training loss: 2662.0725\tvalidation loss: 894.6730\t validation accuracy: 0.4156\n",
      "iteration number: 144\t training loss: 2636.0710\tvalidation loss: 886.0884\t validation accuracy: 0.4244\n",
      "iteration number: 145\t training loss: 2609.5319\tvalidation loss: 877.3150\t validation accuracy: 0.4311\n",
      "iteration number: 146\t training loss: 2582.5837\tvalidation loss: 868.3947\t validation accuracy: 0.4378\n",
      "iteration number: 147\t training loss: 2555.3559\tvalidation loss: 859.3699\t validation accuracy: 0.4511\n",
      "iteration number: 148\t training loss: 2527.9752\tvalidation loss: 850.2822\t validation accuracy: 0.4578\n",
      "iteration number: 149\t training loss: 2500.5622\tvalidation loss: 841.1713\t validation accuracy: 0.4689\n",
      "iteration number: 150\t training loss: 2473.2282\tvalidation loss: 832.0738\t validation accuracy: 0.4800\n",
      "iteration number: 151\t training loss: 2446.0722\tvalidation loss: 823.0224\t validation accuracy: 0.4889\n",
      "iteration number: 152\t training loss: 2419.1789\tvalidation loss: 814.0450\t validation accuracy: 0.5044\n",
      "iteration number: 153\t training loss: 2392.6167\tvalidation loss: 805.1646\t validation accuracy: 0.5178\n",
      "iteration number: 154\t training loss: 2366.4372\tvalidation loss: 796.3984\t validation accuracy: 0.5289\n",
      "iteration number: 155\t training loss: 2340.6750\tvalidation loss: 787.7583\t validation accuracy: 0.5378\n",
      "iteration number: 156\t training loss: 2315.3486\tvalidation loss: 779.2510\t validation accuracy: 0.5533\n",
      "iteration number: 157\t training loss: 2290.4616\tvalidation loss: 770.8786\t validation accuracy: 0.5600\n",
      "iteration number: 158\t training loss: 2266.0054\tvalidation loss: 762.6392\t validation accuracy: 0.5600\n",
      "iteration number: 159\t training loss: 2241.9614\tvalidation loss: 754.5278\t validation accuracy: 0.5711\n",
      "iteration number: 160\t training loss: 2218.3046\tvalidation loss: 746.5376\t validation accuracy: 0.5822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 161\t training loss: 2195.0061\tvalidation loss: 738.6606\t validation accuracy: 0.5933\n",
      "iteration number: 162\t training loss: 2172.0368\tvalidation loss: 730.8887\t validation accuracy: 0.6156\n",
      "iteration number: 163\t training loss: 2149.3697\tvalidation loss: 723.2146\t validation accuracy: 0.6378\n",
      "iteration number: 164\t training loss: 2126.9823\tvalidation loss: 715.6327\t validation accuracy: 0.6467\n",
      "iteration number: 165\t training loss: 2104.8583\tvalidation loss: 708.1389\t validation accuracy: 0.6644\n",
      "iteration number: 166\t training loss: 2082.9885\tvalidation loss: 700.7317\t validation accuracy: 0.6756\n",
      "iteration number: 167\t training loss: 2061.3709\tvalidation loss: 693.4115\t validation accuracy: 0.6844\n",
      "iteration number: 168\t training loss: 2040.0102\tvalidation loss: 686.1809\t validation accuracy: 0.6911\n",
      "iteration number: 169\t training loss: 2018.9167\tvalidation loss: 679.0438\t validation accuracy: 0.6911\n",
      "iteration number: 170\t training loss: 1998.1045\tvalidation loss: 672.0054\t validation accuracy: 0.6978\n",
      "iteration number: 171\t training loss: 1977.5898\tvalidation loss: 665.0711\t validation accuracy: 0.7000\n",
      "iteration number: 172\t training loss: 1957.3888\tvalidation loss: 658.2463\t validation accuracy: 0.7000\n",
      "iteration number: 173\t training loss: 1937.5158\tvalidation loss: 651.5354\t validation accuracy: 0.7067\n",
      "iteration number: 174\t training loss: 1917.9813\tvalidation loss: 644.9414\t validation accuracy: 0.7089\n",
      "iteration number: 175\t training loss: 1898.7911\tvalidation loss: 638.4660\t validation accuracy: 0.7111\n",
      "iteration number: 176\t training loss: 1879.9453\tvalidation loss: 632.1087\t validation accuracy: 0.7156\n",
      "iteration number: 177\t training loss: 1861.4379\tvalidation loss: 625.8670\t validation accuracy: 0.7222\n",
      "iteration number: 178\t training loss: 1843.2575\tvalidation loss: 619.7368\t validation accuracy: 0.7244\n",
      "iteration number: 179\t training loss: 1825.3874\tvalidation loss: 613.7124\t validation accuracy: 0.7244\n",
      "iteration number: 180\t training loss: 1807.8072\tvalidation loss: 607.7867\t validation accuracy: 0.7356\n",
      "iteration number: 181\t training loss: 1790.4938\tvalidation loss: 601.9521\t validation accuracy: 0.7400\n",
      "iteration number: 182\t training loss: 1773.4230\tvalidation loss: 596.2005\t validation accuracy: 0.7444\n",
      "iteration number: 183\t training loss: 1756.5709\tvalidation loss: 590.5240\t validation accuracy: 0.7467\n",
      "iteration number: 184\t training loss: 1739.9147\tvalidation loss: 584.9151\t validation accuracy: 0.7467\n",
      "iteration number: 185\t training loss: 1723.4345\tvalidation loss: 579.3674\t validation accuracy: 0.7444\n",
      "iteration number: 186\t training loss: 1707.1130\tvalidation loss: 573.8751\t validation accuracy: 0.7533\n",
      "iteration number: 187\t training loss: 1690.9368\tvalidation loss: 568.4339\t validation accuracy: 0.7578\n",
      "iteration number: 188\t training loss: 1674.8959\tvalidation loss: 563.0404\t validation accuracy: 0.7622\n",
      "iteration number: 189\t training loss: 1658.9831\tvalidation loss: 557.6923\t validation accuracy: 0.7667\n",
      "iteration number: 190\t training loss: 1643.1944\tvalidation loss: 552.3879\t validation accuracy: 0.7689\n",
      "iteration number: 191\t training loss: 1627.5275\tvalidation loss: 547.1264\t validation accuracy: 0.7733\n",
      "iteration number: 192\t training loss: 1611.9814\tvalidation loss: 541.9072\t validation accuracy: 0.7800\n",
      "iteration number: 193\t training loss: 1596.5558\tvalidation loss: 536.7300\t validation accuracy: 0.7822\n",
      "iteration number: 194\t training loss: 1581.2505\tvalidation loss: 531.5943\t validation accuracy: 0.7911\n",
      "iteration number: 195\t training loss: 1566.0649\tvalidation loss: 526.4999\t validation accuracy: 0.7933\n",
      "iteration number: 196\t training loss: 1550.9978\tvalidation loss: 521.4458\t validation accuracy: 0.7911\n",
      "iteration number: 197\t training loss: 1536.0474\tvalidation loss: 516.4315\t validation accuracy: 0.7933\n",
      "iteration number: 198\t training loss: 1521.2111\tvalidation loss: 511.4557\t validation accuracy: 0.7933\n",
      "iteration number: 199\t training loss: 1506.4862\tvalidation loss: 506.5177\t validation accuracy: 0.7956\n",
      "iteration number: 200\t training loss: 1491.8702\tvalidation loss: 501.6163\t validation accuracy: 0.7978\n",
      "iteration number: 201\t training loss: 1477.3606\tvalidation loss: 496.7508\t validation accuracy: 0.7956\n",
      "iteration number: 202\t training loss: 1462.9559\tvalidation loss: 491.9207\t validation accuracy: 0.7978\n",
      "iteration number: 203\t training loss: 1448.6556\tvalidation loss: 487.1259\t validation accuracy: 0.7978\n",
      "iteration number: 204\t training loss: 1434.4603\tvalidation loss: 482.3667\t validation accuracy: 0.7978\n",
      "iteration number: 205\t training loss: 1420.3720\tvalidation loss: 477.6438\t validation accuracy: 0.7978\n",
      "iteration number: 206\t training loss: 1406.3940\tvalidation loss: 472.9584\t validation accuracy: 0.8000\n",
      "iteration number: 207\t training loss: 1392.5308\tvalidation loss: 468.3120\t validation accuracy: 0.8022\n",
      "iteration number: 208\t training loss: 1378.7877\tvalidation loss: 463.7063\t validation accuracy: 0.8022\n",
      "iteration number: 209\t training loss: 1365.1708\tvalidation loss: 459.1433\t validation accuracy: 0.8111\n",
      "iteration number: 210\t training loss: 1351.6866\tvalidation loss: 454.6252\t validation accuracy: 0.8111\n",
      "iteration number: 211\t training loss: 1338.3415\tvalidation loss: 450.1540\t validation accuracy: 0.8111\n",
      "iteration number: 212\t training loss: 1325.1419\tvalidation loss: 445.7315\t validation accuracy: 0.8133\n",
      "iteration number: 213\t training loss: 1312.0935\tvalidation loss: 441.3597\t validation accuracy: 0.8133\n",
      "iteration number: 214\t training loss: 1299.2015\tvalidation loss: 437.0401\t validation accuracy: 0.8156\n",
      "iteration number: 215\t training loss: 1286.4703\tvalidation loss: 432.7739\t validation accuracy: 0.8200\n",
      "iteration number: 216\t training loss: 1273.9034\tvalidation loss: 428.5623\t validation accuracy: 0.8200\n",
      "iteration number: 217\t training loss: 1261.5035\tvalidation loss: 424.4060\t validation accuracy: 0.8178\n",
      "iteration number: 218\t training loss: 1249.2728\tvalidation loss: 420.3057\t validation accuracy: 0.8178\n",
      "iteration number: 219\t training loss: 1237.2124\tvalidation loss: 416.2617\t validation accuracy: 0.8200\n",
      "iteration number: 220\t training loss: 1225.3233\tvalidation loss: 412.2743\t validation accuracy: 0.8200\n",
      "iteration number: 221\t training loss: 1213.6059\tvalidation loss: 408.3436\t validation accuracy: 0.8200\n",
      "iteration number: 222\t training loss: 1202.0601\tvalidation loss: 404.4696\t validation accuracy: 0.8200\n",
      "iteration number: 223\t training loss: 1190.6858\tvalidation loss: 400.6524\t validation accuracy: 0.8222\n",
      "iteration number: 224\t training loss: 1179.4826\tvalidation loss: 396.8917\t validation accuracy: 0.8244\n",
      "iteration number: 225\t training loss: 1168.4500\tvalidation loss: 393.1876\t validation accuracy: 0.8311\n",
      "iteration number: 226\t training loss: 1157.5873\tvalidation loss: 389.5398\t validation accuracy: 0.8333\n",
      "iteration number: 227\t training loss: 1146.8937\tvalidation loss: 385.9482\t validation accuracy: 0.8333\n",
      "iteration number: 228\t training loss: 1136.3681\tvalidation loss: 382.4122\t validation accuracy: 0.8356\n",
      "iteration number: 229\t training loss: 1126.0091\tvalidation loss: 378.9317\t validation accuracy: 0.8378\n",
      "iteration number: 230\t training loss: 1115.8151\tvalidation loss: 375.5061\t validation accuracy: 0.8400\n",
      "iteration number: 231\t training loss: 1105.7842\tvalidation loss: 372.1347\t validation accuracy: 0.8422\n",
      "iteration number: 232\t training loss: 1095.9139\tvalidation loss: 368.8169\t validation accuracy: 0.8444\n",
      "iteration number: 233\t training loss: 1086.2018\tvalidation loss: 365.5519\t validation accuracy: 0.8467\n",
      "iteration number: 234\t training loss: 1076.6447\tvalidation loss: 362.3387\t validation accuracy: 0.8489\n",
      "iteration number: 235\t training loss: 1067.2395\tvalidation loss: 359.1764\t validation accuracy: 0.8511\n",
      "iteration number: 236\t training loss: 1057.9825\tvalidation loss: 356.0638\t validation accuracy: 0.8511\n",
      "iteration number: 237\t training loss: 1048.8702\tvalidation loss: 352.9999\t validation accuracy: 0.8511\n",
      "iteration number: 238\t training loss: 1039.8986\tvalidation loss: 349.9835\t validation accuracy: 0.8511\n",
      "iteration number: 239\t training loss: 1031.0641\tvalidation loss: 347.0136\t validation accuracy: 0.8533\n",
      "iteration number: 240\t training loss: 1022.3627\tvalidation loss: 344.0890\t validation accuracy: 0.8556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 241\t training loss: 1013.7907\tvalidation loss: 341.2087\t validation accuracy: 0.8556\n",
      "iteration number: 242\t training loss: 1005.3445\tvalidation loss: 338.3716\t validation accuracy: 0.8578\n",
      "iteration number: 243\t training loss: 997.0205\tvalidation loss: 335.5767\t validation accuracy: 0.8600\n",
      "iteration number: 244\t training loss: 988.8155\tvalidation loss: 332.8231\t validation accuracy: 0.8644\n",
      "iteration number: 245\t training loss: 980.7263\tvalidation loss: 330.1098\t validation accuracy: 0.8644\n",
      "iteration number: 246\t training loss: 972.7497\tvalidation loss: 327.4361\t validation accuracy: 0.8667\n",
      "iteration number: 247\t training loss: 964.8827\tvalidation loss: 324.8010\t validation accuracy: 0.8667\n",
      "iteration number: 248\t training loss: 957.1226\tvalidation loss: 322.2037\t validation accuracy: 0.8667\n",
      "iteration number: 249\t training loss: 949.4666\tvalidation loss: 319.6434\t validation accuracy: 0.8667\n",
      "iteration number: 250\t training loss: 941.9118\tvalidation loss: 317.1194\t validation accuracy: 0.8689\n",
      "iteration number: 251\t training loss: 934.4556\tvalidation loss: 314.6307\t validation accuracy: 0.8711\n",
      "iteration number: 252\t training loss: 927.0953\tvalidation loss: 312.1766\t validation accuracy: 0.8711\n",
      "iteration number: 253\t training loss: 919.8282\tvalidation loss: 309.7563\t validation accuracy: 0.8733\n",
      "iteration number: 254\t training loss: 912.6517\tvalidation loss: 307.3689\t validation accuracy: 0.8733\n",
      "iteration number: 255\t training loss: 905.5633\tvalidation loss: 305.0137\t validation accuracy: 0.8756\n",
      "iteration number: 256\t training loss: 898.5604\tvalidation loss: 302.6898\t validation accuracy: 0.8756\n",
      "iteration number: 257\t training loss: 891.6406\tvalidation loss: 300.3965\t validation accuracy: 0.8778\n",
      "iteration number: 258\t training loss: 884.8014\tvalidation loss: 298.1331\t validation accuracy: 0.8778\n",
      "iteration number: 259\t training loss: 878.0408\tvalidation loss: 295.8987\t validation accuracy: 0.8778\n",
      "iteration number: 260\t training loss: 871.3564\tvalidation loss: 293.6928\t validation accuracy: 0.8778\n",
      "iteration number: 261\t training loss: 864.7463\tvalidation loss: 291.5146\t validation accuracy: 0.8778\n",
      "iteration number: 262\t training loss: 858.2086\tvalidation loss: 289.3635\t validation accuracy: 0.8778\n",
      "iteration number: 263\t training loss: 851.7415\tvalidation loss: 287.2390\t validation accuracy: 0.8778\n",
      "iteration number: 264\t training loss: 845.3434\tvalidation loss: 285.1405\t validation accuracy: 0.8756\n",
      "iteration number: 265\t training loss: 839.0126\tvalidation loss: 283.0675\t validation accuracy: 0.8778\n",
      "iteration number: 266\t training loss: 832.7479\tvalidation loss: 281.0194\t validation accuracy: 0.8778\n",
      "iteration number: 267\t training loss: 826.5477\tvalidation loss: 278.9958\t validation accuracy: 0.8800\n",
      "iteration number: 268\t training loss: 820.4107\tvalidation loss: 276.9962\t validation accuracy: 0.8800\n",
      "iteration number: 269\t training loss: 814.3358\tvalidation loss: 275.0202\t validation accuracy: 0.8800\n",
      "iteration number: 270\t training loss: 808.3217\tvalidation loss: 273.0672\t validation accuracy: 0.8800\n",
      "iteration number: 271\t training loss: 802.3674\tvalidation loss: 271.1369\t validation accuracy: 0.8800\n",
      "iteration number: 272\t training loss: 796.4716\tvalidation loss: 269.2288\t validation accuracy: 0.8822\n",
      "iteration number: 273\t training loss: 790.6334\tvalidation loss: 267.3425\t validation accuracy: 0.8822\n",
      "iteration number: 274\t training loss: 784.8518\tvalidation loss: 265.4776\t validation accuracy: 0.8822\n",
      "iteration number: 275\t training loss: 779.1257\tvalidation loss: 263.6337\t validation accuracy: 0.8844\n",
      "iteration number: 276\t training loss: 773.4544\tvalidation loss: 261.8105\t validation accuracy: 0.8844\n",
      "iteration number: 277\t training loss: 767.8368\tvalidation loss: 260.0076\t validation accuracy: 0.8844\n",
      "iteration number: 278\t training loss: 762.2724\tvalidation loss: 258.2246\t validation accuracy: 0.8844\n",
      "iteration number: 279\t training loss: 756.7602\tvalidation loss: 256.4612\t validation accuracy: 0.8867\n",
      "iteration number: 280\t training loss: 751.2997\tvalidation loss: 254.7171\t validation accuracy: 0.8889\n",
      "iteration number: 281\t training loss: 745.8903\tvalidation loss: 252.9920\t validation accuracy: 0.8889\n",
      "iteration number: 282\t training loss: 740.5313\tvalidation loss: 251.2856\t validation accuracy: 0.8889\n",
      "iteration number: 283\t training loss: 735.2222\tvalidation loss: 249.5977\t validation accuracy: 0.8889\n",
      "iteration number: 284\t training loss: 729.9626\tvalidation loss: 247.9281\t validation accuracy: 0.8933\n",
      "iteration number: 285\t training loss: 724.7521\tvalidation loss: 246.2764\t validation accuracy: 0.8956\n",
      "iteration number: 286\t training loss: 719.5901\tvalidation loss: 244.6425\t validation accuracy: 0.8978\n",
      "iteration number: 287\t training loss: 714.4765\tvalidation loss: 243.0262\t validation accuracy: 0.8978\n",
      "iteration number: 288\t training loss: 709.4107\tvalidation loss: 241.4272\t validation accuracy: 0.8978\n",
      "iteration number: 289\t training loss: 704.3925\tvalidation loss: 239.8453\t validation accuracy: 0.8978\n",
      "iteration number: 290\t training loss: 699.4215\tvalidation loss: 238.2803\t validation accuracy: 0.9022\n",
      "iteration number: 291\t training loss: 694.4974\tvalidation loss: 236.7321\t validation accuracy: 0.9044\n",
      "iteration number: 292\t training loss: 689.6199\tvalidation loss: 235.2004\t validation accuracy: 0.9044\n",
      "iteration number: 293\t training loss: 684.7887\tvalidation loss: 233.6850\t validation accuracy: 0.9044\n",
      "iteration number: 294\t training loss: 680.0036\tvalidation loss: 232.1857\t validation accuracy: 0.9067\n",
      "iteration number: 295\t training loss: 675.2641\tvalidation loss: 230.7024\t validation accuracy: 0.9089\n",
      "iteration number: 296\t training loss: 670.5702\tvalidation loss: 229.2348\t validation accuracy: 0.9089\n",
      "iteration number: 297\t training loss: 665.9215\tvalidation loss: 227.7829\t validation accuracy: 0.9089\n",
      "iteration number: 298\t training loss: 661.3177\tvalidation loss: 226.3464\t validation accuracy: 0.9089\n",
      "iteration number: 299\t training loss: 656.7588\tvalidation loss: 224.9251\t validation accuracy: 0.9111\n",
      "iteration number: 300\t training loss: 652.2444\tvalidation loss: 223.5190\t validation accuracy: 0.9111\n",
      "iteration number: 301\t training loss: 647.7743\tvalidation loss: 222.1278\t validation accuracy: 0.9111\n",
      "iteration number: 302\t training loss: 643.3484\tvalidation loss: 220.7514\t validation accuracy: 0.9178\n",
      "iteration number: 303\t training loss: 638.9664\tvalidation loss: 219.3896\t validation accuracy: 0.9178\n",
      "iteration number: 304\t training loss: 634.6281\tvalidation loss: 218.0424\t validation accuracy: 0.9178\n",
      "iteration number: 305\t training loss: 630.3334\tvalidation loss: 216.7095\t validation accuracy: 0.9178\n",
      "iteration number: 306\t training loss: 626.0821\tvalidation loss: 215.3909\t validation accuracy: 0.9178\n",
      "iteration number: 307\t training loss: 621.8739\tvalidation loss: 214.0863\t validation accuracy: 0.9200\n",
      "iteration number: 308\t training loss: 617.7087\tvalidation loss: 212.7957\t validation accuracy: 0.9200\n",
      "iteration number: 309\t training loss: 613.5862\tvalidation loss: 211.5189\t validation accuracy: 0.9200\n",
      "iteration number: 310\t training loss: 609.5062\tvalidation loss: 210.2557\t validation accuracy: 0.9200\n",
      "iteration number: 311\t training loss: 605.4686\tvalidation loss: 209.0061\t validation accuracy: 0.9200\n",
      "iteration number: 312\t training loss: 601.4730\tvalidation loss: 207.7699\t validation accuracy: 0.9200\n",
      "iteration number: 313\t training loss: 597.5193\tvalidation loss: 206.5470\t validation accuracy: 0.9222\n",
      "iteration number: 314\t training loss: 593.6073\tvalidation loss: 205.3372\t validation accuracy: 0.9222\n",
      "iteration number: 315\t training loss: 589.7366\tvalidation loss: 204.1403\t validation accuracy: 0.9222\n",
      "iteration number: 316\t training loss: 585.9072\tvalidation loss: 202.9564\t validation accuracy: 0.9244\n",
      "iteration number: 317\t training loss: 582.1186\tvalidation loss: 201.7851\t validation accuracy: 0.9244\n",
      "iteration number: 318\t training loss: 578.3706\tvalidation loss: 200.6265\t validation accuracy: 0.9244\n",
      "iteration number: 319\t training loss: 574.6631\tvalidation loss: 199.4804\t validation accuracy: 0.9244\n",
      "iteration number: 320\t training loss: 570.9958\tvalidation loss: 198.3466\t validation accuracy: 0.9244\n",
      "iteration number: 321\t training loss: 567.3683\tvalidation loss: 197.2250\t validation accuracy: 0.9289\n",
      "iteration number: 322\t training loss: 563.7805\tvalidation loss: 196.1155\t validation accuracy: 0.9289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 323\t training loss: 560.2320\tvalidation loss: 195.0181\t validation accuracy: 0.9289\n",
      "iteration number: 324\t training loss: 556.7226\tvalidation loss: 193.9325\t validation accuracy: 0.9289\n",
      "iteration number: 325\t training loss: 553.2520\tvalidation loss: 192.8586\t validation accuracy: 0.9289\n",
      "iteration number: 326\t training loss: 549.8199\tvalidation loss: 191.7964\t validation accuracy: 0.9289\n",
      "iteration number: 327\t training loss: 546.4260\tvalidation loss: 190.7457\t validation accuracy: 0.9289\n",
      "iteration number: 328\t training loss: 543.0701\tvalidation loss: 189.7064\t validation accuracy: 0.9289\n",
      "iteration number: 329\t training loss: 539.7518\tvalidation loss: 188.6783\t validation accuracy: 0.9311\n",
      "iteration number: 330\t training loss: 536.4708\tvalidation loss: 187.6615\t validation accuracy: 0.9311\n",
      "iteration number: 331\t training loss: 533.2268\tvalidation loss: 186.6557\t validation accuracy: 0.9311\n",
      "iteration number: 332\t training loss: 530.0195\tvalidation loss: 185.6608\t validation accuracy: 0.9333\n",
      "iteration number: 333\t training loss: 526.8485\tvalidation loss: 184.6768\t validation accuracy: 0.9333\n",
      "iteration number: 334\t training loss: 523.7136\tvalidation loss: 183.7035\t validation accuracy: 0.9333\n",
      "iteration number: 335\t training loss: 520.6144\tvalidation loss: 182.7408\t validation accuracy: 0.9333\n",
      "iteration number: 336\t training loss: 517.5505\tvalidation loss: 181.7887\t validation accuracy: 0.9333\n",
      "iteration number: 337\t training loss: 514.5217\tvalidation loss: 180.8469\t validation accuracy: 0.9333\n",
      "iteration number: 338\t training loss: 511.5276\tvalidation loss: 179.9154\t validation accuracy: 0.9333\n",
      "iteration number: 339\t training loss: 508.5678\tvalidation loss: 178.9940\t validation accuracy: 0.9356\n",
      "iteration number: 340\t training loss: 505.6420\tvalidation loss: 178.0828\t validation accuracy: 0.9356\n",
      "iteration number: 341\t training loss: 502.7498\tvalidation loss: 177.1815\t validation accuracy: 0.9378\n",
      "iteration number: 342\t training loss: 499.8910\tvalidation loss: 176.2901\t validation accuracy: 0.9378\n",
      "iteration number: 343\t training loss: 497.0650\tvalidation loss: 175.4084\t validation accuracy: 0.9378\n",
      "iteration number: 344\t training loss: 494.2717\tvalidation loss: 174.5364\t validation accuracy: 0.9400\n",
      "iteration number: 345\t training loss: 491.5105\tvalidation loss: 173.6740\t validation accuracy: 0.9400\n",
      "iteration number: 346\t training loss: 488.7812\tvalidation loss: 172.8210\t validation accuracy: 0.9422\n",
      "iteration number: 347\t training loss: 486.0834\tvalidation loss: 171.9774\t validation accuracy: 0.9422\n",
      "iteration number: 348\t training loss: 483.4167\tvalidation loss: 171.1430\t validation accuracy: 0.9422\n",
      "iteration number: 349\t training loss: 480.7807\tvalidation loss: 170.3178\t validation accuracy: 0.9422\n",
      "iteration number: 350\t training loss: 478.1752\tvalidation loss: 169.5016\t validation accuracy: 0.9422\n",
      "iteration number: 351\t training loss: 475.5996\tvalidation loss: 168.6944\t validation accuracy: 0.9422\n",
      "iteration number: 352\t training loss: 473.0537\tvalidation loss: 167.8961\t validation accuracy: 0.9422\n",
      "iteration number: 353\t training loss: 470.5370\tvalidation loss: 167.1065\t validation accuracy: 0.9422\n",
      "iteration number: 354\t training loss: 468.0493\tvalidation loss: 166.3255\t validation accuracy: 0.9422\n",
      "iteration number: 355\t training loss: 465.5901\tvalidation loss: 165.5532\t validation accuracy: 0.9422\n",
      "iteration number: 356\t training loss: 463.1591\tvalidation loss: 164.7893\t validation accuracy: 0.9422\n",
      "iteration number: 357\t training loss: 460.7558\tvalidation loss: 164.0337\t validation accuracy: 0.9444\n",
      "iteration number: 358\t training loss: 458.3801\tvalidation loss: 163.2865\t validation accuracy: 0.9444\n",
      "iteration number: 359\t training loss: 456.0314\tvalidation loss: 162.5474\t validation accuracy: 0.9444\n",
      "iteration number: 360\t training loss: 453.7094\tvalidation loss: 161.8164\t validation accuracy: 0.9444\n",
      "iteration number: 361\t training loss: 451.4137\tvalidation loss: 161.0934\t validation accuracy: 0.9444\n",
      "iteration number: 362\t training loss: 449.1441\tvalidation loss: 160.3784\t validation accuracy: 0.9444\n",
      "iteration number: 363\t training loss: 446.9000\tvalidation loss: 159.6711\t validation accuracy: 0.9467\n",
      "iteration number: 364\t training loss: 444.6813\tvalidation loss: 158.9716\t validation accuracy: 0.9467\n",
      "iteration number: 365\t training loss: 442.4875\tvalidation loss: 158.2796\t validation accuracy: 0.9489\n",
      "iteration number: 366\t training loss: 440.3182\tvalidation loss: 157.5953\t validation accuracy: 0.9489\n",
      "iteration number: 367\t training loss: 438.1732\tvalidation loss: 156.9184\t validation accuracy: 0.9489\n",
      "iteration number: 368\t training loss: 436.0520\tvalidation loss: 156.2488\t validation accuracy: 0.9489\n",
      "iteration number: 369\t training loss: 433.9544\tvalidation loss: 155.5865\t validation accuracy: 0.9489\n",
      "iteration number: 370\t training loss: 431.8800\tvalidation loss: 154.9314\t validation accuracy: 0.9489\n",
      "iteration number: 371\t training loss: 429.8285\tvalidation loss: 154.2834\t validation accuracy: 0.9489\n",
      "iteration number: 372\t training loss: 427.7995\tvalidation loss: 153.6424\t validation accuracy: 0.9489\n",
      "iteration number: 373\t training loss: 425.7926\tvalidation loss: 153.0083\t validation accuracy: 0.9489\n",
      "iteration number: 374\t training loss: 423.8077\tvalidation loss: 152.3811\t validation accuracy: 0.9489\n",
      "iteration number: 375\t training loss: 421.8443\tvalidation loss: 151.7606\t validation accuracy: 0.9511\n",
      "iteration number: 376\t training loss: 419.9021\tvalidation loss: 151.1468\t validation accuracy: 0.9511\n",
      "iteration number: 377\t training loss: 417.9809\tvalidation loss: 150.5396\t validation accuracy: 0.9511\n",
      "iteration number: 378\t training loss: 416.0802\tvalidation loss: 149.9389\t validation accuracy: 0.9511\n",
      "iteration number: 379\t training loss: 414.1999\tvalidation loss: 149.3446\t validation accuracy: 0.9511\n",
      "iteration number: 380\t training loss: 412.3395\tvalidation loss: 148.7567\t validation accuracy: 0.9511\n",
      "iteration number: 381\t training loss: 410.4988\tvalidation loss: 148.1750\t validation accuracy: 0.9489\n",
      "iteration number: 382\t training loss: 408.6775\tvalidation loss: 147.5996\t validation accuracy: 0.9489\n",
      "iteration number: 383\t training loss: 406.8754\tvalidation loss: 147.0302\t validation accuracy: 0.9489\n",
      "iteration number: 384\t training loss: 405.0920\tvalidation loss: 146.4668\t validation accuracy: 0.9489\n",
      "iteration number: 385\t training loss: 403.3271\tvalidation loss: 145.9095\t validation accuracy: 0.9489\n",
      "iteration number: 386\t training loss: 401.5806\tvalidation loss: 145.3579\t validation accuracy: 0.9489\n",
      "iteration number: 387\t training loss: 399.8519\tvalidation loss: 144.8122\t validation accuracy: 0.9489\n",
      "iteration number: 388\t training loss: 398.1410\tvalidation loss: 144.2723\t validation accuracy: 0.9489\n",
      "iteration number: 389\t training loss: 396.4475\tvalidation loss: 143.7380\t validation accuracy: 0.9489\n",
      "iteration number: 390\t training loss: 394.7712\tvalidation loss: 143.2092\t validation accuracy: 0.9489\n",
      "iteration number: 391\t training loss: 393.1118\tvalidation loss: 142.6860\t validation accuracy: 0.9511\n",
      "iteration number: 392\t training loss: 391.4690\tvalidation loss: 142.1682\t validation accuracy: 0.9511\n",
      "iteration number: 393\t training loss: 389.8427\tvalidation loss: 141.6558\t validation accuracy: 0.9511\n",
      "iteration number: 394\t training loss: 388.2325\tvalidation loss: 141.1487\t validation accuracy: 0.9511\n",
      "iteration number: 395\t training loss: 386.6382\tvalidation loss: 140.6468\t validation accuracy: 0.9511\n",
      "iteration number: 396\t training loss: 385.0595\tvalidation loss: 140.1501\t validation accuracy: 0.9511\n",
      "iteration number: 397\t training loss: 383.4963\tvalidation loss: 139.6585\t validation accuracy: 0.9511\n",
      "iteration number: 398\t training loss: 381.9483\tvalidation loss: 139.1719\t validation accuracy: 0.9511\n",
      "iteration number: 399\t training loss: 380.4153\tvalidation loss: 138.6903\t validation accuracy: 0.9511\n",
      "iteration number: 400\t training loss: 378.8970\tvalidation loss: 138.2136\t validation accuracy: 0.9511\n",
      "iteration number: 401\t training loss: 377.3932\tvalidation loss: 137.7417\t validation accuracy: 0.9511\n",
      "iteration number: 402\t training loss: 375.9038\tvalidation loss: 137.2746\t validation accuracy: 0.9511\n",
      "iteration number: 403\t training loss: 374.4284\tvalidation loss: 136.8123\t validation accuracy: 0.9511\n",
      "iteration number: 404\t training loss: 372.9669\tvalidation loss: 136.3545\t validation accuracy: 0.9511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 405\t training loss: 371.5191\tvalidation loss: 135.9014\t validation accuracy: 0.9511\n",
      "iteration number: 406\t training loss: 370.0848\tvalidation loss: 135.4528\t validation accuracy: 0.9511\n",
      "iteration number: 407\t training loss: 368.6637\tvalidation loss: 135.0087\t validation accuracy: 0.9511\n",
      "iteration number: 408\t training loss: 367.2557\tvalidation loss: 134.5690\t validation accuracy: 0.9511\n",
      "iteration number: 409\t training loss: 365.8606\tvalidation loss: 134.1337\t validation accuracy: 0.9511\n",
      "iteration number: 410\t training loss: 364.4782\tvalidation loss: 133.7026\t validation accuracy: 0.9511\n",
      "iteration number: 411\t training loss: 363.1083\tvalidation loss: 133.2759\t validation accuracy: 0.9511\n",
      "iteration number: 412\t training loss: 361.7508\tvalidation loss: 132.8533\t validation accuracy: 0.9511\n",
      "iteration number: 413\t training loss: 360.4054\tvalidation loss: 132.4348\t validation accuracy: 0.9511\n",
      "iteration number: 414\t training loss: 359.0719\tvalidation loss: 132.0205\t validation accuracy: 0.9511\n",
      "iteration number: 415\t training loss: 357.7503\tvalidation loss: 131.6102\t validation accuracy: 0.9533\n",
      "iteration number: 416\t training loss: 356.4403\tvalidation loss: 131.2038\t validation accuracy: 0.9533\n",
      "iteration number: 417\t training loss: 355.1418\tvalidation loss: 130.8014\t validation accuracy: 0.9533\n",
      "iteration number: 418\t training loss: 353.8545\tvalidation loss: 130.4029\t validation accuracy: 0.9533\n",
      "iteration number: 419\t training loss: 352.5785\tvalidation loss: 130.0082\t validation accuracy: 0.9533\n",
      "iteration number: 420\t training loss: 351.3134\tvalidation loss: 129.6173\t validation accuracy: 0.9533\n",
      "iteration number: 421\t training loss: 350.0591\tvalidation loss: 129.2302\t validation accuracy: 0.9556\n",
      "iteration number: 422\t training loss: 348.8155\tvalidation loss: 128.8467\t validation accuracy: 0.9556\n",
      "iteration number: 423\t training loss: 347.5824\tvalidation loss: 128.4669\t validation accuracy: 0.9556\n",
      "iteration number: 424\t training loss: 346.3598\tvalidation loss: 128.0906\t validation accuracy: 0.9556\n",
      "iteration number: 425\t training loss: 345.1473\tvalidation loss: 127.7180\t validation accuracy: 0.9556\n",
      "iteration number: 426\t training loss: 343.9450\tvalidation loss: 127.3488\t validation accuracy: 0.9556\n",
      "iteration number: 427\t training loss: 342.7526\tvalidation loss: 126.9831\t validation accuracy: 0.9556\n",
      "iteration number: 428\t training loss: 341.5700\tvalidation loss: 126.6208\t validation accuracy: 0.9556\n",
      "iteration number: 429\t training loss: 340.3971\tvalidation loss: 126.2619\t validation accuracy: 0.9556\n",
      "iteration number: 430\t training loss: 339.2338\tvalidation loss: 125.9063\t validation accuracy: 0.9556\n",
      "iteration number: 431\t training loss: 338.0799\tvalidation loss: 125.5540\t validation accuracy: 0.9556\n",
      "iteration number: 432\t training loss: 336.9353\tvalidation loss: 125.2050\t validation accuracy: 0.9556\n",
      "iteration number: 433\t training loss: 335.7999\tvalidation loss: 124.8592\t validation accuracy: 0.9556\n",
      "iteration number: 434\t training loss: 334.6736\tvalidation loss: 124.5165\t validation accuracy: 0.9556\n",
      "iteration number: 435\t training loss: 333.5562\tvalidation loss: 124.1770\t validation accuracy: 0.9578\n",
      "iteration number: 436\t training loss: 332.4475\tvalidation loss: 123.8406\t validation accuracy: 0.9578\n",
      "iteration number: 437\t training loss: 331.3476\tvalidation loss: 123.5072\t validation accuracy: 0.9578\n",
      "iteration number: 438\t training loss: 330.2563\tvalidation loss: 123.1769\t validation accuracy: 0.9578\n",
      "iteration number: 439\t training loss: 329.1735\tvalidation loss: 122.8496\t validation accuracy: 0.9578\n",
      "iteration number: 440\t training loss: 328.0990\tvalidation loss: 122.5252\t validation accuracy: 0.9578\n",
      "iteration number: 441\t training loss: 327.0328\tvalidation loss: 122.2037\t validation accuracy: 0.9578\n",
      "iteration number: 442\t training loss: 325.9748\tvalidation loss: 121.8850\t validation accuracy: 0.9578\n",
      "iteration number: 443\t training loss: 324.9248\tvalidation loss: 121.5693\t validation accuracy: 0.9578\n",
      "iteration number: 444\t training loss: 323.8827\tvalidation loss: 121.2563\t validation accuracy: 0.9578\n",
      "iteration number: 445\t training loss: 322.8485\tvalidation loss: 120.9461\t validation accuracy: 0.9578\n",
      "iteration number: 446\t training loss: 321.8221\tvalidation loss: 120.6386\t validation accuracy: 0.9578\n",
      "iteration number: 447\t training loss: 320.8033\tvalidation loss: 120.3339\t validation accuracy: 0.9578\n",
      "iteration number: 448\t training loss: 319.7921\tvalidation loss: 120.0318\t validation accuracy: 0.9600\n",
      "iteration number: 449\t training loss: 318.7883\tvalidation loss: 119.7324\t validation accuracy: 0.9600\n",
      "iteration number: 450\t training loss: 317.7919\tvalidation loss: 119.4356\t validation accuracy: 0.9600\n",
      "iteration number: 451\t training loss: 316.8028\tvalidation loss: 119.1413\t validation accuracy: 0.9600\n",
      "iteration number: 452\t training loss: 315.8209\tvalidation loss: 118.8497\t validation accuracy: 0.9600\n",
      "iteration number: 453\t training loss: 314.8461\tvalidation loss: 118.5605\t validation accuracy: 0.9578\n",
      "iteration number: 454\t training loss: 313.8783\tvalidation loss: 118.2738\t validation accuracy: 0.9578\n",
      "iteration number: 455\t training loss: 312.9174\tvalidation loss: 117.9896\t validation accuracy: 0.9578\n",
      "iteration number: 456\t training loss: 311.9635\tvalidation loss: 117.7079\t validation accuracy: 0.9578\n",
      "iteration number: 457\t training loss: 311.0162\tvalidation loss: 117.4285\t validation accuracy: 0.9578\n",
      "iteration number: 458\t training loss: 310.0757\tvalidation loss: 117.1515\t validation accuracy: 0.9578\n",
      "iteration number: 459\t training loss: 309.1418\tvalidation loss: 116.8769\t validation accuracy: 0.9600\n",
      "iteration number: 460\t training loss: 308.2145\tvalidation loss: 116.6046\t validation accuracy: 0.9600\n",
      "iteration number: 461\t training loss: 307.2936\tvalidation loss: 116.3345\t validation accuracy: 0.9600\n",
      "iteration number: 462\t training loss: 306.3791\tvalidation loss: 116.0668\t validation accuracy: 0.9600\n",
      "iteration number: 463\t training loss: 305.4709\tvalidation loss: 115.8013\t validation accuracy: 0.9600\n",
      "iteration number: 464\t training loss: 304.5689\tvalidation loss: 115.5380\t validation accuracy: 0.9600\n",
      "iteration number: 465\t training loss: 303.6732\tvalidation loss: 115.2769\t validation accuracy: 0.9600\n",
      "iteration number: 466\t training loss: 302.7835\tvalidation loss: 115.0180\t validation accuracy: 0.9600\n",
      "iteration number: 467\t training loss: 301.8998\tvalidation loss: 114.7613\t validation accuracy: 0.9600\n",
      "iteration number: 468\t training loss: 301.0222\tvalidation loss: 114.5066\t validation accuracy: 0.9600\n",
      "iteration number: 469\t training loss: 300.1504\tvalidation loss: 114.2541\t validation accuracy: 0.9600\n",
      "iteration number: 470\t training loss: 299.2845\tvalidation loss: 114.0036\t validation accuracy: 0.9600\n",
      "iteration number: 471\t training loss: 298.4243\tvalidation loss: 113.7552\t validation accuracy: 0.9600\n",
      "iteration number: 472\t training loss: 297.5699\tvalidation loss: 113.5088\t validation accuracy: 0.9600\n",
      "iteration number: 473\t training loss: 296.7210\tvalidation loss: 113.2644\t validation accuracy: 0.9600\n",
      "iteration number: 474\t training loss: 295.8778\tvalidation loss: 113.0220\t validation accuracy: 0.9622\n",
      "iteration number: 475\t training loss: 295.0401\tvalidation loss: 112.7816\t validation accuracy: 0.9622\n",
      "iteration number: 476\t training loss: 294.2079\tvalidation loss: 112.5431\t validation accuracy: 0.9644\n",
      "iteration number: 477\t training loss: 293.3810\tvalidation loss: 112.3065\t validation accuracy: 0.9644\n",
      "iteration number: 478\t training loss: 292.5595\tvalidation loss: 112.0718\t validation accuracy: 0.9644\n",
      "iteration number: 479\t training loss: 291.7433\tvalidation loss: 111.8390\t validation accuracy: 0.9644\n",
      "iteration number: 480\t training loss: 290.9324\tvalidation loss: 111.6081\t validation accuracy: 0.9644\n",
      "iteration number: 481\t training loss: 290.1266\tvalidation loss: 111.3790\t validation accuracy: 0.9644\n",
      "iteration number: 482\t training loss: 289.3259\tvalidation loss: 111.1517\t validation accuracy: 0.9644\n",
      "iteration number: 483\t training loss: 288.5304\tvalidation loss: 110.9262\t validation accuracy: 0.9644\n",
      "iteration number: 484\t training loss: 287.7398\tvalidation loss: 110.7025\t validation accuracy: 0.9644\n",
      "iteration number: 485\t training loss: 286.9542\tvalidation loss: 110.4806\t validation accuracy: 0.9644\n",
      "iteration number: 486\t training loss: 286.1735\tvalidation loss: 110.2604\t validation accuracy: 0.9644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 487\t training loss: 285.3977\tvalidation loss: 110.0419\t validation accuracy: 0.9644\n",
      "iteration number: 488\t training loss: 284.6267\tvalidation loss: 109.8252\t validation accuracy: 0.9644\n",
      "iteration number: 489\t training loss: 283.8605\tvalidation loss: 109.6101\t validation accuracy: 0.9644\n",
      "iteration number: 490\t training loss: 283.0990\tvalidation loss: 109.3967\t validation accuracy: 0.9644\n",
      "iteration number: 491\t training loss: 282.3421\tvalidation loss: 109.1849\t validation accuracy: 0.9644\n",
      "iteration number: 492\t training loss: 281.5899\tvalidation loss: 108.9748\t validation accuracy: 0.9644\n",
      "iteration number: 493\t training loss: 280.8423\tvalidation loss: 108.7663\t validation accuracy: 0.9644\n",
      "iteration number: 494\t training loss: 280.0992\tvalidation loss: 108.5594\t validation accuracy: 0.9644\n",
      "iteration number: 495\t training loss: 279.3606\tvalidation loss: 108.3541\t validation accuracy: 0.9644\n",
      "iteration number: 496\t training loss: 278.6264\tvalidation loss: 108.1503\t validation accuracy: 0.9644\n",
      "iteration number: 497\t training loss: 277.8967\tvalidation loss: 107.9482\t validation accuracy: 0.9644\n",
      "iteration number: 498\t training loss: 277.1713\tvalidation loss: 107.7475\t validation accuracy: 0.9644\n",
      "iteration number: 499\t training loss: 276.4502\tvalidation loss: 107.5484\t validation accuracy: 0.9644\n",
      "iteration number: 500\t training loss: 275.7334\tvalidation loss: 107.3507\t validation accuracy: 0.9644\n",
      "iteration number: 501\t training loss: 275.0209\tvalidation loss: 107.1546\t validation accuracy: 0.9644\n",
      "iteration number: 502\t training loss: 274.3125\tvalidation loss: 106.9599\t validation accuracy: 0.9644\n",
      "iteration number: 503\t training loss: 273.6083\tvalidation loss: 106.7667\t validation accuracy: 0.9644\n",
      "iteration number: 504\t training loss: 272.9082\tvalidation loss: 106.5750\t validation accuracy: 0.9644\n",
      "iteration number: 505\t training loss: 272.2121\tvalidation loss: 106.3847\t validation accuracy: 0.9644\n",
      "iteration number: 506\t training loss: 271.5202\tvalidation loss: 106.1958\t validation accuracy: 0.9644\n",
      "iteration number: 507\t training loss: 270.8322\tvalidation loss: 106.0083\t validation accuracy: 0.9644\n",
      "iteration number: 508\t training loss: 270.1482\tvalidation loss: 105.8221\t validation accuracy: 0.9644\n",
      "iteration number: 509\t training loss: 269.4681\tvalidation loss: 105.6374\t validation accuracy: 0.9644\n",
      "iteration number: 510\t training loss: 268.7919\tvalidation loss: 105.4540\t validation accuracy: 0.9644\n",
      "iteration number: 511\t training loss: 268.1195\tvalidation loss: 105.2720\t validation accuracy: 0.9644\n",
      "iteration number: 512\t training loss: 267.4510\tvalidation loss: 105.0913\t validation accuracy: 0.9644\n",
      "iteration number: 513\t training loss: 266.7862\tvalidation loss: 104.9119\t validation accuracy: 0.9644\n",
      "iteration number: 514\t training loss: 266.1252\tvalidation loss: 104.7339\t validation accuracy: 0.9644\n",
      "iteration number: 515\t training loss: 265.4679\tvalidation loss: 104.5571\t validation accuracy: 0.9644\n",
      "iteration number: 516\t training loss: 264.8143\tvalidation loss: 104.3816\t validation accuracy: 0.9644\n",
      "iteration number: 517\t training loss: 264.1644\tvalidation loss: 104.2074\t validation accuracy: 0.9644\n",
      "iteration number: 518\t training loss: 263.5180\tvalidation loss: 104.0345\t validation accuracy: 0.9644\n",
      "iteration number: 519\t training loss: 262.8753\tvalidation loss: 103.8628\t validation accuracy: 0.9644\n",
      "iteration number: 520\t training loss: 262.2360\tvalidation loss: 103.6923\t validation accuracy: 0.9644\n",
      "iteration number: 521\t training loss: 261.6004\tvalidation loss: 103.5231\t validation accuracy: 0.9667\n",
      "iteration number: 522\t training loss: 260.9681\tvalidation loss: 103.3550\t validation accuracy: 0.9667\n",
      "iteration number: 523\t training loss: 260.3394\tvalidation loss: 103.1882\t validation accuracy: 0.9667\n",
      "iteration number: 524\t training loss: 259.7141\tvalidation loss: 103.0226\t validation accuracy: 0.9667\n",
      "iteration number: 525\t training loss: 259.0922\tvalidation loss: 102.8581\t validation accuracy: 0.9667\n",
      "iteration number: 526\t training loss: 258.4736\tvalidation loss: 102.6948\t validation accuracy: 0.9667\n",
      "iteration number: 527\t training loss: 257.8584\tvalidation loss: 102.5326\t validation accuracy: 0.9667\n",
      "iteration number: 528\t training loss: 257.2465\tvalidation loss: 102.3716\t validation accuracy: 0.9667\n",
      "iteration number: 529\t training loss: 256.6379\tvalidation loss: 102.2118\t validation accuracy: 0.9667\n",
      "iteration number: 530\t training loss: 256.0325\tvalidation loss: 102.0530\t validation accuracy: 0.9667\n",
      "iteration number: 531\t training loss: 255.4303\tvalidation loss: 101.8954\t validation accuracy: 0.9667\n",
      "iteration number: 532\t training loss: 254.8314\tvalidation loss: 101.7388\t validation accuracy: 0.9667\n",
      "iteration number: 533\t training loss: 254.2356\tvalidation loss: 101.5834\t validation accuracy: 0.9667\n",
      "iteration number: 534\t training loss: 253.6430\tvalidation loss: 101.4290\t validation accuracy: 0.9667\n",
      "iteration number: 535\t training loss: 253.0534\tvalidation loss: 101.2757\t validation accuracy: 0.9667\n",
      "iteration number: 536\t training loss: 252.4670\tvalidation loss: 101.1235\t validation accuracy: 0.9667\n",
      "iteration number: 537\t training loss: 251.8836\tvalidation loss: 100.9723\t validation accuracy: 0.9667\n",
      "iteration number: 538\t training loss: 251.3033\tvalidation loss: 100.8222\t validation accuracy: 0.9667\n",
      "iteration number: 539\t training loss: 250.7260\tvalidation loss: 100.6731\t validation accuracy: 0.9667\n",
      "iteration number: 540\t training loss: 250.1517\tvalidation loss: 100.5250\t validation accuracy: 0.9667\n",
      "iteration number: 541\t training loss: 249.5803\tvalidation loss: 100.3779\t validation accuracy: 0.9667\n",
      "iteration number: 542\t training loss: 249.0119\tvalidation loss: 100.2319\t validation accuracy: 0.9667\n",
      "iteration number: 543\t training loss: 248.4463\tvalidation loss: 100.0868\t validation accuracy: 0.9667\n",
      "iteration number: 544\t training loss: 247.8837\tvalidation loss: 99.9427\t validation accuracy: 0.9667\n",
      "iteration number: 545\t training loss: 247.3240\tvalidation loss: 99.7996\t validation accuracy: 0.9667\n",
      "iteration number: 546\t training loss: 246.7670\tvalidation loss: 99.6575\t validation accuracy: 0.9667\n",
      "iteration number: 547\t training loss: 246.2130\tvalidation loss: 99.5163\t validation accuracy: 0.9667\n",
      "iteration number: 548\t training loss: 245.6617\tvalidation loss: 99.3761\t validation accuracy: 0.9667\n",
      "iteration number: 549\t training loss: 245.1131\tvalidation loss: 99.2368\t validation accuracy: 0.9667\n",
      "iteration number: 550\t training loss: 244.5674\tvalidation loss: 99.0984\t validation accuracy: 0.9667\n",
      "iteration number: 551\t training loss: 244.0243\tvalidation loss: 98.9610\t validation accuracy: 0.9667\n",
      "iteration number: 552\t training loss: 243.4840\tvalidation loss: 98.8245\t validation accuracy: 0.9667\n",
      "iteration number: 553\t training loss: 242.9463\tvalidation loss: 98.6889\t validation accuracy: 0.9667\n",
      "iteration number: 554\t training loss: 242.4113\tvalidation loss: 98.5542\t validation accuracy: 0.9667\n",
      "iteration number: 555\t training loss: 241.8790\tvalidation loss: 98.4204\t validation accuracy: 0.9667\n",
      "iteration number: 556\t training loss: 241.3493\tvalidation loss: 98.2875\t validation accuracy: 0.9667\n",
      "iteration number: 557\t training loss: 240.8221\tvalidation loss: 98.1554\t validation accuracy: 0.9667\n",
      "iteration number: 558\t training loss: 240.2976\tvalidation loss: 98.0242\t validation accuracy: 0.9667\n",
      "iteration number: 559\t training loss: 239.7756\tvalidation loss: 97.8939\t validation accuracy: 0.9667\n",
      "iteration number: 560\t training loss: 239.2562\tvalidation loss: 97.7645\t validation accuracy: 0.9667\n",
      "iteration number: 561\t training loss: 238.7393\tvalidation loss: 97.6359\t validation accuracy: 0.9667\n",
      "iteration number: 562\t training loss: 238.2249\tvalidation loss: 97.5081\t validation accuracy: 0.9667\n",
      "iteration number: 563\t training loss: 237.7129\tvalidation loss: 97.3812\t validation accuracy: 0.9667\n",
      "iteration number: 564\t training loss: 237.2034\tvalidation loss: 97.2550\t validation accuracy: 0.9667\n",
      "iteration number: 565\t training loss: 236.6964\tvalidation loss: 97.1297\t validation accuracy: 0.9667\n",
      "iteration number: 566\t training loss: 236.1918\tvalidation loss: 97.0053\t validation accuracy: 0.9667\n",
      "iteration number: 567\t training loss: 235.6896\tvalidation loss: 96.8816\t validation accuracy: 0.9667\n",
      "iteration number: 568\t training loss: 235.1898\tvalidation loss: 96.7587\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 569\t training loss: 234.6923\tvalidation loss: 96.6366\t validation accuracy: 0.9667\n",
      "iteration number: 570\t training loss: 234.1972\tvalidation loss: 96.5153\t validation accuracy: 0.9667\n",
      "iteration number: 571\t training loss: 233.7045\tvalidation loss: 96.3948\t validation accuracy: 0.9667\n",
      "iteration number: 572\t training loss: 233.2140\tvalidation loss: 96.2750\t validation accuracy: 0.9667\n",
      "iteration number: 573\t training loss: 232.7259\tvalidation loss: 96.1560\t validation accuracy: 0.9667\n",
      "iteration number: 574\t training loss: 232.2400\tvalidation loss: 96.0377\t validation accuracy: 0.9667\n",
      "iteration number: 575\t training loss: 231.7564\tvalidation loss: 95.9202\t validation accuracy: 0.9667\n",
      "iteration number: 576\t training loss: 231.2750\tvalidation loss: 95.8035\t validation accuracy: 0.9667\n",
      "iteration number: 577\t training loss: 230.7959\tvalidation loss: 95.6875\t validation accuracy: 0.9667\n",
      "iteration number: 578\t training loss: 230.3190\tvalidation loss: 95.5722\t validation accuracy: 0.9667\n",
      "iteration number: 579\t training loss: 229.8442\tvalidation loss: 95.4576\t validation accuracy: 0.9667\n",
      "iteration number: 580\t training loss: 229.3717\tvalidation loss: 95.3438\t validation accuracy: 0.9667\n",
      "iteration number: 581\t training loss: 228.9013\tvalidation loss: 95.2307\t validation accuracy: 0.9667\n",
      "iteration number: 582\t training loss: 228.4331\tvalidation loss: 95.1183\t validation accuracy: 0.9667\n",
      "iteration number: 583\t training loss: 227.9669\tvalidation loss: 95.0065\t validation accuracy: 0.9667\n",
      "iteration number: 584\t training loss: 227.5029\tvalidation loss: 94.8955\t validation accuracy: 0.9667\n",
      "iteration number: 585\t training loss: 227.0410\tvalidation loss: 94.7852\t validation accuracy: 0.9667\n",
      "iteration number: 586\t training loss: 226.5812\tvalidation loss: 94.6755\t validation accuracy: 0.9667\n",
      "iteration number: 587\t training loss: 226.1235\tvalidation loss: 94.5666\t validation accuracy: 0.9667\n",
      "iteration number: 588\t training loss: 225.6678\tvalidation loss: 94.4583\t validation accuracy: 0.9667\n",
      "iteration number: 589\t training loss: 225.2141\tvalidation loss: 94.3506\t validation accuracy: 0.9667\n",
      "iteration number: 590\t training loss: 224.7625\tvalidation loss: 94.2437\t validation accuracy: 0.9667\n",
      "iteration number: 591\t training loss: 224.3129\tvalidation loss: 94.1373\t validation accuracy: 0.9667\n",
      "iteration number: 592\t training loss: 223.8653\tvalidation loss: 94.0317\t validation accuracy: 0.9667\n",
      "iteration number: 593\t training loss: 223.4196\tvalidation loss: 93.9267\t validation accuracy: 0.9667\n",
      "iteration number: 594\t training loss: 222.9759\tvalidation loss: 93.8223\t validation accuracy: 0.9667\n",
      "iteration number: 595\t training loss: 222.5342\tvalidation loss: 93.7185\t validation accuracy: 0.9667\n",
      "iteration number: 596\t training loss: 222.0944\tvalidation loss: 93.6154\t validation accuracy: 0.9667\n",
      "iteration number: 597\t training loss: 221.6565\tvalidation loss: 93.5129\t validation accuracy: 0.9667\n",
      "iteration number: 598\t training loss: 221.2206\tvalidation loss: 93.4110\t validation accuracy: 0.9667\n",
      "iteration number: 599\t training loss: 220.7865\tvalidation loss: 93.3098\t validation accuracy: 0.9667\n",
      "iteration number: 600\t training loss: 220.3543\tvalidation loss: 93.2091\t validation accuracy: 0.9667\n",
      "iteration number: 601\t training loss: 219.9240\tvalidation loss: 93.1091\t validation accuracy: 0.9667\n",
      "iteration number: 602\t training loss: 219.4956\tvalidation loss: 93.0096\t validation accuracy: 0.9667\n",
      "iteration number: 603\t training loss: 219.0689\tvalidation loss: 92.9108\t validation accuracy: 0.9667\n",
      "iteration number: 604\t training loss: 218.6442\tvalidation loss: 92.8125\t validation accuracy: 0.9667\n",
      "iteration number: 605\t training loss: 218.2212\tvalidation loss: 92.7148\t validation accuracy: 0.9667\n",
      "iteration number: 606\t training loss: 217.8000\tvalidation loss: 92.6177\t validation accuracy: 0.9667\n",
      "iteration number: 607\t training loss: 217.3806\tvalidation loss: 92.5212\t validation accuracy: 0.9667\n",
      "iteration number: 608\t training loss: 216.9630\tvalidation loss: 92.4252\t validation accuracy: 0.9667\n",
      "iteration number: 609\t training loss: 216.5472\tvalidation loss: 92.3298\t validation accuracy: 0.9667\n",
      "iteration number: 610\t training loss: 216.1331\tvalidation loss: 92.2350\t validation accuracy: 0.9667\n",
      "iteration number: 611\t training loss: 215.7208\tvalidation loss: 92.1407\t validation accuracy: 0.9667\n",
      "iteration number: 612\t training loss: 215.3102\tvalidation loss: 92.0470\t validation accuracy: 0.9667\n",
      "iteration number: 613\t training loss: 214.9013\tvalidation loss: 91.9538\t validation accuracy: 0.9667\n",
      "iteration number: 614\t training loss: 214.4941\tvalidation loss: 91.8612\t validation accuracy: 0.9667\n",
      "iteration number: 615\t training loss: 214.0886\tvalidation loss: 91.7691\t validation accuracy: 0.9667\n",
      "iteration number: 616\t training loss: 213.6848\tvalidation loss: 91.6776\t validation accuracy: 0.9667\n",
      "iteration number: 617\t training loss: 213.2827\tvalidation loss: 91.5865\t validation accuracy: 0.9667\n",
      "iteration number: 618\t training loss: 212.8822\tvalidation loss: 91.4961\t validation accuracy: 0.9667\n",
      "iteration number: 619\t training loss: 212.4834\tvalidation loss: 91.4061\t validation accuracy: 0.9667\n",
      "iteration number: 620\t training loss: 212.0862\tvalidation loss: 91.3166\t validation accuracy: 0.9667\n",
      "iteration number: 621\t training loss: 211.6907\tvalidation loss: 91.2277\t validation accuracy: 0.9667\n",
      "iteration number: 622\t training loss: 211.2967\tvalidation loss: 91.1393\t validation accuracy: 0.9667\n",
      "iteration number: 623\t training loss: 210.9044\tvalidation loss: 91.0513\t validation accuracy: 0.9667\n",
      "iteration number: 624\t training loss: 210.5136\tvalidation loss: 90.9639\t validation accuracy: 0.9667\n",
      "iteration number: 625\t training loss: 210.1244\tvalidation loss: 90.8770\t validation accuracy: 0.9667\n",
      "iteration number: 626\t training loss: 209.7368\tvalidation loss: 90.7905\t validation accuracy: 0.9667\n",
      "iteration number: 627\t training loss: 209.3508\tvalidation loss: 90.7046\t validation accuracy: 0.9667\n",
      "iteration number: 628\t training loss: 208.9663\tvalidation loss: 90.6192\t validation accuracy: 0.9667\n",
      "iteration number: 629\t training loss: 208.5834\tvalidation loss: 90.5342\t validation accuracy: 0.9667\n",
      "iteration number: 630\t training loss: 208.2019\tvalidation loss: 90.4497\t validation accuracy: 0.9667\n",
      "iteration number: 631\t training loss: 207.8220\tvalidation loss: 90.3657\t validation accuracy: 0.9667\n",
      "iteration number: 632\t training loss: 207.4437\tvalidation loss: 90.2821\t validation accuracy: 0.9667\n",
      "iteration number: 633\t training loss: 207.0668\tvalidation loss: 90.1991\t validation accuracy: 0.9667\n",
      "iteration number: 634\t training loss: 206.6914\tvalidation loss: 90.1165\t validation accuracy: 0.9667\n",
      "iteration number: 635\t training loss: 206.3174\tvalidation loss: 90.0343\t validation accuracy: 0.9667\n",
      "iteration number: 636\t training loss: 205.9450\tvalidation loss: 89.9526\t validation accuracy: 0.9667\n",
      "iteration number: 637\t training loss: 205.5740\tvalidation loss: 89.8714\t validation accuracy: 0.9667\n",
      "iteration number: 638\t training loss: 205.2045\tvalidation loss: 89.7906\t validation accuracy: 0.9667\n",
      "iteration number: 639\t training loss: 204.8364\tvalidation loss: 89.7102\t validation accuracy: 0.9667\n",
      "iteration number: 640\t training loss: 204.4697\tvalidation loss: 89.6303\t validation accuracy: 0.9667\n",
      "iteration number: 641\t training loss: 204.1044\tvalidation loss: 89.5509\t validation accuracy: 0.9667\n",
      "iteration number: 642\t training loss: 203.7406\tvalidation loss: 89.4719\t validation accuracy: 0.9667\n",
      "iteration number: 643\t training loss: 203.3782\tvalidation loss: 89.3933\t validation accuracy: 0.9667\n",
      "iteration number: 644\t training loss: 203.0171\tvalidation loss: 89.3151\t validation accuracy: 0.9667\n",
      "iteration number: 645\t training loss: 202.6575\tvalidation loss: 89.2374\t validation accuracy: 0.9667\n",
      "iteration number: 646\t training loss: 202.2992\tvalidation loss: 89.1601\t validation accuracy: 0.9667\n",
      "iteration number: 647\t training loss: 201.9423\tvalidation loss: 89.0832\t validation accuracy: 0.9667\n",
      "iteration number: 648\t training loss: 201.5867\tvalidation loss: 89.0067\t validation accuracy: 0.9667\n",
      "iteration number: 649\t training loss: 201.2325\tvalidation loss: 88.9307\t validation accuracy: 0.9667\n",
      "iteration number: 650\t training loss: 200.8797\tvalidation loss: 88.8550\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 651\t training loss: 200.5282\tvalidation loss: 88.7798\t validation accuracy: 0.9667\n",
      "iteration number: 652\t training loss: 200.1780\tvalidation loss: 88.7050\t validation accuracy: 0.9667\n",
      "iteration number: 653\t training loss: 199.8291\tvalidation loss: 88.6306\t validation accuracy: 0.9667\n",
      "iteration number: 654\t training loss: 199.4815\tvalidation loss: 88.5565\t validation accuracy: 0.9667\n",
      "iteration number: 655\t training loss: 199.1352\tvalidation loss: 88.4829\t validation accuracy: 0.9667\n",
      "iteration number: 656\t training loss: 198.7902\tvalidation loss: 88.4097\t validation accuracy: 0.9667\n",
      "iteration number: 657\t training loss: 198.4465\tvalidation loss: 88.3368\t validation accuracy: 0.9667\n",
      "iteration number: 658\t training loss: 198.1041\tvalidation loss: 88.2643\t validation accuracy: 0.9667\n",
      "iteration number: 659\t training loss: 197.7629\tvalidation loss: 88.1923\t validation accuracy: 0.9667\n",
      "iteration number: 660\t training loss: 197.4230\tvalidation loss: 88.1206\t validation accuracy: 0.9667\n",
      "iteration number: 661\t training loss: 197.0844\tvalidation loss: 88.0493\t validation accuracy: 0.9667\n",
      "iteration number: 662\t training loss: 196.7470\tvalidation loss: 87.9783\t validation accuracy: 0.9667\n",
      "iteration number: 663\t training loss: 196.4108\tvalidation loss: 87.9077\t validation accuracy: 0.9667\n",
      "iteration number: 664\t training loss: 196.0759\tvalidation loss: 87.8375\t validation accuracy: 0.9667\n",
      "iteration number: 665\t training loss: 195.7421\tvalidation loss: 87.7677\t validation accuracy: 0.9667\n",
      "iteration number: 666\t training loss: 195.4096\tvalidation loss: 87.6982\t validation accuracy: 0.9667\n",
      "iteration number: 667\t training loss: 195.0783\tvalidation loss: 87.6291\t validation accuracy: 0.9667\n",
      "iteration number: 668\t training loss: 194.7482\tvalidation loss: 87.5604\t validation accuracy: 0.9667\n",
      "iteration number: 669\t training loss: 194.4193\tvalidation loss: 87.4920\t validation accuracy: 0.9667\n",
      "iteration number: 670\t training loss: 194.0915\tvalidation loss: 87.4240\t validation accuracy: 0.9667\n",
      "iteration number: 671\t training loss: 193.7650\tvalidation loss: 87.3563\t validation accuracy: 0.9667\n",
      "iteration number: 672\t training loss: 193.4396\tvalidation loss: 87.2890\t validation accuracy: 0.9667\n",
      "iteration number: 673\t training loss: 193.1153\tvalidation loss: 87.2220\t validation accuracy: 0.9667\n",
      "iteration number: 674\t training loss: 192.7922\tvalidation loss: 87.1553\t validation accuracy: 0.9667\n",
      "iteration number: 675\t training loss: 192.4703\tvalidation loss: 87.0890\t validation accuracy: 0.9667\n",
      "iteration number: 676\t training loss: 192.1495\tvalidation loss: 87.0231\t validation accuracy: 0.9667\n",
      "iteration number: 677\t training loss: 191.8298\tvalidation loss: 86.9574\t validation accuracy: 0.9667\n",
      "iteration number: 678\t training loss: 191.5113\tvalidation loss: 86.8922\t validation accuracy: 0.9667\n",
      "iteration number: 679\t training loss: 191.1939\tvalidation loss: 86.8272\t validation accuracy: 0.9667\n",
      "iteration number: 680\t training loss: 190.8776\tvalidation loss: 86.7626\t validation accuracy: 0.9667\n",
      "iteration number: 681\t training loss: 190.5624\tvalidation loss: 86.6983\t validation accuracy: 0.9667\n",
      "iteration number: 682\t training loss: 190.2483\tvalidation loss: 86.6343\t validation accuracy: 0.9667\n",
      "iteration number: 683\t training loss: 189.9352\tvalidation loss: 86.5706\t validation accuracy: 0.9667\n",
      "iteration number: 684\t training loss: 189.6233\tvalidation loss: 86.5073\t validation accuracy: 0.9667\n",
      "iteration number: 685\t training loss: 189.3125\tvalidation loss: 86.4443\t validation accuracy: 0.9667\n",
      "iteration number: 686\t training loss: 189.0027\tvalidation loss: 86.3816\t validation accuracy: 0.9667\n",
      "iteration number: 687\t training loss: 188.6940\tvalidation loss: 86.3192\t validation accuracy: 0.9667\n",
      "iteration number: 688\t training loss: 188.3863\tvalidation loss: 86.2571\t validation accuracy: 0.9667\n",
      "iteration number: 689\t training loss: 188.0798\tvalidation loss: 86.1953\t validation accuracy: 0.9667\n",
      "iteration number: 690\t training loss: 187.7742\tvalidation loss: 86.1339\t validation accuracy: 0.9667\n",
      "iteration number: 691\t training loss: 187.4697\tvalidation loss: 86.0727\t validation accuracy: 0.9667\n",
      "iteration number: 692\t training loss: 187.1662\tvalidation loss: 86.0119\t validation accuracy: 0.9667\n",
      "iteration number: 693\t training loss: 186.8638\tvalidation loss: 85.9513\t validation accuracy: 0.9667\n",
      "iteration number: 694\t training loss: 186.5624\tvalidation loss: 85.8911\t validation accuracy: 0.9667\n",
      "iteration number: 695\t training loss: 186.2620\tvalidation loss: 85.8311\t validation accuracy: 0.9667\n",
      "iteration number: 696\t training loss: 185.9626\tvalidation loss: 85.7714\t validation accuracy: 0.9667\n",
      "iteration number: 697\t training loss: 185.6642\tvalidation loss: 85.7121\t validation accuracy: 0.9667\n",
      "iteration number: 698\t training loss: 185.3668\tvalidation loss: 85.6530\t validation accuracy: 0.9667\n",
      "iteration number: 699\t training loss: 185.0704\tvalidation loss: 85.5942\t validation accuracy: 0.9667\n",
      "iteration number: 700\t training loss: 184.7750\tvalidation loss: 85.5357\t validation accuracy: 0.9667\n",
      "iteration number: 701\t training loss: 184.4806\tvalidation loss: 85.4774\t validation accuracy: 0.9667\n",
      "iteration number: 702\t training loss: 184.1872\tvalidation loss: 85.4195\t validation accuracy: 0.9667\n",
      "iteration number: 703\t training loss: 183.8947\tvalidation loss: 85.3618\t validation accuracy: 0.9667\n",
      "iteration number: 704\t training loss: 183.6032\tvalidation loss: 85.3044\t validation accuracy: 0.9667\n",
      "iteration number: 705\t training loss: 183.3126\tvalidation loss: 85.2473\t validation accuracy: 0.9667\n",
      "iteration number: 706\t training loss: 183.0231\tvalidation loss: 85.1905\t validation accuracy: 0.9667\n",
      "iteration number: 707\t training loss: 182.7344\tvalidation loss: 85.1339\t validation accuracy: 0.9667\n",
      "iteration number: 708\t training loss: 182.4467\tvalidation loss: 85.0776\t validation accuracy: 0.9667\n",
      "iteration number: 709\t training loss: 182.1599\tvalidation loss: 85.0216\t validation accuracy: 0.9667\n",
      "iteration number: 710\t training loss: 181.8741\tvalidation loss: 84.9658\t validation accuracy: 0.9667\n",
      "iteration number: 711\t training loss: 181.5892\tvalidation loss: 84.9103\t validation accuracy: 0.9667\n",
      "iteration number: 712\t training loss: 181.3052\tvalidation loss: 84.8551\t validation accuracy: 0.9667\n",
      "iteration number: 713\t training loss: 181.0222\tvalidation loss: 84.8001\t validation accuracy: 0.9667\n",
      "iteration number: 714\t training loss: 180.7400\tvalidation loss: 84.7454\t validation accuracy: 0.9667\n",
      "iteration number: 715\t training loss: 180.4588\tvalidation loss: 84.6910\t validation accuracy: 0.9667\n",
      "iteration number: 716\t training loss: 180.1784\tvalidation loss: 84.6368\t validation accuracy: 0.9667\n",
      "iteration number: 717\t training loss: 179.8990\tvalidation loss: 84.5828\t validation accuracy: 0.9667\n",
      "iteration number: 718\t training loss: 179.6204\tvalidation loss: 84.5291\t validation accuracy: 0.9667\n",
      "iteration number: 719\t training loss: 179.3427\tvalidation loss: 84.4757\t validation accuracy: 0.9667\n",
      "iteration number: 720\t training loss: 179.0659\tvalidation loss: 84.4225\t validation accuracy: 0.9667\n",
      "iteration number: 721\t training loss: 178.7900\tvalidation loss: 84.3695\t validation accuracy: 0.9667\n",
      "iteration number: 722\t training loss: 178.5150\tvalidation loss: 84.3168\t validation accuracy: 0.9667\n",
      "iteration number: 723\t training loss: 178.2408\tvalidation loss: 84.2644\t validation accuracy: 0.9667\n",
      "iteration number: 724\t training loss: 177.9675\tvalidation loss: 84.2122\t validation accuracy: 0.9667\n",
      "iteration number: 725\t training loss: 177.6950\tvalidation loss: 84.1602\t validation accuracy: 0.9667\n",
      "iteration number: 726\t training loss: 177.4234\tvalidation loss: 84.1084\t validation accuracy: 0.9667\n",
      "iteration number: 727\t training loss: 177.1527\tvalidation loss: 84.0569\t validation accuracy: 0.9667\n",
      "iteration number: 728\t training loss: 176.8827\tvalidation loss: 84.0057\t validation accuracy: 0.9667\n",
      "iteration number: 729\t training loss: 176.6137\tvalidation loss: 83.9547\t validation accuracy: 0.9667\n",
      "iteration number: 730\t training loss: 176.3454\tvalidation loss: 83.9039\t validation accuracy: 0.9667\n",
      "iteration number: 731\t training loss: 176.0780\tvalidation loss: 83.8533\t validation accuracy: 0.9667\n",
      "iteration number: 732\t training loss: 175.8114\tvalidation loss: 83.8030\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 733\t training loss: 175.5457\tvalidation loss: 83.7529\t validation accuracy: 0.9667\n",
      "iteration number: 734\t training loss: 175.2807\tvalidation loss: 83.7030\t validation accuracy: 0.9667\n",
      "iteration number: 735\t training loss: 175.0166\tvalidation loss: 83.6533\t validation accuracy: 0.9667\n",
      "iteration number: 736\t training loss: 174.7532\tvalidation loss: 83.6039\t validation accuracy: 0.9667\n",
      "iteration number: 737\t training loss: 174.4907\tvalidation loss: 83.5547\t validation accuracy: 0.9667\n",
      "iteration number: 738\t training loss: 174.2290\tvalidation loss: 83.5057\t validation accuracy: 0.9667\n",
      "iteration number: 739\t training loss: 173.9680\tvalidation loss: 83.4569\t validation accuracy: 0.9667\n",
      "iteration number: 740\t training loss: 173.7079\tvalidation loss: 83.4084\t validation accuracy: 0.9667\n",
      "iteration number: 741\t training loss: 173.4485\tvalidation loss: 83.3600\t validation accuracy: 0.9667\n",
      "iteration number: 742\t training loss: 173.1899\tvalidation loss: 83.3119\t validation accuracy: 0.9667\n",
      "iteration number: 743\t training loss: 172.9321\tvalidation loss: 83.2640\t validation accuracy: 0.9667\n",
      "iteration number: 744\t training loss: 172.6751\tvalidation loss: 83.2163\t validation accuracy: 0.9667\n",
      "iteration number: 745\t training loss: 172.4188\tvalidation loss: 83.1688\t validation accuracy: 0.9667\n",
      "iteration number: 746\t training loss: 172.1633\tvalidation loss: 83.1215\t validation accuracy: 0.9667\n",
      "iteration number: 747\t training loss: 171.9086\tvalidation loss: 83.0745\t validation accuracy: 0.9667\n",
      "iteration number: 748\t training loss: 171.6546\tvalidation loss: 83.0276\t validation accuracy: 0.9667\n",
      "iteration number: 749\t training loss: 171.4014\tvalidation loss: 82.9810\t validation accuracy: 0.9667\n",
      "iteration number: 750\t training loss: 171.1489\tvalidation loss: 82.9345\t validation accuracy: 0.9667\n",
      "iteration number: 751\t training loss: 170.8972\tvalidation loss: 82.8883\t validation accuracy: 0.9667\n",
      "iteration number: 752\t training loss: 170.6462\tvalidation loss: 82.8422\t validation accuracy: 0.9667\n",
      "iteration number: 753\t training loss: 170.3960\tvalidation loss: 82.7964\t validation accuracy: 0.9667\n",
      "iteration number: 754\t training loss: 170.1464\tvalidation loss: 82.7507\t validation accuracy: 0.9667\n",
      "iteration number: 755\t training loss: 169.8976\tvalidation loss: 82.7053\t validation accuracy: 0.9667\n",
      "iteration number: 756\t training loss: 169.6496\tvalidation loss: 82.6600\t validation accuracy: 0.9667\n",
      "iteration number: 757\t training loss: 169.4022\tvalidation loss: 82.6149\t validation accuracy: 0.9667\n",
      "iteration number: 758\t training loss: 169.1556\tvalidation loss: 82.5701\t validation accuracy: 0.9667\n",
      "iteration number: 759\t training loss: 168.9097\tvalidation loss: 82.5254\t validation accuracy: 0.9667\n",
      "iteration number: 760\t training loss: 168.6645\tvalidation loss: 82.4809\t validation accuracy: 0.9667\n",
      "iteration number: 761\t training loss: 168.4200\tvalidation loss: 82.4366\t validation accuracy: 0.9667\n",
      "iteration number: 762\t training loss: 168.1762\tvalidation loss: 82.3925\t validation accuracy: 0.9667\n",
      "iteration number: 763\t training loss: 167.9331\tvalidation loss: 82.3486\t validation accuracy: 0.9667\n",
      "iteration number: 764\t training loss: 167.6908\tvalidation loss: 82.3049\t validation accuracy: 0.9667\n",
      "iteration number: 765\t training loss: 167.4491\tvalidation loss: 82.2613\t validation accuracy: 0.9667\n",
      "iteration number: 766\t training loss: 167.2081\tvalidation loss: 82.2180\t validation accuracy: 0.9667\n",
      "iteration number: 767\t training loss: 166.9677\tvalidation loss: 82.1748\t validation accuracy: 0.9667\n",
      "iteration number: 768\t training loss: 166.7281\tvalidation loss: 82.1318\t validation accuracy: 0.9667\n",
      "iteration number: 769\t training loss: 166.4891\tvalidation loss: 82.0890\t validation accuracy: 0.9667\n",
      "iteration number: 770\t training loss: 166.2508\tvalidation loss: 82.0463\t validation accuracy: 0.9667\n",
      "iteration number: 771\t training loss: 166.0132\tvalidation loss: 82.0039\t validation accuracy: 0.9667\n",
      "iteration number: 772\t training loss: 165.7763\tvalidation loss: 81.9616\t validation accuracy: 0.9667\n",
      "iteration number: 773\t training loss: 165.5400\tvalidation loss: 81.9195\t validation accuracy: 0.9667\n",
      "iteration number: 774\t training loss: 165.3044\tvalidation loss: 81.8775\t validation accuracy: 0.9667\n",
      "iteration number: 775\t training loss: 165.0694\tvalidation loss: 81.8358\t validation accuracy: 0.9667\n",
      "iteration number: 776\t training loss: 164.8351\tvalidation loss: 81.7942\t validation accuracy: 0.9667\n",
      "iteration number: 777\t training loss: 164.6015\tvalidation loss: 81.7528\t validation accuracy: 0.9667\n",
      "iteration number: 778\t training loss: 164.3685\tvalidation loss: 81.7115\t validation accuracy: 0.9667\n",
      "iteration number: 779\t training loss: 164.1361\tvalidation loss: 81.6704\t validation accuracy: 0.9667\n",
      "iteration number: 780\t training loss: 163.9044\tvalidation loss: 81.6295\t validation accuracy: 0.9667\n",
      "iteration number: 781\t training loss: 163.6734\tvalidation loss: 81.5888\t validation accuracy: 0.9667\n",
      "iteration number: 782\t training loss: 163.4429\tvalidation loss: 81.5482\t validation accuracy: 0.9667\n",
      "iteration number: 783\t training loss: 163.2131\tvalidation loss: 81.5078\t validation accuracy: 0.9667\n",
      "iteration number: 784\t training loss: 162.9840\tvalidation loss: 81.4676\t validation accuracy: 0.9667\n",
      "iteration number: 785\t training loss: 162.7554\tvalidation loss: 81.4275\t validation accuracy: 0.9667\n",
      "iteration number: 786\t training loss: 162.5275\tvalidation loss: 81.3876\t validation accuracy: 0.9667\n",
      "iteration number: 787\t training loss: 162.3002\tvalidation loss: 81.3478\t validation accuracy: 0.9667\n",
      "iteration number: 788\t training loss: 162.0735\tvalidation loss: 81.3082\t validation accuracy: 0.9667\n",
      "iteration number: 789\t training loss: 161.8474\tvalidation loss: 81.2688\t validation accuracy: 0.9667\n",
      "iteration number: 790\t training loss: 161.6220\tvalidation loss: 81.2295\t validation accuracy: 0.9667\n",
      "iteration number: 791\t training loss: 161.3971\tvalidation loss: 81.1904\t validation accuracy: 0.9667\n",
      "iteration number: 792\t training loss: 161.1729\tvalidation loss: 81.1514\t validation accuracy: 0.9667\n",
      "iteration number: 793\t training loss: 160.9493\tvalidation loss: 81.1126\t validation accuracy: 0.9667\n",
      "iteration number: 794\t training loss: 160.7262\tvalidation loss: 81.0740\t validation accuracy: 0.9667\n",
      "iteration number: 795\t training loss: 160.5038\tvalidation loss: 81.0354\t validation accuracy: 0.9667\n",
      "iteration number: 796\t training loss: 160.2820\tvalidation loss: 80.9971\t validation accuracy: 0.9667\n",
      "iteration number: 797\t training loss: 160.0607\tvalidation loss: 80.9589\t validation accuracy: 0.9667\n",
      "iteration number: 798\t training loss: 159.8400\tvalidation loss: 80.9209\t validation accuracy: 0.9667\n",
      "iteration number: 799\t training loss: 159.6200\tvalidation loss: 80.8830\t validation accuracy: 0.9667\n",
      "iteration number: 800\t training loss: 159.4005\tvalidation loss: 80.8452\t validation accuracy: 0.9667\n",
      "iteration number: 801\t training loss: 159.1816\tvalidation loss: 80.8076\t validation accuracy: 0.9667\n",
      "iteration number: 802\t training loss: 158.9632\tvalidation loss: 80.7702\t validation accuracy: 0.9667\n",
      "iteration number: 803\t training loss: 158.7455\tvalidation loss: 80.7328\t validation accuracy: 0.9667\n",
      "iteration number: 804\t training loss: 158.5283\tvalidation loss: 80.6957\t validation accuracy: 0.9667\n",
      "iteration number: 805\t training loss: 158.3117\tvalidation loss: 80.6587\t validation accuracy: 0.9667\n",
      "iteration number: 806\t training loss: 158.0956\tvalidation loss: 80.6218\t validation accuracy: 0.9667\n",
      "iteration number: 807\t training loss: 157.8801\tvalidation loss: 80.5851\t validation accuracy: 0.9667\n",
      "iteration number: 808\t training loss: 157.6652\tvalidation loss: 80.5485\t validation accuracy: 0.9667\n",
      "iteration number: 809\t training loss: 157.4508\tvalidation loss: 80.5120\t validation accuracy: 0.9667\n",
      "iteration number: 810\t training loss: 157.2370\tvalidation loss: 80.4757\t validation accuracy: 0.9667\n",
      "iteration number: 811\t training loss: 157.0238\tvalidation loss: 80.4396\t validation accuracy: 0.9667\n",
      "iteration number: 812\t training loss: 156.8111\tvalidation loss: 80.4035\t validation accuracy: 0.9667\n",
      "iteration number: 813\t training loss: 156.5989\tvalidation loss: 80.3676\t validation accuracy: 0.9667\n",
      "iteration number: 814\t training loss: 156.3873\tvalidation loss: 80.3319\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 815\t training loss: 156.1762\tvalidation loss: 80.2963\t validation accuracy: 0.9667\n",
      "iteration number: 816\t training loss: 155.9657\tvalidation loss: 80.2608\t validation accuracy: 0.9667\n",
      "iteration number: 817\t training loss: 155.7557\tvalidation loss: 80.2254\t validation accuracy: 0.9667\n",
      "iteration number: 818\t training loss: 155.5463\tvalidation loss: 80.1902\t validation accuracy: 0.9667\n",
      "iteration number: 819\t training loss: 155.3374\tvalidation loss: 80.1551\t validation accuracy: 0.9667\n",
      "iteration number: 820\t training loss: 155.1290\tvalidation loss: 80.1202\t validation accuracy: 0.9667\n",
      "iteration number: 821\t training loss: 154.9211\tvalidation loss: 80.0854\t validation accuracy: 0.9667\n",
      "iteration number: 822\t training loss: 154.7138\tvalidation loss: 80.0507\t validation accuracy: 0.9667\n",
      "iteration number: 823\t training loss: 154.5070\tvalidation loss: 80.0161\t validation accuracy: 0.9667\n",
      "iteration number: 824\t training loss: 154.3007\tvalidation loss: 79.9817\t validation accuracy: 0.9667\n",
      "iteration number: 825\t training loss: 154.0950\tvalidation loss: 79.9474\t validation accuracy: 0.9667\n",
      "iteration number: 826\t training loss: 153.8897\tvalidation loss: 79.9132\t validation accuracy: 0.9667\n",
      "iteration number: 827\t training loss: 153.6850\tvalidation loss: 79.8792\t validation accuracy: 0.9667\n",
      "iteration number: 828\t training loss: 153.4808\tvalidation loss: 79.8453\t validation accuracy: 0.9667\n",
      "iteration number: 829\t training loss: 153.2771\tvalidation loss: 79.8115\t validation accuracy: 0.9667\n",
      "iteration number: 830\t training loss: 153.0739\tvalidation loss: 79.7778\t validation accuracy: 0.9667\n",
      "iteration number: 831\t training loss: 152.8712\tvalidation loss: 79.7442\t validation accuracy: 0.9667\n",
      "iteration number: 832\t training loss: 152.6690\tvalidation loss: 79.7108\t validation accuracy: 0.9667\n",
      "iteration number: 833\t training loss: 152.4673\tvalidation loss: 79.6775\t validation accuracy: 0.9667\n",
      "iteration number: 834\t training loss: 152.2661\tvalidation loss: 79.6443\t validation accuracy: 0.9667\n",
      "iteration number: 835\t training loss: 152.0654\tvalidation loss: 79.6113\t validation accuracy: 0.9667\n",
      "iteration number: 836\t training loss: 151.8652\tvalidation loss: 79.5783\t validation accuracy: 0.9667\n",
      "iteration number: 837\t training loss: 151.6655\tvalidation loss: 79.5455\t validation accuracy: 0.9667\n",
      "iteration number: 838\t training loss: 151.4663\tvalidation loss: 79.5128\t validation accuracy: 0.9667\n",
      "iteration number: 839\t training loss: 151.2676\tvalidation loss: 79.4803\t validation accuracy: 0.9667\n",
      "iteration number: 840\t training loss: 151.0694\tvalidation loss: 79.4478\t validation accuracy: 0.9667\n",
      "iteration number: 841\t training loss: 150.8716\tvalidation loss: 79.4154\t validation accuracy: 0.9667\n",
      "iteration number: 842\t training loss: 150.6743\tvalidation loss: 79.3832\t validation accuracy: 0.9667\n",
      "iteration number: 843\t training loss: 150.4776\tvalidation loss: 79.3511\t validation accuracy: 0.9667\n",
      "iteration number: 844\t training loss: 150.2812\tvalidation loss: 79.3191\t validation accuracy: 0.9667\n",
      "iteration number: 845\t training loss: 150.0854\tvalidation loss: 79.2872\t validation accuracy: 0.9667\n",
      "iteration number: 846\t training loss: 149.8900\tvalidation loss: 79.2555\t validation accuracy: 0.9667\n",
      "iteration number: 847\t training loss: 149.6951\tvalidation loss: 79.2238\t validation accuracy: 0.9667\n",
      "iteration number: 848\t training loss: 149.5007\tvalidation loss: 79.1923\t validation accuracy: 0.9667\n",
      "iteration number: 849\t training loss: 149.3068\tvalidation loss: 79.1608\t validation accuracy: 0.9667\n",
      "iteration number: 850\t training loss: 149.1133\tvalidation loss: 79.1295\t validation accuracy: 0.9667\n",
      "iteration number: 851\t training loss: 148.9202\tvalidation loss: 79.0983\t validation accuracy: 0.9667\n",
      "iteration number: 852\t training loss: 148.7277\tvalidation loss: 79.0672\t validation accuracy: 0.9667\n",
      "iteration number: 853\t training loss: 148.5356\tvalidation loss: 79.0362\t validation accuracy: 0.9667\n",
      "iteration number: 854\t training loss: 148.3439\tvalidation loss: 79.0053\t validation accuracy: 0.9667\n",
      "iteration number: 855\t training loss: 148.1527\tvalidation loss: 78.9745\t validation accuracy: 0.9667\n",
      "iteration number: 856\t training loss: 147.9620\tvalidation loss: 78.9439\t validation accuracy: 0.9667\n",
      "iteration number: 857\t training loss: 147.7717\tvalidation loss: 78.9133\t validation accuracy: 0.9667\n",
      "iteration number: 858\t training loss: 147.5819\tvalidation loss: 78.8829\t validation accuracy: 0.9667\n",
      "iteration number: 859\t training loss: 147.3925\tvalidation loss: 78.8525\t validation accuracy: 0.9667\n",
      "iteration number: 860\t training loss: 147.2035\tvalidation loss: 78.8223\t validation accuracy: 0.9667\n",
      "iteration number: 861\t training loss: 147.0150\tvalidation loss: 78.7921\t validation accuracy: 0.9667\n",
      "iteration number: 862\t training loss: 146.8270\tvalidation loss: 78.7621\t validation accuracy: 0.9667\n",
      "iteration number: 863\t training loss: 146.6394\tvalidation loss: 78.7322\t validation accuracy: 0.9667\n",
      "iteration number: 864\t training loss: 146.4522\tvalidation loss: 78.7023\t validation accuracy: 0.9667\n",
      "iteration number: 865\t training loss: 146.2654\tvalidation loss: 78.6726\t validation accuracy: 0.9667\n",
      "iteration number: 866\t training loss: 146.0791\tvalidation loss: 78.6430\t validation accuracy: 0.9667\n",
      "iteration number: 867\t training loss: 145.8933\tvalidation loss: 78.6135\t validation accuracy: 0.9667\n",
      "iteration number: 868\t training loss: 145.7078\tvalidation loss: 78.5840\t validation accuracy: 0.9667\n",
      "iteration number: 869\t training loss: 145.5228\tvalidation loss: 78.5547\t validation accuracy: 0.9667\n",
      "iteration number: 870\t training loss: 145.3382\tvalidation loss: 78.5255\t validation accuracy: 0.9667\n",
      "iteration number: 871\t training loss: 145.1541\tvalidation loss: 78.4964\t validation accuracy: 0.9667\n",
      "iteration number: 872\t training loss: 144.9703\tvalidation loss: 78.4674\t validation accuracy: 0.9667\n",
      "iteration number: 873\t training loss: 144.7870\tvalidation loss: 78.4384\t validation accuracy: 0.9667\n",
      "iteration number: 874\t training loss: 144.6041\tvalidation loss: 78.4096\t validation accuracy: 0.9667\n",
      "iteration number: 875\t training loss: 144.4217\tvalidation loss: 78.3809\t validation accuracy: 0.9667\n",
      "iteration number: 876\t training loss: 144.2396\tvalidation loss: 78.3522\t validation accuracy: 0.9667\n",
      "iteration number: 877\t training loss: 144.0580\tvalidation loss: 78.3237\t validation accuracy: 0.9667\n",
      "iteration number: 878\t training loss: 143.8768\tvalidation loss: 78.2952\t validation accuracy: 0.9667\n",
      "iteration number: 879\t training loss: 143.6960\tvalidation loss: 78.2669\t validation accuracy: 0.9667\n",
      "iteration number: 880\t training loss: 143.5156\tvalidation loss: 78.2386\t validation accuracy: 0.9667\n",
      "iteration number: 881\t training loss: 143.3356\tvalidation loss: 78.2105\t validation accuracy: 0.9667\n",
      "iteration number: 882\t training loss: 143.1560\tvalidation loss: 78.1824\t validation accuracy: 0.9667\n",
      "iteration number: 883\t training loss: 142.9768\tvalidation loss: 78.1544\t validation accuracy: 0.9667\n",
      "iteration number: 884\t training loss: 142.7981\tvalidation loss: 78.1265\t validation accuracy: 0.9667\n",
      "iteration number: 885\t training loss: 142.6197\tvalidation loss: 78.0987\t validation accuracy: 0.9667\n",
      "iteration number: 886\t training loss: 142.4417\tvalidation loss: 78.0710\t validation accuracy: 0.9667\n",
      "iteration number: 887\t training loss: 142.2642\tvalidation loss: 78.0434\t validation accuracy: 0.9667\n",
      "iteration number: 888\t training loss: 142.0870\tvalidation loss: 78.0159\t validation accuracy: 0.9667\n",
      "iteration number: 889\t training loss: 141.9102\tvalidation loss: 77.9885\t validation accuracy: 0.9667\n",
      "iteration number: 890\t training loss: 141.7338\tvalidation loss: 77.9611\t validation accuracy: 0.9667\n",
      "iteration number: 891\t training loss: 141.5579\tvalidation loss: 77.9339\t validation accuracy: 0.9667\n",
      "iteration number: 892\t training loss: 141.3823\tvalidation loss: 77.9067\t validation accuracy: 0.9667\n",
      "iteration number: 893\t training loss: 141.2071\tvalidation loss: 77.8796\t validation accuracy: 0.9667\n",
      "iteration number: 894\t training loss: 141.0322\tvalidation loss: 77.8526\t validation accuracy: 0.9667\n",
      "iteration number: 895\t training loss: 140.8578\tvalidation loss: 77.8257\t validation accuracy: 0.9667\n",
      "iteration number: 896\t training loss: 140.6838\tvalidation loss: 77.7989\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 897\t training loss: 140.5101\tvalidation loss: 77.7722\t validation accuracy: 0.9667\n",
      "iteration number: 898\t training loss: 140.3369\tvalidation loss: 77.7456\t validation accuracy: 0.9667\n",
      "iteration number: 899\t training loss: 140.1640\tvalidation loss: 77.7190\t validation accuracy: 0.9667\n",
      "iteration number: 900\t training loss: 139.9914\tvalidation loss: 77.6925\t validation accuracy: 0.9667\n",
      "iteration number: 901\t training loss: 139.8193\tvalidation loss: 77.6661\t validation accuracy: 0.9667\n",
      "iteration number: 902\t training loss: 139.6476\tvalidation loss: 77.6398\t validation accuracy: 0.9667\n",
      "iteration number: 903\t training loss: 139.4762\tvalidation loss: 77.6136\t validation accuracy: 0.9667\n",
      "iteration number: 904\t training loss: 139.3052\tvalidation loss: 77.5875\t validation accuracy: 0.9667\n",
      "iteration number: 905\t training loss: 139.1345\tvalidation loss: 77.5614\t validation accuracy: 0.9667\n",
      "iteration number: 906\t training loss: 138.9643\tvalidation loss: 77.5354\t validation accuracy: 0.9667\n",
      "iteration number: 907\t training loss: 138.7944\tvalidation loss: 77.5095\t validation accuracy: 0.9667\n",
      "iteration number: 908\t training loss: 138.6248\tvalidation loss: 77.4837\t validation accuracy: 0.9667\n",
      "iteration number: 909\t training loss: 138.4557\tvalidation loss: 77.4580\t validation accuracy: 0.9667\n",
      "iteration number: 910\t training loss: 138.2869\tvalidation loss: 77.4323\t validation accuracy: 0.9667\n",
      "iteration number: 911\t training loss: 138.1184\tvalidation loss: 77.4068\t validation accuracy: 0.9667\n",
      "iteration number: 912\t training loss: 137.9504\tvalidation loss: 77.3813\t validation accuracy: 0.9667\n",
      "iteration number: 913\t training loss: 137.7827\tvalidation loss: 77.3559\t validation accuracy: 0.9667\n",
      "iteration number: 914\t training loss: 137.6153\tvalidation loss: 77.3305\t validation accuracy: 0.9667\n",
      "iteration number: 915\t training loss: 137.4483\tvalidation loss: 77.3053\t validation accuracy: 0.9667\n",
      "iteration number: 916\t training loss: 137.2817\tvalidation loss: 77.2801\t validation accuracy: 0.9667\n",
      "iteration number: 917\t training loss: 137.1154\tvalidation loss: 77.2550\t validation accuracy: 0.9667\n",
      "iteration number: 918\t training loss: 136.9495\tvalidation loss: 77.2300\t validation accuracy: 0.9667\n",
      "iteration number: 919\t training loss: 136.7839\tvalidation loss: 77.2050\t validation accuracy: 0.9667\n",
      "iteration number: 920\t training loss: 136.6187\tvalidation loss: 77.1802\t validation accuracy: 0.9667\n",
      "iteration number: 921\t training loss: 136.4539\tvalidation loss: 77.1554\t validation accuracy: 0.9667\n",
      "iteration number: 922\t training loss: 136.2893\tvalidation loss: 77.1307\t validation accuracy: 0.9667\n",
      "iteration number: 923\t training loss: 136.1252\tvalidation loss: 77.1060\t validation accuracy: 0.9667\n",
      "iteration number: 924\t training loss: 135.9613\tvalidation loss: 77.0815\t validation accuracy: 0.9667\n",
      "iteration number: 925\t training loss: 135.7979\tvalidation loss: 77.0570\t validation accuracy: 0.9667\n",
      "iteration number: 926\t training loss: 135.6347\tvalidation loss: 77.0325\t validation accuracy: 0.9667\n",
      "iteration number: 927\t training loss: 135.4719\tvalidation loss: 77.0082\t validation accuracy: 0.9667\n",
      "iteration number: 928\t training loss: 135.3095\tvalidation loss: 76.9839\t validation accuracy: 0.9667\n",
      "iteration number: 929\t training loss: 135.1474\tvalidation loss: 76.9597\t validation accuracy: 0.9667\n",
      "iteration number: 930\t training loss: 134.9856\tvalidation loss: 76.9356\t validation accuracy: 0.9667\n",
      "iteration number: 931\t training loss: 134.8242\tvalidation loss: 76.9115\t validation accuracy: 0.9667\n",
      "iteration number: 932\t training loss: 134.6631\tvalidation loss: 76.8876\t validation accuracy: 0.9667\n",
      "iteration number: 933\t training loss: 134.5023\tvalidation loss: 76.8637\t validation accuracy: 0.9667\n",
      "iteration number: 934\t training loss: 134.3419\tvalidation loss: 76.8398\t validation accuracy: 0.9667\n",
      "iteration number: 935\t training loss: 134.1818\tvalidation loss: 76.8161\t validation accuracy: 0.9667\n",
      "iteration number: 936\t training loss: 134.0221\tvalidation loss: 76.7924\t validation accuracy: 0.9667\n",
      "iteration number: 937\t training loss: 133.8626\tvalidation loss: 76.7687\t validation accuracy: 0.9667\n",
      "iteration number: 938\t training loss: 133.7035\tvalidation loss: 76.7452\t validation accuracy: 0.9667\n",
      "iteration number: 939\t training loss: 133.5448\tvalidation loss: 76.7217\t validation accuracy: 0.9667\n",
      "iteration number: 940\t training loss: 133.3863\tvalidation loss: 76.6983\t validation accuracy: 0.9667\n",
      "iteration number: 941\t training loss: 133.2282\tvalidation loss: 76.6749\t validation accuracy: 0.9667\n",
      "iteration number: 942\t training loss: 133.0704\tvalidation loss: 76.6516\t validation accuracy: 0.9667\n",
      "iteration number: 943\t training loss: 132.9129\tvalidation loss: 76.6284\t validation accuracy: 0.9667\n",
      "iteration number: 944\t training loss: 132.7558\tvalidation loss: 76.6053\t validation accuracy: 0.9667\n",
      "iteration number: 945\t training loss: 132.5990\tvalidation loss: 76.5822\t validation accuracy: 0.9667\n",
      "iteration number: 946\t training loss: 132.4425\tvalidation loss: 76.5592\t validation accuracy: 0.9667\n",
      "iteration number: 947\t training loss: 132.2863\tvalidation loss: 76.5362\t validation accuracy: 0.9667\n",
      "iteration number: 948\t training loss: 132.1304\tvalidation loss: 76.5134\t validation accuracy: 0.9667\n",
      "iteration number: 949\t training loss: 131.9749\tvalidation loss: 76.4905\t validation accuracy: 0.9667\n",
      "iteration number: 950\t training loss: 131.8196\tvalidation loss: 76.4678\t validation accuracy: 0.9667\n",
      "iteration number: 951\t training loss: 131.6647\tvalidation loss: 76.4451\t validation accuracy: 0.9667\n",
      "iteration number: 952\t training loss: 131.5101\tvalidation loss: 76.4225\t validation accuracy: 0.9667\n",
      "iteration number: 953\t training loss: 131.3558\tvalidation loss: 76.4000\t validation accuracy: 0.9667\n",
      "iteration number: 954\t training loss: 131.2018\tvalidation loss: 76.3775\t validation accuracy: 0.9667\n",
      "iteration number: 955\t training loss: 131.0481\tvalidation loss: 76.3550\t validation accuracy: 0.9667\n",
      "iteration number: 956\t training loss: 130.8948\tvalidation loss: 76.3327\t validation accuracy: 0.9667\n",
      "iteration number: 957\t training loss: 130.7417\tvalidation loss: 76.3104\t validation accuracy: 0.9667\n",
      "iteration number: 958\t training loss: 130.5890\tvalidation loss: 76.2882\t validation accuracy: 0.9667\n",
      "iteration number: 959\t training loss: 130.4365\tvalidation loss: 76.2660\t validation accuracy: 0.9667\n",
      "iteration number: 960\t training loss: 130.2844\tvalidation loss: 76.2439\t validation accuracy: 0.9667\n",
      "iteration number: 961\t training loss: 130.1325\tvalidation loss: 76.2219\t validation accuracy: 0.9667\n",
      "iteration number: 962\t training loss: 129.9810\tvalidation loss: 76.1999\t validation accuracy: 0.9667\n",
      "iteration number: 963\t training loss: 129.8298\tvalidation loss: 76.1780\t validation accuracy: 0.9667\n",
      "iteration number: 964\t training loss: 129.6788\tvalidation loss: 76.1561\t validation accuracy: 0.9667\n",
      "iteration number: 965\t training loss: 129.5282\tvalidation loss: 76.1343\t validation accuracy: 0.9667\n",
      "iteration number: 966\t training loss: 129.3779\tvalidation loss: 76.1126\t validation accuracy: 0.9667\n",
      "iteration number: 967\t training loss: 129.2278\tvalidation loss: 76.0909\t validation accuracy: 0.9667\n",
      "iteration number: 968\t training loss: 129.0781\tvalidation loss: 76.0693\t validation accuracy: 0.9667\n",
      "iteration number: 969\t training loss: 128.9287\tvalidation loss: 76.0477\t validation accuracy: 0.9667\n",
      "iteration number: 970\t training loss: 128.7795\tvalidation loss: 76.0262\t validation accuracy: 0.9667\n",
      "iteration number: 971\t training loss: 128.6307\tvalidation loss: 76.0048\t validation accuracy: 0.9667\n",
      "iteration number: 972\t training loss: 128.4821\tvalidation loss: 75.9834\t validation accuracy: 0.9667\n",
      "iteration number: 973\t training loss: 128.3338\tvalidation loss: 75.9621\t validation accuracy: 0.9667\n",
      "iteration number: 974\t training loss: 128.1859\tvalidation loss: 75.9408\t validation accuracy: 0.9667\n",
      "iteration number: 975\t training loss: 128.0382\tvalidation loss: 75.9196\t validation accuracy: 0.9667\n",
      "iteration number: 976\t training loss: 127.8908\tvalidation loss: 75.8985\t validation accuracy: 0.9667\n",
      "iteration number: 977\t training loss: 127.7437\tvalidation loss: 75.8774\t validation accuracy: 0.9667\n",
      "iteration number: 978\t training loss: 127.5968\tvalidation loss: 75.8564\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 979\t training loss: 127.4503\tvalidation loss: 75.8354\t validation accuracy: 0.9667\n",
      "iteration number: 980\t training loss: 127.3040\tvalidation loss: 75.8145\t validation accuracy: 0.9667\n",
      "iteration number: 981\t training loss: 127.1581\tvalidation loss: 75.7937\t validation accuracy: 0.9667\n",
      "iteration number: 982\t training loss: 127.0124\tvalidation loss: 75.7729\t validation accuracy: 0.9667\n",
      "iteration number: 983\t training loss: 126.8670\tvalidation loss: 75.7521\t validation accuracy: 0.9667\n",
      "iteration number: 984\t training loss: 126.7218\tvalidation loss: 75.7314\t validation accuracy: 0.9667\n",
      "iteration number: 985\t training loss: 126.5770\tvalidation loss: 75.7108\t validation accuracy: 0.9667\n",
      "iteration number: 986\t training loss: 126.4324\tvalidation loss: 75.6902\t validation accuracy: 0.9667\n",
      "iteration number: 987\t training loss: 126.2881\tvalidation loss: 75.6697\t validation accuracy: 0.9667\n",
      "iteration number: 988\t training loss: 126.1441\tvalidation loss: 75.6492\t validation accuracy: 0.9667\n",
      "iteration number: 989\t training loss: 126.0004\tvalidation loss: 75.6288\t validation accuracy: 0.9667\n",
      "iteration number: 990\t training loss: 125.8569\tvalidation loss: 75.6085\t validation accuracy: 0.9667\n",
      "iteration number: 991\t training loss: 125.7138\tvalidation loss: 75.5882\t validation accuracy: 0.9667\n",
      "iteration number: 992\t training loss: 125.5709\tvalidation loss: 75.5679\t validation accuracy: 0.9667\n",
      "iteration number: 993\t training loss: 125.4282\tvalidation loss: 75.5477\t validation accuracy: 0.9667\n",
      "iteration number: 994\t training loss: 125.2859\tvalidation loss: 75.5276\t validation accuracy: 0.9667\n",
      "iteration number: 995\t training loss: 125.1438\tvalidation loss: 75.5075\t validation accuracy: 0.9667\n",
      "iteration number: 996\t training loss: 125.0019\tvalidation loss: 75.4875\t validation accuracy: 0.9667\n",
      "iteration number: 997\t training loss: 124.8604\tvalidation loss: 75.4675\t validation accuracy: 0.9667\n",
      "iteration number: 998\t training loss: 124.7191\tvalidation loss: 75.4476\t validation accuracy: 0.9667\n",
      "iteration number: 999\t training loss: 124.5781\tvalidation loss: 75.4277\t validation accuracy: 0.9667\n",
      "iteration number: 1000\t training loss: 124.4373\tvalidation loss: 75.4079\t validation accuracy: 0.9667\n",
      "iteration number: 1001\t training loss: 124.2969\tvalidation loss: 75.3881\t validation accuracy: 0.9667\n",
      "iteration number: 1002\t training loss: 124.1566\tvalidation loss: 75.3684\t validation accuracy: 0.9667\n",
      "iteration number: 1003\t training loss: 124.0167\tvalidation loss: 75.3487\t validation accuracy: 0.9667\n",
      "iteration number: 1004\t training loss: 123.8770\tvalidation loss: 75.3291\t validation accuracy: 0.9667\n",
      "iteration number: 1005\t training loss: 123.7376\tvalidation loss: 75.3095\t validation accuracy: 0.9667\n",
      "iteration number: 1006\t training loss: 123.5984\tvalidation loss: 75.2900\t validation accuracy: 0.9667\n",
      "iteration number: 1007\t training loss: 123.4595\tvalidation loss: 75.2706\t validation accuracy: 0.9667\n",
      "iteration number: 1008\t training loss: 123.3209\tvalidation loss: 75.2511\t validation accuracy: 0.9667\n",
      "iteration number: 1009\t training loss: 123.1825\tvalidation loss: 75.2318\t validation accuracy: 0.9667\n",
      "iteration number: 1010\t training loss: 123.0443\tvalidation loss: 75.2125\t validation accuracy: 0.9667\n",
      "iteration number: 1011\t training loss: 122.9065\tvalidation loss: 75.1932\t validation accuracy: 0.9667\n",
      "iteration number: 1012\t training loss: 122.7689\tvalidation loss: 75.1740\t validation accuracy: 0.9667\n",
      "iteration number: 1013\t training loss: 122.6315\tvalidation loss: 75.1548\t validation accuracy: 0.9667\n",
      "iteration number: 1014\t training loss: 122.4944\tvalidation loss: 75.1357\t validation accuracy: 0.9667\n",
      "iteration number: 1015\t training loss: 122.3576\tvalidation loss: 75.1166\t validation accuracy: 0.9667\n",
      "iteration number: 1016\t training loss: 122.2210\tvalidation loss: 75.0976\t validation accuracy: 0.9667\n",
      "iteration number: 1017\t training loss: 122.0846\tvalidation loss: 75.0786\t validation accuracy: 0.9667\n",
      "iteration number: 1018\t training loss: 121.9485\tvalidation loss: 75.0597\t validation accuracy: 0.9667\n",
      "iteration number: 1019\t training loss: 121.8127\tvalidation loss: 75.0408\t validation accuracy: 0.9667\n",
      "iteration number: 1020\t training loss: 121.6771\tvalidation loss: 75.0220\t validation accuracy: 0.9667\n",
      "iteration number: 1021\t training loss: 121.5418\tvalidation loss: 75.0032\t validation accuracy: 0.9667\n",
      "iteration number: 1022\t training loss: 121.4067\tvalidation loss: 74.9845\t validation accuracy: 0.9667\n",
      "iteration number: 1023\t training loss: 121.2719\tvalidation loss: 74.9658\t validation accuracy: 0.9667\n",
      "iteration number: 1024\t training loss: 121.1373\tvalidation loss: 74.9472\t validation accuracy: 0.9667\n",
      "iteration number: 1025\t training loss: 121.0029\tvalidation loss: 74.9286\t validation accuracy: 0.9667\n",
      "iteration number: 1026\t training loss: 120.8688\tvalidation loss: 74.9100\t validation accuracy: 0.9667\n",
      "iteration number: 1027\t training loss: 120.7350\tvalidation loss: 74.8915\t validation accuracy: 0.9667\n",
      "iteration number: 1028\t training loss: 120.6014\tvalidation loss: 74.8731\t validation accuracy: 0.9667\n",
      "iteration number: 1029\t training loss: 120.4680\tvalidation loss: 74.8547\t validation accuracy: 0.9667\n",
      "iteration number: 1030\t training loss: 120.3349\tvalidation loss: 74.8363\t validation accuracy: 0.9667\n",
      "iteration number: 1031\t training loss: 120.2020\tvalidation loss: 74.8180\t validation accuracy: 0.9667\n",
      "iteration number: 1032\t training loss: 120.0694\tvalidation loss: 74.7997\t validation accuracy: 0.9667\n",
      "iteration number: 1033\t training loss: 119.9370\tvalidation loss: 74.7815\t validation accuracy: 0.9667\n",
      "iteration number: 1034\t training loss: 119.8048\tvalidation loss: 74.7633\t validation accuracy: 0.9667\n",
      "iteration number: 1035\t training loss: 119.6729\tvalidation loss: 74.7452\t validation accuracy: 0.9667\n",
      "iteration number: 1036\t training loss: 119.5412\tvalidation loss: 74.7271\t validation accuracy: 0.9667\n",
      "iteration number: 1037\t training loss: 119.4098\tvalidation loss: 74.7090\t validation accuracy: 0.9667\n",
      "iteration number: 1038\t training loss: 119.2786\tvalidation loss: 74.6910\t validation accuracy: 0.9667\n",
      "iteration number: 1039\t training loss: 119.1476\tvalidation loss: 74.6731\t validation accuracy: 0.9667\n",
      "iteration number: 1040\t training loss: 119.0169\tvalidation loss: 74.6552\t validation accuracy: 0.9667\n",
      "iteration number: 1041\t training loss: 118.8864\tvalidation loss: 74.6373\t validation accuracy: 0.9667\n",
      "iteration number: 1042\t training loss: 118.7561\tvalidation loss: 74.6195\t validation accuracy: 0.9667\n",
      "iteration number: 1043\t training loss: 118.6261\tvalidation loss: 74.6017\t validation accuracy: 0.9667\n",
      "iteration number: 1044\t training loss: 118.4963\tvalidation loss: 74.5839\t validation accuracy: 0.9667\n",
      "iteration number: 1045\t training loss: 118.3667\tvalidation loss: 74.5662\t validation accuracy: 0.9667\n",
      "iteration number: 1046\t training loss: 118.2374\tvalidation loss: 74.5486\t validation accuracy: 0.9667\n",
      "iteration number: 1047\t training loss: 118.1083\tvalidation loss: 74.5310\t validation accuracy: 0.9667\n",
      "iteration number: 1048\t training loss: 117.9795\tvalidation loss: 74.5134\t validation accuracy: 0.9667\n",
      "iteration number: 1049\t training loss: 117.8508\tvalidation loss: 74.4959\t validation accuracy: 0.9667\n",
      "iteration number: 1050\t training loss: 117.7224\tvalidation loss: 74.4784\t validation accuracy: 0.9667\n",
      "iteration number: 1051\t training loss: 117.5942\tvalidation loss: 74.4609\t validation accuracy: 0.9667\n",
      "iteration number: 1052\t training loss: 117.4663\tvalidation loss: 74.4435\t validation accuracy: 0.9667\n",
      "iteration number: 1053\t training loss: 117.3385\tvalidation loss: 74.4262\t validation accuracy: 0.9667\n",
      "iteration number: 1054\t training loss: 117.2110\tvalidation loss: 74.4088\t validation accuracy: 0.9667\n",
      "iteration number: 1055\t training loss: 117.0838\tvalidation loss: 74.3916\t validation accuracy: 0.9667\n",
      "iteration number: 1056\t training loss: 116.9567\tvalidation loss: 74.3743\t validation accuracy: 0.9667\n",
      "iteration number: 1057\t training loss: 116.8299\tvalidation loss: 74.3571\t validation accuracy: 0.9667\n",
      "iteration number: 1058\t training loss: 116.7033\tvalidation loss: 74.3400\t validation accuracy: 0.9667\n",
      "iteration number: 1059\t training loss: 116.5769\tvalidation loss: 74.3228\t validation accuracy: 0.9667\n",
      "iteration number: 1060\t training loss: 116.4507\tvalidation loss: 74.3058\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1061\t training loss: 116.3248\tvalidation loss: 74.2887\t validation accuracy: 0.9667\n",
      "iteration number: 1062\t training loss: 116.1991\tvalidation loss: 74.2717\t validation accuracy: 0.9667\n",
      "iteration number: 1063\t training loss: 116.0736\tvalidation loss: 74.2548\t validation accuracy: 0.9667\n",
      "iteration number: 1064\t training loss: 115.9483\tvalidation loss: 74.2379\t validation accuracy: 0.9667\n",
      "iteration number: 1065\t training loss: 115.8233\tvalidation loss: 74.2210\t validation accuracy: 0.9667\n",
      "iteration number: 1066\t training loss: 115.6984\tvalidation loss: 74.2041\t validation accuracy: 0.9667\n",
      "iteration number: 1067\t training loss: 115.5738\tvalidation loss: 74.1873\t validation accuracy: 0.9667\n",
      "iteration number: 1068\t training loss: 115.4494\tvalidation loss: 74.1706\t validation accuracy: 0.9667\n",
      "iteration number: 1069\t training loss: 115.3252\tvalidation loss: 74.1539\t validation accuracy: 0.9667\n",
      "iteration number: 1070\t training loss: 115.2013\tvalidation loss: 74.1372\t validation accuracy: 0.9667\n",
      "iteration number: 1071\t training loss: 115.0775\tvalidation loss: 74.1205\t validation accuracy: 0.9667\n",
      "iteration number: 1072\t training loss: 114.9540\tvalidation loss: 74.1039\t validation accuracy: 0.9667\n",
      "iteration number: 1073\t training loss: 114.8306\tvalidation loss: 74.0874\t validation accuracy: 0.9667\n",
      "iteration number: 1074\t training loss: 114.7075\tvalidation loss: 74.0708\t validation accuracy: 0.9667\n",
      "iteration number: 1075\t training loss: 114.5846\tvalidation loss: 74.0543\t validation accuracy: 0.9667\n",
      "iteration number: 1076\t training loss: 114.4620\tvalidation loss: 74.0379\t validation accuracy: 0.9667\n",
      "iteration number: 1077\t training loss: 114.3395\tvalidation loss: 74.0215\t validation accuracy: 0.9667\n",
      "iteration number: 1078\t training loss: 114.2172\tvalidation loss: 74.0051\t validation accuracy: 0.9667\n",
      "iteration number: 1079\t training loss: 114.0952\tvalidation loss: 73.9888\t validation accuracy: 0.9667\n",
      "iteration number: 1080\t training loss: 113.9733\tvalidation loss: 73.9724\t validation accuracy: 0.9667\n",
      "iteration number: 1081\t training loss: 113.8517\tvalidation loss: 73.9562\t validation accuracy: 0.9667\n",
      "iteration number: 1082\t training loss: 113.7303\tvalidation loss: 73.9400\t validation accuracy: 0.9667\n",
      "iteration number: 1083\t training loss: 113.6091\tvalidation loss: 73.9238\t validation accuracy: 0.9667\n",
      "iteration number: 1084\t training loss: 113.4881\tvalidation loss: 73.9076\t validation accuracy: 0.9667\n",
      "iteration number: 1085\t training loss: 113.3673\tvalidation loss: 73.8915\t validation accuracy: 0.9667\n",
      "iteration number: 1086\t training loss: 113.2467\tvalidation loss: 73.8754\t validation accuracy: 0.9667\n",
      "iteration number: 1087\t training loss: 113.1263\tvalidation loss: 73.8594\t validation accuracy: 0.9667\n",
      "iteration number: 1088\t training loss: 113.0061\tvalidation loss: 73.8433\t validation accuracy: 0.9667\n",
      "iteration number: 1089\t training loss: 112.8861\tvalidation loss: 73.8274\t validation accuracy: 0.9667\n",
      "iteration number: 1090\t training loss: 112.7663\tvalidation loss: 73.8114\t validation accuracy: 0.9667\n",
      "iteration number: 1091\t training loss: 112.6468\tvalidation loss: 73.7955\t validation accuracy: 0.9667\n",
      "iteration number: 1092\t training loss: 112.5274\tvalidation loss: 73.7797\t validation accuracy: 0.9667\n",
      "iteration number: 1093\t training loss: 112.4082\tvalidation loss: 73.7638\t validation accuracy: 0.9667\n",
      "iteration number: 1094\t training loss: 112.2893\tvalidation loss: 73.7480\t validation accuracy: 0.9667\n",
      "iteration number: 1095\t training loss: 112.1705\tvalidation loss: 73.7323\t validation accuracy: 0.9667\n",
      "iteration number: 1096\t training loss: 112.0520\tvalidation loss: 73.7166\t validation accuracy: 0.9667\n",
      "iteration number: 1097\t training loss: 111.9336\tvalidation loss: 73.7009\t validation accuracy: 0.9667\n",
      "iteration number: 1098\t training loss: 111.8154\tvalidation loss: 73.6852\t validation accuracy: 0.9667\n",
      "iteration number: 1099\t training loss: 111.6975\tvalidation loss: 73.6696\t validation accuracy: 0.9667\n",
      "iteration number: 1100\t training loss: 111.5797\tvalidation loss: 73.6540\t validation accuracy: 0.9667\n",
      "iteration number: 1101\t training loss: 111.4622\tvalidation loss: 73.6384\t validation accuracy: 0.9667\n",
      "iteration number: 1102\t training loss: 111.3448\tvalidation loss: 73.6229\t validation accuracy: 0.9667\n",
      "iteration number: 1103\t training loss: 111.2276\tvalidation loss: 73.6074\t validation accuracy: 0.9667\n",
      "iteration number: 1104\t training loss: 111.1107\tvalidation loss: 73.5920\t validation accuracy: 0.9667\n",
      "iteration number: 1105\t training loss: 110.9939\tvalidation loss: 73.5766\t validation accuracy: 0.9667\n",
      "iteration number: 1106\t training loss: 110.8773\tvalidation loss: 73.5612\t validation accuracy: 0.9667\n",
      "iteration number: 1107\t training loss: 110.7609\tvalidation loss: 73.5458\t validation accuracy: 0.9667\n",
      "iteration number: 1108\t training loss: 110.6447\tvalidation loss: 73.5305\t validation accuracy: 0.9667\n",
      "iteration number: 1109\t training loss: 110.5287\tvalidation loss: 73.5152\t validation accuracy: 0.9667\n",
      "iteration number: 1110\t training loss: 110.4129\tvalidation loss: 73.5000\t validation accuracy: 0.9667\n",
      "iteration number: 1111\t training loss: 110.2973\tvalidation loss: 73.4848\t validation accuracy: 0.9667\n",
      "iteration number: 1112\t training loss: 110.1819\tvalidation loss: 73.4696\t validation accuracy: 0.9667\n",
      "iteration number: 1113\t training loss: 110.0667\tvalidation loss: 73.4544\t validation accuracy: 0.9667\n",
      "iteration number: 1114\t training loss: 109.9517\tvalidation loss: 73.4393\t validation accuracy: 0.9667\n",
      "iteration number: 1115\t training loss: 109.8368\tvalidation loss: 73.4242\t validation accuracy: 0.9667\n",
      "iteration number: 1116\t training loss: 109.7222\tvalidation loss: 73.4092\t validation accuracy: 0.9667\n",
      "iteration number: 1117\t training loss: 109.6077\tvalidation loss: 73.3942\t validation accuracy: 0.9667\n",
      "iteration number: 1118\t training loss: 109.4934\tvalidation loss: 73.3792\t validation accuracy: 0.9667\n",
      "iteration number: 1119\t training loss: 109.3794\tvalidation loss: 73.3642\t validation accuracy: 0.9667\n",
      "iteration number: 1120\t training loss: 109.2655\tvalidation loss: 73.3493\t validation accuracy: 0.9667\n",
      "iteration number: 1121\t training loss: 109.1518\tvalidation loss: 73.3344\t validation accuracy: 0.9667\n",
      "iteration number: 1122\t training loss: 109.0382\tvalidation loss: 73.3196\t validation accuracy: 0.9667\n",
      "iteration number: 1123\t training loss: 108.9249\tvalidation loss: 73.3047\t validation accuracy: 0.9667\n",
      "iteration number: 1124\t training loss: 108.8118\tvalidation loss: 73.2899\t validation accuracy: 0.9667\n",
      "iteration number: 1125\t training loss: 108.6988\tvalidation loss: 73.2752\t validation accuracy: 0.9667\n",
      "iteration number: 1126\t training loss: 108.5860\tvalidation loss: 73.2604\t validation accuracy: 0.9667\n",
      "iteration number: 1127\t training loss: 108.4734\tvalidation loss: 73.2457\t validation accuracy: 0.9667\n",
      "iteration number: 1128\t training loss: 108.3610\tvalidation loss: 73.2311\t validation accuracy: 0.9667\n",
      "iteration number: 1129\t training loss: 108.2488\tvalidation loss: 73.2164\t validation accuracy: 0.9667\n",
      "iteration number: 1130\t training loss: 108.1368\tvalidation loss: 73.2018\t validation accuracy: 0.9667\n",
      "iteration number: 1131\t training loss: 108.0249\tvalidation loss: 73.1872\t validation accuracy: 0.9667\n",
      "iteration number: 1132\t training loss: 107.9133\tvalidation loss: 73.1727\t validation accuracy: 0.9667\n",
      "iteration number: 1133\t training loss: 107.8018\tvalidation loss: 73.1582\t validation accuracy: 0.9667\n",
      "iteration number: 1134\t training loss: 107.6905\tvalidation loss: 73.1437\t validation accuracy: 0.9667\n",
      "iteration number: 1135\t training loss: 107.5793\tvalidation loss: 73.1292\t validation accuracy: 0.9667\n",
      "iteration number: 1136\t training loss: 107.4684\tvalidation loss: 73.1148\t validation accuracy: 0.9667\n",
      "iteration number: 1137\t training loss: 107.3576\tvalidation loss: 73.1004\t validation accuracy: 0.9667\n",
      "iteration number: 1138\t training loss: 107.2470\tvalidation loss: 73.0860\t validation accuracy: 0.9667\n",
      "iteration number: 1139\t training loss: 107.1366\tvalidation loss: 73.0717\t validation accuracy: 0.9667\n",
      "iteration number: 1140\t training loss: 107.0264\tvalidation loss: 73.0574\t validation accuracy: 0.9667\n",
      "iteration number: 1141\t training loss: 106.9164\tvalidation loss: 73.0431\t validation accuracy: 0.9667\n",
      "iteration number: 1142\t training loss: 106.8065\tvalidation loss: 73.0289\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1143\t training loss: 106.6968\tvalidation loss: 73.0147\t validation accuracy: 0.9667\n",
      "iteration number: 1144\t training loss: 106.5873\tvalidation loss: 73.0005\t validation accuracy: 0.9667\n",
      "iteration number: 1145\t training loss: 106.4779\tvalidation loss: 72.9863\t validation accuracy: 0.9667\n",
      "iteration number: 1146\t training loss: 106.3688\tvalidation loss: 72.9722\t validation accuracy: 0.9667\n",
      "iteration number: 1147\t training loss: 106.2598\tvalidation loss: 72.9581\t validation accuracy: 0.9667\n",
      "iteration number: 1148\t training loss: 106.1510\tvalidation loss: 72.9440\t validation accuracy: 0.9667\n",
      "iteration number: 1149\t training loss: 106.0423\tvalidation loss: 72.9300\t validation accuracy: 0.9667\n",
      "iteration number: 1150\t training loss: 105.9339\tvalidation loss: 72.9160\t validation accuracy: 0.9667\n",
      "iteration number: 1151\t training loss: 105.8256\tvalidation loss: 72.9020\t validation accuracy: 0.9667\n",
      "iteration number: 1152\t training loss: 105.7175\tvalidation loss: 72.8880\t validation accuracy: 0.9667\n",
      "iteration number: 1153\t training loss: 105.6095\tvalidation loss: 72.8741\t validation accuracy: 0.9667\n",
      "iteration number: 1154\t training loss: 105.5018\tvalidation loss: 72.8602\t validation accuracy: 0.9667\n",
      "iteration number: 1155\t training loss: 105.3942\tvalidation loss: 72.8463\t validation accuracy: 0.9667\n",
      "iteration number: 1156\t training loss: 105.2867\tvalidation loss: 72.8325\t validation accuracy: 0.9667\n",
      "iteration number: 1157\t training loss: 105.1795\tvalidation loss: 72.8187\t validation accuracy: 0.9667\n",
      "iteration number: 1158\t training loss: 105.0724\tvalidation loss: 72.8049\t validation accuracy: 0.9667\n",
      "iteration number: 1159\t training loss: 104.9655\tvalidation loss: 72.7912\t validation accuracy: 0.9667\n",
      "iteration number: 1160\t training loss: 104.8587\tvalidation loss: 72.7774\t validation accuracy: 0.9667\n",
      "iteration number: 1161\t training loss: 104.7522\tvalidation loss: 72.7637\t validation accuracy: 0.9667\n",
      "iteration number: 1162\t training loss: 104.6458\tvalidation loss: 72.7501\t validation accuracy: 0.9667\n",
      "iteration number: 1163\t training loss: 104.5395\tvalidation loss: 72.7364\t validation accuracy: 0.9667\n",
      "iteration number: 1164\t training loss: 104.4335\tvalidation loss: 72.7228\t validation accuracy: 0.9667\n",
      "iteration number: 1165\t training loss: 104.3276\tvalidation loss: 72.7092\t validation accuracy: 0.9667\n",
      "iteration number: 1166\t training loss: 104.2218\tvalidation loss: 72.6956\t validation accuracy: 0.9667\n",
      "iteration number: 1167\t training loss: 104.1163\tvalidation loss: 72.6821\t validation accuracy: 0.9667\n",
      "iteration number: 1168\t training loss: 104.0109\tvalidation loss: 72.6686\t validation accuracy: 0.9667\n",
      "iteration number: 1169\t training loss: 103.9056\tvalidation loss: 72.6551\t validation accuracy: 0.9667\n",
      "iteration number: 1170\t training loss: 103.8006\tvalidation loss: 72.6417\t validation accuracy: 0.9667\n",
      "iteration number: 1171\t training loss: 103.6957\tvalidation loss: 72.6282\t validation accuracy: 0.9667\n",
      "iteration number: 1172\t training loss: 103.5909\tvalidation loss: 72.6148\t validation accuracy: 0.9667\n",
      "iteration number: 1173\t training loss: 103.4864\tvalidation loss: 72.6015\t validation accuracy: 0.9667\n",
      "iteration number: 1174\t training loss: 103.3820\tvalidation loss: 72.5881\t validation accuracy: 0.9667\n",
      "iteration number: 1175\t training loss: 103.2777\tvalidation loss: 72.5748\t validation accuracy: 0.9667\n",
      "iteration number: 1176\t training loss: 103.1737\tvalidation loss: 72.5615\t validation accuracy: 0.9667\n",
      "iteration number: 1177\t training loss: 103.0697\tvalidation loss: 72.5482\t validation accuracy: 0.9667\n",
      "iteration number: 1178\t training loss: 102.9660\tvalidation loss: 72.5350\t validation accuracy: 0.9667\n",
      "iteration number: 1179\t training loss: 102.8624\tvalidation loss: 72.5218\t validation accuracy: 0.9667\n",
      "iteration number: 1180\t training loss: 102.7590\tvalidation loss: 72.5086\t validation accuracy: 0.9667\n",
      "iteration number: 1181\t training loss: 102.6557\tvalidation loss: 72.4954\t validation accuracy: 0.9667\n",
      "iteration number: 1182\t training loss: 102.5526\tvalidation loss: 72.4823\t validation accuracy: 0.9667\n",
      "iteration number: 1183\t training loss: 102.4497\tvalidation loss: 72.4692\t validation accuracy: 0.9667\n",
      "iteration number: 1184\t training loss: 102.3469\tvalidation loss: 72.4561\t validation accuracy: 0.9667\n",
      "iteration number: 1185\t training loss: 102.2442\tvalidation loss: 72.4430\t validation accuracy: 0.9667\n",
      "iteration number: 1186\t training loss: 102.1418\tvalidation loss: 72.4300\t validation accuracy: 0.9667\n",
      "iteration number: 1187\t training loss: 102.0395\tvalidation loss: 72.4170\t validation accuracy: 0.9667\n",
      "iteration number: 1188\t training loss: 101.9373\tvalidation loss: 72.4040\t validation accuracy: 0.9667\n",
      "iteration number: 1189\t training loss: 101.8353\tvalidation loss: 72.3911\t validation accuracy: 0.9667\n",
      "iteration number: 1190\t training loss: 101.7335\tvalidation loss: 72.3781\t validation accuracy: 0.9667\n",
      "iteration number: 1191\t training loss: 101.6319\tvalidation loss: 72.3652\t validation accuracy: 0.9667\n",
      "iteration number: 1192\t training loss: 101.5303\tvalidation loss: 72.3524\t validation accuracy: 0.9667\n",
      "iteration number: 1193\t training loss: 101.4290\tvalidation loss: 72.3395\t validation accuracy: 0.9667\n",
      "iteration number: 1194\t training loss: 101.3278\tvalidation loss: 72.3267\t validation accuracy: 0.9667\n",
      "iteration number: 1195\t training loss: 101.2267\tvalidation loss: 72.3139\t validation accuracy: 0.9667\n",
      "iteration number: 1196\t training loss: 101.1258\tvalidation loss: 72.3011\t validation accuracy: 0.9667\n",
      "iteration number: 1197\t training loss: 101.0251\tvalidation loss: 72.2883\t validation accuracy: 0.9667\n",
      "iteration number: 1198\t training loss: 100.9245\tvalidation loss: 72.2756\t validation accuracy: 0.9667\n",
      "iteration number: 1199\t training loss: 100.8241\tvalidation loss: 72.2629\t validation accuracy: 0.9667\n",
      "iteration number: 1200\t training loss: 100.7238\tvalidation loss: 72.2502\t validation accuracy: 0.9667\n",
      "iteration number: 1201\t training loss: 100.6237\tvalidation loss: 72.2376\t validation accuracy: 0.9667\n",
      "iteration number: 1202\t training loss: 100.5238\tvalidation loss: 72.2249\t validation accuracy: 0.9667\n",
      "iteration number: 1203\t training loss: 100.4240\tvalidation loss: 72.2123\t validation accuracy: 0.9667\n",
      "iteration number: 1204\t training loss: 100.3243\tvalidation loss: 72.1997\t validation accuracy: 0.9667\n",
      "iteration number: 1205\t training loss: 100.2248\tvalidation loss: 72.1872\t validation accuracy: 0.9667\n",
      "iteration number: 1206\t training loss: 100.1255\tvalidation loss: 72.1746\t validation accuracy: 0.9667\n",
      "iteration number: 1207\t training loss: 100.0263\tvalidation loss: 72.1621\t validation accuracy: 0.9667\n",
      "iteration number: 1208\t training loss: 99.9272\tvalidation loss: 72.1496\t validation accuracy: 0.9667\n",
      "iteration number: 1209\t training loss: 99.8283\tvalidation loss: 72.1372\t validation accuracy: 0.9667\n",
      "iteration number: 1210\t training loss: 99.7296\tvalidation loss: 72.1247\t validation accuracy: 0.9667\n",
      "iteration number: 1211\t training loss: 99.6310\tvalidation loss: 72.1123\t validation accuracy: 0.9667\n",
      "iteration number: 1212\t training loss: 99.5325\tvalidation loss: 72.0999\t validation accuracy: 0.9667\n",
      "iteration number: 1213\t training loss: 99.4343\tvalidation loss: 72.0876\t validation accuracy: 0.9667\n",
      "iteration number: 1214\t training loss: 99.3361\tvalidation loss: 72.0752\t validation accuracy: 0.9667\n",
      "iteration number: 1215\t training loss: 99.2381\tvalidation loss: 72.0629\t validation accuracy: 0.9667\n",
      "iteration number: 1216\t training loss: 99.1403\tvalidation loss: 72.0506\t validation accuracy: 0.9667\n",
      "iteration number: 1217\t training loss: 99.0426\tvalidation loss: 72.0383\t validation accuracy: 0.9667\n",
      "iteration number: 1218\t training loss: 98.9450\tvalidation loss: 72.0261\t validation accuracy: 0.9667\n",
      "iteration number: 1219\t training loss: 98.8476\tvalidation loss: 72.0139\t validation accuracy: 0.9667\n",
      "iteration number: 1220\t training loss: 98.7504\tvalidation loss: 72.0017\t validation accuracy: 0.9667\n",
      "iteration number: 1221\t training loss: 98.6533\tvalidation loss: 71.9895\t validation accuracy: 0.9667\n",
      "iteration number: 1222\t training loss: 98.5563\tvalidation loss: 71.9773\t validation accuracy: 0.9667\n",
      "iteration number: 1223\t training loss: 98.4595\tvalidation loss: 71.9652\t validation accuracy: 0.9667\n",
      "iteration number: 1224\t training loss: 98.3628\tvalidation loss: 71.9531\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1225\t training loss: 98.2663\tvalidation loss: 71.9410\t validation accuracy: 0.9667\n",
      "iteration number: 1226\t training loss: 98.1699\tvalidation loss: 71.9289\t validation accuracy: 0.9667\n",
      "iteration number: 1227\t training loss: 98.0737\tvalidation loss: 71.9169\t validation accuracy: 0.9667\n",
      "iteration number: 1228\t training loss: 97.9776\tvalidation loss: 71.9049\t validation accuracy: 0.9667\n",
      "iteration number: 1229\t training loss: 97.8817\tvalidation loss: 71.8929\t validation accuracy: 0.9667\n",
      "iteration number: 1230\t training loss: 97.7859\tvalidation loss: 71.8809\t validation accuracy: 0.9667\n",
      "iteration number: 1231\t training loss: 97.6902\tvalidation loss: 71.8689\t validation accuracy: 0.9667\n",
      "iteration number: 1232\t training loss: 97.5947\tvalidation loss: 71.8570\t validation accuracy: 0.9667\n",
      "iteration number: 1233\t training loss: 97.4993\tvalidation loss: 71.8451\t validation accuracy: 0.9667\n",
      "iteration number: 1234\t training loss: 97.4041\tvalidation loss: 71.8332\t validation accuracy: 0.9667\n",
      "iteration number: 1235\t training loss: 97.3090\tvalidation loss: 71.8214\t validation accuracy: 0.9667\n",
      "iteration number: 1236\t training loss: 97.2141\tvalidation loss: 71.8095\t validation accuracy: 0.9667\n",
      "iteration number: 1237\t training loss: 97.1193\tvalidation loss: 71.7977\t validation accuracy: 0.9667\n",
      "iteration number: 1238\t training loss: 97.0246\tvalidation loss: 71.7859\t validation accuracy: 0.9667\n",
      "iteration number: 1239\t training loss: 96.9301\tvalidation loss: 71.7741\t validation accuracy: 0.9667\n",
      "iteration number: 1240\t training loss: 96.8357\tvalidation loss: 71.7624\t validation accuracy: 0.9667\n",
      "iteration number: 1241\t training loss: 96.7415\tvalidation loss: 71.7506\t validation accuracy: 0.9667\n",
      "iteration number: 1242\t training loss: 96.6474\tvalidation loss: 71.7389\t validation accuracy: 0.9667\n",
      "iteration number: 1243\t training loss: 96.5534\tvalidation loss: 71.7272\t validation accuracy: 0.9667\n",
      "iteration number: 1244\t training loss: 96.4596\tvalidation loss: 71.7156\t validation accuracy: 0.9667\n",
      "iteration number: 1245\t training loss: 96.3659\tvalidation loss: 71.7039\t validation accuracy: 0.9667\n",
      "iteration number: 1246\t training loss: 96.2724\tvalidation loss: 71.6923\t validation accuracy: 0.9667\n",
      "iteration number: 1247\t training loss: 96.1790\tvalidation loss: 71.6807\t validation accuracy: 0.9667\n",
      "iteration number: 1248\t training loss: 96.0858\tvalidation loss: 71.6691\t validation accuracy: 0.9667\n",
      "iteration number: 1249\t training loss: 95.9926\tvalidation loss: 71.6576\t validation accuracy: 0.9667\n",
      "iteration number: 1250\t training loss: 95.8996\tvalidation loss: 71.6460\t validation accuracy: 0.9667\n",
      "iteration number: 1251\t training loss: 95.8068\tvalidation loss: 71.6345\t validation accuracy: 0.9667\n",
      "iteration number: 1252\t training loss: 95.7141\tvalidation loss: 71.6230\t validation accuracy: 0.9667\n",
      "iteration number: 1253\t training loss: 95.6215\tvalidation loss: 71.6116\t validation accuracy: 0.9667\n",
      "iteration number: 1254\t training loss: 95.5291\tvalidation loss: 71.6001\t validation accuracy: 0.9667\n",
      "iteration number: 1255\t training loss: 95.4368\tvalidation loss: 71.5887\t validation accuracy: 0.9667\n",
      "iteration number: 1256\t training loss: 95.3446\tvalidation loss: 71.5773\t validation accuracy: 0.9667\n",
      "iteration number: 1257\t training loss: 95.2526\tvalidation loss: 71.5659\t validation accuracy: 0.9667\n",
      "iteration number: 1258\t training loss: 95.1607\tvalidation loss: 71.5545\t validation accuracy: 0.9667\n",
      "iteration number: 1259\t training loss: 95.0689\tvalidation loss: 71.5432\t validation accuracy: 0.9667\n",
      "iteration number: 1260\t training loss: 94.9773\tvalidation loss: 71.5318\t validation accuracy: 0.9667\n",
      "iteration number: 1261\t training loss: 94.8858\tvalidation loss: 71.5205\t validation accuracy: 0.9667\n",
      "iteration number: 1262\t training loss: 94.7945\tvalidation loss: 71.5092\t validation accuracy: 0.9667\n",
      "iteration number: 1263\t training loss: 94.7033\tvalidation loss: 71.4980\t validation accuracy: 0.9667\n",
      "iteration number: 1264\t training loss: 94.6122\tvalidation loss: 71.4867\t validation accuracy: 0.9667\n",
      "iteration number: 1265\t training loss: 94.5212\tvalidation loss: 71.4755\t validation accuracy: 0.9667\n",
      "iteration number: 1266\t training loss: 94.4304\tvalidation loss: 71.4643\t validation accuracy: 0.9667\n",
      "iteration number: 1267\t training loss: 94.3397\tvalidation loss: 71.4531\t validation accuracy: 0.9667\n",
      "iteration number: 1268\t training loss: 94.2492\tvalidation loss: 71.4420\t validation accuracy: 0.9667\n",
      "iteration number: 1269\t training loss: 94.1587\tvalidation loss: 71.4308\t validation accuracy: 0.9667\n",
      "iteration number: 1270\t training loss: 94.0684\tvalidation loss: 71.4197\t validation accuracy: 0.9667\n",
      "iteration number: 1271\t training loss: 93.9783\tvalidation loss: 71.4086\t validation accuracy: 0.9667\n",
      "iteration number: 1272\t training loss: 93.8883\tvalidation loss: 71.3975\t validation accuracy: 0.9667\n",
      "iteration number: 1273\t training loss: 93.7984\tvalidation loss: 71.3865\t validation accuracy: 0.9667\n",
      "iteration number: 1274\t training loss: 93.7086\tvalidation loss: 71.3754\t validation accuracy: 0.9667\n",
      "iteration number: 1275\t training loss: 93.6190\tvalidation loss: 71.3644\t validation accuracy: 0.9667\n",
      "iteration number: 1276\t training loss: 93.5295\tvalidation loss: 71.3534\t validation accuracy: 0.9667\n",
      "iteration number: 1277\t training loss: 93.4401\tvalidation loss: 71.3424\t validation accuracy: 0.9667\n",
      "iteration number: 1278\t training loss: 93.3508\tvalidation loss: 71.3315\t validation accuracy: 0.9667\n",
      "iteration number: 1279\t training loss: 93.2617\tvalidation loss: 71.3205\t validation accuracy: 0.9667\n",
      "iteration number: 1280\t training loss: 93.1727\tvalidation loss: 71.3096\t validation accuracy: 0.9667\n",
      "iteration number: 1281\t training loss: 93.0839\tvalidation loss: 71.2987\t validation accuracy: 0.9667\n",
      "iteration number: 1282\t training loss: 92.9951\tvalidation loss: 71.2878\t validation accuracy: 0.9667\n",
      "iteration number: 1283\t training loss: 92.9065\tvalidation loss: 71.2770\t validation accuracy: 0.9667\n",
      "iteration number: 1284\t training loss: 92.8181\tvalidation loss: 71.2661\t validation accuracy: 0.9667\n",
      "iteration number: 1285\t training loss: 92.7297\tvalidation loss: 71.2553\t validation accuracy: 0.9667\n",
      "iteration number: 1286\t training loss: 92.6415\tvalidation loss: 71.2445\t validation accuracy: 0.9667\n",
      "iteration number: 1287\t training loss: 92.5534\tvalidation loss: 71.2337\t validation accuracy: 0.9667\n",
      "iteration number: 1288\t training loss: 92.4655\tvalidation loss: 71.2230\t validation accuracy: 0.9667\n",
      "iteration number: 1289\t training loss: 92.3776\tvalidation loss: 71.2122\t validation accuracy: 0.9667\n",
      "iteration number: 1290\t training loss: 92.2899\tvalidation loss: 71.2015\t validation accuracy: 0.9667\n",
      "iteration number: 1291\t training loss: 92.2023\tvalidation loss: 71.1908\t validation accuracy: 0.9667\n",
      "iteration number: 1292\t training loss: 92.1149\tvalidation loss: 71.1801\t validation accuracy: 0.9667\n",
      "iteration number: 1293\t training loss: 92.0275\tvalidation loss: 71.1694\t validation accuracy: 0.9667\n",
      "iteration number: 1294\t training loss: 91.9403\tvalidation loss: 71.1588\t validation accuracy: 0.9667\n",
      "iteration number: 1295\t training loss: 91.8532\tvalidation loss: 71.1482\t validation accuracy: 0.9667\n",
      "iteration number: 1296\t training loss: 91.7663\tvalidation loss: 71.1375\t validation accuracy: 0.9667\n",
      "iteration number: 1297\t training loss: 91.6795\tvalidation loss: 71.1270\t validation accuracy: 0.9667\n",
      "iteration number: 1298\t training loss: 91.5927\tvalidation loss: 71.1164\t validation accuracy: 0.9667\n",
      "iteration number: 1299\t training loss: 91.5062\tvalidation loss: 71.1058\t validation accuracy: 0.9667\n",
      "iteration number: 1300\t training loss: 91.4197\tvalidation loss: 71.0953\t validation accuracy: 0.9667\n",
      "iteration number: 1301\t training loss: 91.3334\tvalidation loss: 71.0848\t validation accuracy: 0.9667\n",
      "iteration number: 1302\t training loss: 91.2472\tvalidation loss: 71.0743\t validation accuracy: 0.9667\n",
      "iteration number: 1303\t training loss: 91.1611\tvalidation loss: 71.0638\t validation accuracy: 0.9667\n",
      "iteration number: 1304\t training loss: 91.0751\tvalidation loss: 71.0533\t validation accuracy: 0.9667\n",
      "iteration number: 1305\t training loss: 90.9893\tvalidation loss: 71.0429\t validation accuracy: 0.9667\n",
      "iteration number: 1306\t training loss: 90.9035\tvalidation loss: 71.0325\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1307\t training loss: 90.8179\tvalidation loss: 71.0221\t validation accuracy: 0.9667\n",
      "iteration number: 1308\t training loss: 90.7324\tvalidation loss: 71.0117\t validation accuracy: 0.9667\n",
      "iteration number: 1309\t training loss: 90.6471\tvalidation loss: 71.0013\t validation accuracy: 0.9667\n",
      "iteration number: 1310\t training loss: 90.5619\tvalidation loss: 70.9910\t validation accuracy: 0.9667\n",
      "iteration number: 1311\t training loss: 90.4767\tvalidation loss: 70.9806\t validation accuracy: 0.9667\n",
      "iteration number: 1312\t training loss: 90.3917\tvalidation loss: 70.9703\t validation accuracy: 0.9667\n",
      "iteration number: 1313\t training loss: 90.3069\tvalidation loss: 70.9600\t validation accuracy: 0.9667\n",
      "iteration number: 1314\t training loss: 90.2221\tvalidation loss: 70.9498\t validation accuracy: 0.9667\n",
      "iteration number: 1315\t training loss: 90.1375\tvalidation loss: 70.9395\t validation accuracy: 0.9667\n",
      "iteration number: 1316\t training loss: 90.0530\tvalidation loss: 70.9293\t validation accuracy: 0.9667\n",
      "iteration number: 1317\t training loss: 89.9686\tvalidation loss: 70.9191\t validation accuracy: 0.9667\n",
      "iteration number: 1318\t training loss: 89.8843\tvalidation loss: 70.9089\t validation accuracy: 0.9667\n",
      "iteration number: 1319\t training loss: 89.8001\tvalidation loss: 70.8987\t validation accuracy: 0.9667\n",
      "iteration number: 1320\t training loss: 89.7161\tvalidation loss: 70.8885\t validation accuracy: 0.9667\n",
      "iteration number: 1321\t training loss: 89.6322\tvalidation loss: 70.8784\t validation accuracy: 0.9667\n",
      "iteration number: 1322\t training loss: 89.5484\tvalidation loss: 70.8682\t validation accuracy: 0.9667\n",
      "iteration number: 1323\t training loss: 89.4647\tvalidation loss: 70.8581\t validation accuracy: 0.9667\n",
      "iteration number: 1324\t training loss: 89.3811\tvalidation loss: 70.8480\t validation accuracy: 0.9667\n",
      "iteration number: 1325\t training loss: 89.2977\tvalidation loss: 70.8379\t validation accuracy: 0.9667\n",
      "iteration number: 1326\t training loss: 89.2144\tvalidation loss: 70.8279\t validation accuracy: 0.9667\n",
      "iteration number: 1327\t training loss: 89.1312\tvalidation loss: 70.8178\t validation accuracy: 0.9667\n",
      "iteration number: 1328\t training loss: 89.0481\tvalidation loss: 70.8078\t validation accuracy: 0.9667\n",
      "iteration number: 1329\t training loss: 88.9651\tvalidation loss: 70.7978\t validation accuracy: 0.9667\n",
      "iteration number: 1330\t training loss: 88.8822\tvalidation loss: 70.7878\t validation accuracy: 0.9667\n",
      "iteration number: 1331\t training loss: 88.7995\tvalidation loss: 70.7779\t validation accuracy: 0.9667\n",
      "iteration number: 1332\t training loss: 88.7169\tvalidation loss: 70.7679\t validation accuracy: 0.9667\n",
      "iteration number: 1333\t training loss: 88.6343\tvalidation loss: 70.7580\t validation accuracy: 0.9667\n",
      "iteration number: 1334\t training loss: 88.5519\tvalidation loss: 70.7480\t validation accuracy: 0.9667\n",
      "iteration number: 1335\t training loss: 88.4697\tvalidation loss: 70.7381\t validation accuracy: 0.9667\n",
      "iteration number: 1336\t training loss: 88.3875\tvalidation loss: 70.7283\t validation accuracy: 0.9667\n",
      "iteration number: 1337\t training loss: 88.3054\tvalidation loss: 70.7184\t validation accuracy: 0.9667\n",
      "iteration number: 1338\t training loss: 88.2235\tvalidation loss: 70.7086\t validation accuracy: 0.9667\n",
      "iteration number: 1339\t training loss: 88.1417\tvalidation loss: 70.6987\t validation accuracy: 0.9667\n",
      "iteration number: 1340\t training loss: 88.0600\tvalidation loss: 70.6889\t validation accuracy: 0.9667\n",
      "iteration number: 1341\t training loss: 87.9784\tvalidation loss: 70.6791\t validation accuracy: 0.9667\n",
      "iteration number: 1342\t training loss: 87.8969\tvalidation loss: 70.6693\t validation accuracy: 0.9667\n",
      "iteration number: 1343\t training loss: 87.8155\tvalidation loss: 70.6596\t validation accuracy: 0.9667\n",
      "iteration number: 1344\t training loss: 87.7343\tvalidation loss: 70.6498\t validation accuracy: 0.9667\n",
      "iteration number: 1345\t training loss: 87.6531\tvalidation loss: 70.6401\t validation accuracy: 0.9667\n",
      "iteration number: 1346\t training loss: 87.5721\tvalidation loss: 70.6304\t validation accuracy: 0.9667\n",
      "iteration number: 1347\t training loss: 87.4912\tvalidation loss: 70.6207\t validation accuracy: 0.9667\n",
      "iteration number: 1348\t training loss: 87.4104\tvalidation loss: 70.6110\t validation accuracy: 0.9667\n",
      "iteration number: 1349\t training loss: 87.3297\tvalidation loss: 70.6014\t validation accuracy: 0.9667\n",
      "iteration number: 1350\t training loss: 87.2491\tvalidation loss: 70.5917\t validation accuracy: 0.9667\n",
      "iteration number: 1351\t training loss: 87.1687\tvalidation loss: 70.5821\t validation accuracy: 0.9667\n",
      "iteration number: 1352\t training loss: 87.0883\tvalidation loss: 70.5725\t validation accuracy: 0.9667\n",
      "iteration number: 1353\t training loss: 87.0081\tvalidation loss: 70.5629\t validation accuracy: 0.9667\n",
      "iteration number: 1354\t training loss: 86.9279\tvalidation loss: 70.5533\t validation accuracy: 0.9667\n",
      "iteration number: 1355\t training loss: 86.8479\tvalidation loss: 70.5438\t validation accuracy: 0.9667\n",
      "iteration number: 1356\t training loss: 86.7680\tvalidation loss: 70.5342\t validation accuracy: 0.9667\n",
      "iteration number: 1357\t training loss: 86.6882\tvalidation loss: 70.5247\t validation accuracy: 0.9667\n",
      "iteration number: 1358\t training loss: 86.6085\tvalidation loss: 70.5152\t validation accuracy: 0.9667\n",
      "iteration number: 1359\t training loss: 86.5289\tvalidation loss: 70.5057\t validation accuracy: 0.9667\n",
      "iteration number: 1360\t training loss: 86.4494\tvalidation loss: 70.4962\t validation accuracy: 0.9667\n",
      "iteration number: 1361\t training loss: 86.3701\tvalidation loss: 70.4868\t validation accuracy: 0.9667\n",
      "iteration number: 1362\t training loss: 86.2908\tvalidation loss: 70.4773\t validation accuracy: 0.9667\n",
      "iteration number: 1363\t training loss: 86.2117\tvalidation loss: 70.4679\t validation accuracy: 0.9667\n",
      "iteration number: 1364\t training loss: 86.1327\tvalidation loss: 70.4585\t validation accuracy: 0.9667\n",
      "iteration number: 1365\t training loss: 86.0537\tvalidation loss: 70.4491\t validation accuracy: 0.9667\n",
      "iteration number: 1366\t training loss: 85.9749\tvalidation loss: 70.4397\t validation accuracy: 0.9667\n",
      "iteration number: 1367\t training loss: 85.8962\tvalidation loss: 70.4304\t validation accuracy: 0.9667\n",
      "iteration number: 1368\t training loss: 85.8176\tvalidation loss: 70.4210\t validation accuracy: 0.9667\n",
      "iteration number: 1369\t training loss: 85.7391\tvalidation loss: 70.4117\t validation accuracy: 0.9667\n",
      "iteration number: 1370\t training loss: 85.6607\tvalidation loss: 70.4024\t validation accuracy: 0.9667\n",
      "iteration number: 1371\t training loss: 85.5825\tvalidation loss: 70.3931\t validation accuracy: 0.9667\n",
      "iteration number: 1372\t training loss: 85.5043\tvalidation loss: 70.3838\t validation accuracy: 0.9667\n",
      "iteration number: 1373\t training loss: 85.4262\tvalidation loss: 70.3745\t validation accuracy: 0.9667\n",
      "iteration number: 1374\t training loss: 85.3483\tvalidation loss: 70.3653\t validation accuracy: 0.9667\n",
      "iteration number: 1375\t training loss: 85.2704\tvalidation loss: 70.3561\t validation accuracy: 0.9667\n",
      "iteration number: 1376\t training loss: 85.1927\tvalidation loss: 70.3468\t validation accuracy: 0.9667\n",
      "iteration number: 1377\t training loss: 85.1151\tvalidation loss: 70.3377\t validation accuracy: 0.9667\n",
      "iteration number: 1378\t training loss: 85.0375\tvalidation loss: 70.3285\t validation accuracy: 0.9667\n",
      "iteration number: 1379\t training loss: 84.9601\tvalidation loss: 70.3193\t validation accuracy: 0.9667\n",
      "iteration number: 1380\t training loss: 84.8828\tvalidation loss: 70.3102\t validation accuracy: 0.9667\n",
      "iteration number: 1381\t training loss: 84.8056\tvalidation loss: 70.3010\t validation accuracy: 0.9667\n",
      "iteration number: 1382\t training loss: 84.7285\tvalidation loss: 70.2919\t validation accuracy: 0.9667\n",
      "iteration number: 1383\t training loss: 84.6515\tvalidation loss: 70.2828\t validation accuracy: 0.9667\n",
      "iteration number: 1384\t training loss: 84.5746\tvalidation loss: 70.2737\t validation accuracy: 0.9667\n",
      "iteration number: 1385\t training loss: 84.4978\tvalidation loss: 70.2646\t validation accuracy: 0.9667\n",
      "iteration number: 1386\t training loss: 84.4211\tvalidation loss: 70.2556\t validation accuracy: 0.9667\n",
      "iteration number: 1387\t training loss: 84.3445\tvalidation loss: 70.2465\t validation accuracy: 0.9667\n",
      "iteration number: 1388\t training loss: 84.2680\tvalidation loss: 70.2375\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1389\t training loss: 84.1917\tvalidation loss: 70.2285\t validation accuracy: 0.9667\n",
      "iteration number: 1390\t training loss: 84.1154\tvalidation loss: 70.2195\t validation accuracy: 0.9667\n",
      "iteration number: 1391\t training loss: 84.0392\tvalidation loss: 70.2106\t validation accuracy: 0.9667\n",
      "iteration number: 1392\t training loss: 83.9632\tvalidation loss: 70.2016\t validation accuracy: 0.9667\n",
      "iteration number: 1393\t training loss: 83.8872\tvalidation loss: 70.1926\t validation accuracy: 0.9667\n",
      "iteration number: 1394\t training loss: 83.8113\tvalidation loss: 70.1837\t validation accuracy: 0.9667\n",
      "iteration number: 1395\t training loss: 83.7356\tvalidation loss: 70.1748\t validation accuracy: 0.9667\n",
      "iteration number: 1396\t training loss: 83.6599\tvalidation loss: 70.1659\t validation accuracy: 0.9667\n",
      "iteration number: 1397\t training loss: 83.5844\tvalidation loss: 70.1570\t validation accuracy: 0.9667\n",
      "iteration number: 1398\t training loss: 83.5089\tvalidation loss: 70.1482\t validation accuracy: 0.9667\n",
      "iteration number: 1399\t training loss: 83.4336\tvalidation loss: 70.1393\t validation accuracy: 0.9667\n",
      "iteration number: 1400\t training loss: 83.3583\tvalidation loss: 70.1305\t validation accuracy: 0.9667\n",
      "iteration number: 1401\t training loss: 83.2832\tvalidation loss: 70.1216\t validation accuracy: 0.9667\n",
      "iteration number: 1402\t training loss: 83.2082\tvalidation loss: 70.1128\t validation accuracy: 0.9667\n",
      "iteration number: 1403\t training loss: 83.1332\tvalidation loss: 70.1040\t validation accuracy: 0.9667\n",
      "iteration number: 1404\t training loss: 83.0584\tvalidation loss: 70.0953\t validation accuracy: 0.9667\n",
      "iteration number: 1405\t training loss: 82.9837\tvalidation loss: 70.0865\t validation accuracy: 0.9667\n",
      "iteration number: 1406\t training loss: 82.9090\tvalidation loss: 70.0778\t validation accuracy: 0.9667\n",
      "iteration number: 1407\t training loss: 82.8345\tvalidation loss: 70.0690\t validation accuracy: 0.9667\n",
      "iteration number: 1408\t training loss: 82.7600\tvalidation loss: 70.0603\t validation accuracy: 0.9667\n",
      "iteration number: 1409\t training loss: 82.6857\tvalidation loss: 70.0516\t validation accuracy: 0.9667\n",
      "iteration number: 1410\t training loss: 82.6115\tvalidation loss: 70.0429\t validation accuracy: 0.9667\n",
      "iteration number: 1411\t training loss: 82.5373\tvalidation loss: 70.0343\t validation accuracy: 0.9667\n",
      "iteration number: 1412\t training loss: 82.4633\tvalidation loss: 70.0256\t validation accuracy: 0.9667\n",
      "iteration number: 1413\t training loss: 82.3894\tvalidation loss: 70.0170\t validation accuracy: 0.9667\n",
      "iteration number: 1414\t training loss: 82.3155\tvalidation loss: 70.0084\t validation accuracy: 0.9667\n",
      "iteration number: 1415\t training loss: 82.2418\tvalidation loss: 69.9998\t validation accuracy: 0.9667\n",
      "iteration number: 1416\t training loss: 82.1682\tvalidation loss: 69.9912\t validation accuracy: 0.9667\n",
      "iteration number: 1417\t training loss: 82.0946\tvalidation loss: 69.9826\t validation accuracy: 0.9667\n",
      "iteration number: 1418\t training loss: 82.0212\tvalidation loss: 69.9740\t validation accuracy: 0.9667\n",
      "iteration number: 1419\t training loss: 81.9478\tvalidation loss: 69.9655\t validation accuracy: 0.9667\n",
      "iteration number: 1420\t training loss: 81.8746\tvalidation loss: 69.9569\t validation accuracy: 0.9667\n",
      "iteration number: 1421\t training loss: 81.8015\tvalidation loss: 69.9484\t validation accuracy: 0.9667\n",
      "iteration number: 1422\t training loss: 81.7284\tvalidation loss: 69.9399\t validation accuracy: 0.9667\n",
      "iteration number: 1423\t training loss: 81.6555\tvalidation loss: 69.9314\t validation accuracy: 0.9667\n",
      "iteration number: 1424\t training loss: 81.5826\tvalidation loss: 69.9229\t validation accuracy: 0.9667\n",
      "iteration number: 1425\t training loss: 81.5098\tvalidation loss: 69.9145\t validation accuracy: 0.9667\n",
      "iteration number: 1426\t training loss: 81.4372\tvalidation loss: 69.9060\t validation accuracy: 0.9667\n",
      "iteration number: 1427\t training loss: 81.3646\tvalidation loss: 69.8976\t validation accuracy: 0.9667\n",
      "iteration number: 1428\t training loss: 81.2922\tvalidation loss: 69.8892\t validation accuracy: 0.9667\n",
      "iteration number: 1429\t training loss: 81.2198\tvalidation loss: 69.8808\t validation accuracy: 0.9667\n",
      "iteration number: 1430\t training loss: 81.1475\tvalidation loss: 69.8724\t validation accuracy: 0.9667\n",
      "iteration number: 1431\t training loss: 81.0754\tvalidation loss: 69.8640\t validation accuracy: 0.9667\n",
      "iteration number: 1432\t training loss: 81.0033\tvalidation loss: 69.8557\t validation accuracy: 0.9667\n",
      "iteration number: 1433\t training loss: 80.9313\tvalidation loss: 69.8473\t validation accuracy: 0.9667\n",
      "iteration number: 1434\t training loss: 80.8594\tvalidation loss: 69.8390\t validation accuracy: 0.9667\n",
      "iteration number: 1435\t training loss: 80.7876\tvalidation loss: 69.8307\t validation accuracy: 0.9667\n",
      "iteration number: 1436\t training loss: 80.7159\tvalidation loss: 69.8224\t validation accuracy: 0.9667\n",
      "iteration number: 1437\t training loss: 80.6443\tvalidation loss: 69.8141\t validation accuracy: 0.9667\n",
      "iteration number: 1438\t training loss: 80.5728\tvalidation loss: 69.8058\t validation accuracy: 0.9667\n",
      "iteration number: 1439\t training loss: 80.5014\tvalidation loss: 69.7976\t validation accuracy: 0.9667\n",
      "iteration number: 1440\t training loss: 80.4301\tvalidation loss: 69.7893\t validation accuracy: 0.9667\n",
      "iteration number: 1441\t training loss: 80.3589\tvalidation loss: 69.7811\t validation accuracy: 0.9667\n",
      "iteration number: 1442\t training loss: 80.2877\tvalidation loss: 69.7729\t validation accuracy: 0.9667\n",
      "iteration number: 1443\t training loss: 80.2167\tvalidation loss: 69.7647\t validation accuracy: 0.9667\n",
      "iteration number: 1444\t training loss: 80.1458\tvalidation loss: 69.7565\t validation accuracy: 0.9667\n",
      "iteration number: 1445\t training loss: 80.0749\tvalidation loss: 69.7484\t validation accuracy: 0.9667\n",
      "iteration number: 1446\t training loss: 80.0042\tvalidation loss: 69.7402\t validation accuracy: 0.9667\n",
      "iteration number: 1447\t training loss: 79.9335\tvalidation loss: 69.7321\t validation accuracy: 0.9667\n",
      "iteration number: 1448\t training loss: 79.8630\tvalidation loss: 69.7239\t validation accuracy: 0.9667\n",
      "iteration number: 1449\t training loss: 79.7925\tvalidation loss: 69.7158\t validation accuracy: 0.9667\n",
      "iteration number: 1450\t training loss: 79.7221\tvalidation loss: 69.7077\t validation accuracy: 0.9667\n",
      "iteration number: 1451\t training loss: 79.6518\tvalidation loss: 69.6996\t validation accuracy: 0.9667\n",
      "iteration number: 1452\t training loss: 79.5817\tvalidation loss: 69.6916\t validation accuracy: 0.9667\n",
      "iteration number: 1453\t training loss: 79.5116\tvalidation loss: 69.6835\t validation accuracy: 0.9667\n",
      "iteration number: 1454\t training loss: 79.4415\tvalidation loss: 69.6755\t validation accuracy: 0.9667\n",
      "iteration number: 1455\t training loss: 79.3716\tvalidation loss: 69.6674\t validation accuracy: 0.9667\n",
      "iteration number: 1456\t training loss: 79.3018\tvalidation loss: 69.6594\t validation accuracy: 0.9667\n",
      "iteration number: 1457\t training loss: 79.2321\tvalidation loss: 69.6514\t validation accuracy: 0.9667\n",
      "iteration number: 1458\t training loss: 79.1625\tvalidation loss: 69.6434\t validation accuracy: 0.9667\n",
      "iteration number: 1459\t training loss: 79.0929\tvalidation loss: 69.6355\t validation accuracy: 0.9667\n",
      "iteration number: 1460\t training loss: 79.0235\tvalidation loss: 69.6275\t validation accuracy: 0.9667\n",
      "iteration number: 1461\t training loss: 78.9541\tvalidation loss: 69.6196\t validation accuracy: 0.9667\n",
      "iteration number: 1462\t training loss: 78.8848\tvalidation loss: 69.6116\t validation accuracy: 0.9667\n",
      "iteration number: 1463\t training loss: 78.8156\tvalidation loss: 69.6037\t validation accuracy: 0.9667\n",
      "iteration number: 1464\t training loss: 78.7466\tvalidation loss: 69.5958\t validation accuracy: 0.9667\n",
      "iteration number: 1465\t training loss: 78.6776\tvalidation loss: 69.5879\t validation accuracy: 0.9667\n",
      "iteration number: 1466\t training loss: 78.6087\tvalidation loss: 69.5801\t validation accuracy: 0.9667\n",
      "iteration number: 1467\t training loss: 78.5398\tvalidation loss: 69.5722\t validation accuracy: 0.9667\n",
      "iteration number: 1468\t training loss: 78.4711\tvalidation loss: 69.5643\t validation accuracy: 0.9667\n",
      "iteration number: 1469\t training loss: 78.4025\tvalidation loss: 69.5565\t validation accuracy: 0.9667\n",
      "iteration number: 1470\t training loss: 78.3339\tvalidation loss: 69.5487\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1471\t training loss: 78.2655\tvalidation loss: 69.5409\t validation accuracy: 0.9667\n",
      "iteration number: 1472\t training loss: 78.1971\tvalidation loss: 69.5331\t validation accuracy: 0.9667\n",
      "iteration number: 1473\t training loss: 78.1288\tvalidation loss: 69.5253\t validation accuracy: 0.9667\n",
      "iteration number: 1474\t training loss: 78.0606\tvalidation loss: 69.5176\t validation accuracy: 0.9667\n",
      "iteration number: 1475\t training loss: 77.9926\tvalidation loss: 69.5098\t validation accuracy: 0.9667\n",
      "iteration number: 1476\t training loss: 77.9245\tvalidation loss: 69.5021\t validation accuracy: 0.9667\n",
      "iteration number: 1477\t training loss: 77.8566\tvalidation loss: 69.4943\t validation accuracy: 0.9667\n",
      "iteration number: 1478\t training loss: 77.7888\tvalidation loss: 69.4866\t validation accuracy: 0.9667\n",
      "iteration number: 1479\t training loss: 77.7211\tvalidation loss: 69.4789\t validation accuracy: 0.9667\n",
      "iteration number: 1480\t training loss: 77.6534\tvalidation loss: 69.4713\t validation accuracy: 0.9667\n",
      "iteration number: 1481\t training loss: 77.5858\tvalidation loss: 69.4636\t validation accuracy: 0.9667\n",
      "iteration number: 1482\t training loss: 77.5184\tvalidation loss: 69.4559\t validation accuracy: 0.9667\n",
      "iteration number: 1483\t training loss: 77.4510\tvalidation loss: 69.4483\t validation accuracy: 0.9667\n",
      "iteration number: 1484\t training loss: 77.3837\tvalidation loss: 69.4407\t validation accuracy: 0.9667\n",
      "iteration number: 1485\t training loss: 77.3165\tvalidation loss: 69.4330\t validation accuracy: 0.9667\n",
      "iteration number: 1486\t training loss: 77.2493\tvalidation loss: 69.4254\t validation accuracy: 0.9667\n",
      "iteration number: 1487\t training loss: 77.1823\tvalidation loss: 69.4179\t validation accuracy: 0.9667\n",
      "iteration number: 1488\t training loss: 77.1153\tvalidation loss: 69.4103\t validation accuracy: 0.9667\n",
      "iteration number: 1489\t training loss: 77.0485\tvalidation loss: 69.4027\t validation accuracy: 0.9667\n",
      "iteration number: 1490\t training loss: 76.9817\tvalidation loss: 69.3952\t validation accuracy: 0.9667\n",
      "iteration number: 1491\t training loss: 76.9150\tvalidation loss: 69.3876\t validation accuracy: 0.9667\n",
      "iteration number: 1492\t training loss: 76.8484\tvalidation loss: 69.3801\t validation accuracy: 0.9667\n",
      "iteration number: 1493\t training loss: 76.7819\tvalidation loss: 69.3726\t validation accuracy: 0.9667\n",
      "iteration number: 1494\t training loss: 76.7155\tvalidation loss: 69.3651\t validation accuracy: 0.9667\n",
      "iteration number: 1495\t training loss: 76.6491\tvalidation loss: 69.3576\t validation accuracy: 0.9667\n",
      "iteration number: 1496\t training loss: 76.5829\tvalidation loss: 69.3502\t validation accuracy: 0.9667\n",
      "iteration number: 1497\t training loss: 76.5167\tvalidation loss: 69.3427\t validation accuracy: 0.9667\n",
      "iteration number: 1498\t training loss: 76.4506\tvalidation loss: 69.3353\t validation accuracy: 0.9667\n",
      "iteration number: 1499\t training loss: 76.3846\tvalidation loss: 69.3278\t validation accuracy: 0.9667\n",
      "iteration number: 1500\t training loss: 76.3187\tvalidation loss: 69.3204\t validation accuracy: 0.9667\n",
      "iteration number: 1501\t training loss: 76.2529\tvalidation loss: 69.3130\t validation accuracy: 0.9667\n",
      "iteration number: 1502\t training loss: 76.1871\tvalidation loss: 69.3056\t validation accuracy: 0.9667\n",
      "iteration number: 1503\t training loss: 76.1215\tvalidation loss: 69.2982\t validation accuracy: 0.9667\n",
      "iteration number: 1504\t training loss: 76.0559\tvalidation loss: 69.2909\t validation accuracy: 0.9667\n",
      "iteration number: 1505\t training loss: 75.9904\tvalidation loss: 69.2835\t validation accuracy: 0.9667\n",
      "iteration number: 1506\t training loss: 75.9250\tvalidation loss: 69.2762\t validation accuracy: 0.9667\n",
      "iteration number: 1507\t training loss: 75.8597\tvalidation loss: 69.2689\t validation accuracy: 0.9667\n",
      "iteration number: 1508\t training loss: 75.7944\tvalidation loss: 69.2616\t validation accuracy: 0.9667\n",
      "iteration number: 1509\t training loss: 75.7293\tvalidation loss: 69.2543\t validation accuracy: 0.9667\n",
      "iteration number: 1510\t training loss: 75.6642\tvalidation loss: 69.2470\t validation accuracy: 0.9667\n",
      "iteration number: 1511\t training loss: 75.5992\tvalidation loss: 69.2397\t validation accuracy: 0.9667\n",
      "iteration number: 1512\t training loss: 75.5343\tvalidation loss: 69.2324\t validation accuracy: 0.9667\n",
      "iteration number: 1513\t training loss: 75.4695\tvalidation loss: 69.2252\t validation accuracy: 0.9667\n",
      "iteration number: 1514\t training loss: 75.4048\tvalidation loss: 69.2180\t validation accuracy: 0.9667\n",
      "iteration number: 1515\t training loss: 75.3402\tvalidation loss: 69.2107\t validation accuracy: 0.9667\n",
      "iteration number: 1516\t training loss: 75.2756\tvalidation loss: 69.2035\t validation accuracy: 0.9667\n",
      "iteration number: 1517\t training loss: 75.2111\tvalidation loss: 69.1963\t validation accuracy: 0.9667\n",
      "iteration number: 1518\t training loss: 75.1467\tvalidation loss: 69.1892\t validation accuracy: 0.9667\n",
      "iteration number: 1519\t training loss: 75.0824\tvalidation loss: 69.1820\t validation accuracy: 0.9667\n",
      "iteration number: 1520\t training loss: 75.0182\tvalidation loss: 69.1748\t validation accuracy: 0.9667\n",
      "iteration number: 1521\t training loss: 74.9540\tvalidation loss: 69.1677\t validation accuracy: 0.9667\n",
      "iteration number: 1522\t training loss: 74.8899\tvalidation loss: 69.1606\t validation accuracy: 0.9667\n",
      "iteration number: 1523\t training loss: 74.8260\tvalidation loss: 69.1534\t validation accuracy: 0.9667\n",
      "iteration number: 1524\t training loss: 74.7621\tvalidation loss: 69.1463\t validation accuracy: 0.9667\n",
      "iteration number: 1525\t training loss: 74.6982\tvalidation loss: 69.1393\t validation accuracy: 0.9667\n",
      "iteration number: 1526\t training loss: 74.6345\tvalidation loss: 69.1322\t validation accuracy: 0.9667\n",
      "iteration number: 1527\t training loss: 74.5708\tvalidation loss: 69.1251\t validation accuracy: 0.9667\n",
      "iteration number: 1528\t training loss: 74.5073\tvalidation loss: 69.1180\t validation accuracy: 0.9667\n",
      "iteration number: 1529\t training loss: 74.4438\tvalidation loss: 69.1110\t validation accuracy: 0.9667\n",
      "iteration number: 1530\t training loss: 74.3804\tvalidation loss: 69.1040\t validation accuracy: 0.9667\n",
      "iteration number: 1531\t training loss: 74.3170\tvalidation loss: 69.0970\t validation accuracy: 0.9667\n",
      "iteration number: 1532\t training loss: 74.2538\tvalidation loss: 69.0900\t validation accuracy: 0.9667\n",
      "iteration number: 1533\t training loss: 74.1906\tvalidation loss: 69.0830\t validation accuracy: 0.9667\n",
      "iteration number: 1534\t training loss: 74.1275\tvalidation loss: 69.0760\t validation accuracy: 0.9667\n",
      "iteration number: 1535\t training loss: 74.0645\tvalidation loss: 69.0690\t validation accuracy: 0.9667\n",
      "iteration number: 1536\t training loss: 74.0016\tvalidation loss: 69.0621\t validation accuracy: 0.9667\n",
      "iteration number: 1537\t training loss: 73.9388\tvalidation loss: 69.0551\t validation accuracy: 0.9667\n",
      "iteration number: 1538\t training loss: 73.8760\tvalidation loss: 69.0482\t validation accuracy: 0.9667\n",
      "iteration number: 1539\t training loss: 73.8133\tvalidation loss: 69.0413\t validation accuracy: 0.9667\n",
      "iteration number: 1540\t training loss: 73.7507\tvalidation loss: 69.0344\t validation accuracy: 0.9667\n",
      "iteration number: 1541\t training loss: 73.6882\tvalidation loss: 69.0275\t validation accuracy: 0.9667\n",
      "iteration number: 1542\t training loss: 73.6258\tvalidation loss: 69.0206\t validation accuracy: 0.9667\n",
      "iteration number: 1543\t training loss: 73.5634\tvalidation loss: 69.0137\t validation accuracy: 0.9667\n",
      "iteration number: 1544\t training loss: 73.5011\tvalidation loss: 69.0069\t validation accuracy: 0.9667\n",
      "iteration number: 1545\t training loss: 73.4389\tvalidation loss: 69.0001\t validation accuracy: 0.9667\n",
      "iteration number: 1546\t training loss: 73.3768\tvalidation loss: 68.9932\t validation accuracy: 0.9667\n",
      "iteration number: 1547\t training loss: 73.3147\tvalidation loss: 68.9864\t validation accuracy: 0.9667\n",
      "iteration number: 1548\t training loss: 73.2528\tvalidation loss: 68.9796\t validation accuracy: 0.9667\n",
      "iteration number: 1549\t training loss: 73.1909\tvalidation loss: 68.9728\t validation accuracy: 0.9667\n",
      "iteration number: 1550\t training loss: 73.1291\tvalidation loss: 68.9660\t validation accuracy: 0.9667\n",
      "iteration number: 1551\t training loss: 73.0673\tvalidation loss: 68.9593\t validation accuracy: 0.9667\n",
      "iteration number: 1552\t training loss: 73.0057\tvalidation loss: 68.9525\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1553\t training loss: 72.9441\tvalidation loss: 68.9458\t validation accuracy: 0.9667\n",
      "iteration number: 1554\t training loss: 72.8826\tvalidation loss: 68.9390\t validation accuracy: 0.9667\n",
      "iteration number: 1555\t training loss: 72.8212\tvalidation loss: 68.9323\t validation accuracy: 0.9667\n",
      "iteration number: 1556\t training loss: 72.7599\tvalidation loss: 68.9256\t validation accuracy: 0.9667\n",
      "iteration number: 1557\t training loss: 72.6986\tvalidation loss: 68.9189\t validation accuracy: 0.9667\n",
      "iteration number: 1558\t training loss: 72.6374\tvalidation loss: 68.9122\t validation accuracy: 0.9667\n",
      "iteration number: 1559\t training loss: 72.5763\tvalidation loss: 68.9056\t validation accuracy: 0.9667\n",
      "iteration number: 1560\t training loss: 72.5153\tvalidation loss: 68.8989\t validation accuracy: 0.9667\n",
      "iteration number: 1561\t training loss: 72.4543\tvalidation loss: 68.8923\t validation accuracy: 0.9667\n",
      "iteration number: 1562\t training loss: 72.3935\tvalidation loss: 68.8856\t validation accuracy: 0.9667\n",
      "iteration number: 1563\t training loss: 72.3327\tvalidation loss: 68.8790\t validation accuracy: 0.9667\n",
      "iteration number: 1564\t training loss: 72.2720\tvalidation loss: 68.8724\t validation accuracy: 0.9667\n",
      "iteration number: 1565\t training loss: 72.2113\tvalidation loss: 68.8658\t validation accuracy: 0.9667\n",
      "iteration number: 1566\t training loss: 72.1508\tvalidation loss: 68.8592\t validation accuracy: 0.9667\n",
      "iteration number: 1567\t training loss: 72.0903\tvalidation loss: 68.8526\t validation accuracy: 0.9667\n",
      "iteration number: 1568\t training loss: 72.0299\tvalidation loss: 68.8461\t validation accuracy: 0.9667\n",
      "iteration number: 1569\t training loss: 71.9695\tvalidation loss: 68.8395\t validation accuracy: 0.9667\n",
      "iteration number: 1570\t training loss: 71.9093\tvalidation loss: 68.8330\t validation accuracy: 0.9667\n",
      "iteration number: 1571\t training loss: 71.8491\tvalidation loss: 68.8265\t validation accuracy: 0.9667\n",
      "iteration number: 1572\t training loss: 71.7890\tvalidation loss: 68.8200\t validation accuracy: 0.9667\n",
      "iteration number: 1573\t training loss: 71.7290\tvalidation loss: 68.8135\t validation accuracy: 0.9667\n",
      "iteration number: 1574\t training loss: 71.6690\tvalidation loss: 68.8070\t validation accuracy: 0.9667\n",
      "iteration number: 1575\t training loss: 71.6091\tvalidation loss: 68.8005\t validation accuracy: 0.9667\n",
      "iteration number: 1576\t training loss: 71.5493\tvalidation loss: 68.7940\t validation accuracy: 0.9667\n",
      "iteration number: 1577\t training loss: 71.4896\tvalidation loss: 68.7876\t validation accuracy: 0.9667\n",
      "iteration number: 1578\t training loss: 71.4300\tvalidation loss: 68.7811\t validation accuracy: 0.9667\n",
      "iteration number: 1579\t training loss: 71.3704\tvalidation loss: 68.7747\t validation accuracy: 0.9667\n",
      "iteration number: 1580\t training loss: 71.3109\tvalidation loss: 68.7683\t validation accuracy: 0.9667\n",
      "iteration number: 1581\t training loss: 71.2515\tvalidation loss: 68.7619\t validation accuracy: 0.9667\n",
      "iteration number: 1582\t training loss: 71.1921\tvalidation loss: 68.7555\t validation accuracy: 0.9667\n",
      "iteration number: 1583\t training loss: 71.1328\tvalidation loss: 68.7491\t validation accuracy: 0.9667\n",
      "iteration number: 1584\t training loss: 71.0736\tvalidation loss: 68.7427\t validation accuracy: 0.9667\n",
      "iteration number: 1585\t training loss: 71.0145\tvalidation loss: 68.7364\t validation accuracy: 0.9667\n",
      "iteration number: 1586\t training loss: 70.9555\tvalidation loss: 68.7300\t validation accuracy: 0.9667\n",
      "iteration number: 1587\t training loss: 70.8965\tvalidation loss: 68.7237\t validation accuracy: 0.9667\n",
      "iteration number: 1588\t training loss: 70.8376\tvalidation loss: 68.7174\t validation accuracy: 0.9667\n",
      "iteration number: 1589\t training loss: 70.7788\tvalidation loss: 68.7110\t validation accuracy: 0.9667\n",
      "iteration number: 1590\t training loss: 70.7200\tvalidation loss: 68.7047\t validation accuracy: 0.9667\n",
      "iteration number: 1591\t training loss: 70.6613\tvalidation loss: 68.6985\t validation accuracy: 0.9667\n",
      "iteration number: 1592\t training loss: 70.6027\tvalidation loss: 68.6922\t validation accuracy: 0.9667\n",
      "iteration number: 1593\t training loss: 70.5442\tvalidation loss: 68.6859\t validation accuracy: 0.9667\n",
      "iteration number: 1594\t training loss: 70.4857\tvalidation loss: 68.6797\t validation accuracy: 0.9667\n",
      "iteration number: 1595\t training loss: 70.4274\tvalidation loss: 68.6734\t validation accuracy: 0.9667\n",
      "iteration number: 1596\t training loss: 70.3690\tvalidation loss: 68.6672\t validation accuracy: 0.9667\n",
      "iteration number: 1597\t training loss: 70.3108\tvalidation loss: 68.6610\t validation accuracy: 0.9667\n",
      "iteration number: 1598\t training loss: 70.2526\tvalidation loss: 68.6548\t validation accuracy: 0.9667\n",
      "iteration number: 1599\t training loss: 70.1945\tvalidation loss: 68.6486\t validation accuracy: 0.9667\n",
      "iteration number: 1600\t training loss: 70.1365\tvalidation loss: 68.6424\t validation accuracy: 0.9667\n",
      "iteration number: 1601\t training loss: 70.0786\tvalidation loss: 68.6362\t validation accuracy: 0.9667\n",
      "iteration number: 1602\t training loss: 70.0207\tvalidation loss: 68.6300\t validation accuracy: 0.9667\n",
      "iteration number: 1603\t training loss: 69.9629\tvalidation loss: 68.6239\t validation accuracy: 0.9667\n",
      "iteration number: 1604\t training loss: 69.9052\tvalidation loss: 68.6178\t validation accuracy: 0.9667\n",
      "iteration number: 1605\t training loss: 69.8475\tvalidation loss: 68.6116\t validation accuracy: 0.9667\n",
      "iteration number: 1606\t training loss: 69.7899\tvalidation loss: 68.6055\t validation accuracy: 0.9667\n",
      "iteration number: 1607\t training loss: 69.7324\tvalidation loss: 68.5994\t validation accuracy: 0.9667\n",
      "iteration number: 1608\t training loss: 69.6750\tvalidation loss: 68.5933\t validation accuracy: 0.9667\n",
      "iteration number: 1609\t training loss: 69.6176\tvalidation loss: 68.5872\t validation accuracy: 0.9667\n",
      "iteration number: 1610\t training loss: 69.5603\tvalidation loss: 68.5812\t validation accuracy: 0.9667\n",
      "iteration number: 1611\t training loss: 69.5031\tvalidation loss: 68.5751\t validation accuracy: 0.9667\n",
      "iteration number: 1612\t training loss: 69.4460\tvalidation loss: 68.5691\t validation accuracy: 0.9667\n",
      "iteration number: 1613\t training loss: 69.3889\tvalidation loss: 68.5630\t validation accuracy: 0.9667\n",
      "iteration number: 1614\t training loss: 69.3319\tvalidation loss: 68.5570\t validation accuracy: 0.9667\n",
      "iteration number: 1615\t training loss: 69.2749\tvalidation loss: 68.5510\t validation accuracy: 0.9667\n",
      "iteration number: 1616\t training loss: 69.2181\tvalidation loss: 68.5450\t validation accuracy: 0.9667\n",
      "iteration number: 1617\t training loss: 69.1613\tvalidation loss: 68.5390\t validation accuracy: 0.9667\n",
      "iteration number: 1618\t training loss: 69.1045\tvalidation loss: 68.5330\t validation accuracy: 0.9667\n",
      "iteration number: 1619\t training loss: 69.0479\tvalidation loss: 68.5270\t validation accuracy: 0.9667\n",
      "iteration number: 1620\t training loss: 68.9913\tvalidation loss: 68.5211\t validation accuracy: 0.9667\n",
      "iteration number: 1621\t training loss: 68.9348\tvalidation loss: 68.5151\t validation accuracy: 0.9667\n",
      "iteration number: 1622\t training loss: 68.8783\tvalidation loss: 68.5092\t validation accuracy: 0.9667\n",
      "iteration number: 1623\t training loss: 68.8220\tvalidation loss: 68.5033\t validation accuracy: 0.9667\n",
      "iteration number: 1624\t training loss: 68.7657\tvalidation loss: 68.4974\t validation accuracy: 0.9667\n",
      "iteration number: 1625\t training loss: 68.7094\tvalidation loss: 68.4915\t validation accuracy: 0.9667\n",
      "iteration number: 1626\t training loss: 68.6533\tvalidation loss: 68.4856\t validation accuracy: 0.9667\n",
      "iteration number: 1627\t training loss: 68.5972\tvalidation loss: 68.4797\t validation accuracy: 0.9667\n",
      "iteration number: 1628\t training loss: 68.5412\tvalidation loss: 68.4738\t validation accuracy: 0.9667\n",
      "iteration number: 1629\t training loss: 68.4852\tvalidation loss: 68.4680\t validation accuracy: 0.9667\n",
      "iteration number: 1630\t training loss: 68.4293\tvalidation loss: 68.4621\t validation accuracy: 0.9667\n",
      "iteration number: 1631\t training loss: 68.3735\tvalidation loss: 68.4563\t validation accuracy: 0.9667\n",
      "iteration number: 1632\t training loss: 68.3178\tvalidation loss: 68.4505\t validation accuracy: 0.9667\n",
      "iteration number: 1633\t training loss: 68.2621\tvalidation loss: 68.4446\t validation accuracy: 0.9667\n",
      "iteration number: 1634\t training loss: 68.2065\tvalidation loss: 68.4388\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1635\t training loss: 68.1509\tvalidation loss: 68.4331\t validation accuracy: 0.9667\n",
      "iteration number: 1636\t training loss: 68.0955\tvalidation loss: 68.4273\t validation accuracy: 0.9667\n",
      "iteration number: 1637\t training loss: 68.0401\tvalidation loss: 68.4215\t validation accuracy: 0.9667\n",
      "iteration number: 1638\t training loss: 67.9848\tvalidation loss: 68.4158\t validation accuracy: 0.9667\n",
      "iteration number: 1639\t training loss: 67.9295\tvalidation loss: 68.4100\t validation accuracy: 0.9667\n",
      "iteration number: 1640\t training loss: 67.8743\tvalidation loss: 68.4043\t validation accuracy: 0.9667\n",
      "iteration number: 1641\t training loss: 67.8192\tvalidation loss: 68.3985\t validation accuracy: 0.9667\n",
      "iteration number: 1642\t training loss: 67.7641\tvalidation loss: 68.3928\t validation accuracy: 0.9667\n",
      "iteration number: 1643\t training loss: 67.7091\tvalidation loss: 68.3871\t validation accuracy: 0.9667\n",
      "iteration number: 1644\t training loss: 67.6542\tvalidation loss: 68.3814\t validation accuracy: 0.9667\n",
      "iteration number: 1645\t training loss: 67.5994\tvalidation loss: 68.3758\t validation accuracy: 0.9667\n",
      "iteration number: 1646\t training loss: 67.5446\tvalidation loss: 68.3701\t validation accuracy: 0.9667\n",
      "iteration number: 1647\t training loss: 67.4899\tvalidation loss: 68.3644\t validation accuracy: 0.9667\n",
      "iteration number: 1648\t training loss: 67.4352\tvalidation loss: 68.3588\t validation accuracy: 0.9667\n",
      "iteration number: 1649\t training loss: 67.3806\tvalidation loss: 68.3531\t validation accuracy: 0.9667\n",
      "iteration number: 1650\t training loss: 67.3261\tvalidation loss: 68.3475\t validation accuracy: 0.9667\n",
      "iteration number: 1651\t training loss: 67.2717\tvalidation loss: 68.3419\t validation accuracy: 0.9667\n",
      "iteration number: 1652\t training loss: 67.2173\tvalidation loss: 68.3363\t validation accuracy: 0.9667\n",
      "iteration number: 1653\t training loss: 67.1630\tvalidation loss: 68.3307\t validation accuracy: 0.9667\n",
      "iteration number: 1654\t training loss: 67.1087\tvalidation loss: 68.3251\t validation accuracy: 0.9667\n",
      "iteration number: 1655\t training loss: 67.0546\tvalidation loss: 68.3195\t validation accuracy: 0.9667\n",
      "iteration number: 1656\t training loss: 67.0005\tvalidation loss: 68.3140\t validation accuracy: 0.9667\n",
      "iteration number: 1657\t training loss: 66.9464\tvalidation loss: 68.3084\t validation accuracy: 0.9667\n",
      "iteration number: 1658\t training loss: 66.8924\tvalidation loss: 68.3029\t validation accuracy: 0.9667\n",
      "iteration number: 1659\t training loss: 66.8385\tvalidation loss: 68.2973\t validation accuracy: 0.9667\n",
      "iteration number: 1660\t training loss: 66.7847\tvalidation loss: 68.2918\t validation accuracy: 0.9667\n",
      "iteration number: 1661\t training loss: 66.7309\tvalidation loss: 68.2863\t validation accuracy: 0.9667\n",
      "iteration number: 1662\t training loss: 66.6772\tvalidation loss: 68.2808\t validation accuracy: 0.9667\n",
      "iteration number: 1663\t training loss: 66.6235\tvalidation loss: 68.2753\t validation accuracy: 0.9667\n",
      "iteration number: 1664\t training loss: 66.5700\tvalidation loss: 68.2698\t validation accuracy: 0.9667\n",
      "iteration number: 1665\t training loss: 66.5165\tvalidation loss: 68.2644\t validation accuracy: 0.9667\n",
      "iteration number: 1666\t training loss: 66.4630\tvalidation loss: 68.2589\t validation accuracy: 0.9667\n",
      "iteration number: 1667\t training loss: 66.4096\tvalidation loss: 68.2535\t validation accuracy: 0.9667\n",
      "iteration number: 1668\t training loss: 66.3563\tvalidation loss: 68.2480\t validation accuracy: 0.9667\n",
      "iteration number: 1669\t training loss: 66.3031\tvalidation loss: 68.2426\t validation accuracy: 0.9667\n",
      "iteration number: 1670\t training loss: 66.2499\tvalidation loss: 68.2372\t validation accuracy: 0.9667\n",
      "iteration number: 1671\t training loss: 66.1968\tvalidation loss: 68.2318\t validation accuracy: 0.9667\n",
      "iteration number: 1672\t training loss: 66.1437\tvalidation loss: 68.2264\t validation accuracy: 0.9667\n",
      "iteration number: 1673\t training loss: 66.0907\tvalidation loss: 68.2210\t validation accuracy: 0.9667\n",
      "iteration number: 1674\t training loss: 66.0378\tvalidation loss: 68.2157\t validation accuracy: 0.9667\n",
      "iteration number: 1675\t training loss: 65.9849\tvalidation loss: 68.2103\t validation accuracy: 0.9667\n",
      "iteration number: 1676\t training loss: 65.9321\tvalidation loss: 68.2049\t validation accuracy: 0.9667\n",
      "iteration number: 1677\t training loss: 65.8794\tvalidation loss: 68.1996\t validation accuracy: 0.9667\n",
      "iteration number: 1678\t training loss: 65.8267\tvalidation loss: 68.1943\t validation accuracy: 0.9667\n",
      "iteration number: 1679\t training loss: 65.7741\tvalidation loss: 68.1889\t validation accuracy: 0.9667\n",
      "iteration number: 1680\t training loss: 65.7216\tvalidation loss: 68.1836\t validation accuracy: 0.9667\n",
      "iteration number: 1681\t training loss: 65.6691\tvalidation loss: 68.1783\t validation accuracy: 0.9667\n",
      "iteration number: 1682\t training loss: 65.6167\tvalidation loss: 68.1730\t validation accuracy: 0.9667\n",
      "iteration number: 1683\t training loss: 65.5644\tvalidation loss: 68.1678\t validation accuracy: 0.9667\n",
      "iteration number: 1684\t training loss: 65.5121\tvalidation loss: 68.1625\t validation accuracy: 0.9667\n",
      "iteration number: 1685\t training loss: 65.4599\tvalidation loss: 68.1572\t validation accuracy: 0.9667\n",
      "iteration number: 1686\t training loss: 65.4077\tvalidation loss: 68.1520\t validation accuracy: 0.9667\n",
      "iteration number: 1687\t training loss: 65.3557\tvalidation loss: 68.1468\t validation accuracy: 0.9667\n",
      "iteration number: 1688\t training loss: 65.3036\tvalidation loss: 68.1415\t validation accuracy: 0.9667\n",
      "iteration number: 1689\t training loss: 65.2517\tvalidation loss: 68.1363\t validation accuracy: 0.9667\n",
      "iteration number: 1690\t training loss: 65.1998\tvalidation loss: 68.1311\t validation accuracy: 0.9667\n",
      "iteration number: 1691\t training loss: 65.1479\tvalidation loss: 68.1259\t validation accuracy: 0.9667\n",
      "iteration number: 1692\t training loss: 65.0962\tvalidation loss: 68.1207\t validation accuracy: 0.9667\n",
      "iteration number: 1693\t training loss: 65.0445\tvalidation loss: 68.1155\t validation accuracy: 0.9667\n",
      "iteration number: 1694\t training loss: 64.9928\tvalidation loss: 68.1104\t validation accuracy: 0.9667\n",
      "iteration number: 1695\t training loss: 64.9412\tvalidation loss: 68.1052\t validation accuracy: 0.9667\n",
      "iteration number: 1696\t training loss: 64.8897\tvalidation loss: 68.1001\t validation accuracy: 0.9667\n",
      "iteration number: 1697\t training loss: 64.8383\tvalidation loss: 68.0949\t validation accuracy: 0.9667\n",
      "iteration number: 1698\t training loss: 64.7869\tvalidation loss: 68.0898\t validation accuracy: 0.9667\n",
      "iteration number: 1699\t training loss: 64.7356\tvalidation loss: 68.0847\t validation accuracy: 0.9667\n",
      "iteration number: 1700\t training loss: 64.6843\tvalidation loss: 68.0796\t validation accuracy: 0.9667\n",
      "iteration number: 1701\t training loss: 64.6331\tvalidation loss: 68.0745\t validation accuracy: 0.9667\n",
      "iteration number: 1702\t training loss: 64.5819\tvalidation loss: 68.0694\t validation accuracy: 0.9667\n",
      "iteration number: 1703\t training loss: 64.5309\tvalidation loss: 68.0643\t validation accuracy: 0.9667\n",
      "iteration number: 1704\t training loss: 64.4798\tvalidation loss: 68.0593\t validation accuracy: 0.9667\n",
      "iteration number: 1705\t training loss: 64.4289\tvalidation loss: 68.0542\t validation accuracy: 0.9667\n",
      "iteration number: 1706\t training loss: 64.3780\tvalidation loss: 68.0492\t validation accuracy: 0.9667\n",
      "iteration number: 1707\t training loss: 64.3272\tvalidation loss: 68.0441\t validation accuracy: 0.9667\n",
      "iteration number: 1708\t training loss: 64.2764\tvalidation loss: 68.0391\t validation accuracy: 0.9667\n",
      "iteration number: 1709\t training loss: 64.2257\tvalidation loss: 68.0341\t validation accuracy: 0.9667\n",
      "iteration number: 1710\t training loss: 64.1750\tvalidation loss: 68.0291\t validation accuracy: 0.9667\n",
      "iteration number: 1711\t training loss: 64.1245\tvalidation loss: 68.0241\t validation accuracy: 0.9667\n",
      "iteration number: 1712\t training loss: 64.0739\tvalidation loss: 68.0191\t validation accuracy: 0.9667\n",
      "iteration number: 1713\t training loss: 64.0235\tvalidation loss: 68.0141\t validation accuracy: 0.9667\n",
      "iteration number: 1714\t training loss: 63.9731\tvalidation loss: 68.0092\t validation accuracy: 0.9667\n",
      "iteration number: 1715\t training loss: 63.9227\tvalidation loss: 68.0042\t validation accuracy: 0.9667\n",
      "iteration number: 1716\t training loss: 63.8725\tvalidation loss: 67.9993\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1717\t training loss: 63.8222\tvalidation loss: 67.9943\t validation accuracy: 0.9667\n",
      "iteration number: 1718\t training loss: 63.7721\tvalidation loss: 67.9894\t validation accuracy: 0.9667\n",
      "iteration number: 1719\t training loss: 63.7220\tvalidation loss: 67.9845\t validation accuracy: 0.9667\n",
      "iteration number: 1720\t training loss: 63.6719\tvalidation loss: 67.9796\t validation accuracy: 0.9667\n",
      "iteration number: 1721\t training loss: 63.6220\tvalidation loss: 67.9747\t validation accuracy: 0.9667\n",
      "iteration number: 1722\t training loss: 63.5721\tvalidation loss: 67.9698\t validation accuracy: 0.9667\n",
      "iteration number: 1723\t training loss: 63.5222\tvalidation loss: 67.9649\t validation accuracy: 0.9667\n",
      "iteration number: 1724\t training loss: 63.4724\tvalidation loss: 67.9600\t validation accuracy: 0.9667\n",
      "iteration number: 1725\t training loss: 63.4227\tvalidation loss: 67.9552\t validation accuracy: 0.9667\n",
      "iteration number: 1726\t training loss: 63.3730\tvalidation loss: 67.9503\t validation accuracy: 0.9667\n",
      "iteration number: 1727\t training loss: 63.3234\tvalidation loss: 67.9455\t validation accuracy: 0.9667\n",
      "iteration number: 1728\t training loss: 63.2738\tvalidation loss: 67.9407\t validation accuracy: 0.9667\n",
      "iteration number: 1729\t training loss: 63.2243\tvalidation loss: 67.9358\t validation accuracy: 0.9667\n",
      "iteration number: 1730\t training loss: 63.1749\tvalidation loss: 67.9310\t validation accuracy: 0.9667\n",
      "iteration number: 1731\t training loss: 63.1255\tvalidation loss: 67.9262\t validation accuracy: 0.9667\n",
      "iteration number: 1732\t training loss: 63.0762\tvalidation loss: 67.9214\t validation accuracy: 0.9667\n",
      "iteration number: 1733\t training loss: 63.0270\tvalidation loss: 67.9167\t validation accuracy: 0.9667\n",
      "iteration number: 1734\t training loss: 62.9778\tvalidation loss: 67.9119\t validation accuracy: 0.9667\n",
      "iteration number: 1735\t training loss: 62.9286\tvalidation loss: 67.9071\t validation accuracy: 0.9667\n",
      "iteration number: 1736\t training loss: 62.8796\tvalidation loss: 67.9024\t validation accuracy: 0.9667\n",
      "iteration number: 1737\t training loss: 62.8305\tvalidation loss: 67.8976\t validation accuracy: 0.9667\n",
      "iteration number: 1738\t training loss: 62.7816\tvalidation loss: 67.8929\t validation accuracy: 0.9667\n",
      "iteration number: 1739\t training loss: 62.7327\tvalidation loss: 67.8882\t validation accuracy: 0.9667\n",
      "iteration number: 1740\t training loss: 62.6838\tvalidation loss: 67.8835\t validation accuracy: 0.9667\n",
      "iteration number: 1741\t training loss: 62.6350\tvalidation loss: 67.8788\t validation accuracy: 0.9667\n",
      "iteration number: 1742\t training loss: 62.5863\tvalidation loss: 67.8741\t validation accuracy: 0.9667\n",
      "iteration number: 1743\t training loss: 62.5377\tvalidation loss: 67.8694\t validation accuracy: 0.9667\n",
      "iteration number: 1744\t training loss: 62.4891\tvalidation loss: 67.8647\t validation accuracy: 0.9667\n",
      "iteration number: 1745\t training loss: 62.4405\tvalidation loss: 67.8600\t validation accuracy: 0.9667\n",
      "iteration number: 1746\t training loss: 62.3920\tvalidation loss: 67.8554\t validation accuracy: 0.9667\n",
      "iteration number: 1747\t training loss: 62.3436\tvalidation loss: 67.8507\t validation accuracy: 0.9667\n",
      "iteration number: 1748\t training loss: 62.2952\tvalidation loss: 67.8461\t validation accuracy: 0.9667\n",
      "iteration number: 1749\t training loss: 62.2469\tvalidation loss: 67.8415\t validation accuracy: 0.9667\n",
      "iteration number: 1750\t training loss: 62.1986\tvalidation loss: 67.8369\t validation accuracy: 0.9667\n",
      "iteration number: 1751\t training loss: 62.1504\tvalidation loss: 67.8322\t validation accuracy: 0.9667\n",
      "iteration number: 1752\t training loss: 62.1023\tvalidation loss: 67.8276\t validation accuracy: 0.9667\n",
      "iteration number: 1753\t training loss: 62.0542\tvalidation loss: 67.8231\t validation accuracy: 0.9667\n",
      "iteration number: 1754\t training loss: 62.0062\tvalidation loss: 67.8185\t validation accuracy: 0.9667\n",
      "iteration number: 1755\t training loss: 61.9582\tvalidation loss: 67.8139\t validation accuracy: 0.9667\n",
      "iteration number: 1756\t training loss: 61.9103\tvalidation loss: 67.8093\t validation accuracy: 0.9667\n",
      "iteration number: 1757\t training loss: 61.8624\tvalidation loss: 67.8048\t validation accuracy: 0.9667\n",
      "iteration number: 1758\t training loss: 61.8146\tvalidation loss: 67.8002\t validation accuracy: 0.9667\n",
      "iteration number: 1759\t training loss: 61.7669\tvalidation loss: 67.7957\t validation accuracy: 0.9667\n",
      "iteration number: 1760\t training loss: 61.7192\tvalidation loss: 67.7912\t validation accuracy: 0.9667\n",
      "iteration number: 1761\t training loss: 61.6716\tvalidation loss: 67.7867\t validation accuracy: 0.9667\n",
      "iteration number: 1762\t training loss: 61.6240\tvalidation loss: 67.7822\t validation accuracy: 0.9667\n",
      "iteration number: 1763\t training loss: 61.5765\tvalidation loss: 67.7777\t validation accuracy: 0.9667\n",
      "iteration number: 1764\t training loss: 61.5291\tvalidation loss: 67.7732\t validation accuracy: 0.9667\n",
      "iteration number: 1765\t training loss: 61.4817\tvalidation loss: 67.7687\t validation accuracy: 0.9667\n",
      "iteration number: 1766\t training loss: 61.4343\tvalidation loss: 67.7642\t validation accuracy: 0.9667\n",
      "iteration number: 1767\t training loss: 61.3870\tvalidation loss: 67.7598\t validation accuracy: 0.9667\n",
      "iteration number: 1768\t training loss: 61.3398\tvalidation loss: 67.7553\t validation accuracy: 0.9667\n",
      "iteration number: 1769\t training loss: 61.2926\tvalidation loss: 67.7509\t validation accuracy: 0.9667\n",
      "iteration number: 1770\t training loss: 61.2455\tvalidation loss: 67.7464\t validation accuracy: 0.9667\n",
      "iteration number: 1771\t training loss: 61.1984\tvalidation loss: 67.7420\t validation accuracy: 0.9667\n",
      "iteration number: 1772\t training loss: 61.1514\tvalidation loss: 67.7376\t validation accuracy: 0.9667\n",
      "iteration number: 1773\t training loss: 61.1045\tvalidation loss: 67.7332\t validation accuracy: 0.9667\n",
      "iteration number: 1774\t training loss: 61.0576\tvalidation loss: 67.7288\t validation accuracy: 0.9667\n",
      "iteration number: 1775\t training loss: 61.0108\tvalidation loss: 67.7244\t validation accuracy: 0.9667\n",
      "iteration number: 1776\t training loss: 60.9640\tvalidation loss: 67.7200\t validation accuracy: 0.9667\n",
      "iteration number: 1777\t training loss: 60.9173\tvalidation loss: 67.7156\t validation accuracy: 0.9667\n",
      "iteration number: 1778\t training loss: 60.8706\tvalidation loss: 67.7113\t validation accuracy: 0.9667\n",
      "iteration number: 1779\t training loss: 60.8240\tvalidation loss: 67.7069\t validation accuracy: 0.9667\n",
      "iteration number: 1780\t training loss: 60.7774\tvalidation loss: 67.7026\t validation accuracy: 0.9667\n",
      "iteration number: 1781\t training loss: 60.7309\tvalidation loss: 67.6983\t validation accuracy: 0.9667\n",
      "iteration number: 1782\t training loss: 60.6845\tvalidation loss: 67.6939\t validation accuracy: 0.9667\n",
      "iteration number: 1783\t training loss: 60.6381\tvalidation loss: 67.6896\t validation accuracy: 0.9667\n",
      "iteration number: 1784\t training loss: 60.5917\tvalidation loss: 67.6853\t validation accuracy: 0.9667\n",
      "iteration number: 1785\t training loss: 60.5454\tvalidation loss: 67.6810\t validation accuracy: 0.9667\n",
      "iteration number: 1786\t training loss: 60.4992\tvalidation loss: 67.6767\t validation accuracy: 0.9667\n",
      "iteration number: 1787\t training loss: 60.4530\tvalidation loss: 67.6724\t validation accuracy: 0.9667\n",
      "iteration number: 1788\t training loss: 60.4069\tvalidation loss: 67.6682\t validation accuracy: 0.9667\n",
      "iteration number: 1789\t training loss: 60.3608\tvalidation loss: 67.6639\t validation accuracy: 0.9667\n",
      "iteration number: 1790\t training loss: 60.3148\tvalidation loss: 67.6596\t validation accuracy: 0.9667\n",
      "iteration number: 1791\t training loss: 60.2689\tvalidation loss: 67.6554\t validation accuracy: 0.9667\n",
      "iteration number: 1792\t training loss: 60.2230\tvalidation loss: 67.6512\t validation accuracy: 0.9667\n",
      "iteration number: 1793\t training loss: 60.1771\tvalidation loss: 67.6469\t validation accuracy: 0.9667\n",
      "iteration number: 1794\t training loss: 60.1313\tvalidation loss: 67.6427\t validation accuracy: 0.9667\n",
      "iteration number: 1795\t training loss: 60.0856\tvalidation loss: 67.6385\t validation accuracy: 0.9667\n",
      "iteration number: 1796\t training loss: 60.0399\tvalidation loss: 67.6343\t validation accuracy: 0.9667\n",
      "iteration number: 1797\t training loss: 59.9943\tvalidation loss: 67.6301\t validation accuracy: 0.9667\n",
      "iteration number: 1798\t training loss: 59.9487\tvalidation loss: 67.6259\t validation accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1799\t training loss: 59.9032\tvalidation loss: 67.6218\t validation accuracy: 0.9667\n",
      "iteration number: 1800\t training loss: 59.8577\tvalidation loss: 67.6176\t validation accuracy: 0.9667\n",
      "iteration number: 1801\t training loss: 59.8123\tvalidation loss: 67.6134\t validation accuracy: 0.9667\n",
      "iteration number: 1802\t training loss: 59.7669\tvalidation loss: 67.6093\t validation accuracy: 0.9667\n",
      "iteration number: 1803\t training loss: 59.7216\tvalidation loss: 67.6051\t validation accuracy: 0.9667\n",
      "iteration number: 1804\t training loss: 59.6764\tvalidation loss: 67.6010\t validation accuracy: 0.9667\n",
      "iteration number: 1805\t training loss: 59.6312\tvalidation loss: 67.5969\t validation accuracy: 0.9667\n",
      "iteration number: 1806\t training loss: 59.5860\tvalidation loss: 67.5928\t validation accuracy: 0.9667\n",
      "iteration number: 1807\t training loss: 59.5409\tvalidation loss: 67.5887\t validation accuracy: 0.9667\n",
      "iteration number: 1808\t training loss: 59.4959\tvalidation loss: 67.5846\t validation accuracy: 0.9667\n",
      "iteration number: 1809\t training loss: 59.4509\tvalidation loss: 67.5805\t validation accuracy: 0.9667\n",
      "iteration number: 1810\t training loss: 59.4059\tvalidation loss: 67.5764\t validation accuracy: 0.9667\n",
      "iteration number: 1811\t training loss: 59.3611\tvalidation loss: 67.5723\t validation accuracy: 0.9667\n",
      "iteration number: 1812\t training loss: 59.3162\tvalidation loss: 67.5683\t validation accuracy: 0.9667\n",
      "iteration number: 1813\t training loss: 59.2714\tvalidation loss: 67.5642\t validation accuracy: 0.9667\n",
      "iteration number: 1814\t training loss: 59.2267\tvalidation loss: 67.5602\t validation accuracy: 0.9667\n",
      "iteration number: 1815\t training loss: 59.1820\tvalidation loss: 67.5561\t validation accuracy: 0.9667\n",
      "iteration number: 1816\t training loss: 59.1374\tvalidation loss: 67.5521\t validation accuracy: 0.9667\n",
      "iteration number: 1817\t training loss: 59.0929\tvalidation loss: 67.5481\t validation accuracy: 0.9667\n",
      "iteration number: 1818\t training loss: 59.0483\tvalidation loss: 67.5441\t validation accuracy: 0.9667\n",
      "iteration number: 1819\t training loss: 59.0039\tvalidation loss: 67.5401\t validation accuracy: 0.9667\n",
      "iteration number: 1820\t training loss: 58.9595\tvalidation loss: 67.5361\t validation accuracy: 0.9667\n",
      "iteration number: 1821\t training loss: 58.9151\tvalidation loss: 67.5321\t validation accuracy: 0.9667\n",
      "iteration number: 1822\t training loss: 58.8708\tvalidation loss: 67.5281\t validation accuracy: 0.9667\n",
      "iteration number: 1823\t training loss: 58.8265\tvalidation loss: 67.5241\t validation accuracy: 0.9667\n",
      "iteration number: 1824\t training loss: 58.7823\tvalidation loss: 67.5202\t validation accuracy: 0.9667\n",
      "iteration number: 1825\t training loss: 58.7382\tvalidation loss: 67.5162\t validation accuracy: 0.9667\n",
      "iteration number: 1826\t training loss: 58.6941\tvalidation loss: 67.5123\t validation accuracy: 0.9667\n",
      "iteration number: 1827\t training loss: 58.6500\tvalidation loss: 67.5083\t validation accuracy: 0.9667\n",
      "iteration number: 1828\t training loss: 58.6060\tvalidation loss: 67.5044\t validation accuracy: 0.9667\n",
      "iteration number: 1829\t training loss: 58.5621\tvalidation loss: 67.5005\t validation accuracy: 0.9667\n",
      "iteration number: 1830\t training loss: 58.5182\tvalidation loss: 67.4966\t validation accuracy: 0.9667\n",
      "iteration number: 1831\t training loss: 58.4743\tvalidation loss: 67.4927\t validation accuracy: 0.9667\n",
      "iteration number: 1832\t training loss: 58.4305\tvalidation loss: 67.4888\t validation accuracy: 0.9667\n",
      "iteration number: 1833\t training loss: 58.3868\tvalidation loss: 67.4849\t validation accuracy: 0.9667\n",
      "iteration number: 1834\t training loss: 58.3431\tvalidation loss: 67.4810\t validation accuracy: 0.9667\n",
      "iteration number: 1835\t training loss: 58.2995\tvalidation loss: 67.4772\t validation accuracy: 0.9667\n",
      "iteration number: 1836\t training loss: 58.2559\tvalidation loss: 67.4733\t validation accuracy: 0.9667\n",
      "iteration number: 1837\t training loss: 58.2123\tvalidation loss: 67.4694\t validation accuracy: 0.9667\n",
      "iteration number: 1838\t training loss: 58.1688\tvalidation loss: 67.4656\t validation accuracy: 0.9667\n",
      "iteration number: 1839\t training loss: 58.1254\tvalidation loss: 67.4618\t validation accuracy: 0.9667\n",
      "iteration number: 1840\t training loss: 58.0820\tvalidation loss: 67.4579\t validation accuracy: 0.9667\n",
      "iteration number: 1841\t training loss: 58.0387\tvalidation loss: 67.4541\t validation accuracy: 0.9667\n",
      "iteration number: 1842\t training loss: 57.9954\tvalidation loss: 67.4503\t validation accuracy: 0.9667\n",
      "iteration number: 1843\t training loss: 57.9521\tvalidation loss: 67.4465\t validation accuracy: 0.9667\n",
      "iteration number: 1844\t training loss: 57.9090\tvalidation loss: 67.4427\t validation accuracy: 0.9667\n",
      "iteration number: 1845\t training loss: 57.8658\tvalidation loss: 67.4389\t validation accuracy: 0.9667\n",
      "iteration number: 1846\t training loss: 57.8227\tvalidation loss: 67.4351\t validation accuracy: 0.9667\n",
      "iteration number: 1847\t training loss: 57.7797\tvalidation loss: 67.4314\t validation accuracy: 0.9667\n",
      "iteration number: 1848\t training loss: 57.7367\tvalidation loss: 67.4276\t validation accuracy: 0.9667\n",
      "iteration number: 1849\t training loss: 57.6938\tvalidation loss: 67.4238\t validation accuracy: 0.9667\n",
      "iteration number: 1850\t training loss: 57.6509\tvalidation loss: 67.4201\t validation accuracy: 0.9667\n",
      "iteration number: 1851\t training loss: 57.6080\tvalidation loss: 67.4163\t validation accuracy: 0.9667\n",
      "iteration number: 1852\t training loss: 57.5653\tvalidation loss: 67.4126\t validation accuracy: 0.9667\n",
      "iteration number: 1853\t training loss: 57.5225\tvalidation loss: 67.4089\t validation accuracy: 0.9667\n",
      "iteration number: 1854\t training loss: 57.4798\tvalidation loss: 67.4052\t validation accuracy: 0.9667\n",
      "iteration number: 1855\t training loss: 57.4372\tvalidation loss: 67.4015\t validation accuracy: 0.9667\n",
      "iteration number: 1856\t training loss: 57.3946\tvalidation loss: 67.3978\t validation accuracy: 0.9667\n",
      "iteration number: 1857\t training loss: 57.3521\tvalidation loss: 67.3941\t validation accuracy: 0.9667\n",
      "iteration number: 1858\t training loss: 57.3096\tvalidation loss: 67.3904\t validation accuracy: 0.9667\n",
      "iteration number: 1859\t training loss: 57.2671\tvalidation loss: 67.3867\t validation accuracy: 0.9667\n",
      "iteration number: 1860\t training loss: 57.2247\tvalidation loss: 67.3831\t validation accuracy: 0.9667\n",
      "iteration number: 1861\t training loss: 57.1824\tvalidation loss: 67.3794\t validation accuracy: 0.9667\n",
      "iteration number: 1862\t training loss: 57.1401\tvalidation loss: 67.3757\t validation accuracy: 0.9667\n",
      "iteration number: 1863\t training loss: 57.0978\tvalidation loss: 67.3721\t validation accuracy: 0.9689\n",
      "iteration number: 1864\t training loss: 57.0556\tvalidation loss: 67.3685\t validation accuracy: 0.9689\n",
      "iteration number: 1865\t training loss: 57.0135\tvalidation loss: 67.3648\t validation accuracy: 0.9689\n",
      "iteration number: 1866\t training loss: 56.9714\tvalidation loss: 67.3612\t validation accuracy: 0.9689\n",
      "iteration number: 1867\t training loss: 56.9293\tvalidation loss: 67.3576\t validation accuracy: 0.9689\n",
      "iteration number: 1868\t training loss: 56.8873\tvalidation loss: 67.3540\t validation accuracy: 0.9689\n",
      "iteration number: 1869\t training loss: 56.8454\tvalidation loss: 67.3504\t validation accuracy: 0.9689\n",
      "iteration number: 1870\t training loss: 56.8035\tvalidation loss: 67.3468\t validation accuracy: 0.9689\n",
      "iteration number: 1871\t training loss: 56.7616\tvalidation loss: 67.3432\t validation accuracy: 0.9689\n",
      "iteration number: 1872\t training loss: 56.7198\tvalidation loss: 67.3397\t validation accuracy: 0.9689\n",
      "iteration number: 1873\t training loss: 56.6780\tvalidation loss: 67.3361\t validation accuracy: 0.9689\n",
      "iteration number: 1874\t training loss: 56.6363\tvalidation loss: 67.3325\t validation accuracy: 0.9689\n",
      "iteration number: 1875\t training loss: 56.5946\tvalidation loss: 67.3290\t validation accuracy: 0.9689\n",
      "iteration number: 1876\t training loss: 56.5530\tvalidation loss: 67.3254\t validation accuracy: 0.9689\n",
      "iteration number: 1877\t training loss: 56.5115\tvalidation loss: 67.3219\t validation accuracy: 0.9689\n",
      "iteration number: 1878\t training loss: 56.4699\tvalidation loss: 67.3184\t validation accuracy: 0.9689\n",
      "iteration number: 1879\t training loss: 56.4285\tvalidation loss: 67.3149\t validation accuracy: 0.9689\n",
      "iteration number: 1880\t training loss: 56.3870\tvalidation loss: 67.3113\t validation accuracy: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1881\t training loss: 56.3456\tvalidation loss: 67.3078\t validation accuracy: 0.9689\n",
      "iteration number: 1882\t training loss: 56.3043\tvalidation loss: 67.3043\t validation accuracy: 0.9689\n",
      "iteration number: 1883\t training loss: 56.2630\tvalidation loss: 67.3009\t validation accuracy: 0.9689\n",
      "iteration number: 1884\t training loss: 56.2218\tvalidation loss: 67.2974\t validation accuracy: 0.9689\n",
      "iteration number: 1885\t training loss: 56.1806\tvalidation loss: 67.2939\t validation accuracy: 0.9689\n",
      "iteration number: 1886\t training loss: 56.1394\tvalidation loss: 67.2904\t validation accuracy: 0.9689\n",
      "iteration number: 1887\t training loss: 56.0983\tvalidation loss: 67.2870\t validation accuracy: 0.9689\n",
      "iteration number: 1888\t training loss: 56.0573\tvalidation loss: 67.2835\t validation accuracy: 0.9689\n",
      "iteration number: 1889\t training loss: 56.0163\tvalidation loss: 67.2801\t validation accuracy: 0.9689\n",
      "iteration number: 1890\t training loss: 55.9753\tvalidation loss: 67.2767\t validation accuracy: 0.9689\n",
      "iteration number: 1891\t training loss: 55.9344\tvalidation loss: 67.2732\t validation accuracy: 0.9689\n",
      "iteration number: 1892\t training loss: 55.8935\tvalidation loss: 67.2698\t validation accuracy: 0.9689\n",
      "iteration number: 1893\t training loss: 55.8527\tvalidation loss: 67.2664\t validation accuracy: 0.9689\n",
      "iteration number: 1894\t training loss: 55.8120\tvalidation loss: 67.2630\t validation accuracy: 0.9689\n",
      "iteration number: 1895\t training loss: 55.7712\tvalidation loss: 67.2596\t validation accuracy: 0.9689\n",
      "iteration number: 1896\t training loss: 55.7305\tvalidation loss: 67.2562\t validation accuracy: 0.9689\n",
      "iteration number: 1897\t training loss: 55.6899\tvalidation loss: 67.2528\t validation accuracy: 0.9689\n",
      "iteration number: 1898\t training loss: 55.6493\tvalidation loss: 67.2494\t validation accuracy: 0.9689\n",
      "iteration number: 1899\t training loss: 55.6088\tvalidation loss: 67.2461\t validation accuracy: 0.9689\n",
      "iteration number: 1900\t training loss: 55.5683\tvalidation loss: 67.2427\t validation accuracy: 0.9689\n",
      "iteration number: 1901\t training loss: 55.5278\tvalidation loss: 67.2394\t validation accuracy: 0.9689\n",
      "iteration number: 1902\t training loss: 55.4874\tvalidation loss: 67.2360\t validation accuracy: 0.9689\n",
      "iteration number: 1903\t training loss: 55.4471\tvalidation loss: 67.2327\t validation accuracy: 0.9689\n",
      "iteration number: 1904\t training loss: 55.4068\tvalidation loss: 67.2293\t validation accuracy: 0.9689\n",
      "iteration number: 1905\t training loss: 55.3665\tvalidation loss: 67.2260\t validation accuracy: 0.9689\n",
      "iteration number: 1906\t training loss: 55.3263\tvalidation loss: 67.2227\t validation accuracy: 0.9689\n",
      "iteration number: 1907\t training loss: 55.2861\tvalidation loss: 67.2194\t validation accuracy: 0.9689\n",
      "iteration number: 1908\t training loss: 55.2460\tvalidation loss: 67.2161\t validation accuracy: 0.9689\n",
      "iteration number: 1909\t training loss: 55.2059\tvalidation loss: 67.2128\t validation accuracy: 0.9689\n",
      "iteration number: 1910\t training loss: 55.1659\tvalidation loss: 67.2095\t validation accuracy: 0.9689\n",
      "iteration number: 1911\t training loss: 55.1259\tvalidation loss: 67.2062\t validation accuracy: 0.9689\n",
      "iteration number: 1912\t training loss: 55.0859\tvalidation loss: 67.2030\t validation accuracy: 0.9689\n",
      "iteration number: 1913\t training loss: 55.0460\tvalidation loss: 67.1997\t validation accuracy: 0.9689\n",
      "iteration number: 1914\t training loss: 55.0062\tvalidation loss: 67.1964\t validation accuracy: 0.9689\n",
      "iteration number: 1915\t training loss: 54.9663\tvalidation loss: 67.1932\t validation accuracy: 0.9689\n",
      "iteration number: 1916\t training loss: 54.9266\tvalidation loss: 67.1899\t validation accuracy: 0.9689\n",
      "iteration number: 1917\t training loss: 54.8869\tvalidation loss: 67.1867\t validation accuracy: 0.9689\n",
      "iteration number: 1918\t training loss: 54.8472\tvalidation loss: 67.1835\t validation accuracy: 0.9689\n",
      "iteration number: 1919\t training loss: 54.8075\tvalidation loss: 67.1802\t validation accuracy: 0.9689\n",
      "iteration number: 1920\t training loss: 54.7680\tvalidation loss: 67.1770\t validation accuracy: 0.9689\n",
      "iteration number: 1921\t training loss: 54.7284\tvalidation loss: 67.1738\t validation accuracy: 0.9689\n",
      "iteration number: 1922\t training loss: 54.6889\tvalidation loss: 67.1706\t validation accuracy: 0.9689\n",
      "iteration number: 1923\t training loss: 54.6495\tvalidation loss: 67.1674\t validation accuracy: 0.9689\n",
      "iteration number: 1924\t training loss: 54.6100\tvalidation loss: 67.1642\t validation accuracy: 0.9689\n",
      "iteration number: 1925\t training loss: 54.5707\tvalidation loss: 67.1611\t validation accuracy: 0.9689\n",
      "iteration number: 1926\t training loss: 54.5314\tvalidation loss: 67.1579\t validation accuracy: 0.9689\n",
      "iteration number: 1927\t training loss: 54.4921\tvalidation loss: 67.1547\t validation accuracy: 0.9689\n",
      "iteration number: 1928\t training loss: 54.4528\tvalidation loss: 67.1516\t validation accuracy: 0.9689\n",
      "iteration number: 1929\t training loss: 54.4137\tvalidation loss: 67.1484\t validation accuracy: 0.9689\n",
      "iteration number: 1930\t training loss: 54.3745\tvalidation loss: 67.1453\t validation accuracy: 0.9689\n",
      "iteration number: 1931\t training loss: 54.3354\tvalidation loss: 67.1421\t validation accuracy: 0.9689\n",
      "iteration number: 1932\t training loss: 54.2964\tvalidation loss: 67.1390\t validation accuracy: 0.9689\n",
      "iteration number: 1933\t training loss: 54.2573\tvalidation loss: 67.1359\t validation accuracy: 0.9689\n",
      "iteration number: 1934\t training loss: 54.2184\tvalidation loss: 67.1328\t validation accuracy: 0.9689\n",
      "iteration number: 1935\t training loss: 54.1794\tvalidation loss: 67.1297\t validation accuracy: 0.9689\n",
      "iteration number: 1936\t training loss: 54.1406\tvalidation loss: 67.1266\t validation accuracy: 0.9689\n",
      "iteration number: 1937\t training loss: 54.1017\tvalidation loss: 67.1235\t validation accuracy: 0.9689\n",
      "iteration number: 1938\t training loss: 54.0629\tvalidation loss: 67.1204\t validation accuracy: 0.9689\n",
      "iteration number: 1939\t training loss: 54.0242\tvalidation loss: 67.1173\t validation accuracy: 0.9689\n",
      "iteration number: 1940\t training loss: 53.9855\tvalidation loss: 67.1142\t validation accuracy: 0.9689\n",
      "iteration number: 1941\t training loss: 53.9468\tvalidation loss: 67.1111\t validation accuracy: 0.9689\n",
      "iteration number: 1942\t training loss: 53.9082\tvalidation loss: 67.1081\t validation accuracy: 0.9689\n",
      "iteration number: 1943\t training loss: 53.8696\tvalidation loss: 67.1050\t validation accuracy: 0.9689\n",
      "iteration number: 1944\t training loss: 53.8311\tvalidation loss: 67.1020\t validation accuracy: 0.9689\n",
      "iteration number: 1945\t training loss: 53.7926\tvalidation loss: 67.0989\t validation accuracy: 0.9689\n",
      "iteration number: 1946\t training loss: 53.7541\tvalidation loss: 67.0959\t validation accuracy: 0.9689\n",
      "iteration number: 1947\t training loss: 53.7157\tvalidation loss: 67.0929\t validation accuracy: 0.9689\n",
      "iteration number: 1948\t training loss: 53.6773\tvalidation loss: 67.0899\t validation accuracy: 0.9689\n",
      "iteration number: 1949\t training loss: 53.6390\tvalidation loss: 67.0869\t validation accuracy: 0.9689\n",
      "iteration number: 1950\t training loss: 53.6007\tvalidation loss: 67.0839\t validation accuracy: 0.9689\n",
      "iteration number: 1951\t training loss: 53.5625\tvalidation loss: 67.0809\t validation accuracy: 0.9689\n",
      "iteration number: 1952\t training loss: 53.5243\tvalidation loss: 67.0779\t validation accuracy: 0.9689\n",
      "iteration number: 1953\t training loss: 53.4862\tvalidation loss: 67.0749\t validation accuracy: 0.9689\n",
      "iteration number: 1954\t training loss: 53.4481\tvalidation loss: 67.0719\t validation accuracy: 0.9689\n",
      "iteration number: 1955\t training loss: 53.4100\tvalidation loss: 67.0689\t validation accuracy: 0.9689\n",
      "iteration number: 1956\t training loss: 53.3720\tvalidation loss: 67.0660\t validation accuracy: 0.9689\n",
      "iteration number: 1957\t training loss: 53.3340\tvalidation loss: 67.0630\t validation accuracy: 0.9689\n",
      "iteration number: 1958\t training loss: 53.2960\tvalidation loss: 67.0601\t validation accuracy: 0.9689\n",
      "iteration number: 1959\t training loss: 53.2581\tvalidation loss: 67.0571\t validation accuracy: 0.9689\n",
      "iteration number: 1960\t training loss: 53.2203\tvalidation loss: 67.0542\t validation accuracy: 0.9689\n",
      "iteration number: 1961\t training loss: 53.1825\tvalidation loss: 67.0512\t validation accuracy: 0.9689\n",
      "iteration number: 1962\t training loss: 53.1447\tvalidation loss: 67.0483\t validation accuracy: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1963\t training loss: 53.1070\tvalidation loss: 67.0454\t validation accuracy: 0.9689\n",
      "iteration number: 1964\t training loss: 53.0693\tvalidation loss: 67.0425\t validation accuracy: 0.9689\n",
      "iteration number: 1965\t training loss: 53.0316\tvalidation loss: 67.0396\t validation accuracy: 0.9689\n",
      "iteration number: 1966\t training loss: 52.9940\tvalidation loss: 67.0367\t validation accuracy: 0.9689\n",
      "iteration number: 1967\t training loss: 52.9565\tvalidation loss: 67.0338\t validation accuracy: 0.9689\n",
      "iteration number: 1968\t training loss: 52.9189\tvalidation loss: 67.0309\t validation accuracy: 0.9689\n",
      "iteration number: 1969\t training loss: 52.8815\tvalidation loss: 67.0280\t validation accuracy: 0.9689\n",
      "iteration number: 1970\t training loss: 52.8440\tvalidation loss: 67.0252\t validation accuracy: 0.9689\n",
      "iteration number: 1971\t training loss: 52.8066\tvalidation loss: 67.0223\t validation accuracy: 0.9689\n",
      "iteration number: 1972\t training loss: 52.7693\tvalidation loss: 67.0194\t validation accuracy: 0.9689\n",
      "iteration number: 1973\t training loss: 52.7319\tvalidation loss: 67.0166\t validation accuracy: 0.9689\n",
      "iteration number: 1974\t training loss: 52.6947\tvalidation loss: 67.0137\t validation accuracy: 0.9689\n",
      "iteration number: 1975\t training loss: 52.6574\tvalidation loss: 67.0109\t validation accuracy: 0.9689\n",
      "iteration number: 1976\t training loss: 52.6202\tvalidation loss: 67.0081\t validation accuracy: 0.9689\n",
      "iteration number: 1977\t training loss: 52.5831\tvalidation loss: 67.0052\t validation accuracy: 0.9689\n",
      "iteration number: 1978\t training loss: 52.5460\tvalidation loss: 67.0024\t validation accuracy: 0.9689\n",
      "iteration number: 1979\t training loss: 52.5089\tvalidation loss: 66.9996\t validation accuracy: 0.9689\n",
      "iteration number: 1980\t training loss: 52.4719\tvalidation loss: 66.9968\t validation accuracy: 0.9689\n",
      "iteration number: 1981\t training loss: 52.4349\tvalidation loss: 66.9940\t validation accuracy: 0.9689\n",
      "iteration number: 1982\t training loss: 52.3979\tvalidation loss: 66.9912\t validation accuracy: 0.9689\n",
      "iteration number: 1983\t training loss: 52.3610\tvalidation loss: 66.9884\t validation accuracy: 0.9689\n",
      "iteration number: 1984\t training loss: 52.3242\tvalidation loss: 66.9856\t validation accuracy: 0.9689\n",
      "iteration number: 1985\t training loss: 52.2873\tvalidation loss: 66.9829\t validation accuracy: 0.9689\n",
      "iteration number: 1986\t training loss: 52.2506\tvalidation loss: 66.9801\t validation accuracy: 0.9689\n",
      "iteration number: 1987\t training loss: 52.2138\tvalidation loss: 66.9773\t validation accuracy: 0.9689\n",
      "iteration number: 1988\t training loss: 52.1771\tvalidation loss: 66.9746\t validation accuracy: 0.9689\n",
      "iteration number: 1989\t training loss: 52.1404\tvalidation loss: 66.9718\t validation accuracy: 0.9689\n",
      "iteration number: 1990\t training loss: 52.1038\tvalidation loss: 66.9691\t validation accuracy: 0.9689\n",
      "iteration number: 1991\t training loss: 52.0672\tvalidation loss: 66.9663\t validation accuracy: 0.9689\n",
      "iteration number: 1992\t training loss: 52.0307\tvalidation loss: 66.9636\t validation accuracy: 0.9689\n",
      "iteration number: 1993\t training loss: 51.9942\tvalidation loss: 66.9609\t validation accuracy: 0.9689\n",
      "iteration number: 1994\t training loss: 51.9577\tvalidation loss: 66.9582\t validation accuracy: 0.9689\n",
      "iteration number: 1995\t training loss: 51.9213\tvalidation loss: 66.9555\t validation accuracy: 0.9689\n",
      "iteration number: 1996\t training loss: 51.8849\tvalidation loss: 66.9528\t validation accuracy: 0.9689\n",
      "iteration number: 1997\t training loss: 51.8486\tvalidation loss: 66.9501\t validation accuracy: 0.9689\n",
      "iteration number: 1998\t training loss: 51.8123\tvalidation loss: 66.9474\t validation accuracy: 0.9689\n",
      "iteration number: 1999\t training loss: 51.7760\tvalidation loss: 66.9447\t validation accuracy: 0.9689\n",
      "iteration number: 2000\t training loss: 51.7398\tvalidation loss: 66.9420\t validation accuracy: 0.9689\n",
      "iteration number: 2001\t training loss: 51.7036\tvalidation loss: 66.9393\t validation accuracy: 0.9689\n",
      "iteration number: 2002\t training loss: 51.6674\tvalidation loss: 66.9367\t validation accuracy: 0.9689\n",
      "iteration number: 2003\t training loss: 51.6313\tvalidation loss: 66.9340\t validation accuracy: 0.9689\n",
      "iteration number: 2004\t training loss: 51.5952\tvalidation loss: 66.9314\t validation accuracy: 0.9689\n",
      "iteration number: 2005\t training loss: 51.5592\tvalidation loss: 66.9287\t validation accuracy: 0.9689\n",
      "iteration number: 2006\t training loss: 51.5232\tvalidation loss: 66.9261\t validation accuracy: 0.9689\n",
      "iteration number: 2007\t training loss: 51.4873\tvalidation loss: 66.9234\t validation accuracy: 0.9689\n",
      "iteration number: 2008\t training loss: 51.4514\tvalidation loss: 66.9208\t validation accuracy: 0.9689\n",
      "iteration number: 2009\t training loss: 51.4155\tvalidation loss: 66.9182\t validation accuracy: 0.9689\n",
      "iteration number: 2010\t training loss: 51.3796\tvalidation loss: 66.9156\t validation accuracy: 0.9689\n",
      "iteration number: 2011\t training loss: 51.3438\tvalidation loss: 66.9129\t validation accuracy: 0.9689\n",
      "iteration number: 2012\t training loss: 51.3081\tvalidation loss: 66.9103\t validation accuracy: 0.9689\n",
      "iteration number: 2013\t training loss: 51.2724\tvalidation loss: 66.9077\t validation accuracy: 0.9689\n",
      "iteration number: 2014\t training loss: 51.2367\tvalidation loss: 66.9051\t validation accuracy: 0.9689\n",
      "iteration number: 2015\t training loss: 51.2010\tvalidation loss: 66.9026\t validation accuracy: 0.9689\n",
      "iteration number: 2016\t training loss: 51.1654\tvalidation loss: 66.9000\t validation accuracy: 0.9689\n",
      "iteration number: 2017\t training loss: 51.1299\tvalidation loss: 66.8974\t validation accuracy: 0.9689\n",
      "iteration number: 2018\t training loss: 51.0944\tvalidation loss: 66.8948\t validation accuracy: 0.9689\n",
      "iteration number: 2019\t training loss: 51.0589\tvalidation loss: 66.8923\t validation accuracy: 0.9689\n",
      "iteration number: 2020\t training loss: 51.0234\tvalidation loss: 66.8897\t validation accuracy: 0.9689\n",
      "iteration number: 2021\t training loss: 50.9880\tvalidation loss: 66.8872\t validation accuracy: 0.9689\n",
      "iteration number: 2022\t training loss: 50.9526\tvalidation loss: 66.8846\t validation accuracy: 0.9689\n",
      "iteration number: 2023\t training loss: 50.9173\tvalidation loss: 66.8821\t validation accuracy: 0.9689\n",
      "iteration number: 2024\t training loss: 50.8820\tvalidation loss: 66.8795\t validation accuracy: 0.9689\n",
      "iteration number: 2025\t training loss: 50.8467\tvalidation loss: 66.8770\t validation accuracy: 0.9689\n",
      "iteration number: 2026\t training loss: 50.8115\tvalidation loss: 66.8745\t validation accuracy: 0.9689\n",
      "iteration number: 2027\t training loss: 50.7763\tvalidation loss: 66.8720\t validation accuracy: 0.9689\n",
      "iteration number: 2028\t training loss: 50.7412\tvalidation loss: 66.8695\t validation accuracy: 0.9689\n",
      "iteration number: 2029\t training loss: 50.7061\tvalidation loss: 66.8670\t validation accuracy: 0.9689\n",
      "iteration number: 2030\t training loss: 50.6710\tvalidation loss: 66.8645\t validation accuracy: 0.9689\n",
      "iteration number: 2031\t training loss: 50.6360\tvalidation loss: 66.8620\t validation accuracy: 0.9689\n",
      "iteration number: 2032\t training loss: 50.6010\tvalidation loss: 66.8595\t validation accuracy: 0.9689\n",
      "iteration number: 2033\t training loss: 50.5660\tvalidation loss: 66.8570\t validation accuracy: 0.9689\n",
      "iteration number: 2034\t training loss: 50.5311\tvalidation loss: 66.8545\t validation accuracy: 0.9689\n",
      "iteration number: 2035\t training loss: 50.4962\tvalidation loss: 66.8521\t validation accuracy: 0.9689\n",
      "iteration number: 2036\t training loss: 50.4614\tvalidation loss: 66.8496\t validation accuracy: 0.9689\n",
      "iteration number: 2037\t training loss: 50.4266\tvalidation loss: 66.8471\t validation accuracy: 0.9689\n",
      "iteration number: 2038\t training loss: 50.3918\tvalidation loss: 66.8447\t validation accuracy: 0.9689\n",
      "iteration number: 2039\t training loss: 50.3571\tvalidation loss: 66.8423\t validation accuracy: 0.9689\n",
      "iteration number: 2040\t training loss: 50.3224\tvalidation loss: 66.8398\t validation accuracy: 0.9689\n",
      "iteration number: 2041\t training loss: 50.2877\tvalidation loss: 66.8374\t validation accuracy: 0.9689\n",
      "iteration number: 2042\t training loss: 50.2531\tvalidation loss: 66.8350\t validation accuracy: 0.9689\n",
      "iteration number: 2043\t training loss: 50.2185\tvalidation loss: 66.8325\t validation accuracy: 0.9689\n",
      "iteration number: 2044\t training loss: 50.1840\tvalidation loss: 66.8301\t validation accuracy: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 2045\t training loss: 50.1495\tvalidation loss: 66.8277\t validation accuracy: 0.9689\n",
      "iteration number: 2046\t training loss: 50.1150\tvalidation loss: 66.8253\t validation accuracy: 0.9689\n",
      "iteration number: 2047\t training loss: 50.0806\tvalidation loss: 66.8229\t validation accuracy: 0.9689\n",
      "iteration number: 2048\t training loss: 50.0462\tvalidation loss: 66.8205\t validation accuracy: 0.9689\n",
      "iteration number: 2049\t training loss: 50.0118\tvalidation loss: 66.8181\t validation accuracy: 0.9689\n",
      "iteration number: 2050\t training loss: 49.9775\tvalidation loss: 66.8157\t validation accuracy: 0.9689\n",
      "iteration number: 2051\t training loss: 49.9432\tvalidation loss: 66.8134\t validation accuracy: 0.9689\n",
      "iteration number: 2052\t training loss: 49.9089\tvalidation loss: 66.8110\t validation accuracy: 0.9689\n",
      "iteration number: 2053\t training loss: 49.8747\tvalidation loss: 66.8086\t validation accuracy: 0.9689\n",
      "iteration number: 2054\t training loss: 49.8405\tvalidation loss: 66.8063\t validation accuracy: 0.9689\n",
      "iteration number: 2055\t training loss: 49.8064\tvalidation loss: 66.8039\t validation accuracy: 0.9689\n",
      "iteration number: 2056\t training loss: 49.7723\tvalidation loss: 66.8016\t validation accuracy: 0.9689\n",
      "iteration number: 2057\t training loss: 49.7382\tvalidation loss: 66.7992\t validation accuracy: 0.9689\n",
      "iteration number: 2058\t training loss: 49.7042\tvalidation loss: 66.7969\t validation accuracy: 0.9689\n",
      "iteration number: 2059\t training loss: 49.6702\tvalidation loss: 66.7946\t validation accuracy: 0.9689\n",
      "iteration number: 2060\t training loss: 49.6362\tvalidation loss: 66.7922\t validation accuracy: 0.9689\n",
      "iteration number: 2061\t training loss: 49.6023\tvalidation loss: 66.7899\t validation accuracy: 0.9689\n",
      "iteration number: 2062\t training loss: 49.5684\tvalidation loss: 66.7876\t validation accuracy: 0.9689\n",
      "iteration number: 2063\t training loss: 49.5346\tvalidation loss: 66.7853\t validation accuracy: 0.9689\n",
      "iteration number: 2064\t training loss: 49.5007\tvalidation loss: 66.7830\t validation accuracy: 0.9689\n",
      "iteration number: 2065\t training loss: 49.4670\tvalidation loss: 66.7807\t validation accuracy: 0.9689\n",
      "iteration number: 2066\t training loss: 49.4332\tvalidation loss: 66.7784\t validation accuracy: 0.9689\n",
      "iteration number: 2067\t training loss: 49.3995\tvalidation loss: 66.7761\t validation accuracy: 0.9689\n",
      "iteration number: 2068\t training loss: 49.3658\tvalidation loss: 66.7738\t validation accuracy: 0.9689\n",
      "iteration number: 2069\t training loss: 49.3322\tvalidation loss: 66.7716\t validation accuracy: 0.9689\n",
      "iteration number: 2070\t training loss: 49.2986\tvalidation loss: 66.7693\t validation accuracy: 0.9689\n",
      "iteration number: 2071\t training loss: 49.2650\tvalidation loss: 66.7670\t validation accuracy: 0.9689\n",
      "iteration number: 2072\t training loss: 49.2315\tvalidation loss: 66.7648\t validation accuracy: 0.9689\n",
      "iteration number: 2073\t training loss: 49.1980\tvalidation loss: 66.7625\t validation accuracy: 0.9689\n",
      "iteration number: 2074\t training loss: 49.1645\tvalidation loss: 66.7603\t validation accuracy: 0.9689\n",
      "iteration number: 2075\t training loss: 49.1311\tvalidation loss: 66.7580\t validation accuracy: 0.9689\n",
      "iteration number: 2076\t training loss: 49.0977\tvalidation loss: 66.7558\t validation accuracy: 0.9689\n",
      "iteration number: 2077\t training loss: 49.0643\tvalidation loss: 66.7536\t validation accuracy: 0.9689\n",
      "iteration number: 2078\t training loss: 49.0310\tvalidation loss: 66.7514\t validation accuracy: 0.9689\n",
      "iteration number: 2079\t training loss: 48.9977\tvalidation loss: 66.7491\t validation accuracy: 0.9689\n",
      "iteration number: 2080\t training loss: 48.9645\tvalidation loss: 66.7469\t validation accuracy: 0.9689\n",
      "iteration number: 2081\t training loss: 48.9313\tvalidation loss: 66.7447\t validation accuracy: 0.9689\n",
      "iteration number: 2082\t training loss: 48.8981\tvalidation loss: 66.7425\t validation accuracy: 0.9689\n",
      "iteration number: 2083\t training loss: 48.8649\tvalidation loss: 66.7403\t validation accuracy: 0.9689\n",
      "iteration number: 2084\t training loss: 48.8318\tvalidation loss: 66.7381\t validation accuracy: 0.9689\n",
      "iteration number: 2085\t training loss: 48.7987\tvalidation loss: 66.7359\t validation accuracy: 0.9689\n",
      "iteration number: 2086\t training loss: 48.7657\tvalidation loss: 66.7337\t validation accuracy: 0.9689\n",
      "iteration number: 2087\t training loss: 48.7327\tvalidation loss: 66.7316\t validation accuracy: 0.9689\n",
      "iteration number: 2088\t training loss: 48.6997\tvalidation loss: 66.7294\t validation accuracy: 0.9689\n",
      "iteration number: 2089\t training loss: 48.6668\tvalidation loss: 66.7272\t validation accuracy: 0.9689\n",
      "iteration number: 2090\t training loss: 48.6339\tvalidation loss: 66.7251\t validation accuracy: 0.9689\n",
      "iteration number: 2091\t training loss: 48.6010\tvalidation loss: 66.7229\t validation accuracy: 0.9689\n",
      "iteration number: 2092\t training loss: 48.5682\tvalidation loss: 66.7208\t validation accuracy: 0.9689\n",
      "iteration number: 2093\t training loss: 48.5354\tvalidation loss: 66.7186\t validation accuracy: 0.9689\n",
      "iteration number: 2094\t training loss: 48.5026\tvalidation loss: 66.7165\t validation accuracy: 0.9689\n",
      "iteration number: 2095\t training loss: 48.4699\tvalidation loss: 66.7143\t validation accuracy: 0.9689\n",
      "iteration number: 2096\t training loss: 48.4372\tvalidation loss: 66.7122\t validation accuracy: 0.9689\n",
      "iteration number: 2097\t training loss: 48.4045\tvalidation loss: 66.7101\t validation accuracy: 0.9689\n",
      "iteration number: 2098\t training loss: 48.3719\tvalidation loss: 66.7080\t validation accuracy: 0.9689\n",
      "iteration number: 2099\t training loss: 48.3393\tvalidation loss: 66.7059\t validation accuracy: 0.9689\n",
      "iteration number: 2100\t training loss: 48.3067\tvalidation loss: 66.7038\t validation accuracy: 0.9689\n",
      "iteration number: 2101\t training loss: 48.2742\tvalidation loss: 66.7016\t validation accuracy: 0.9689\n",
      "iteration number: 2102\t training loss: 48.2417\tvalidation loss: 66.6995\t validation accuracy: 0.9689\n",
      "iteration number: 2103\t training loss: 48.2092\tvalidation loss: 66.6975\t validation accuracy: 0.9689\n",
      "iteration number: 2104\t training loss: 48.1768\tvalidation loss: 66.6954\t validation accuracy: 0.9689\n",
      "iteration number: 2105\t training loss: 48.1444\tvalidation loss: 66.6933\t validation accuracy: 0.9689\n",
      "iteration number: 2106\t training loss: 48.1121\tvalidation loss: 66.6912\t validation accuracy: 0.9689\n",
      "iteration number: 2107\t training loss: 48.0797\tvalidation loss: 66.6891\t validation accuracy: 0.9689\n",
      "iteration number: 2108\t training loss: 48.0474\tvalidation loss: 66.6871\t validation accuracy: 0.9689\n",
      "iteration number: 2109\t training loss: 48.0152\tvalidation loss: 66.6850\t validation accuracy: 0.9689\n",
      "iteration number: 2110\t training loss: 47.9830\tvalidation loss: 66.6830\t validation accuracy: 0.9689\n",
      "iteration number: 2111\t training loss: 47.9508\tvalidation loss: 66.6809\t validation accuracy: 0.9689\n",
      "iteration number: 2112\t training loss: 47.9186\tvalidation loss: 66.6789\t validation accuracy: 0.9689\n",
      "iteration number: 2113\t training loss: 47.8865\tvalidation loss: 66.6768\t validation accuracy: 0.9689\n",
      "iteration number: 2114\t training loss: 47.8544\tvalidation loss: 66.6748\t validation accuracy: 0.9689\n",
      "iteration number: 2115\t training loss: 47.8223\tvalidation loss: 66.6728\t validation accuracy: 0.9689\n",
      "iteration number: 2116\t training loss: 47.7903\tvalidation loss: 66.6707\t validation accuracy: 0.9689\n",
      "iteration number: 2117\t training loss: 47.7583\tvalidation loss: 66.6687\t validation accuracy: 0.9689\n",
      "iteration number: 2118\t training loss: 47.7264\tvalidation loss: 66.6667\t validation accuracy: 0.9689\n",
      "iteration number: 2119\t training loss: 47.6944\tvalidation loss: 66.6647\t validation accuracy: 0.9689\n",
      "iteration number: 2120\t training loss: 47.6625\tvalidation loss: 66.6627\t validation accuracy: 0.9689\n",
      "iteration number: 2121\t training loss: 47.6307\tvalidation loss: 66.6607\t validation accuracy: 0.9689\n",
      "iteration number: 2122\t training loss: 47.5989\tvalidation loss: 66.6587\t validation accuracy: 0.9689\n",
      "iteration number: 2123\t training loss: 47.5671\tvalidation loss: 66.6567\t validation accuracy: 0.9689\n",
      "iteration number: 2124\t training loss: 47.5353\tvalidation loss: 66.6547\t validation accuracy: 0.9689\n",
      "iteration number: 2125\t training loss: 47.5036\tvalidation loss: 66.6527\t validation accuracy: 0.9689\n",
      "iteration number: 2126\t training loss: 47.4719\tvalidation loss: 66.6507\t validation accuracy: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 2127\t training loss: 47.4402\tvalidation loss: 66.6488\t validation accuracy: 0.9689\n",
      "iteration number: 2128\t training loss: 47.4086\tvalidation loss: 66.6468\t validation accuracy: 0.9689\n",
      "iteration number: 2129\t training loss: 47.3770\tvalidation loss: 66.6449\t validation accuracy: 0.9689\n",
      "iteration number: 2130\t training loss: 47.3454\tvalidation loss: 66.6429\t validation accuracy: 0.9689\n",
      "iteration number: 2131\t training loss: 47.3139\tvalidation loss: 66.6409\t validation accuracy: 0.9689\n",
      "iteration number: 2132\t training loss: 47.2824\tvalidation loss: 66.6390\t validation accuracy: 0.9689\n",
      "iteration number: 2133\t training loss: 47.2509\tvalidation loss: 66.6371\t validation accuracy: 0.9689\n",
      "iteration number: 2134\t training loss: 47.2195\tvalidation loss: 66.6351\t validation accuracy: 0.9689\n",
      "iteration number: 2135\t training loss: 47.1881\tvalidation loss: 66.6332\t validation accuracy: 0.9689\n",
      "iteration number: 2136\t training loss: 47.1567\tvalidation loss: 66.6313\t validation accuracy: 0.9689\n",
      "iteration number: 2137\t training loss: 47.1254\tvalidation loss: 66.6293\t validation accuracy: 0.9689\n",
      "iteration number: 2138\t training loss: 47.0941\tvalidation loss: 66.6274\t validation accuracy: 0.9689\n",
      "iteration number: 2139\t training loss: 47.0628\tvalidation loss: 66.6255\t validation accuracy: 0.9689\n",
      "iteration number: 2140\t training loss: 47.0315\tvalidation loss: 66.6236\t validation accuracy: 0.9689\n",
      "iteration number: 2141\t training loss: 47.0003\tvalidation loss: 66.6217\t validation accuracy: 0.9689\n",
      "iteration number: 2142\t training loss: 46.9691\tvalidation loss: 66.6198\t validation accuracy: 0.9689\n",
      "iteration number: 2143\t training loss: 46.9380\tvalidation loss: 66.6179\t validation accuracy: 0.9689\n",
      "iteration number: 2144\t training loss: 46.9069\tvalidation loss: 66.6160\t validation accuracy: 0.9689\n",
      "iteration number: 2145\t training loss: 46.8758\tvalidation loss: 66.6142\t validation accuracy: 0.9689\n",
      "iteration number: 2146\t training loss: 46.8447\tvalidation loss: 66.6123\t validation accuracy: 0.9689\n",
      "iteration number: 2147\t training loss: 46.8137\tvalidation loss: 66.6104\t validation accuracy: 0.9689\n",
      "iteration number: 2148\t training loss: 46.7827\tvalidation loss: 66.6085\t validation accuracy: 0.9689\n",
      "iteration number: 2149\t training loss: 46.7518\tvalidation loss: 66.6067\t validation accuracy: 0.9689\n",
      "iteration number: 2150\t training loss: 46.7209\tvalidation loss: 66.6048\t validation accuracy: 0.9689\n",
      "iteration number: 2151\t training loss: 46.6900\tvalidation loss: 66.6030\t validation accuracy: 0.9689\n",
      "iteration number: 2152\t training loss: 46.6591\tvalidation loss: 66.6011\t validation accuracy: 0.9689\n",
      "iteration number: 2153\t training loss: 46.6283\tvalidation loss: 66.5993\t validation accuracy: 0.9689\n",
      "iteration number: 2154\t training loss: 46.5975\tvalidation loss: 66.5974\t validation accuracy: 0.9689\n",
      "iteration number: 2155\t training loss: 46.5667\tvalidation loss: 66.5956\t validation accuracy: 0.9689\n",
      "iteration number: 2156\t training loss: 46.5360\tvalidation loss: 66.5938\t validation accuracy: 0.9689\n",
      "iteration number: 2157\t training loss: 46.5053\tvalidation loss: 66.5919\t validation accuracy: 0.9689\n",
      "iteration number: 2158\t training loss: 46.4746\tvalidation loss: 66.5901\t validation accuracy: 0.9689\n",
      "iteration number: 2159\t training loss: 46.4439\tvalidation loss: 66.5883\t validation accuracy: 0.9689\n",
      "iteration number: 2160\t training loss: 46.4133\tvalidation loss: 66.5865\t validation accuracy: 0.9689\n",
      "iteration number: 2161\t training loss: 46.3827\tvalidation loss: 66.5847\t validation accuracy: 0.9689\n",
      "iteration number: 2162\t training loss: 46.3522\tvalidation loss: 66.5829\t validation accuracy: 0.9689\n",
      "iteration number: 2163\t training loss: 46.3217\tvalidation loss: 66.5811\t validation accuracy: 0.9689\n",
      "iteration number: 2164\t training loss: 46.2912\tvalidation loss: 66.5793\t validation accuracy: 0.9689\n",
      "iteration number: 2165\t training loss: 46.2607\tvalidation loss: 66.5775\t validation accuracy: 0.9689\n",
      "iteration number: 2166\t training loss: 46.2303\tvalidation loss: 66.5757\t validation accuracy: 0.9689\n",
      "iteration number: 2167\t training loss: 46.1999\tvalidation loss: 66.5740\t validation accuracy: 0.9689\n",
      "iteration number: 2168\t training loss: 46.1695\tvalidation loss: 66.5722\t validation accuracy: 0.9689\n",
      "iteration number: 2169\t training loss: 46.1392\tvalidation loss: 66.5704\t validation accuracy: 0.9689\n",
      "iteration number: 2170\t training loss: 46.1089\tvalidation loss: 66.5687\t validation accuracy: 0.9689\n",
      "iteration number: 2171\t training loss: 46.0786\tvalidation loss: 66.5669\t validation accuracy: 0.9689\n",
      "iteration number: 2172\t training loss: 46.0484\tvalidation loss: 66.5651\t validation accuracy: 0.9689\n",
      "iteration number: 2173\t training loss: 46.0182\tvalidation loss: 66.5634\t validation accuracy: 0.9689\n",
      "iteration number: 2174\t training loss: 45.9880\tvalidation loss: 66.5616\t validation accuracy: 0.9689\n",
      "iteration number: 2175\t training loss: 45.9578\tvalidation loss: 66.5599\t validation accuracy: 0.9689\n",
      "iteration number: 2176\t training loss: 45.9277\tvalidation loss: 66.5582\t validation accuracy: 0.9689\n",
      "iteration number: 2177\t training loss: 45.8976\tvalidation loss: 66.5564\t validation accuracy: 0.9689\n",
      "iteration number: 2178\t training loss: 45.8676\tvalidation loss: 66.5547\t validation accuracy: 0.9689\n",
      "iteration number: 2179\t training loss: 45.8375\tvalidation loss: 66.5530\t validation accuracy: 0.9689\n",
      "iteration number: 2180\t training loss: 45.8075\tvalidation loss: 66.5513\t validation accuracy: 0.9689\n",
      "iteration number: 2181\t training loss: 45.7776\tvalidation loss: 66.5496\t validation accuracy: 0.9689\n",
      "iteration number: 2182\t training loss: 45.7476\tvalidation loss: 66.5478\t validation accuracy: 0.9689\n",
      "iteration number: 2183\t training loss: 45.7177\tvalidation loss: 66.5461\t validation accuracy: 0.9689\n",
      "iteration number: 2184\t training loss: 45.6879\tvalidation loss: 66.5444\t validation accuracy: 0.9689\n",
      "iteration number: 2185\t training loss: 45.6580\tvalidation loss: 66.5427\t validation accuracy: 0.9689\n",
      "iteration number: 2186\t training loss: 45.6282\tvalidation loss: 66.5411\t validation accuracy: 0.9689\n",
      "iteration number: 2187\t training loss: 45.5984\tvalidation loss: 66.5394\t validation accuracy: 0.9689\n",
      "iteration number: 2188\t training loss: 45.5686\tvalidation loss: 66.5377\t validation accuracy: 0.9689\n",
      "iteration number: 2189\t training loss: 45.5389\tvalidation loss: 66.5360\t validation accuracy: 0.9689\n",
      "iteration number: 2190\t training loss: 45.5092\tvalidation loss: 66.5343\t validation accuracy: 0.9689\n",
      "iteration number: 2191\t training loss: 45.4795\tvalidation loss: 66.5327\t validation accuracy: 0.9689\n",
      "iteration number: 2192\t training loss: 45.4499\tvalidation loss: 66.5310\t validation accuracy: 0.9689\n",
      "iteration number: 2193\t training loss: 45.4203\tvalidation loss: 66.5293\t validation accuracy: 0.9689\n",
      "iteration number: 2194\t training loss: 45.3907\tvalidation loss: 66.5277\t validation accuracy: 0.9689\n",
      "iteration number: 2195\t training loss: 45.3612\tvalidation loss: 66.5260\t validation accuracy: 0.9689\n",
      "iteration number: 2196\t training loss: 45.3316\tvalidation loss: 66.5244\t validation accuracy: 0.9689\n",
      "iteration number: 2197\t training loss: 45.3021\tvalidation loss: 66.5228\t validation accuracy: 0.9689\n",
      "iteration number: 2198\t training loss: 45.2727\tvalidation loss: 66.5211\t validation accuracy: 0.9689\n",
      "iteration number: 2199\t training loss: 45.2432\tvalidation loss: 66.5195\t validation accuracy: 0.9689\n",
      "iteration number: 2200\t training loss: 45.2138\tvalidation loss: 66.5179\t validation accuracy: 0.9689\n",
      "iteration number: 2201\t training loss: 45.1845\tvalidation loss: 66.5162\t validation accuracy: 0.9689\n",
      "iteration number: 2202\t training loss: 45.1551\tvalidation loss: 66.5146\t validation accuracy: 0.9689\n",
      "iteration number: 2203\t training loss: 45.1258\tvalidation loss: 66.5130\t validation accuracy: 0.9689\n",
      "iteration number: 2204\t training loss: 45.0965\tvalidation loss: 66.5114\t validation accuracy: 0.9689\n",
      "iteration number: 2205\t training loss: 45.0673\tvalidation loss: 66.5098\t validation accuracy: 0.9689\n",
      "iteration number: 2206\t training loss: 45.0380\tvalidation loss: 66.5082\t validation accuracy: 0.9689\n",
      "iteration number: 2207\t training loss: 45.0088\tvalidation loss: 66.5066\t validation accuracy: 0.9689\n",
      "iteration number: 2208\t training loss: 44.9797\tvalidation loss: 66.5050\t validation accuracy: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 2209\t training loss: 44.9505\tvalidation loss: 66.5034\t validation accuracy: 0.9689\n",
      "iteration number: 2210\t training loss: 44.9214\tvalidation loss: 66.5018\t validation accuracy: 0.9689\n",
      "iteration number: 2211\t training loss: 44.8923\tvalidation loss: 66.5002\t validation accuracy: 0.9689\n",
      "iteration number: 2212\t training loss: 44.8633\tvalidation loss: 66.4987\t validation accuracy: 0.9689\n",
      "iteration number: 2213\t training loss: 44.8342\tvalidation loss: 66.4971\t validation accuracy: 0.9689\n",
      "iteration number: 2214\t training loss: 44.8053\tvalidation loss: 66.4955\t validation accuracy: 0.9689\n",
      "iteration number: 2215\t training loss: 44.7763\tvalidation loss: 66.4940\t validation accuracy: 0.9689\n",
      "iteration number: 2216\t training loss: 44.7473\tvalidation loss: 66.4924\t validation accuracy: 0.9689\n",
      "iteration number: 2217\t training loss: 44.7184\tvalidation loss: 66.4908\t validation accuracy: 0.9689\n",
      "iteration number: 2218\t training loss: 44.6896\tvalidation loss: 66.4893\t validation accuracy: 0.9689\n",
      "iteration number: 2219\t training loss: 44.6607\tvalidation loss: 66.4877\t validation accuracy: 0.9689\n",
      "iteration number: 2220\t training loss: 44.6319\tvalidation loss: 66.4862\t validation accuracy: 0.9689\n",
      "iteration number: 2221\t training loss: 44.6031\tvalidation loss: 66.4847\t validation accuracy: 0.9689\n",
      "iteration number: 2222\t training loss: 44.5743\tvalidation loss: 66.4831\t validation accuracy: 0.9689\n",
      "iteration number: 2223\t training loss: 44.5456\tvalidation loss: 66.4816\t validation accuracy: 0.9689\n",
      "iteration number: 2224\t training loss: 44.5169\tvalidation loss: 66.4801\t validation accuracy: 0.9689\n",
      "iteration number: 2225\t training loss: 44.4882\tvalidation loss: 66.4786\t validation accuracy: 0.9689\n",
      "iteration number: 2226\t training loss: 44.4595\tvalidation loss: 66.4770\t validation accuracy: 0.9689\n",
      "iteration number: 2227\t training loss: 44.4309\tvalidation loss: 66.4755\t validation accuracy: 0.9689\n",
      "iteration number: 2228\t training loss: 44.4023\tvalidation loss: 66.4740\t validation accuracy: 0.9689\n",
      "iteration number: 2229\t training loss: 44.3737\tvalidation loss: 66.4725\t validation accuracy: 0.9689\n",
      "iteration number: 2230\t training loss: 44.3452\tvalidation loss: 66.4710\t validation accuracy: 0.9689\n",
      "iteration number: 2231\t training loss: 44.3167\tvalidation loss: 66.4695\t validation accuracy: 0.9689\n",
      "iteration number: 2232\t training loss: 44.2882\tvalidation loss: 66.4680\t validation accuracy: 0.9689\n",
      "iteration number: 2233\t training loss: 44.2597\tvalidation loss: 66.4665\t validation accuracy: 0.9689\n",
      "iteration number: 2234\t training loss: 44.2313\tvalidation loss: 66.4651\t validation accuracy: 0.9689\n",
      "iteration number: 2235\t training loss: 44.2029\tvalidation loss: 66.4636\t validation accuracy: 0.9711\n",
      "iteration number: 2236\t training loss: 44.1745\tvalidation loss: 66.4621\t validation accuracy: 0.9711\n",
      "iteration number: 2237\t training loss: 44.1462\tvalidation loss: 66.4606\t validation accuracy: 0.9711\n",
      "iteration number: 2238\t training loss: 44.1179\tvalidation loss: 66.4592\t validation accuracy: 0.9711\n",
      "iteration number: 2239\t training loss: 44.0896\tvalidation loss: 66.4577\t validation accuracy: 0.9711\n",
      "iteration number: 2240\t training loss: 44.0613\tvalidation loss: 66.4562\t validation accuracy: 0.9711\n",
      "iteration number: 2241\t training loss: 44.0331\tvalidation loss: 66.4548\t validation accuracy: 0.9711\n",
      "iteration number: 2242\t training loss: 44.0049\tvalidation loss: 66.4533\t validation accuracy: 0.9711\n",
      "iteration number: 2243\t training loss: 43.9767\tvalidation loss: 66.4519\t validation accuracy: 0.9711\n",
      "iteration number: 2244\t training loss: 43.9485\tvalidation loss: 66.4504\t validation accuracy: 0.9711\n",
      "iteration number: 2245\t training loss: 43.9204\tvalidation loss: 66.4490\t validation accuracy: 0.9711\n",
      "iteration number: 2246\t training loss: 43.8923\tvalidation loss: 66.4476\t validation accuracy: 0.9711\n",
      "iteration number: 2247\t training loss: 43.8642\tvalidation loss: 66.4461\t validation accuracy: 0.9711\n",
      "iteration number: 2248\t training loss: 43.8362\tvalidation loss: 66.4447\t validation accuracy: 0.9711\n",
      "iteration number: 2249\t training loss: 43.8082\tvalidation loss: 66.4433\t validation accuracy: 0.9711\n",
      "iteration number: 2250\t training loss: 43.7802\tvalidation loss: 66.4419\t validation accuracy: 0.9711\n",
      "iteration number: 2251\t training loss: 43.7522\tvalidation loss: 66.4405\t validation accuracy: 0.9711\n",
      "iteration number: 2252\t training loss: 43.7243\tvalidation loss: 66.4391\t validation accuracy: 0.9711\n",
      "iteration number: 2253\t training loss: 43.6964\tvalidation loss: 66.4377\t validation accuracy: 0.9711\n",
      "iteration number: 2254\t training loss: 43.6685\tvalidation loss: 66.4363\t validation accuracy: 0.9711\n",
      "iteration number: 2255\t training loss: 43.6407\tvalidation loss: 66.4349\t validation accuracy: 0.9711\n",
      "iteration number: 2256\t training loss: 43.6128\tvalidation loss: 66.4335\t validation accuracy: 0.9711\n",
      "iteration number: 2257\t training loss: 43.5850\tvalidation loss: 66.4321\t validation accuracy: 0.9711\n",
      "iteration number: 2258\t training loss: 43.5573\tvalidation loss: 66.4307\t validation accuracy: 0.9711\n",
      "iteration number: 2259\t training loss: 43.5295\tvalidation loss: 66.4293\t validation accuracy: 0.9711\n",
      "iteration number: 2260\t training loss: 43.5018\tvalidation loss: 66.4279\t validation accuracy: 0.9711\n",
      "iteration number: 2261\t training loss: 43.4741\tvalidation loss: 66.4266\t validation accuracy: 0.9711\n",
      "iteration number: 2262\t training loss: 43.4465\tvalidation loss: 66.4252\t validation accuracy: 0.9711\n",
      "iteration number: 2263\t training loss: 43.4188\tvalidation loss: 66.4238\t validation accuracy: 0.9711\n",
      "iteration number: 2264\t training loss: 43.3912\tvalidation loss: 66.4225\t validation accuracy: 0.9711\n",
      "iteration number: 2265\t training loss: 43.3636\tvalidation loss: 66.4211\t validation accuracy: 0.9711\n",
      "iteration number: 2266\t training loss: 43.3361\tvalidation loss: 66.4197\t validation accuracy: 0.9711\n",
      "iteration number: 2267\t training loss: 43.3086\tvalidation loss: 66.4184\t validation accuracy: 0.9711\n",
      "iteration number: 2268\t training loss: 43.2811\tvalidation loss: 66.4171\t validation accuracy: 0.9711\n",
      "iteration number: 2269\t training loss: 43.2536\tvalidation loss: 66.4157\t validation accuracy: 0.9711\n",
      "iteration number: 2270\t training loss: 43.2261\tvalidation loss: 66.4144\t validation accuracy: 0.9711\n",
      "iteration number: 2271\t training loss: 43.1987\tvalidation loss: 66.4130\t validation accuracy: 0.9711\n",
      "iteration number: 2272\t training loss: 43.1713\tvalidation loss: 66.4117\t validation accuracy: 0.9711\n",
      "iteration number: 2273\t training loss: 43.1439\tvalidation loss: 66.4104\t validation accuracy: 0.9711\n",
      "iteration number: 2274\t training loss: 43.1166\tvalidation loss: 66.4091\t validation accuracy: 0.9711\n",
      "iteration number: 2275\t training loss: 43.0893\tvalidation loss: 66.4077\t validation accuracy: 0.9711\n",
      "iteration number: 2276\t training loss: 43.0620\tvalidation loss: 66.4064\t validation accuracy: 0.9711\n",
      "iteration number: 2277\t training loss: 43.0347\tvalidation loss: 66.4051\t validation accuracy: 0.9711\n",
      "iteration number: 2278\t training loss: 43.0075\tvalidation loss: 66.4038\t validation accuracy: 0.9711\n",
      "iteration number: 2279\t training loss: 42.9803\tvalidation loss: 66.4025\t validation accuracy: 0.9711\n",
      "iteration number: 2280\t training loss: 42.9531\tvalidation loss: 66.4012\t validation accuracy: 0.9711\n",
      "iteration number: 2281\t training loss: 42.9260\tvalidation loss: 66.3999\t validation accuracy: 0.9711\n",
      "iteration number: 2282\t training loss: 42.8988\tvalidation loss: 66.3986\t validation accuracy: 0.9711\n",
      "iteration number: 2283\t training loss: 42.8717\tvalidation loss: 66.3973\t validation accuracy: 0.9711\n",
      "iteration number: 2284\t training loss: 42.8446\tvalidation loss: 66.3960\t validation accuracy: 0.9711\n",
      "iteration number: 2285\t training loss: 42.8176\tvalidation loss: 66.3948\t validation accuracy: 0.9711\n",
      "iteration number: 2286\t training loss: 42.7906\tvalidation loss: 66.3935\t validation accuracy: 0.9711\n",
      "iteration number: 2287\t training loss: 42.7636\tvalidation loss: 66.3922\t validation accuracy: 0.9711\n",
      "iteration number: 2288\t training loss: 42.7366\tvalidation loss: 66.3910\t validation accuracy: 0.9711\n",
      "iteration number: 2289\t training loss: 42.7096\tvalidation loss: 66.3897\t validation accuracy: 0.9711\n",
      "iteration number: 2290\t training loss: 42.6827\tvalidation loss: 66.3884\t validation accuracy: 0.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 2291\t training loss: 42.6558\tvalidation loss: 66.3872\t validation accuracy: 0.9711\n",
      "iteration number: 2292\t training loss: 42.6289\tvalidation loss: 66.3859\t validation accuracy: 0.9711\n",
      "iteration number: 2293\t training loss: 42.6021\tvalidation loss: 66.3847\t validation accuracy: 0.9711\n",
      "iteration number: 2294\t training loss: 42.5753\tvalidation loss: 66.3834\t validation accuracy: 0.9711\n",
      "iteration number: 2295\t training loss: 42.5485\tvalidation loss: 66.3822\t validation accuracy: 0.9711\n",
      "iteration number: 2296\t training loss: 42.5217\tvalidation loss: 66.3809\t validation accuracy: 0.9711\n",
      "iteration number: 2297\t training loss: 42.4950\tvalidation loss: 66.3797\t validation accuracy: 0.9711\n",
      "iteration number: 2298\t training loss: 42.4682\tvalidation loss: 66.3785\t validation accuracy: 0.9711\n",
      "iteration number: 2299\t training loss: 42.4416\tvalidation loss: 66.3772\t validation accuracy: 0.9711\n",
      "iteration number: 2300\t training loss: 42.4149\tvalidation loss: 66.3760\t validation accuracy: 0.9711\n",
      "iteration number: 2301\t training loss: 42.3882\tvalidation loss: 66.3748\t validation accuracy: 0.9711\n",
      "iteration number: 2302\t training loss: 42.3616\tvalidation loss: 66.3736\t validation accuracy: 0.9711\n",
      "iteration number: 2303\t training loss: 42.3350\tvalidation loss: 66.3724\t validation accuracy: 0.9711\n",
      "iteration number: 2304\t training loss: 42.3085\tvalidation loss: 66.3712\t validation accuracy: 0.9711\n",
      "iteration number: 2305\t training loss: 42.2819\tvalidation loss: 66.3700\t validation accuracy: 0.9711\n",
      "iteration number: 2306\t training loss: 42.2554\tvalidation loss: 66.3688\t validation accuracy: 0.9711\n",
      "iteration number: 2307\t training loss: 42.2289\tvalidation loss: 66.3676\t validation accuracy: 0.9711\n",
      "iteration number: 2308\t training loss: 42.2025\tvalidation loss: 66.3664\t validation accuracy: 0.9711\n",
      "iteration number: 2309\t training loss: 42.1760\tvalidation loss: 66.3652\t validation accuracy: 0.9711\n",
      "iteration number: 2310\t training loss: 42.1496\tvalidation loss: 66.3640\t validation accuracy: 0.9711\n",
      "iteration number: 2311\t training loss: 42.1232\tvalidation loss: 66.3628\t validation accuracy: 0.9711\n",
      "iteration number: 2312\t training loss: 42.0969\tvalidation loss: 66.3616\t validation accuracy: 0.9711\n",
      "iteration number: 2313\t training loss: 42.0705\tvalidation loss: 66.3605\t validation accuracy: 0.9711\n",
      "iteration number: 2314\t training loss: 42.0442\tvalidation loss: 66.3593\t validation accuracy: 0.9711\n",
      "iteration number: 2315\t training loss: 42.0179\tvalidation loss: 66.3581\t validation accuracy: 0.9711\n",
      "iteration number: 2316\t training loss: 41.9917\tvalidation loss: 66.3570\t validation accuracy: 0.9711\n",
      "iteration number: 2317\t training loss: 41.9654\tvalidation loss: 66.3558\t validation accuracy: 0.9711\n",
      "iteration number: 2318\t training loss: 41.9392\tvalidation loss: 66.3546\t validation accuracy: 0.9711\n",
      "iteration number: 2319\t training loss: 41.9130\tvalidation loss: 66.3535\t validation accuracy: 0.9711\n",
      "iteration number: 2320\t training loss: 41.8869\tvalidation loss: 66.3523\t validation accuracy: 0.9711\n",
      "iteration number: 2321\t training loss: 41.8607\tvalidation loss: 66.3512\t validation accuracy: 0.9711\n",
      "iteration number: 2322\t training loss: 41.8346\tvalidation loss: 66.3500\t validation accuracy: 0.9711\n",
      "iteration number: 2323\t training loss: 41.8085\tvalidation loss: 66.3489\t validation accuracy: 0.9711\n",
      "iteration number: 2324\t training loss: 41.7825\tvalidation loss: 66.3478\t validation accuracy: 0.9711\n",
      "iteration number: 2325\t training loss: 41.7564\tvalidation loss: 66.3466\t validation accuracy: 0.9711\n",
      "iteration number: 2326\t training loss: 41.7304\tvalidation loss: 66.3455\t validation accuracy: 0.9711\n",
      "iteration number: 2327\t training loss: 41.7044\tvalidation loss: 66.3444\t validation accuracy: 0.9711\n",
      "iteration number: 2328\t training loss: 41.6785\tvalidation loss: 66.3433\t validation accuracy: 0.9711\n",
      "iteration number: 2329\t training loss: 41.6525\tvalidation loss: 66.3422\t validation accuracy: 0.9711\n",
      "iteration number: 2330\t training loss: 41.6266\tvalidation loss: 66.3410\t validation accuracy: 0.9711\n",
      "iteration number: 2331\t training loss: 41.6007\tvalidation loss: 66.3399\t validation accuracy: 0.9711\n",
      "iteration number: 2332\t training loss: 41.5748\tvalidation loss: 66.3388\t validation accuracy: 0.9711\n",
      "iteration number: 2333\t training loss: 41.5490\tvalidation loss: 66.3377\t validation accuracy: 0.9711\n",
      "iteration number: 2334\t training loss: 41.5232\tvalidation loss: 66.3366\t validation accuracy: 0.9711\n",
      "iteration number: 2335\t training loss: 41.4974\tvalidation loss: 66.3355\t validation accuracy: 0.9711\n",
      "iteration number: 2336\t training loss: 41.4716\tvalidation loss: 66.3344\t validation accuracy: 0.9711\n",
      "iteration number: 2337\t training loss: 41.4459\tvalidation loss: 66.3333\t validation accuracy: 0.9711\n",
      "iteration number: 2338\t training loss: 41.4201\tvalidation loss: 66.3323\t validation accuracy: 0.9711\n",
      "iteration number: 2339\t training loss: 41.3945\tvalidation loss: 66.3312\t validation accuracy: 0.9711\n",
      "iteration number: 2340\t training loss: 41.3688\tvalidation loss: 66.3301\t validation accuracy: 0.9711\n",
      "iteration number: 2341\t training loss: 41.3431\tvalidation loss: 66.3290\t validation accuracy: 0.9711\n",
      "iteration number: 2342\t training loss: 41.3175\tvalidation loss: 66.3280\t validation accuracy: 0.9711\n",
      "iteration number: 2343\t training loss: 41.2919\tvalidation loss: 66.3269\t validation accuracy: 0.9711\n",
      "iteration number: 2344\t training loss: 41.2663\tvalidation loss: 66.3258\t validation accuracy: 0.9711\n",
      "iteration number: 2345\t training loss: 41.2408\tvalidation loss: 66.3248\t validation accuracy: 0.9711\n",
      "iteration number: 2346\t training loss: 41.2153\tvalidation loss: 66.3237\t validation accuracy: 0.9711\n",
      "iteration number: 2347\t training loss: 41.1897\tvalidation loss: 66.3226\t validation accuracy: 0.9711\n",
      "iteration number: 2348\t training loss: 41.1643\tvalidation loss: 66.3216\t validation accuracy: 0.9711\n",
      "iteration number: 2349\t training loss: 41.1388\tvalidation loss: 66.3206\t validation accuracy: 0.9711\n",
      "iteration number: 2350\t training loss: 41.1134\tvalidation loss: 66.3195\t validation accuracy: 0.9711\n",
      "iteration number: 2351\t training loss: 41.0880\tvalidation loss: 66.3185\t validation accuracy: 0.9711\n",
      "iteration number: 2352\t training loss: 41.0626\tvalidation loss: 66.3174\t validation accuracy: 0.9711\n",
      "iteration number: 2353\t training loss: 41.0372\tvalidation loss: 66.3164\t validation accuracy: 0.9711\n",
      "iteration number: 2354\t training loss: 41.0119\tvalidation loss: 66.3154\t validation accuracy: 0.9711\n",
      "iteration number: 2355\t training loss: 40.9866\tvalidation loss: 66.3143\t validation accuracy: 0.9711\n",
      "iteration number: 2356\t training loss: 40.9613\tvalidation loss: 66.3133\t validation accuracy: 0.9711\n",
      "iteration number: 2357\t training loss: 40.9360\tvalidation loss: 66.3123\t validation accuracy: 0.9711\n",
      "iteration number: 2358\t training loss: 40.9108\tvalidation loss: 66.3113\t validation accuracy: 0.9711\n",
      "iteration number: 2359\t training loss: 40.8856\tvalidation loss: 66.3103\t validation accuracy: 0.9711\n",
      "iteration number: 2360\t training loss: 40.8604\tvalidation loss: 66.3093\t validation accuracy: 0.9711\n",
      "iteration number: 2361\t training loss: 40.8352\tvalidation loss: 66.3083\t validation accuracy: 0.9711\n",
      "iteration number: 2362\t training loss: 40.8100\tvalidation loss: 66.3073\t validation accuracy: 0.9711\n",
      "iteration number: 2363\t training loss: 40.7849\tvalidation loss: 66.3063\t validation accuracy: 0.9711\n",
      "iteration number: 2364\t training loss: 40.7598\tvalidation loss: 66.3053\t validation accuracy: 0.9711\n",
      "iteration number: 2365\t training loss: 40.7347\tvalidation loss: 66.3043\t validation accuracy: 0.9711\n",
      "iteration number: 2366\t training loss: 40.7097\tvalidation loss: 66.3033\t validation accuracy: 0.9711\n",
      "iteration number: 2367\t training loss: 40.6847\tvalidation loss: 66.3023\t validation accuracy: 0.9711\n",
      "iteration number: 2368\t training loss: 40.6596\tvalidation loss: 66.3013\t validation accuracy: 0.9711\n",
      "iteration number: 2369\t training loss: 40.6347\tvalidation loss: 66.3003\t validation accuracy: 0.9711\n",
      "iteration number: 2370\t training loss: 40.6097\tvalidation loss: 66.2994\t validation accuracy: 0.9711\n",
      "iteration number: 2371\t training loss: 40.5848\tvalidation loss: 66.2984\t validation accuracy: 0.9711\n",
      "iteration number: 2372\t training loss: 40.5598\tvalidation loss: 66.2974\t validation accuracy: 0.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 2373\t training loss: 40.5350\tvalidation loss: 66.2965\t validation accuracy: 0.9711\n",
      "iteration number: 2374\t training loss: 40.5101\tvalidation loss: 66.2955\t validation accuracy: 0.9711\n",
      "iteration number: 2375\t training loss: 40.4852\tvalidation loss: 66.2945\t validation accuracy: 0.9711\n",
      "iteration number: 2376\t training loss: 40.4604\tvalidation loss: 66.2936\t validation accuracy: 0.9711\n",
      "iteration number: 2377\t training loss: 40.4356\tvalidation loss: 66.2926\t validation accuracy: 0.9711\n",
      "iteration number: 2378\t training loss: 40.4108\tvalidation loss: 66.2917\t validation accuracy: 0.9711\n",
      "iteration number: 2379\t training loss: 40.3861\tvalidation loss: 66.2907\t validation accuracy: 0.9711\n",
      "iteration number: 2380\t training loss: 40.3614\tvalidation loss: 66.2898\t validation accuracy: 0.9711\n",
      "iteration number: 2381\t training loss: 40.3367\tvalidation loss: 66.2889\t validation accuracy: 0.9711\n",
      "iteration number: 2382\t training loss: 40.3120\tvalidation loss: 66.2879\t validation accuracy: 0.9711\n",
      "iteration number: 2383\t training loss: 40.2873\tvalidation loss: 66.2870\t validation accuracy: 0.9711\n",
      "iteration number: 2384\t training loss: 40.2627\tvalidation loss: 66.2861\t validation accuracy: 0.9711\n",
      "iteration number: 2385\t training loss: 40.2381\tvalidation loss: 66.2851\t validation accuracy: 0.9711\n",
      "iteration number: 2386\t training loss: 40.2135\tvalidation loss: 66.2842\t validation accuracy: 0.9711\n",
      "iteration number: 2387\t training loss: 40.1889\tvalidation loss: 66.2833\t validation accuracy: 0.9711\n",
      "iteration number: 2388\t training loss: 40.1643\tvalidation loss: 66.2824\t validation accuracy: 0.9711\n",
      "iteration number: 2389\t training loss: 40.1398\tvalidation loss: 66.2815\t validation accuracy: 0.9711\n",
      "iteration number: 2390\t training loss: 40.1153\tvalidation loss: 66.2806\t validation accuracy: 0.9711\n",
      "iteration number: 2391\t training loss: 40.0908\tvalidation loss: 66.2796\t validation accuracy: 0.9711\n",
      "iteration number: 2392\t training loss: 40.0664\tvalidation loss: 66.2787\t validation accuracy: 0.9711\n",
      "iteration number: 2393\t training loss: 40.0419\tvalidation loss: 66.2778\t validation accuracy: 0.9711\n",
      "iteration number: 2394\t training loss: 40.0175\tvalidation loss: 66.2770\t validation accuracy: 0.9711\n",
      "iteration number: 2395\t training loss: 39.9931\tvalidation loss: 66.2761\t validation accuracy: 0.9711\n",
      "iteration number: 2396\t training loss: 39.9688\tvalidation loss: 66.2752\t validation accuracy: 0.9711\n",
      "iteration number: 2397\t training loss: 39.9444\tvalidation loss: 66.2743\t validation accuracy: 0.9711\n",
      "iteration number: 2398\t training loss: 39.9201\tvalidation loss: 66.2734\t validation accuracy: 0.9711\n",
      "iteration number: 2399\t training loss: 39.8958\tvalidation loss: 66.2725\t validation accuracy: 0.9711\n",
      "iteration number: 2400\t training loss: 39.8715\tvalidation loss: 66.2716\t validation accuracy: 0.9711\n",
      "iteration number: 2401\t training loss: 39.8473\tvalidation loss: 66.2708\t validation accuracy: 0.9711\n",
      "iteration number: 2402\t training loss: 39.8231\tvalidation loss: 66.2699\t validation accuracy: 0.9711\n",
      "iteration number: 2403\t training loss: 39.7988\tvalidation loss: 66.2690\t validation accuracy: 0.9711\n",
      "iteration number: 2404\t training loss: 39.7747\tvalidation loss: 66.2682\t validation accuracy: 0.9711\n",
      "iteration number: 2405\t training loss: 39.7505\tvalidation loss: 66.2673\t validation accuracy: 0.9711\n",
      "iteration number: 2406\t training loss: 39.7263\tvalidation loss: 66.2665\t validation accuracy: 0.9711\n",
      "iteration number: 2407\t training loss: 39.7022\tvalidation loss: 66.2656\t validation accuracy: 0.9711\n",
      "iteration number: 2408\t training loss: 39.6781\tvalidation loss: 66.2647\t validation accuracy: 0.9711\n",
      "iteration number: 2409\t training loss: 39.6540\tvalidation loss: 66.2639\t validation accuracy: 0.9711\n",
      "iteration number: 2410\t training loss: 39.6300\tvalidation loss: 66.2631\t validation accuracy: 0.9711\n",
      "iteration number: 2411\t training loss: 39.6060\tvalidation loss: 66.2622\t validation accuracy: 0.9711\n",
      "iteration number: 2412\t training loss: 39.5819\tvalidation loss: 66.2614\t validation accuracy: 0.9711\n",
      "iteration number: 2413\t training loss: 39.5580\tvalidation loss: 66.2605\t validation accuracy: 0.9711\n",
      "iteration number: 2414\t training loss: 39.5340\tvalidation loss: 66.2597\t validation accuracy: 0.9711\n",
      "iteration number: 2415\t training loss: 39.5100\tvalidation loss: 66.2589\t validation accuracy: 0.9711\n",
      "iteration number: 2416\t training loss: 39.4861\tvalidation loss: 66.2581\t validation accuracy: 0.9711\n",
      "iteration number: 2417\t training loss: 39.4622\tvalidation loss: 66.2572\t validation accuracy: 0.9711\n",
      "iteration number: 2418\t training loss: 39.4383\tvalidation loss: 66.2564\t validation accuracy: 0.9711\n",
      "iteration number: 2419\t training loss: 39.4145\tvalidation loss: 66.2556\t validation accuracy: 0.9711\n",
      "iteration number: 2420\t training loss: 39.3907\tvalidation loss: 66.2548\t validation accuracy: 0.9711\n",
      "iteration number: 2421\t training loss: 39.3668\tvalidation loss: 66.2540\t validation accuracy: 0.9711\n",
      "iteration number: 2422\t training loss: 39.3430\tvalidation loss: 66.2532\t validation accuracy: 0.9711\n",
      "iteration number: 2423\t training loss: 39.3193\tvalidation loss: 66.2524\t validation accuracy: 0.9711\n",
      "iteration number: 2424\t training loss: 39.2955\tvalidation loss: 66.2516\t validation accuracy: 0.9711\n",
      "iteration number: 2425\t training loss: 39.2718\tvalidation loss: 66.2508\t validation accuracy: 0.9711\n",
      "iteration number: 2426\t training loss: 39.2481\tvalidation loss: 66.2500\t validation accuracy: 0.9711\n",
      "iteration number: 2427\t training loss: 39.2244\tvalidation loss: 66.2492\t validation accuracy: 0.9711\n",
      "iteration number: 2428\t training loss: 39.2008\tvalidation loss: 66.2484\t validation accuracy: 0.9711\n",
      "iteration number: 2429\t training loss: 39.1771\tvalidation loss: 66.2476\t validation accuracy: 0.9711\n",
      "iteration number: 2430\t training loss: 39.1535\tvalidation loss: 66.2468\t validation accuracy: 0.9711\n",
      "iteration number: 2431\t training loss: 39.1299\tvalidation loss: 66.2460\t validation accuracy: 0.9711\n",
      "iteration number: 2432\t training loss: 39.1063\tvalidation loss: 66.2453\t validation accuracy: 0.9711\n",
      "iteration number: 2433\t training loss: 39.0828\tvalidation loss: 66.2445\t validation accuracy: 0.9711\n",
      "iteration number: 2434\t training loss: 39.0592\tvalidation loss: 66.2437\t validation accuracy: 0.9711\n",
      "iteration number: 2435\t training loss: 39.0357\tvalidation loss: 66.2430\t validation accuracy: 0.9711\n",
      "iteration number: 2436\t training loss: 39.0122\tvalidation loss: 66.2422\t validation accuracy: 0.9711\n",
      "iteration number: 2437\t training loss: 38.9888\tvalidation loss: 66.2414\t validation accuracy: 0.9711\n",
      "iteration number: 2438\t training loss: 38.9653\tvalidation loss: 66.2407\t validation accuracy: 0.9711\n",
      "iteration number: 2439\t training loss: 38.9419\tvalidation loss: 66.2399\t validation accuracy: 0.9711\n",
      "iteration number: 2440\t training loss: 38.9185\tvalidation loss: 66.2392\t validation accuracy: 0.9711\n",
      "iteration number: 2441\t training loss: 38.8951\tvalidation loss: 66.2384\t validation accuracy: 0.9711\n",
      "iteration number: 2442\t training loss: 38.8717\tvalidation loss: 66.2377\t validation accuracy: 0.9711\n",
      "iteration number: 2443\t training loss: 38.8484\tvalidation loss: 66.2369\t validation accuracy: 0.9711\n",
      "iteration number: 2444\t training loss: 38.8251\tvalidation loss: 66.2362\t validation accuracy: 0.9711\n",
      "iteration number: 2445\t training loss: 38.8018\tvalidation loss: 66.2355\t validation accuracy: 0.9711\n",
      "iteration number: 2446\t training loss: 38.7785\tvalidation loss: 66.2347\t validation accuracy: 0.9711\n",
      "iteration number: 2447\t training loss: 38.7552\tvalidation loss: 66.2340\t validation accuracy: 0.9711\n",
      "iteration number: 2448\t training loss: 38.7320\tvalidation loss: 66.2333\t validation accuracy: 0.9711\n",
      "iteration number: 2449\t training loss: 38.7088\tvalidation loss: 66.2326\t validation accuracy: 0.9711\n",
      "iteration number: 2450\t training loss: 38.6856\tvalidation loss: 66.2318\t validation accuracy: 0.9711\n",
      "iteration number: 2451\t training loss: 38.6624\tvalidation loss: 66.2311\t validation accuracy: 0.9711\n",
      "iteration number: 2452\t training loss: 38.6393\tvalidation loss: 66.2304\t validation accuracy: 0.9711\n",
      "iteration number: 2453\t training loss: 38.6162\tvalidation loss: 66.2297\t validation accuracy: 0.9711\n",
      "iteration number: 2454\t training loss: 38.5930\tvalidation loss: 66.2290\t validation accuracy: 0.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 2455\t training loss: 38.5700\tvalidation loss: 66.2283\t validation accuracy: 0.9711\n",
      "iteration number: 2456\t training loss: 38.5469\tvalidation loss: 66.2276\t validation accuracy: 0.9711\n",
      "iteration number: 2457\t training loss: 38.5238\tvalidation loss: 66.2269\t validation accuracy: 0.9711\n",
      "iteration number: 2458\t training loss: 38.5008\tvalidation loss: 66.2262\t validation accuracy: 0.9711\n",
      "iteration number: 2459\t training loss: 38.4778\tvalidation loss: 66.2255\t validation accuracy: 0.9711\n",
      "iteration number: 2460\t training loss: 38.4548\tvalidation loss: 66.2248\t validation accuracy: 0.9711\n",
      "iteration number: 2461\t training loss: 38.4319\tvalidation loss: 66.2241\t validation accuracy: 0.9711\n",
      "iteration number: 2462\t training loss: 38.4089\tvalidation loss: 66.2234\t validation accuracy: 0.9711\n",
      "iteration number: 2463\t training loss: 38.3860\tvalidation loss: 66.2227\t validation accuracy: 0.9711\n",
      "iteration number: 2464\t training loss: 38.3631\tvalidation loss: 66.2221\t validation accuracy: 0.9711\n",
      "iteration number: 2465\t training loss: 38.3402\tvalidation loss: 66.2214\t validation accuracy: 0.9711\n",
      "iteration number: 2466\t training loss: 38.3174\tvalidation loss: 66.2207\t validation accuracy: 0.9711\n",
      "iteration number: 2467\t training loss: 38.2945\tvalidation loss: 66.2200\t validation accuracy: 0.9711\n",
      "iteration number: 2468\t training loss: 38.2717\tvalidation loss: 66.2194\t validation accuracy: 0.9711\n",
      "iteration number: 2469\t training loss: 38.2489\tvalidation loss: 66.2187\t validation accuracy: 0.9711\n",
      "iteration number: 2470\t training loss: 38.2261\tvalidation loss: 66.2180\t validation accuracy: 0.9711\n",
      "iteration number: 2471\t training loss: 38.2034\tvalidation loss: 66.2174\t validation accuracy: 0.9711\n",
      "iteration number: 2472\t training loss: 38.1806\tvalidation loss: 66.2167\t validation accuracy: 0.9711\n",
      "iteration number: 2473\t training loss: 38.1579\tvalidation loss: 66.2161\t validation accuracy: 0.9711\n",
      "iteration number: 2474\t training loss: 38.1352\tvalidation loss: 66.2154\t validation accuracy: 0.9711\n",
      "iteration number: 2475\t training loss: 38.1125\tvalidation loss: 66.2148\t validation accuracy: 0.9711\n",
      "iteration number: 2476\t training loss: 38.0899\tvalidation loss: 66.2141\t validation accuracy: 0.9711\n",
      "iteration number: 2477\t training loss: 38.0672\tvalidation loss: 66.2135\t validation accuracy: 0.9711\n",
      "iteration number: 2478\t training loss: 38.0446\tvalidation loss: 66.2129\t validation accuracy: 0.9711\n",
      "iteration number: 2479\t training loss: 38.0220\tvalidation loss: 66.2122\t validation accuracy: 0.9711\n",
      "iteration number: 2480\t training loss: 37.9995\tvalidation loss: 66.2116\t validation accuracy: 0.9711\n",
      "iteration number: 2481\t training loss: 37.9769\tvalidation loss: 66.2110\t validation accuracy: 0.9711\n",
      "iteration number: 2482\t training loss: 37.9544\tvalidation loss: 66.2103\t validation accuracy: 0.9711\n",
      "iteration number: 2483\t training loss: 37.9318\tvalidation loss: 66.2097\t validation accuracy: 0.9711\n",
      "iteration number: 2484\t training loss: 37.9094\tvalidation loss: 66.2091\t validation accuracy: 0.9711\n",
      "iteration number: 2485\t training loss: 37.8869\tvalidation loss: 66.2085\t validation accuracy: 0.9711\n",
      "iteration number: 2486\t training loss: 37.8644\tvalidation loss: 66.2079\t validation accuracy: 0.9711\n",
      "iteration number: 2487\t training loss: 37.8420\tvalidation loss: 66.2072\t validation accuracy: 0.9711\n",
      "iteration number: 2488\t training loss: 37.8196\tvalidation loss: 66.2066\t validation accuracy: 0.9711\n",
      "iteration number: 2489\t training loss: 37.7972\tvalidation loss: 66.2060\t validation accuracy: 0.9711\n",
      "iteration number: 2490\t training loss: 37.7748\tvalidation loss: 66.2054\t validation accuracy: 0.9711\n",
      "iteration number: 2491\t training loss: 37.7525\tvalidation loss: 66.2048\t validation accuracy: 0.9711\n",
      "iteration number: 2492\t training loss: 37.7301\tvalidation loss: 66.2042\t validation accuracy: 0.9711\n",
      "iteration number: 2493\t training loss: 37.7078\tvalidation loss: 66.2036\t validation accuracy: 0.9711\n",
      "iteration number: 2494\t training loss: 37.6855\tvalidation loss: 66.2030\t validation accuracy: 0.9711\n",
      "iteration number: 2495\t training loss: 37.6632\tvalidation loss: 66.2024\t validation accuracy: 0.9711\n",
      "iteration number: 2496\t training loss: 37.6410\tvalidation loss: 66.2019\t validation accuracy: 0.9711\n",
      "iteration number: 2497\t training loss: 37.6188\tvalidation loss: 66.2013\t validation accuracy: 0.9711\n",
      "iteration number: 2498\t training loss: 37.5965\tvalidation loss: 66.2007\t validation accuracy: 0.9711\n",
      "iteration number: 2499\t training loss: 37.5743\tvalidation loss: 66.2001\t validation accuracy: 0.9711\n",
      "iteration number: 2500\t training loss: 37.5522\tvalidation loss: 66.1995\t validation accuracy: 0.9711\n",
      "iteration number: 2501\t training loss: 37.5300\tvalidation loss: 66.1990\t validation accuracy: 0.9711\n",
      "iteration number: 2502\t training loss: 37.5079\tvalidation loss: 66.1984\t validation accuracy: 0.9711\n",
      "iteration number: 2503\t training loss: 37.4858\tvalidation loss: 66.1978\t validation accuracy: 0.9711\n",
      "iteration number: 2504\t training loss: 37.4637\tvalidation loss: 66.1973\t validation accuracy: 0.9711\n",
      "iteration number: 2505\t training loss: 37.4416\tvalidation loss: 66.1967\t validation accuracy: 0.9711\n",
      "iteration number: 2506\t training loss: 37.4195\tvalidation loss: 66.1961\t validation accuracy: 0.9711\n",
      "iteration number: 2507\t training loss: 37.3975\tvalidation loss: 66.1956\t validation accuracy: 0.9711\n",
      "iteration number: 2508\t training loss: 37.3755\tvalidation loss: 66.1950\t validation accuracy: 0.9711\n",
      "iteration number: 2509\t training loss: 37.3535\tvalidation loss: 66.1945\t validation accuracy: 0.9711\n",
      "iteration number: 2510\t training loss: 37.3315\tvalidation loss: 66.1939\t validation accuracy: 0.9711\n",
      "iteration number: 2511\t training loss: 37.3095\tvalidation loss: 66.1934\t validation accuracy: 0.9711\n",
      "iteration number: 2512\t training loss: 37.2876\tvalidation loss: 66.1929\t validation accuracy: 0.9711\n",
      "iteration number: 2513\t training loss: 37.2657\tvalidation loss: 66.1923\t validation accuracy: 0.9711\n",
      "iteration number: 2514\t training loss: 37.2438\tvalidation loss: 66.1918\t validation accuracy: 0.9711\n",
      "iteration number: 2515\t training loss: 37.2219\tvalidation loss: 66.1912\t validation accuracy: 0.9711\n",
      "iteration number: 2516\t training loss: 37.2000\tvalidation loss: 66.1907\t validation accuracy: 0.9711\n",
      "iteration number: 2517\t training loss: 37.1782\tvalidation loss: 66.1902\t validation accuracy: 0.9711\n",
      "iteration number: 2518\t training loss: 37.1564\tvalidation loss: 66.1897\t validation accuracy: 0.9711\n",
      "iteration number: 2519\t training loss: 37.1346\tvalidation loss: 66.1891\t validation accuracy: 0.9711\n",
      "iteration number: 2520\t training loss: 37.1128\tvalidation loss: 66.1886\t validation accuracy: 0.9711\n",
      "iteration number: 2521\t training loss: 37.0910\tvalidation loss: 66.1881\t validation accuracy: 0.9711\n",
      "iteration number: 2522\t training loss: 37.0693\tvalidation loss: 66.1876\t validation accuracy: 0.9711\n",
      "iteration number: 2523\t training loss: 37.0476\tvalidation loss: 66.1871\t validation accuracy: 0.9711\n",
      "iteration number: 2524\t training loss: 37.0258\tvalidation loss: 66.1866\t validation accuracy: 0.9711\n",
      "iteration number: 2525\t training loss: 37.0042\tvalidation loss: 66.1861\t validation accuracy: 0.9711\n",
      "iteration number: 2526\t training loss: 36.9825\tvalidation loss: 66.1856\t validation accuracy: 0.9711\n",
      "iteration number: 2527\t training loss: 36.9608\tvalidation loss: 66.1851\t validation accuracy: 0.9711\n",
      "iteration number: 2528\t training loss: 36.9392\tvalidation loss: 66.1846\t validation accuracy: 0.9711\n",
      "iteration number: 2529\t training loss: 36.9176\tvalidation loss: 66.1841\t validation accuracy: 0.9711\n",
      "iteration number: 2530\t training loss: 36.8960\tvalidation loss: 66.1836\t validation accuracy: 0.9711\n",
      "iteration number: 2531\t training loss: 36.8744\tvalidation loss: 66.1831\t validation accuracy: 0.9711\n",
      "iteration number: 2532\t training loss: 36.8529\tvalidation loss: 66.1826\t validation accuracy: 0.9711\n",
      "iteration number: 2533\t training loss: 36.8313\tvalidation loss: 66.1821\t validation accuracy: 0.9711\n",
      "iteration number: 2534\t training loss: 36.8098\tvalidation loss: 66.1816\t validation accuracy: 0.9711\n",
      "iteration number: 2535\t training loss: 36.7883\tvalidation loss: 66.1812\t validation accuracy: 0.9711\n",
      "iteration number: 2536\t training loss: 36.7669\tvalidation loss: 66.1807\t validation accuracy: 0.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 2537\t training loss: 36.7454\tvalidation loss: 66.1802\t validation accuracy: 0.9711\n",
      "iteration number: 2538\t training loss: 36.7240\tvalidation loss: 66.1797\t validation accuracy: 0.9711\n",
      "iteration number: 2539\t training loss: 36.7025\tvalidation loss: 66.1793\t validation accuracy: 0.9711\n",
      "iteration number: 2540\t training loss: 36.6811\tvalidation loss: 66.1788\t validation accuracy: 0.9711\n",
      "iteration number: 2541\t training loss: 36.6597\tvalidation loss: 66.1783\t validation accuracy: 0.9711\n",
      "iteration number: 2542\t training loss: 36.6384\tvalidation loss: 66.1779\t validation accuracy: 0.9711\n",
      "iteration number: 2543\t training loss: 36.6170\tvalidation loss: 66.1774\t validation accuracy: 0.9711\n",
      "iteration number: 2544\t training loss: 36.5957\tvalidation loss: 66.1770\t validation accuracy: 0.9711\n",
      "iteration number: 2545\t training loss: 36.5744\tvalidation loss: 66.1765\t validation accuracy: 0.9711\n",
      "iteration number: 2546\t training loss: 36.5531\tvalidation loss: 66.1761\t validation accuracy: 0.9711\n",
      "iteration number: 2547\t training loss: 36.5318\tvalidation loss: 66.1756\t validation accuracy: 0.9711\n",
      "iteration number: 2548\t training loss: 36.5106\tvalidation loss: 66.1752\t validation accuracy: 0.9711\n",
      "iteration number: 2549\t training loss: 36.4893\tvalidation loss: 66.1747\t validation accuracy: 0.9711\n",
      "iteration number: 2550\t training loss: 36.4681\tvalidation loss: 66.1743\t validation accuracy: 0.9711\n",
      "iteration number: 2551\t training loss: 36.4469\tvalidation loss: 66.1739\t validation accuracy: 0.9711\n",
      "iteration number: 2552\t training loss: 36.4258\tvalidation loss: 66.1734\t validation accuracy: 0.9711\n",
      "iteration number: 2553\t training loss: 36.4046\tvalidation loss: 66.1730\t validation accuracy: 0.9711\n",
      "iteration number: 2554\t training loss: 36.3835\tvalidation loss: 66.1726\t validation accuracy: 0.9711\n",
      "iteration number: 2555\t training loss: 36.3623\tvalidation loss: 66.1721\t validation accuracy: 0.9711\n",
      "iteration number: 2556\t training loss: 36.3412\tvalidation loss: 66.1717\t validation accuracy: 0.9711\n",
      "iteration number: 2557\t training loss: 36.3201\tvalidation loss: 66.1713\t validation accuracy: 0.9711\n",
      "iteration number: 2558\t training loss: 36.2991\tvalidation loss: 66.1709\t validation accuracy: 0.9711\n",
      "iteration number: 2559\t training loss: 36.2780\tvalidation loss: 66.1705\t validation accuracy: 0.9711\n",
      "iteration number: 2560\t training loss: 36.2570\tvalidation loss: 66.1701\t validation accuracy: 0.9711\n",
      "iteration number: 2561\t training loss: 36.2360\tvalidation loss: 66.1696\t validation accuracy: 0.9711\n",
      "iteration number: 2562\t training loss: 36.2150\tvalidation loss: 66.1692\t validation accuracy: 0.9711\n",
      "iteration number: 2563\t training loss: 36.1940\tvalidation loss: 66.1688\t validation accuracy: 0.9711\n",
      "iteration number: 2564\t training loss: 36.1731\tvalidation loss: 66.1684\t validation accuracy: 0.9711\n",
      "iteration number: 2565\t training loss: 36.1521\tvalidation loss: 66.1680\t validation accuracy: 0.9711\n",
      "iteration number: 2566\t training loss: 36.1312\tvalidation loss: 66.1676\t validation accuracy: 0.9711\n",
      "iteration number: 2567\t training loss: 36.1103\tvalidation loss: 66.1672\t validation accuracy: 0.9711\n",
      "iteration number: 2568\t training loss: 36.0894\tvalidation loss: 66.1668\t validation accuracy: 0.9711\n",
      "iteration number: 2569\t training loss: 36.0685\tvalidation loss: 66.1665\t validation accuracy: 0.9711\n",
      "iteration number: 2570\t training loss: 36.0477\tvalidation loss: 66.1661\t validation accuracy: 0.9711\n",
      "iteration number: 2571\t training loss: 36.0269\tvalidation loss: 66.1657\t validation accuracy: 0.9711\n",
      "iteration number: 2572\t training loss: 36.0061\tvalidation loss: 66.1653\t validation accuracy: 0.9711\n",
      "iteration number: 2573\t training loss: 35.9853\tvalidation loss: 66.1649\t validation accuracy: 0.9711\n",
      "iteration number: 2574\t training loss: 35.9645\tvalidation loss: 66.1646\t validation accuracy: 0.9711\n",
      "iteration number: 2575\t training loss: 35.9437\tvalidation loss: 66.1642\t validation accuracy: 0.9711\n",
      "iteration number: 2576\t training loss: 35.9230\tvalidation loss: 66.1638\t validation accuracy: 0.9711\n",
      "iteration number: 2577\t training loss: 35.9023\tvalidation loss: 66.1634\t validation accuracy: 0.9711\n",
      "iteration number: 2578\t training loss: 35.8816\tvalidation loss: 66.1631\t validation accuracy: 0.9711\n",
      "iteration number: 2579\t training loss: 35.8609\tvalidation loss: 66.1627\t validation accuracy: 0.9711\n",
      "iteration number: 2580\t training loss: 35.8402\tvalidation loss: 66.1624\t validation accuracy: 0.9711\n",
      "iteration number: 2581\t training loss: 35.8196\tvalidation loss: 66.1620\t validation accuracy: 0.9711\n",
      "iteration number: 2582\t training loss: 35.7989\tvalidation loss: 66.1616\t validation accuracy: 0.9711\n",
      "iteration number: 2583\t training loss: 35.7783\tvalidation loss: 66.1613\t validation accuracy: 0.9711\n",
      "iteration number: 2584\t training loss: 35.7577\tvalidation loss: 66.1609\t validation accuracy: 0.9711\n",
      "iteration number: 2585\t training loss: 35.7372\tvalidation loss: 66.1606\t validation accuracy: 0.9711\n",
      "iteration number: 2586\t training loss: 35.7166\tvalidation loss: 66.1602\t validation accuracy: 0.9711\n",
      "iteration number: 2587\t training loss: 35.6961\tvalidation loss: 66.1599\t validation accuracy: 0.9711\n",
      "iteration number: 2588\t training loss: 35.6755\tvalidation loss: 66.1596\t validation accuracy: 0.9711\n",
      "iteration number: 2589\t training loss: 35.6550\tvalidation loss: 66.1592\t validation accuracy: 0.9711\n",
      "iteration number: 2590\t training loss: 35.6345\tvalidation loss: 66.1589\t validation accuracy: 0.9711\n",
      "iteration number: 2591\t training loss: 35.6141\tvalidation loss: 66.1586\t validation accuracy: 0.9711\n",
      "iteration number: 2592\t training loss: 35.5936\tvalidation loss: 66.1582\t validation accuracy: 0.9711\n",
      "iteration number: 2593\t training loss: 35.5732\tvalidation loss: 66.1579\t validation accuracy: 0.9711\n",
      "iteration number: 2594\t training loss: 35.5528\tvalidation loss: 66.1576\t validation accuracy: 0.9711\n",
      "iteration number: 2595\t training loss: 35.5324\tvalidation loss: 66.1573\t validation accuracy: 0.9711\n",
      "iteration number: 2596\t training loss: 35.5120\tvalidation loss: 66.1569\t validation accuracy: 0.9711\n",
      "iteration number: 2597\t training loss: 35.4916\tvalidation loss: 66.1566\t validation accuracy: 0.9711\n",
      "iteration number: 2598\t training loss: 35.4713\tvalidation loss: 66.1563\t validation accuracy: 0.9711\n",
      "iteration number: 2599\t training loss: 35.4509\tvalidation loss: 66.1560\t validation accuracy: 0.9711\n",
      "iteration number: 2600\t training loss: 35.4306\tvalidation loss: 66.1557\t validation accuracy: 0.9711\n",
      "iteration number: 2601\t training loss: 35.4103\tvalidation loss: 66.1554\t validation accuracy: 0.9711\n",
      "iteration number: 2602\t training loss: 35.3901\tvalidation loss: 66.1551\t validation accuracy: 0.9711\n",
      "iteration number: 2603\t training loss: 35.3698\tvalidation loss: 66.1548\t validation accuracy: 0.9711\n",
      "iteration number: 2604\t training loss: 35.3496\tvalidation loss: 66.1545\t validation accuracy: 0.9711\n",
      "iteration number: 2605\t training loss: 35.3293\tvalidation loss: 66.1542\t validation accuracy: 0.9711\n",
      "iteration number: 2606\t training loss: 35.3091\tvalidation loss: 66.1539\t validation accuracy: 0.9711\n",
      "iteration number: 2607\t training loss: 35.2889\tvalidation loss: 66.1536\t validation accuracy: 0.9711\n",
      "iteration number: 2608\t training loss: 35.2688\tvalidation loss: 66.1533\t validation accuracy: 0.9711\n",
      "iteration number: 2609\t training loss: 35.2486\tvalidation loss: 66.1530\t validation accuracy: 0.9711\n",
      "iteration number: 2610\t training loss: 35.2285\tvalidation loss: 66.1527\t validation accuracy: 0.9711\n",
      "iteration number: 2611\t training loss: 35.2084\tvalidation loss: 66.1524\t validation accuracy: 0.9711\n",
      "iteration number: 2612\t training loss: 35.1883\tvalidation loss: 66.1522\t validation accuracy: 0.9711\n",
      "iteration number: 2613\t training loss: 35.1682\tvalidation loss: 66.1519\t validation accuracy: 0.9711\n",
      "iteration number: 2614\t training loss: 35.1481\tvalidation loss: 66.1516\t validation accuracy: 0.9711\n",
      "iteration number: 2615\t training loss: 35.1281\tvalidation loss: 66.1513\t validation accuracy: 0.9711\n",
      "iteration number: 2616\t training loss: 35.1080\tvalidation loss: 66.1511\t validation accuracy: 0.9711\n",
      "iteration number: 2617\t training loss: 35.0880\tvalidation loss: 66.1508\t validation accuracy: 0.9711\n",
      "iteration number: 2618\t training loss: 35.0680\tvalidation loss: 66.1505\t validation accuracy: 0.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 2619\t training loss: 35.0480\tvalidation loss: 66.1503\t validation accuracy: 0.9711\n",
      "iteration number: 2620\t training loss: 35.0281\tvalidation loss: 66.1500\t validation accuracy: 0.9711\n",
      "iteration number: 2621\t training loss: 35.0081\tvalidation loss: 66.1497\t validation accuracy: 0.9711\n",
      "iteration number: 2622\t training loss: 34.9882\tvalidation loss: 66.1495\t validation accuracy: 0.9711\n",
      "iteration number: 2623\t training loss: 34.9683\tvalidation loss: 66.1492\t validation accuracy: 0.9711\n",
      "iteration number: 2624\t training loss: 34.9484\tvalidation loss: 66.1490\t validation accuracy: 0.9711\n",
      "iteration number: 2625\t training loss: 34.9285\tvalidation loss: 66.1487\t validation accuracy: 0.9711\n",
      "iteration number: 2626\t training loss: 34.9087\tvalidation loss: 66.1485\t validation accuracy: 0.9711\n",
      "iteration number: 2627\t training loss: 34.8888\tvalidation loss: 66.1482\t validation accuracy: 0.9711\n",
      "iteration number: 2628\t training loss: 34.8690\tvalidation loss: 66.1480\t validation accuracy: 0.9711\n",
      "iteration number: 2629\t training loss: 34.8492\tvalidation loss: 66.1478\t validation accuracy: 0.9711\n",
      "iteration number: 2630\t training loss: 34.8294\tvalidation loss: 66.1475\t validation accuracy: 0.9711\n",
      "iteration number: 2631\t training loss: 34.8096\tvalidation loss: 66.1473\t validation accuracy: 0.9711\n",
      "iteration number: 2632\t training loss: 34.7899\tvalidation loss: 66.1471\t validation accuracy: 0.9711\n",
      "iteration number: 2633\t training loss: 34.7701\tvalidation loss: 66.1468\t validation accuracy: 0.9711\n",
      "iteration number: 2634\t training loss: 34.7504\tvalidation loss: 66.1466\t validation accuracy: 0.9711\n",
      "iteration number: 2635\t training loss: 34.7307\tvalidation loss: 66.1464\t validation accuracy: 0.9711\n",
      "iteration number: 2636\t training loss: 34.7110\tvalidation loss: 66.1462\t validation accuracy: 0.9711\n",
      "iteration number: 2637\t training loss: 34.6913\tvalidation loss: 66.1459\t validation accuracy: 0.9711\n",
      "iteration number: 2638\t training loss: 34.6717\tvalidation loss: 66.1457\t validation accuracy: 0.9711\n",
      "iteration number: 2639\t training loss: 34.6520\tvalidation loss: 66.1455\t validation accuracy: 0.9711\n",
      "iteration number: 2640\t training loss: 34.6324\tvalidation loss: 66.1453\t validation accuracy: 0.9711\n",
      "iteration number: 2641\t training loss: 34.6128\tvalidation loss: 66.1451\t validation accuracy: 0.9711\n",
      "iteration number: 2642\t training loss: 34.5932\tvalidation loss: 66.1449\t validation accuracy: 0.9711\n",
      "iteration number: 2643\t training loss: 34.5736\tvalidation loss: 66.1447\t validation accuracy: 0.9711\n",
      "iteration number: 2644\t training loss: 34.5541\tvalidation loss: 66.1445\t validation accuracy: 0.9711\n",
      "iteration number: 2645\t training loss: 34.5345\tvalidation loss: 66.1443\t validation accuracy: 0.9711\n",
      "iteration number: 2646\t training loss: 34.5150\tvalidation loss: 66.1441\t validation accuracy: 0.9711\n",
      "iteration number: 2647\t training loss: 34.4955\tvalidation loss: 66.1439\t validation accuracy: 0.9711\n",
      "iteration number: 2648\t training loss: 34.4760\tvalidation loss: 66.1437\t validation accuracy: 0.9711\n",
      "iteration number: 2649\t training loss: 34.4565\tvalidation loss: 66.1435\t validation accuracy: 0.9711\n",
      "iteration number: 2650\t training loss: 34.4371\tvalidation loss: 66.1433\t validation accuracy: 0.9711\n",
      "iteration number: 2651\t training loss: 34.4176\tvalidation loss: 66.1431\t validation accuracy: 0.9711\n",
      "iteration number: 2652\t training loss: 34.3982\tvalidation loss: 66.1429\t validation accuracy: 0.9711\n",
      "iteration number: 2653\t training loss: 34.3788\tvalidation loss: 66.1428\t validation accuracy: 0.9711\n",
      "iteration number: 2654\t training loss: 34.3594\tvalidation loss: 66.1426\t validation accuracy: 0.9711\n",
      "iteration number: 2655\t training loss: 34.3401\tvalidation loss: 66.1424\t validation accuracy: 0.9711\n",
      "iteration number: 2656\t training loss: 34.3207\tvalidation loss: 66.1422\t validation accuracy: 0.9711\n",
      "iteration number: 2657\t training loss: 34.3014\tvalidation loss: 66.1421\t validation accuracy: 0.9711\n",
      "iteration number: 2658\t training loss: 34.2820\tvalidation loss: 66.1419\t validation accuracy: 0.9711\n",
      "iteration number: 2659\t training loss: 34.2627\tvalidation loss: 66.1417\t validation accuracy: 0.9711\n",
      "iteration number: 2660\t training loss: 34.2434\tvalidation loss: 66.1416\t validation accuracy: 0.9711\n",
      "iteration number: 2661\t training loss: 34.2242\tvalidation loss: 66.1414\t validation accuracy: 0.9711\n",
      "iteration number: 2662\t training loss: 34.2049\tvalidation loss: 66.1412\t validation accuracy: 0.9711\n",
      "iteration number: 2663\t training loss: 34.1857\tvalidation loss: 66.1411\t validation accuracy: 0.9711\n",
      "iteration number: 2664\t training loss: 34.1664\tvalidation loss: 66.1409\t validation accuracy: 0.9711\n",
      "iteration number: 2665\t training loss: 34.1472\tvalidation loss: 66.1408\t validation accuracy: 0.9711\n",
      "iteration number: 2666\t training loss: 34.1280\tvalidation loss: 66.1406\t validation accuracy: 0.9711\n",
      "iteration number: 2667\t training loss: 34.1089\tvalidation loss: 66.1405\t validation accuracy: 0.9711\n",
      "iteration number: 2668\t training loss: 34.0897\tvalidation loss: 66.1403\t validation accuracy: 0.9711\n",
      "iteration number: 2669\t training loss: 34.0706\tvalidation loss: 66.1402\t validation accuracy: 0.9711\n",
      "iteration number: 2670\t training loss: 34.0514\tvalidation loss: 66.1400\t validation accuracy: 0.9711\n",
      "iteration number: 2671\t training loss: 34.0323\tvalidation loss: 66.1399\t validation accuracy: 0.9711\n",
      "iteration number: 2672\t training loss: 34.0132\tvalidation loss: 66.1398\t validation accuracy: 0.9711\n",
      "iteration number: 2673\t training loss: 33.9941\tvalidation loss: 66.1396\t validation accuracy: 0.9711\n",
      "iteration number: 2674\t training loss: 33.9751\tvalidation loss: 66.1395\t validation accuracy: 0.9711\n",
      "iteration number: 2675\t training loss: 33.9560\tvalidation loss: 66.1394\t validation accuracy: 0.9711\n",
      "iteration number: 2676\t training loss: 33.9370\tvalidation loss: 66.1392\t validation accuracy: 0.9711\n",
      "iteration number: 2677\t training loss: 33.9180\tvalidation loss: 66.1391\t validation accuracy: 0.9711\n",
      "iteration number: 2678\t training loss: 33.8990\tvalidation loss: 66.1390\t validation accuracy: 0.9711\n",
      "iteration number: 2679\t training loss: 33.8800\tvalidation loss: 66.1389\t validation accuracy: 0.9711\n",
      "iteration number: 2680\t training loss: 33.8610\tvalidation loss: 66.1388\t validation accuracy: 0.9711\n",
      "iteration number: 2681\t training loss: 33.8421\tvalidation loss: 66.1386\t validation accuracy: 0.9711\n",
      "iteration number: 2682\t training loss: 33.8232\tvalidation loss: 66.1385\t validation accuracy: 0.9711\n",
      "iteration number: 2683\t training loss: 33.8042\tvalidation loss: 66.1384\t validation accuracy: 0.9711\n",
      "iteration number: 2684\t training loss: 33.7853\tvalidation loss: 66.1383\t validation accuracy: 0.9711\n",
      "iteration number: 2685\t training loss: 33.7665\tvalidation loss: 66.1382\t validation accuracy: 0.9711\n",
      "iteration number: 2686\t training loss: 33.7476\tvalidation loss: 66.1381\t validation accuracy: 0.9711\n",
      "iteration number: 2687\t training loss: 33.7287\tvalidation loss: 66.1380\t validation accuracy: 0.9711\n",
      "iteration number: 2688\t training loss: 33.7099\tvalidation loss: 66.1379\t validation accuracy: 0.9711\n",
      "iteration number: 2689\t training loss: 33.6911\tvalidation loss: 66.1378\t validation accuracy: 0.9711\n",
      "iteration number: 2690\t training loss: 33.6723\tvalidation loss: 66.1377\t validation accuracy: 0.9711\n",
      "iteration number: 2691\t training loss: 33.6535\tvalidation loss: 66.1376\t validation accuracy: 0.9711\n",
      "iteration number: 2692\t training loss: 33.6347\tvalidation loss: 66.1375\t validation accuracy: 0.9711\n",
      "iteration number: 2693\t training loss: 33.6160\tvalidation loss: 66.1374\t validation accuracy: 0.9711\n",
      "iteration number: 2694\t training loss: 33.5972\tvalidation loss: 66.1373\t validation accuracy: 0.9711\n",
      "iteration number: 2695\t training loss: 33.5785\tvalidation loss: 66.1373\t validation accuracy: 0.9711\n",
      "iteration number: 2696\t training loss: 33.5598\tvalidation loss: 66.1372\t validation accuracy: 0.9711\n",
      "iteration number: 2697\t training loss: 33.5411\tvalidation loss: 66.1371\t validation accuracy: 0.9711\n",
      "iteration number: 2698\t training loss: 33.5224\tvalidation loss: 66.1370\t validation accuracy: 0.9711\n",
      "iteration number: 2699\t training loss: 33.5037\tvalidation loss: 66.1369\t validation accuracy: 0.9711\n",
      "iteration number: 2700\t training loss: 33.4851\tvalidation loss: 66.1369\t validation accuracy: 0.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 2701\t training loss: 33.4665\tvalidation loss: 66.1368\t validation accuracy: 0.9711\n",
      "iteration number: 2702\t training loss: 33.4478\tvalidation loss: 66.1367\t validation accuracy: 0.9711\n",
      "iteration number: 2703\t training loss: 33.4292\tvalidation loss: 66.1367\t validation accuracy: 0.9711\n",
      "iteration number: 2704\t training loss: 33.4107\tvalidation loss: 66.1366\t validation accuracy: 0.9711\n",
      "iteration number: 2705\t training loss: 33.3921\tvalidation loss: 66.1365\t validation accuracy: 0.9711\n",
      "iteration number: 2706\t training loss: 33.3735\tvalidation loss: 66.1365\t validation accuracy: 0.9711\n",
      "iteration number: 2707\t training loss: 33.3550\tvalidation loss: 66.1364\t validation accuracy: 0.9711\n",
      "iteration number: 2708\t training loss: 33.3365\tvalidation loss: 66.1364\t validation accuracy: 0.9711\n",
      "iteration number: 2709\t training loss: 33.3180\tvalidation loss: 66.1363\t validation accuracy: 0.9711\n",
      "iteration number: 2710\t training loss: 33.2995\tvalidation loss: 66.1363\t validation accuracy: 0.9711\n",
      "iteration number: 2711\t training loss: 33.2810\tvalidation loss: 66.1362\t validation accuracy: 0.9711\n",
      "iteration number: 2712\t training loss: 33.2625\tvalidation loss: 66.1362\t validation accuracy: 0.9711\n",
      "iteration number: 2713\t training loss: 33.2441\tvalidation loss: 66.1361\t validation accuracy: 0.9711\n",
      "iteration number: 2714\t training loss: 33.2257\tvalidation loss: 66.1361\t validation accuracy: 0.9711\n",
      "iteration number: 2715\t training loss: 33.2073\tvalidation loss: 66.1360\t validation accuracy: 0.9711\n",
      "iteration number: 2716\t training loss: 33.1889\tvalidation loss: 66.1360\t validation accuracy: 0.9711\n",
      "iteration number: 2717\t training loss: 33.1705\tvalidation loss: 66.1360\t validation accuracy: 0.9711\n",
      "iteration number: 2718\t training loss: 33.1521\tvalidation loss: 66.1359\t validation accuracy: 0.9711\n",
      "iteration number: 2719\t training loss: 33.1338\tvalidation loss: 66.1359\t validation accuracy: 0.9711\n",
      "iteration number: 2720\t training loss: 33.1154\tvalidation loss: 66.1359\t validation accuracy: 0.9711\n",
      "iteration number: 2721\t training loss: 33.0971\tvalidation loss: 66.1359\t validation accuracy: 0.9711\n",
      "iteration number: 2722\t training loss: 33.0788\tvalidation loss: 66.1358\t validation accuracy: 0.9711\n",
      "iteration number: 2723\t training loss: 33.0605\tvalidation loss: 66.1358\t validation accuracy: 0.9711\n",
      "iteration number: 2724\t training loss: 33.0422\tvalidation loss: 66.1358\t validation accuracy: 0.9711\n",
      "iteration number: 2725\t training loss: 33.0240\tvalidation loss: 66.1358\t validation accuracy: 0.9711\n",
      "iteration number: 2726\t training loss: 33.0057\tvalidation loss: 66.1358\t validation accuracy: 0.9711\n",
      "iteration number: 2727\t training loss: 32.9875\tvalidation loss: 66.1357\t validation accuracy: 0.9711\n",
      "iteration number: 2728\t training loss: 32.9693\tvalidation loss: 66.1357\t validation accuracy: 0.9711\n",
      "iteration number: 2729\t training loss: 32.9511\tvalidation loss: 66.1357\t validation accuracy: 0.9711\n",
      "iteration number: 2730\t training loss: 32.9329\tvalidation loss: 66.1357\t validation accuracy: 0.9711\n",
      "iteration number: 2731\t training loss: 32.9148\tvalidation loss: 66.1357\t validation accuracy: 0.9711\n",
      "iteration number: 2732\t training loss: 32.8966\tvalidation loss: 66.1357\t validation accuracy: 0.9711\n",
      "iteration number: 2733\t training loss: 32.8785\tvalidation loss: 66.1357\t validation accuracy: 0.9711\n",
      "iteration number: 2734\t training loss: 32.8603\tvalidation loss: 66.1357\t validation accuracy: 0.9711\n",
      "iteration number: 2735\t training loss: 32.8422\tvalidation loss: 66.1357\t validation accuracy: 0.9711\n",
      "iteration number: 2736\t training loss: 32.8241\tvalidation loss: 66.1357\t validation accuracy: 0.9711\n",
      "iteration number: 2737\t training loss: 32.8061\tvalidation loss: 66.1357\t validation accuracy: 0.9711\n",
      "iteration number: 2738\t training loss: 32.7880\tvalidation loss: 66.1357\t validation accuracy: 0.9711\n",
      "iteration number: 2739\t training loss: 32.7700\tvalidation loss: 66.1358\t validation accuracy: 0.9711\n",
      "iteration number: 2740\t training loss: 32.7519\tvalidation loss: 66.1358\t validation accuracy: 0.9711\n",
      "iteration number: 2741\t training loss: 32.7339\tvalidation loss: 66.1358\t validation accuracy: 0.9711\n",
      "iteration number: 2742\t training loss: 32.7159\tvalidation loss: 66.1358\t validation accuracy: 0.9711\n",
      "iteration number: 2743\t training loss: 32.6979\tvalidation loss: 66.1358\t validation accuracy: 0.9711\n",
      "iteration number: 2744\t training loss: 32.6800\tvalidation loss: 66.1359\t validation accuracy: 0.9711\n",
      "iteration number: 2745\t training loss: 32.6620\tvalidation loss: 66.1359\t validation accuracy: 0.9711\n",
      "iteration number: 2746\t training loss: 32.6441\tvalidation loss: 66.1359\t validation accuracy: 0.9711\n",
      "iteration number: 2747\t training loss: 32.6261\tvalidation loss: 66.1359\t validation accuracy: 0.9711\n",
      "iteration number: 2748\t training loss: 32.6082\tvalidation loss: 66.1360\t validation accuracy: 0.9711\n",
      "iteration number: 2749\t training loss: 32.5903\tvalidation loss: 66.1360\t validation accuracy: 0.9711\n",
      "iteration number: 2750\t training loss: 32.5724\tvalidation loss: 66.1360\t validation accuracy: 0.9711\n",
      "iteration number: 2751\t training loss: 32.5546\tvalidation loss: 66.1361\t validation accuracy: 0.9711\n",
      "iteration number: 2752\t training loss: 32.5367\tvalidation loss: 66.1361\t validation accuracy: 0.9711\n",
      "iteration number: 2753\t training loss: 32.5189\tvalidation loss: 66.1362\t validation accuracy: 0.9711\n",
      "iteration number: 2754\t training loss: 32.5011\tvalidation loss: 66.1362\t validation accuracy: 0.9711\n",
      "iteration number: 2755\t training loss: 32.4833\tvalidation loss: 66.1363\t validation accuracy: 0.9711\n",
      "iteration number: 2756\t training loss: 32.4655\tvalidation loss: 66.1363\t validation accuracy: 0.9711\n",
      "iteration number: 2757\t training loss: 32.4477\tvalidation loss: 66.1364\t validation accuracy: 0.9711\n",
      "iteration number: 2758\t training loss: 32.4299\tvalidation loss: 66.1364\t validation accuracy: 0.9711\n",
      "iteration number: 2759\t training loss: 32.4122\tvalidation loss: 66.1365\t validation accuracy: 0.9711\n",
      "iteration number: 2760\t training loss: 32.3945\tvalidation loss: 66.1365\t validation accuracy: 0.9711\n",
      "iteration number: 2761\t training loss: 32.3767\tvalidation loss: 66.1366\t validation accuracy: 0.9711\n",
      "iteration number: 2762\t training loss: 32.3590\tvalidation loss: 66.1366\t validation accuracy: 0.9711\n",
      "iteration number: 2763\t training loss: 32.3413\tvalidation loss: 66.1367\t validation accuracy: 0.9711\n",
      "iteration number: 2764\t training loss: 32.3237\tvalidation loss: 66.1368\t validation accuracy: 0.9711\n",
      "iteration number: 2765\t training loss: 32.3060\tvalidation loss: 66.1368\t validation accuracy: 0.9711\n",
      "iteration number: 2766\t training loss: 32.2884\tvalidation loss: 66.1369\t validation accuracy: 0.9711\n",
      "iteration number: 2767\t training loss: 32.2707\tvalidation loss: 66.1370\t validation accuracy: 0.9711\n",
      "iteration number: 2768\t training loss: 32.2531\tvalidation loss: 66.1371\t validation accuracy: 0.9711\n",
      "iteration number: 2769\t training loss: 32.2355\tvalidation loss: 66.1371\t validation accuracy: 0.9711\n",
      "iteration number: 2770\t training loss: 32.2179\tvalidation loss: 66.1372\t validation accuracy: 0.9711\n",
      "iteration number: 2771\t training loss: 32.2004\tvalidation loss: 66.1373\t validation accuracy: 0.9711\n",
      "iteration number: 2772\t training loss: 32.1828\tvalidation loss: 66.1374\t validation accuracy: 0.9711\n",
      "iteration number: 2773\t training loss: 32.1653\tvalidation loss: 66.1375\t validation accuracy: 0.9711\n",
      "iteration number: 2774\t training loss: 32.1477\tvalidation loss: 66.1375\t validation accuracy: 0.9711\n",
      "iteration number: 2775\t training loss: 32.1302\tvalidation loss: 66.1376\t validation accuracy: 0.9711\n",
      "iteration number: 2776\t training loss: 32.1127\tvalidation loss: 66.1377\t validation accuracy: 0.9711\n",
      "iteration number: 2777\t training loss: 32.0952\tvalidation loss: 66.1378\t validation accuracy: 0.9711\n",
      "iteration number: 2778\t training loss: 32.0778\tvalidation loss: 66.1379\t validation accuracy: 0.9711\n",
      "iteration number: 2779\t training loss: 32.0603\tvalidation loss: 66.1380\t validation accuracy: 0.9711\n",
      "iteration number: 2780\t training loss: 32.0429\tvalidation loss: 66.1381\t validation accuracy: 0.9711\n",
      "iteration number: 2781\t training loss: 32.0255\tvalidation loss: 66.1382\t validation accuracy: 0.9711\n",
      "iteration number: 2782\t training loss: 32.0080\tvalidation loss: 66.1383\t validation accuracy: 0.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 2783\t training loss: 31.9907\tvalidation loss: 66.1384\t validation accuracy: 0.9711\n",
      "iteration number: 2784\t training loss: 31.9733\tvalidation loss: 66.1385\t validation accuracy: 0.9711\n",
      "iteration number: 2785\t training loss: 31.9559\tvalidation loss: 66.1386\t validation accuracy: 0.9711\n",
      "iteration number: 2786\t training loss: 31.9385\tvalidation loss: 66.1387\t validation accuracy: 0.9711\n",
      "iteration number: 2787\t training loss: 31.9212\tvalidation loss: 66.1389\t validation accuracy: 0.9711\n",
      "iteration number: 2788\t training loss: 31.9039\tvalidation loss: 66.1390\t validation accuracy: 0.9711\n",
      "iteration number: 2789\t training loss: 31.8866\tvalidation loss: 66.1391\t validation accuracy: 0.9711\n",
      "iteration number: 2790\t training loss: 31.8693\tvalidation loss: 66.1392\t validation accuracy: 0.9711\n",
      "iteration number: 2791\t training loss: 31.8520\tvalidation loss: 66.1393\t validation accuracy: 0.9711\n",
      "iteration number: 2792\t training loss: 31.8347\tvalidation loss: 66.1395\t validation accuracy: 0.9711\n",
      "iteration number: 2793\t training loss: 31.8175\tvalidation loss: 66.1396\t validation accuracy: 0.9711\n",
      "iteration number: 2794\t training loss: 31.8002\tvalidation loss: 66.1397\t validation accuracy: 0.9711\n",
      "iteration number: 2795\t training loss: 31.7830\tvalidation loss: 66.1398\t validation accuracy: 0.9711\n",
      "iteration number: 2796\t training loss: 31.7658\tvalidation loss: 66.1400\t validation accuracy: 0.9711\n",
      "iteration number: 2797\t training loss: 31.7486\tvalidation loss: 66.1401\t validation accuracy: 0.9711\n",
      "iteration number: 2798\t training loss: 31.7314\tvalidation loss: 66.1402\t validation accuracy: 0.9733\n",
      "iteration number: 2799\t training loss: 31.7142\tvalidation loss: 66.1404\t validation accuracy: 0.9733\n",
      "iteration number: 2800\t training loss: 31.6971\tvalidation loss: 66.1405\t validation accuracy: 0.9733\n",
      "iteration number: 2801\t training loss: 31.6800\tvalidation loss: 66.1407\t validation accuracy: 0.9733\n",
      "iteration number: 2802\t training loss: 31.6628\tvalidation loss: 66.1408\t validation accuracy: 0.9733\n",
      "iteration number: 2803\t training loss: 31.6457\tvalidation loss: 66.1410\t validation accuracy: 0.9733\n",
      "iteration number: 2804\t training loss: 31.6286\tvalidation loss: 66.1411\t validation accuracy: 0.9733\n",
      "iteration number: 2805\t training loss: 31.6115\tvalidation loss: 66.1413\t validation accuracy: 0.9733\n",
      "iteration number: 2806\t training loss: 31.5945\tvalidation loss: 66.1414\t validation accuracy: 0.9733\n",
      "iteration number: 2807\t training loss: 31.5774\tvalidation loss: 66.1416\t validation accuracy: 0.9733\n",
      "iteration number: 2808\t training loss: 31.5604\tvalidation loss: 66.1417\t validation accuracy: 0.9733\n",
      "iteration number: 2809\t training loss: 31.5433\tvalidation loss: 66.1419\t validation accuracy: 0.9733\n",
      "iteration number: 2810\t training loss: 31.5263\tvalidation loss: 66.1420\t validation accuracy: 0.9733\n",
      "iteration number: 2811\t training loss: 31.5093\tvalidation loss: 66.1422\t validation accuracy: 0.9733\n",
      "iteration number: 2812\t training loss: 31.4923\tvalidation loss: 66.1424\t validation accuracy: 0.9733\n",
      "iteration number: 2813\t training loss: 31.4754\tvalidation loss: 66.1425\t validation accuracy: 0.9733\n",
      "iteration number: 2814\t training loss: 31.4584\tvalidation loss: 66.1427\t validation accuracy: 0.9733\n",
      "iteration number: 2815\t training loss: 31.4415\tvalidation loss: 66.1429\t validation accuracy: 0.9733\n",
      "iteration number: 2816\t training loss: 31.4245\tvalidation loss: 66.1430\t validation accuracy: 0.9733\n",
      "iteration number: 2817\t training loss: 31.4076\tvalidation loss: 66.1432\t validation accuracy: 0.9733\n",
      "iteration number: 2818\t training loss: 31.3907\tvalidation loss: 66.1434\t validation accuracy: 0.9733\n",
      "iteration number: 2819\t training loss: 31.3738\tvalidation loss: 66.1436\t validation accuracy: 0.9733\n",
      "iteration number: 2820\t training loss: 31.3570\tvalidation loss: 66.1437\t validation accuracy: 0.9733\n",
      "iteration number: 2821\t training loss: 31.3401\tvalidation loss: 66.1439\t validation accuracy: 0.9733\n",
      "iteration number: 2822\t training loss: 31.3233\tvalidation loss: 66.1441\t validation accuracy: 0.9733\n",
      "iteration number: 2823\t training loss: 31.3064\tvalidation loss: 66.1443\t validation accuracy: 0.9733\n",
      "iteration number: 2824\t training loss: 31.2896\tvalidation loss: 66.1445\t validation accuracy: 0.9733\n",
      "iteration number: 2825\t training loss: 31.2728\tvalidation loss: 66.1447\t validation accuracy: 0.9733\n",
      "iteration number: 2826\t training loss: 31.2560\tvalidation loss: 66.1449\t validation accuracy: 0.9733\n",
      "iteration number: 2827\t training loss: 31.2392\tvalidation loss: 66.1451\t validation accuracy: 0.9733\n",
      "iteration number: 2828\t training loss: 31.2225\tvalidation loss: 66.1453\t validation accuracy: 0.9733\n",
      "iteration number: 2829\t training loss: 31.2057\tvalidation loss: 66.1455\t validation accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#attention, gradient descent standard prend longtemp Ã  converger \n",
    "mlp = MultiLayerPerceptron(X, Y, hidden_size=50, activation='sigmoid')\n",
    "mlp.train(optimizer=\"gd\",momentum=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.plot_loss_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAEWCAYAAACaMLagAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZxcVZ338c+XJBDIQjRpERJCZ5QBwhagDToBB0R8EmCIOiBhewYfQ5BFYHRE3BCRURx5ENQghC2iQGSRRYwsDkFli3RCAwmBMUBDGpB0QgIJa5bf/HFvx0qnl+ruW7fSN9/365VXquqeOvd3q7pO/eqcc89VRGBmZmZWFJtVOwAzMzOzLDm5MTMzs0JxcmNmZmaF4uTGzMzMCsXJjZmZmRWKkxszMzMrFCc3GzFJV0r6RrXj6IikD0sqaz0BSZ+U1NjN/XT7uWbWc5JOkPRAN597gKSmDrZfJunbbZWVNF/SAR089/eS/q07cXVE0kmSLs663g721yjpk+ntb0i6spv1dPh65UHSHpIeqmYMTm46IGllyb+1kt4uuX9spfcfEZMj4vuV3k8RSWpq9X79vtoxWe+Wfrk/KektSX+T9HNJQ7rw/HVfXhnFk2l91RQRX4yI77WzbdeIuB9A0rmSftVq+4SI+EWW8UjaHPgW8KMs6y1XRHw/IiZ3Vk7SdEnnt3ruuterktJ9v9fqe7JPGsMTwHJJ/1LpONrj5KYDETGw5R/wIvAvJY9d17q8pL75R2kdmFDyfk2odjDWe0n6CvBD4KvA1sBHgR2Ae9Mvwl6v5YvJAJgIPB0RL3XnyZvQd8F/lX5PRsSakm3XASdVKzAnNz0g6XxJv5Z0g6QVwHGSfiXp3JIy6w2nSBoh6VZJzZKel3RqB/Wvq6ulHklfT5/7sqR/kXSYpL9Kek3SWSXP/ZikRyQtl/SKpJ9I6leyfYKk/5H0uqSfSnpQ0gkl2ydLelrSsrTbd/syX5PJkhZIWiHpWUkb/PqQdI6kpenxTyp5vL+kiyQtkvSqpEsl9S9nv2aVImkw8F3gSxFxV0SsiohG4HNALXBcWm69X9GlwyuSfgmMBH6b/sI9S1KtpJA0Jf08vyLpP0qe36X62oj7gLQH8xuSlqTtx7Gt6v+5pJmS3gQOlLS1pGvTNuYFSd+StNn61epnabvxtKSDSjZ8vuSz/5ykDb7YOonl/Nbl022Nafs3HvgGcFR6zI+n2+8vbWck/b80jmWS7pa0Q0vgkn4sabGkN5T0wu3W1j6BCcAfS+rs7L06V9LNStrsN4ATJG0m6ey0HVwq6UZJ7y95zvHpa7xU0jdbHfN6PVSS9pP0kJL2fJGSXsQpwLHAWenr8dvS1yu9vYWki9OYX05vb5Fua/n7+Er6mrwi6fPtvB7dcT9wUMv+8ubkpuc+A1xP8mvu1x0VTBuJO4FHgeHAwcBXSxuITowgec+2A74HXAVMAvYCDgDOkzQyLbsaOAMYBowDxpNm0ZI+ANxI8it0GPA8MLYkzn9Nt00EaoDZ6TGW41XgUGAwcCLwU0l7tDqGQekxfAG4WtKH020/AkYBewA7knxxrPehL4nxckk/6SSWGemH9m5Ju5cZv1lr/wT0B35T+mBErARmknyOOxQRx7N+7+9/lWw+kOTv/VPA11TGUFMn9ZX6IMlnfDjwb8A0STuVbD8G+E+Sz+QDwE9J2rJ/AP4Z+L9A6RfevsCzaZ3fAX5T8oW9GDiM5LP/eeDHkvbuQiydHfNdwPeBX6fHvGfrMpImkiRAnyVpu/4M3JBu/hTwceAf02P8HLC0nd3tDjzTxuMdvVcTgZuBISS9Fl8CPk3yOm4HLAOmpnGOBn4OHJ9uG0rSNm4gTc5+T/Le1ABjgIaImJbup6X3pK0hoG+S9DKOAfYkaee/VbL9g+lrMZykPZ4q6X3pfo+R9ETbL886pyj5YT0n/d5YJ+31WgWU/R5nyclNzz0QEb+NiLUR8XYnZT8GDE7HU9+LiIX8PUEpxzvABRGxCphB8of+44hYmY5xPkOSGBARj0bE7IhYHRHPAdNIPmSQNEANEXF7WtePgSUl+/ki8P2IeCYiVgPnA2MlDe8swPS1eC4S9wH/DexfUmQt8J2IeDfdfhdwZJr4nQicGRHLIuIN4AftvTYRcVJEnN5BKJNIkqNRJI323ZK27ix+szYMA5akn4XWXkm398R3I+LNiHgSuAY4uof1tfbt9PP2R+B3JF/qLW6PiAcjYi3JF9Ek4OsRsSLtnfr/JF/ALRYDF6e9V78maXMOBYiI30XEs+ln/4/APaz/2e8slix8EfhBRCxI36/vA2PSBGEVSRK3M6C0zCvt1DMEWNHG4x29Vw9HxG0l3wVfBL4ZEU0R8S5wLnCEkiGrI4A7I+JP6bZvk7SNbTkG+ENE3JC+7ksjoqHM1+NY4LyIWBwRzSQ9kKXv56p0+6qImAmsJE1GIuL6iNhjgxr/7ickid4H0vinSxrXqswKktcyd05uem5RF8ruAIxMuxaXS1oOnEWSPZdjScmYZksi9WrJ9reBgQCSdpb0OyUTH98AzuPvjfB2pXFHcvXU0jMZdiDJ4FtiXELywWvzl0UpJcNks9NsfjnJL5zSxn9pRLxVcv+FNJ4PAlsAj5fs906SD06XRcQDEfFO2hB9D3iL5Be4WVctAYap7XkU27L+D4PuKG1DWj4PWVkWEW92UH/pvocB/dIypeVLf9S8lLYXG9SnZKj7kZLP/iGs/9nvLJYs7ABcUtKGvAYIGJ7+mPoZSe/JYknTlAw5tmUZSSLUWkfvVevvgh2AW0tiWQCsAbZhwzb4TdrvRdqepLesO7Zjw/ezNOalrZL2t0i/QzoTEXPTRGt1mhhdR9JjVmoQsLzrYfeck5uea30a9JvAViX3SxOXRcBfI2JIyb9B7XQn9tTlwDzgwxExGDiH5EMOya/NdYmKJLF+A7YI+EKrOLeMiNkd7VDSliTdsj8AtomIISS/3lRSbGharsVI4GWSJO09YKeSfW4dEVn1tkSrOMzK9TDwLq0abkkDSeZm/Hf6UEeffdiwrWhROp+t5fPQk/pKvU/SgHbqb13HEpJf8ju0Kl86qXZ42l6sV186r+IW4EL+/tmfyfqfuc5iKUdnx7wIOKmNtushgIj4SUTsA4wmGZ76ajv1PJFub62996qt2BaRnNRQGkv/dLjmldK6JG1FMjTV3jF9qJ1tnb0eL7Ph+9nV17xc67WxaU//5rQ9vFdxTm6y1wAcKul9krYFSodOHgbeSydw9ZfUR9LukvapQByDgNeBNyXtwvqz1u8E9lYyIbkvydycmpLtlwHfTJ+HpCGSjihjn1uQ/DE3A2skHQa0nk+0GXCupM2VrMUwAbg57ZG6ErhYUo0SIyR9qovH3TL5758k9Utf57NJ5gE83NW6zCLidZLu/J9KGp/+XdWSzFtrAn6ZFm0ADpH0fkkfBM5sVdWrJHNZWvu2pK0k7UoyV6Vl7l5362vtu+nnbX+SIemb2jnONekx/aekQelQzpeB0lOvPwCcnr4GRwK7kCQxm5N8/puB1ZImkPTadiuWDrwK1Gr9Sc6lLgO+nr6WKJkgfWR6+yOS9lVyYsWbJMP87Q0FzeTvw/il2nuv2ovlP/X3Cc016ZwgSH4EHqZkovDmJD3r7R3TdcAnJX1OUl9JQyWNSbd19jdwA/CtdN/DSH7k/qqD8mWTdISkgUomTn+KZGL9HSVF/hm4Lx12y52Tm+xNJ+l+fIFkPsmMlg1p998hJJO6Gkl+KV1O8sWbta+QTNpbke5j3YcwIl4FjgIuIukK/RDwGMmvUyLipnTbTemQ1hPA/+lshxGxHPh34FaS7uAjSBKpUk0kDcsrwC+AyRHx15KYXwD+QpKY3UMyprsBJQsc/qydUAalx7yM5FfnQSS/oJZ1dgxmbYlkwu43SHom3iCZZL8IOKik8f4l8DjJZ/seNvzi+wHJF81ylZxpQ3JWzkKSHqALI+KeHtZX6m8kn4OXSb4kvxgRT3dwqF8i+Xw+RzJX7Xrg6pLts0k+k0tIJiIfkQ5NrCD5IXdjur9jWP+LrjuxtKUlGVoqaW7rjRFxK8kp+zPStmseyQ8oSNrZK9IYXiBp+9pbx+a3wM6SWg+btfdeteUSktfgHiVn0z5CMiGbiJgPnEry+r6SxtTmIocR8SLJ98ZXSNrVBpLJwZDM2Ryd/g3c1sbTzwfqSdrwJ4G56WOdknSspPkdFDmDpH1dTvI6nhjrr69zLEmCVxVaf/jUNkVK1rd4maSh+nO14zHbFKS9P88D/dqZrNzT+g8AfhURnc6Vsw0pOdV6dEScWen3qmiUnCF7eUR8rFoxbCoLDVkrStaMeIRkEvLXScba/1LVoMzMNhKRnGpt3RDJ2btVS2zAw1Kbsv1Iup6bSYacPlOtsVEzM7MseVjKzMzMCsU9N2ZmZlYoFZlzM2zYsKitra1E1VW1aFFX1uvruaVL21vTKXtr1qzpvFBG+vTJ7/p8o0ePzm1fAJtvns81FBsbG1myZInX7SlR1HbHzNo2Z86cJRFR09a2iiQ3tbW11NfXV6LqqjrzzNbLTFTW9OnTc9vX66+/ntu+Bg4sawHMTNxxR+uzUSsrry/Xurq6XPbTmxS13TGztkl6ob1tHpYyMzOzQnFyY2ZmZoXi5MbMzMwKxYv4mZmZZWTVqlU0NTXxzjvvVDuUwujfvz8jRoygX79+ZT/HyY2ZmVlGmpqaGDRoELW1tax/AXXrjohg6dKlNDU1MWrUqLKf52EpMzOzjLzzzjsMHTrUiU1GJDF06NAu94Q5uTGzXEm6WtJiSfPa2S5JP5G0UNITkvbOO0aznnBik63uvJ5Obswsb9OB8R1snwDsmP6bAvw8h5jMrEA858bMchURf5JU20GRicC1kVz47hFJQyRtGxGv5BKgWYZqz/5dpvU1XnBoh9uXL1/O9ddfzymnnJLpfnubspIbSeOBS4A+wJURcUFFozKzTdlwoPRaJ03pYxskN5KmkPTuMHLkyFyCs41XlolEZ0nExmr58uVceumlGyQ3q1evpm/fTac/o9NhKUl9gKkkXcWjgaMl5XvBHjOzNkTEtIioi4i6mpo2LzFjtkk5++yzefbZZxkzZgwf+chH2H///Tn88MMZPXo0jY2N7LbbbuvKXnjhhZx77rkAPPvss4wfP5599tmH/fffn6effrpKR5CNctK4scDCiHgOQNIMkm7jpyoZmJltsl4Cti+5PyJ9zMw6ccEFFzBv3jwaGhq4//77OfTQQ5k3bx6jRo2isbGx3edNmTKFyy67jB133JHZs2dzyimncN999+UXeMbKSW7a6iLet3Uhdw+bWUbuAE5Lf0jtC7zu+TZm3TN27NhO14dZuXIlDz30EEceeeS6x959991Kh1ZRmQ3ARcQ0YBpAXV1dZFWvmRWLpBuAA4BhkpqA7wD9ACLiMmAmcAiwEHgL+Hx1IjXr/QYMGLDudt++fVm7du26+y1rx6xdu5YhQ4bQ0NCQe3yVUs6p4O4iNrPMRMTREbFtRPSLiBERcVVEXJYmNkTi1Ij4UETsHhH11Y7ZrLcYNGgQK1asaHPbNttsw+LFi1m6dCnvvvsud955JwCDBw9m1KhR3HTTTUCyKvDjjz+eW8yVUE7PzaPAjpJGkSQ1k4BjKhqVmZlZAeR91tXQoUMZN24cu+22G1tuuSXbbLPNum39+vXjnHPOYezYsQwfPpydd9553bbrrruOk08+mfPPP59Vq1YxadIk9txzz1xjz1KnyU1ErJZ0GnA3yangV0fE/IpHZmZmZl12/fXXt7vt9NNP5/TTT9/g8VGjRnHXXXdVMqxclTXnJiJmkoyDm5mZmW3UfPkFMzMzKxQnN2ZmZlYoTm7MzMysUJzcmJmZWaE4uTEzM7NCcXJjZmZWKVK2/6pg4MCBALz88sscccQRHZa9+OKLeeutt9bdP+SQQ1i+fHlF42uLkxszM7NNzJo1a7r8nO22246bb765wzKtk5uZM2cyZMiQLu+rpzK7tlS13H///bnt65JLLsltXwC33XZbbvvaYYcdcttXbW1tbvuqxofKzKyaGhsbGT9+PPvssw9z585l11135dprr2X06NEcddRR3HvvvZx11ll85CMf4dRTT6W5uZmtttqKK664gp133pnnn3+eY445hpUrVzJx4sT16j3ssMOYN28ea9as4Wtf+xp33XUXm222GSeeeCIRwcsvv8yBBx7IsGHDmDVrFrW1tdTX1zNs2DAuuugirr76agAmT57MmWeeSWNjIxMmTGC//fbjoYceYvjw4dx+++1sueWWPXoN3HNjZmZWMM888wynnHIKCxYsYPDgwVx66aVAcnmGuXPnMmnSJKZMmcJPf/pT5syZw4UXXsgpp5wCwBlnnMHJJ5/Mk08+ybbbbttm/dOmTaOxsZGGhgaeeOIJjj32WE4//XS22247Zs2axaxZs9YrP2fOHK655hpmz57NI488whVXXMFjjz0GwF//+ldOPfVU5s+fz5AhQ7jlllt6fPxObszMzApm++23Z9y4cQAcd9xxPPDAAwAcddRRAKxcuZKHHnqII488kjFjxnDSSSfxyiuvAPDggw9y9NFHA3D88ce3Wf8f/vAHTjrpJPr2TQaA3v/+93cYzwMPPMBnPvMZBgwYwMCBA/nsZz/Ln//8ZyC59MOYMWMA2GeffWhsbOzBkSd6/bCUmZmZrU+tJh+33B8wYAAAa9euZciQITQ0NJT1/EraYost1t3u06cPb7/9do/rdM+NmZlZwbz44os8/PDDQHIhzf3222+97YMHD2bUqFHcdNNNAEQEjz/+OADjxo1jxowZQHK18LYcfPDBXH755axevRqA1157DYBBgwaxYsWKDcrvv//+3Hbbbbz11lu8+eab3Hrrrey///4ZHGnbnNyYmZlVSkS2/8q00047MXXqVHbZZReWLVvGySefvEGZ6667jquuuoo999yTXXfdldtvvx1ITp6ZOnUqu+++Oy+99FKb9U+ePJmRI0eyxx57sOeee667EvmUKVMYP348Bx544Hrl9957b0444QTGjh3Lvvvuy+TJk9lrr73KPp6uUnThxSpXXV1d1NfXZ15vW/I8W6r1m1VpPluq54p6tlRdXR319fXVWfRiI5Vnu2Mbp9qzf5dZXY0XHNqt5y1YsIBddtklszi6o/SspqJo63WVNCci6toq754bMzMzKxQnN2ZmZgVSW1tbqF6b7nByY2ZmlqFKTPfYlHXn9XRyY2ZmlpH+/fuzdOlSJzgZiQiWLl1K//79u/S8Tte5kXQ1cBiwOCJ262Z8ZmZmhTdixAiamppobm6udiiF0b9/f0aMGNGl55SziN904GfAtd2IyczMbJPRr18/Ro0aVe0wNnmdDktFxJ+A13KIxczMzKzHMptzI2mKpHpJ9e6OMzMzs2rJLLmJiGkRURcRdTU1NVlVa2ZmZtYlPlvKzMzMCsXJjZmZmRVKp8mNpBuAh4GdJDVJ+kLlwzIzMzPrnk5PBY+Io/MIxMzMzCwLHpYyMzOzQnFyY2ZmZoXi5MbMcidpvKRnJC2UdHYb20dKmiXpMUlPSDqkGnGaWe/k5MbMciWpDzAVmACMBo6WNLpVsW8BN0bEXsAk4NJ8ozSz3szJjZnlbSywMCKei4j3gBnAxFZlAhic3t4aeDnH+Mysl3NyY2Z5Gw4sKrnflD5W6lzgOElNwEzgS21V5Mu+mFlbnNyY2cboaGB6RIwADgF+KWmD9sqXfTGztnS6zo393Q477JDr/iZObN1Tb1YILwHbl9wfkT5W6gvAeICIeFhSf2AYsDiXCM2sV3PPjZnl7VFgR0mjJG1OMmH4jlZlXgQOApC0C9Af8LiTmZXFyY2Z5SoiVgOnAXcDC0jOipov6TxJh6fFvgKcKOlx4AbghIiI6kRsZr2Nh6XMLHcRMZNkonDpY+eU3H4KGJd3XGZWDO65MTMzs0JxcmNmZmaF4uTGzMzMCsXJjZmZmRWKkxszMzMrFCc3ZmZmVihObszMzKxQOk1uJG0vaZakpyTNl3RGHoGZmZmZdUc5i/itBr4SEXMlDQLmSLo3XWTLzMzMbKPSac9NRLwSEXPT2ytIlksfXunAzMzMzLqjS3NuJNUCewGz29g2RVK9pPrmZl/fzszMzKqj7ORG0kDgFuDMiHij9faImBYRdRFRV1NTk2WMZmZmZmUrK7mR1I8ksbkuIn5T2ZDMzMzMuq+cs6UEXAUsiIiLKh+SmZmZWfeV03MzDjge+ISkhvTfIRWOy8zMzKxbOj0VPCIeAJRDLGZmZmY95hWKzczMrFDKWcTPzMxso9f4w8Oyq+yCyK4uy517bszMzKxQnNyYmZlZoTi5MTMzs0JxcmNmZmaF4uTGzMzMCsXJjZmZmRVKrz8V/PXXX692CBVz5pln5rav2267Lbd9LV++PLd9NTQ05LYvgNra2lz3Z2ZmG3LPjZmZmRWKkxszMzMrFCc3ZmZmVihObszMzKxQnNyYmZlZoTi5MTMzs0JxcmNmZmaF4uTGzHInabykZyQtlHR2O2U+J+kpSfMlXZ93jGbWe/X6RfzMrHeR1AeYChwMNAGPSrojIp4qKbMj8HVgXEQsk/SB6kRrZr1Rpz03kvpL+oukx9NfUN/NIzAzK6yxwMKIeC4i3gNmABNblTkRmBoRywAiYnHOMZpZL1bOsNS7wCciYk9gDDBe0kcrG5aZFdhwYFHJ/ab0sVL/CPyjpAclPSJpfG7RmVmv1+mwVEQEsDK92y/9F5UMysw2eX2BHYEDgBHAnyTtHhHrXZhM0hRgCsDIkSPzjtHMNlJlTSiW1EdSA7AYuDciZrdRZoqkekn1zc3NWcdpZsXxErB9yf0R6WOlmoA7ImJVRDwP/A9JsrOeiJgWEXURUVdTU1OxgM2sdykruYmINRExhqQRGitptzbKuJExs3I8CuwoaZSkzYFJwB2tytxG0muDpGEkw1TP5RmkmfVeXToVPO0SngV4/NvMuiUiVgOnAXcDC4AbI2K+pPMkHZ4WuxtYKukpkjbnqxGxtDoRm1lv0+mcG0k1wKqIWC5pS5LTN39Y8cjMrLAiYiYws9Vj55TcDuDL6T8zsy4pZ52bbYFfpGtTbEbyK+vOyoZlZmZm1j3lnC31BLBXDrGYmZmZ9Zgvv2BmZmaF4uTGzMzMCsXJjZmZmRWKkxszMzMrFCc3ZmZmVihObszMzKxQnNyYmZlZoTi5MTMzs0IpZ4ViSw0ZMqTaIVTMCSeckNu+Lr744tz2NX369Nz2BXDuuefmuj8zM9uQe27MzMysUJzcmJmZWaE4uTEzM7NCcXJjZmZmheLkxszMzArFyY2ZmZkVipMbMzMzKxQnN2ZmZlYoTm7MzMysUJzcmJmZWaGUndxI6iPpMUl3VjIgMzMzs57oSs/NGcCCSgViZmZmloWykhtJI4BDgSsrG46ZmZlZz5Tbc3MxcBawtr0CkqZIqpdU39zcnElwZmZmZl3VaXIj6TBgcUTM6ahcREyLiLqIqKupqcksQDMzM7OuKKfnZhxwuKRGYAbwCUm/qmhUZmZmZt3UaXITEV+PiBERUQtMAu6LiOMqHpmZmZlZN3idGzMzMyuUvl0pHBH3A/dXJBIzMzOzDLjnxszMzArFyY2ZmZkVipMbMzMzKxQnN2aWO0njJT0jaaGkszso96+SQlJdnvGZWe/m5MbMciWpDzAVmACMBo6WNLqNcoNIrmk3O98Izay3c3JjZnkbCyyMiOci4j2SxUEntlHue8APgXfyDM7Mej8nN2aWt+HAopL7Telj60jaG9g+In7XUUW+pp2ZtaVL69xsjCZObOsHX+/fV5Hddtttue1rr732ym1flg1JmwEXASd0VjYipgHTAOrq6qKykZlZb+GeGzPL20vA9iX3R6SPtRgE7Abcn17T7qPAHZ5UbGblcnJjZnl7FNhR0ihJm5Ncs+6Olo0R8XpEDIuI2vSado8Ah0dEfXXCNbPexsmNmeUqIlYDpwF3AwuAGyNivqTzJB1e3ejMrAh6/ZwbM+t9ImImMLPVY+e0U/aAPGIys+Jwz42ZmZkVipMbMzMzKxQnN2ZmZlYoTm7MzMysUJzcmJmZWaE4uTEzM7NCKetU8HSV0BXAGmB1RHilUDMzM9sodWWdmwMjYknFIjEzMzPLgIelzMzMrFDKTW4CuEfSHElT2iogaYqkekn1zc3N2UVoZmZm1gXlJjf7RcTewATgVEkfb10gIqZFRF1E1NXU1GQapJmZmVm5ykpuIuKl9P/FwK3A2EoGZWZmZtZdnSY3kgZIGtRyG/gUMK/SgZmZmZl1RzlnS20D3Cqppfz1EXFXRaMyMzMz66ZOk5uIeA7YM4dYzMzMzHrMp4KbmZlZoTi5MTMzs0JxcmNmZmaF4uTGzMzMCsXJjZmZmRWKkxszMzMrFCc3ZmZmVijlLOJnVXL77bfntq9rrrkmt30tX748t31NnDgxt32ZmdnGwT03ZmZmVihObszMzKxQnNyYmZlZoTi5MTMzs0JxcmNmZmaF4uTGzMzMCsXJjZmZmRWKkxszMzMrFCc3ZmZmVihObswsd5LGS3pG0kJJZ7ex/cuSnpL0hKT/lrRDNeI0s96prORG0hBJN0t6WtICSR+rdGBmVkyS+gBTgQnAaOBoSaNbFXsMqIuIPYCbgf/KN0oz683K7bm5BLgrInYG9gQWVC4kMyu4scDCiHguIt4DZgDrXQQsImZFxFvp3UeAETnHaGa9WKcXzpS0NfBx4ASAtDF6r7JhmVmBDQcWldxvAvbtoPwXgN+3tUHSFGAKwMiRI7OKz8y6QsqurohMqimn52YU0AxcI+kxSVdKGtC6kKQpkuol1Tc3N2cSnJlt2iQdB9QBP2pre0RMi4i6iKirqanJNzgz22iVk9z0BfYGfh4RewFvAhtMAHQjY2ZlegnYvuT+iPSx9Uj6JPBN4PCIeDen2MysAMpJbpqApoiYnd6/mSTZMTPrjkeBHSWNkrQ5MAm4o7SApL2Ay0kSm8VViNHMerFOk5uI+BuwSNJO6UMHAU9VNCozK6yIWA2cBtxNcnLCjRExX9J5kg5Pi/0IGAjcJKlB0h3tVGdmtoFOJxSnvgRcl/7KejyBFxMAAAo+SURBVA74fOVCMrOii4iZwMxWj51TcvuTuQdlZoVRVnITEQ0kk/rMzMzMNmpeodjMzMwKxcmNmZmZFYqTGzMzMysUJzdmZmZWKE5uzMzMrFCc3JiZmVmhOLkxMzOzQnFyY2ZmZoVS7grFBnz605/OdX/Lly/PbV95Htv06dNz25eZmW163HNjZmZmheLkxszMzArFyY2ZmZkVipMbMzMzKxQnN2ZmZlYoTm7MzMysUJzcmJmZWaE4uTEzM7NCcXJjZmZmhdJpciNpJ0kNJf/ekHRmHsGZmZmZdVWnl1+IiGeAMQCS+gAvAbdWOC4zMzOzbunqsNRBwLMR8UIlgjEzMzPrqa4mN5OAG9raIGmKpHpJ9c3NzT2PzMzMzKwbyk5uJG0OHA7c1Nb2iJgWEXURUVdTU5NVfGZmZmZd0pWemwnA3Ih4tVLBmJmZmfVUV5Kbo2lnSMrMzMxsY1FWciNpAHAw8JvKhmNmZmbWM52eCg4QEW8CQysci5mZmVmPeYViMzMzKxQnN2ZmZlYoTm7MzMysUMqac2NmVihSdnVFZFeXmWXCPTdmZmZWKO65MbPcSRoPXAL0Aa6MiAtabd8CuBbYB1gKHBURjXnH2W2V7BmqdK9Tb4690rKKP+/XPcv6e0lPpXtuzCxXkvoAU0lWPR8NHC1pdKtiXwCWRcSHgR8DP8w3SjPrzZzcmFnexgILI+K5iHgPmAFMbFVmIvCL9PbNwEFSlj9tzazIFBXoYpLUDLzQxacNA5ZkHszGoajH5uOqnh0ioldeoVbSEcD4iJic3j8e2DciTispMy8t05TefzYts6RVXVOAKendnYBnMg63kn8Llf47c+z5113p+ntz7JWov912sCJzbrrT6Eqqj4i6SsRTbUU9Nh+XVVtETAOmVar+Sv4tVPrvzLHnX3el6+/NsedRfykPS5lZ3l4Cti+5PyJ9rM0ykvoCW5NMLDYz65STGzPL26PAjpJGSdocmATc0arMHcC/pbePAO6LSoyhm1khbUynglesa3kjUNRj83FZl0XEakmnAXeTnAp+dUTMl3QeUB8RdwBXAb+UtBB4jSQBqoZK/i1U+u/Msedfd6Xr782x51H/OhWZUGxmZmZWLR6WMjMzs0JxcmNmZmaFslEkN5LGS3pG0kJJZ1c7nixI2l7SLElPSZov6Yxqx5QlSX0kPSbpzmrHkiVJQyTdLOlpSQskfazaMVn+KtkmSbpa0uJ0LZ9MVbrdkdRf0l8kPZ7W/90s60/3UbG2RVKjpCclNUiqr0D9FWk/JO2Uxtzy7w1JZ2ZRd8k+/j19T+dJukFS/wzrPiOtd37Wcbe7z2rPuUmXYv8f4GCgieRMiqMj4qmqBtZDkrYFto2IuZIGAXOAT/f242oh6ctAHTA4Ig6rdjxZkfQL4M8RcWV6Js9WEbG82nFZfirdJkn6OLASuDYidsuizpK6K9rupKtED4iIlZL6AQ8AZ0TEI1nUn+6jYm2LpEagrvVikBnWX/H2I/37fIlkUcuuLpbbXp3DSd7L0RHxtqQbgZkRMT2DuncjWYV8LPAecBfwxYhY2NO6O7Ix9NyUsxR7rxMRr0TE3PT2CmABMLy6UWVD0gjgUODKaseSJUlbAx8nOVOHiHjPic0mqaJtUkT8ieQMsMxVut2JxMr0br/0X2a/kHtz25Jj+3EQ8GxWiU2JvsCW6bpSWwEvZ1TvLsDsiHgrIlYDfwQ+m1Hd7doYkpvhwKKS+00UJAloIakW2AuYXd1IMnMxcBawttqBZGwU0Axck3aLXylpQLWDstwVok2qVLuTDhs1AIuBeyMiy/or3bYEcI+kOemlO7KUV/sxCbghywoj4iXgQuBF4BXg9Yi4J6Pq5wH7SxoqaSvgENZfxLMiNobkptAkDQRuAc6MiDeqHU9PSToMWBwRc6odSwX0BfYGfh4RewFvAoWYA2ablkq2OxGxJiLGkKwsPTYdduixnNqW/SJib5Ir0p+aDhFmpeLtRzrUdThwU8b1vo+kd3IUsB0wQNJxWdQdEQuAHwL3kAxJNQBrsqi7IxtDclPOUuy9UjomfQtwXUT8ptrxZGQccHg6dj0D+ISkX1U3pMw0AU0lv0RvJmmsbNPSq9ukvNqddMhlFjA+oyor3rakPRRExGLgVpIhyKzk0X5MAOZGxKsZ1/tJ4PmIaI6IVcBvgH/KqvKIuCoi9omIjwPLSOa0VdTGkNyUsxR7r5NOvLsKWBARF1U7nqxExNcjYkRE1JK8V/dFRCYZfrVFxN+ARZJ2Sh86CCjEBHDrkl7bJlW63ZFUI2lIentLkknXT2dRd6XbFkkD0knWpMNFnyIZMslETu3H0WQ8JJV6EfiopK3Sv6GDSOZrZULSB9L/R5LMt7k+q7rbU/XLL7S3FHuVw8rCOOB44Ml0fBrgGxExs4oxWee+BFyXfqk9B3y+yvFYzirdJkm6ATgAGCapCfhORFyVUfWVbne2BX6RnrGzGXBjRPSW5SC2AW5NvrvpC1wfEXdlvI+KtR9pQnYwcFJWdbaIiNmSbgbmAquBx8j2Ugm3SBoKrAJOzeNEjaqfCm5mZmaWpY1hWMrMzMwsM05uzMzMrFCc3JiZmVmhOLkxMzOzQnFyY2ZmZoXi5MbMzCpG0pr0Stbz06uJf0XSZum2Okk/KaOOh9L/ayUd08X9T5d0RPeit96q6uvcmJlZob2dXq6hZTG364HBJOv71AP1nVUQES2r5dYCx5DDInDWu7nnxszMcpFe9mAKcJoSB0i6E9atfnxv2sNzpaQXJA1Lt7VcifwCkoswNkj699b1S/qapCfTHqIL2th+jqRHJc2TNC1djRdJp0t6StITkmakj/1zup+G9EKYgyrzqlgluOfGzMxyExHPpSscf6DVpu+QXHLhB5LGA19o4+lnA/8REYe13iBpAsnFH/eNiLckvb+N5/8sIs5Ly/8SOAz4bVrvqIh4t+XyEsB/kKym+2B6IdJ3un60Vi3uuTEzs43BfiQXzCS9LMKyLj7/k8A1EfFWWsdrbZQ5UNJsSU8CnwB2TR9/guSyCceRXH4A4EHgIkmnA0MiYvWG1dnGysmNmZnlRtI/AGuAxTnvtz9wKXBEROwOXAH0TzcfCkwluYr3o5L6RsQFwGRgS+BBSTvnGa/1jJMbMzPLhaQa4DKS4aHWFzZ8EPhcWu5TwPvaqGIF0N7cl3uBz0vaKq2j9bBUSyKzJB1mOiIttxmwfUTMAr4GbA0MlPShiHgyIn5IcqV4Jze9iOfcmJlZJW2ZXqG8H8mQzy+Bi9oo913gBknHAw8DfyNJZko9AayR9DgwPSJ+3LIhIu6SNAaol/QeMBP4Rsn25ZKuAOaldT+abuoD/ErS1oCAn6RlvyfpQGAtMB/4fY9eBcuVrwpuZmZVJ2kLYE1ErJb0MeDnLaeQm3WVe27MzGxjMBK4MR0meg84scrxWC/mnhszMzMrFE8oNjMzs0JxcmNmZmaF4uTGzMzMCsXJjZmZmRWKkxszMzMrlP8FD8tfCJUrpwgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.plot_validation_prediction(10)\n",
    "mlp.plot_validation_prediction(11)\n",
    "mlp.plot_validation_prediction(12)\n",
    "mlp.plot_validation_prediction(13)\n",
    "mlp.plot_validation_prediction(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAH6CAYAAACtTEJqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3hUVfrA8e/JTDokoSYQOpGqUhUQUERBXSkC0tQV3BULuMqurqIigm0ta/dnQ1csIIiAwIJ9RUWRooBSVKr00BNK6sz5/XHuDDOTmWQmmTBJeD/Pk2cyd+6959w7t7z3zHvPVVprhBBCCCGEEKdfVKQrIIQQQgghxJlKgnEhhBBCCCEiRIJxIYQQQgghIkSCcSGEEEIIISJEgnEhhBBCCCEiRIJxIYQQQgghIkSCcXHGUUotUUpJn55loJQarZTSSqnR5VxOL6ucyeVZTrgopZpY9Z12GsqabJXVq7zLqsjCtR4q27ZWkSmltiultke6HiIyAu2T1rAlkalVURUpFqiUwbhSqpVS6kWl1DqlVJZSKl8ptUcptUgp9VelVGyk61iZyElIRMrpDF5F+ZPvU4iKF3SeqZRS06zvokmk61ISe6QrECql1CTgQcyFxDLgbeA4kAr0At4AbgU6R6iKQojwWQG0Bg5GuiIV0EvATGBHpCsSYeFaD7KtCVG+WgMnI10JD9cDCZGuBFSyYFwpdR8wBdgJDNVaL/czTj/gztNdNyFE+GmtTwK/RroeFZHW+iASOIZtPci2JkT50lpXqP1La11xGjK01pXiD2gC5Ft/Z5cwbqzPdBqYBrQAZgH7ASfQy2O8s4B3gN1WGXus92f5mX914AFgHZANHAO2WPPu5DPuAOBLYC+QZ833a2BsiMs/EvgKOArkAhuBiZ7L6jGuBpYAtYHXPcpeD9zgM+40a3x/f72scUZb70cDl1vzzjKbj9e8LgE+AQ5b5f0OPA4k+6njEmuescAjwDZrmi2YXz5iPMatgbma3gKoAOtnoTW/zkGsyyW+dbeGRwG3ACsxv7acsP6/FYjyM35Pq9xdVt33AT8AD/qMlwr8G/jNmudR6/9pQLMQtoEGmFbArVZ5h4AFwHk+471qrYuBAebTxfr8Q5/h9YD/A7Zj9oEDwFx8tmnfbcLfthegXNe21sR6P7mYbW+0NU4v6/1kP/MLZZ91ldULuBrTCnrS2lZnAukh7o/VgWes7z4XE8T9A2hmlTMtmG2uhHW53fpLssraDhS41oXnMpV2//eYJtaan2vb2obZL2OL+04DrOOgvk/gfGCR9R14bhcXW/XegDm+5mCOtQ8CccV9t2VZD4G2NU4dq+zAfcAmaz47gSfwOFb5THct8JNV//3Au0D94raFELdB93ITwjZNCPtNCeUr4DZrfeZa83sJSMbadgNt50TgPFKGMoosS6Btz2MZ/f0VOYaFcXlaYY6vO63vNBOYAbT0M+40q4wmwM3AL9b3l4nZT/ytg7Duk372ueL+enmMfxXwnvV9nbD+fgRux+ccXcz8tvuubz/1DzUWCPmY6/tXmVrGbwCigZla63XFjai1zvMzuDmwHPMlTgfiMRsVSqnzgC8wJ9gFmA2uFXAdMFApdanWeqU1rsLsxBdg0mTeAAoxgdLFwLeYjQOl1E3Aa5ggbSGm9aYucK61PC8Hs+BKqf9Y4+8C5mCCua7Aw8AlSqk+WutCn8lSgO8wO+aHmJ17KPAfpZRTa/22Nd5H1usozEXCEo95bPeZ59WYg+jHmICvsUcdbwZewWy0szEnn17APUB/pVR3rfVRP4v3AXCeVccCYCBmR+6slBqgjSNKqZnWOrgU+Nxn/TQErgB+1Fqv8lNGsN4FrsEc0N7A7GCDMN9TD8zJ1VXm5ZhAIhuzzewGamJ+hhuL+QUHpVQC5ntobtV7IeYk1tha1g8xAVCxlFIdgc+sMj7FBMm1MQenpUqpQVrrxdbob2MOstcD8/3MbpT1Os1j/k2BpZhg4X/A+0BDzDZzpVJqiNb6vyXVM0RLMNvpHcBaTm2LAGuKmzCUfdbHWMwF8gLM9t4FGA60U0q1D3Ds8C07FnOBfZ5V7+nWcjwAXFTS9CGKwXwfNTHffzbmBF2SYPd/1zFtDnAlJtB8CXOsHQ20DaGuSwj+++wG3IvZ5v6D2Zbzrc/uwXyX32P2sTigO+a40Mv6bh1B1ino9RCEGZgL8I8x38OfgLsxx/QbPEdUSt2NCdSPYPbHLKCPVZesEMoMRtDbdBn2G3+ewwRBezEBiOv43QWz3eYHmC4i55EwlBGMNZhj/4PAH3gcY/E+t5YklOW5HHM+iMacXzZj4pHBmGP3xVrrn/yU8SRwmTXNZ5j4ZQyQAfT2GTec+6Sn7VjnSh/RmMaNOLzTWh7HNKQux5xzk626Po9ZX3/2GHcK5vzYzvrc9Z0G890GHQt4KNuxJpQr4Uj+YU5+GrgxxOmacOqK6DE/nytMK7MGrvX5bLg1/FesqyHgHGvYvABXUzU83v+IuTqq62fc2kHWf7RV3lwg3uezydZnd/i5StPWRmTzGN4Gc+GwwWf8XhRz5e5RBydwuZ/PG1vLmQ208vnsZWva132GL7GG/+6zzuIwFzka+LPH8M74ac31WQ9jglynSyjaGjPSmsdPQDWP4YnAKuuzazyGz7GGtSvuuwX6W+M962e8GKB6EPW1Yw6wucBFPp/VxxyU9uL9i9Bv1ndS02f8WExrUCZg9xj+qVXP+33Gv8DaZg75rBfXNjHaz7a3JMByTMOjBdRn/5wWYJoi2yYh7rM+20g2cI7PNDOsz4YFuf3cZ40/x6eMppxq5Z3mM02RbS6IdbndGv4FkFjMdt/Lz3cQyv7/Z2v8b/D+RSrFWo8Bv1M/dQr2+9TAzQHGaYafX8AwjQ8aGF5O66HItub53WGO5zU9hidi9ksHkOZT/wLML0sNfbbb9131CmZ9lrCuQ9qmKcV+U0zZF1jjb/ZZJ57H7+0BtvNInkdKU8Z232UJctsLap8p4/LUwFzwHQTa+MzrbEyr7k8+w6dZ89kBNPIYbsccAzRwfjnukyWuF486PuszvLmfcaMwF7wa6BJgPk2KW98+w0KKBTyWK+hjjb+/ytSbSj3rdVcpp8/E/xXYBZgrvmVa6+meH2itZ2FablpiroY85fjOSGvt1Fof8RlciDkw+44bbI7jHdY8/qK19i3zYUyQ5O8q7STwD+1xtaq13oC5cmutlKoWZPme5mutP/Ez/DpMYPmSLpoTdj8mjefPAXq5edhznWmtczEtZgB/8Ri+CrMjDFRKpbmGK6VswF+tMt4PfZHcXGVN0Fof9yj3BKZVAOBGP9P52w78fbf+xsvXWh8Lom5XYlrWX9Raf+0zjz2YFo40zE+vLm9jvpORPvPqjzmAT9fWrylKqQZAX8zB+Umf+X+PWa81MS0tFUFp91mAF7TWv/gMm2q9nh9k+TdgAoq7tdZOj7K3AS8EOY9Q3Glth6EIZf8fZb1O1Frne4x/FHOMKQ9rtNav+ftAa71VW2cyH89ar5eFUE44j4P3aK0Pe8znBOZXkSi8Owy4BhPYvKi13ukxvgYmYIL3cAp2my7LfuPL9UvAoz7rxPP4HUjEziNlLON0CnZ5rsdcND9obdd4TLMOsx10UEq18VPGQ9ojZ9o6H7xlvfU6FoZ5nyyW1UnHKMyvul73/2mtt/iObx2Dnw9jPUobC5TpWFOZgvGyWqv9/wTd0Xr9X4DpXMM7WK8bMD9FjVRKfaeUulspdYFSKsbPtNMxd+puUEo9q5S6SilVJ9gKWykO7TBXvuOtvjvdf5ifxfMwqRG+Nmmts/0Md50cagRbDw8rAgwPuA6tA8pqzJV9Kz/Tfu1n2FLMCauDz/CXMSc5z4PRnzA/yb3nueOUQkdMgLUkQB196+M6mS1XSr2qlBpuBbX+pt0NTFBKfaKUul0p1cm6iAhWN+u1se82YG0HrgOn53bwjrU8o/Dmej/NY5hrub7VWhe5cKToPhBpoe6znvylMQW9TyilqmN+xt3t78RAaD9FByMX+LkU04Wy/3fAbCvf+xl/aSnKDkagYwlKqUSl1H1KqZVW17VOqy/gQ9Yo6SGUE87jYLDbjmu7K7LutNZ/eEwTLsHWqyz7jS/XvIo7fgcSyfNIWco4nYJdHte5oV2Ac0ML63N/MULQx8Iw75MBKaWuxTSarsK0Pjt9Pq+llHpcKfWzUuq41W2h61ercNUj1FjApUzHmsqUM74Xs0GVdmXvCzA82WP+gcoFc/WJ1tqhlOoNTMLkvj1hfX5MKfU2cK8rKNRaP6OUOojJ6bsdGA9opdTXwD91yfnNNTA/LdbB5KCFIlBelCu3PJRg0CUs69BHpu8ArXWhtd7q+nw0E3gaGKOUetzaUW+yPvPbyhaCZOCwZ8tgcfXRWs/16LnnL5gcbZRSP2K2gc+t8bKVUl0xB5gBnLpyP6iUehl4JEAA7KmW9Tq0hPHcV95a611KqS+BPkqp1lrrjUqpuphczTVaa88AryzfXySUpb7+9otQ9glX2UW2W0ugfaS09gdokSpJKPu/a9v3ve8EAi9nWfldT0qpaEygdD7mBrFZmHQP1z7yICbVKlhhOw5q/3nEgdYnBF53mZh0nnAJtV7h2M8DLqPH8TKQSJ5HKsuxLtjlcZ0bxpQwP3+tskFtN+WwT/qllLoIc//IH0A/bXo38vw8BXMTZVPMBd07mLTAQk7dqxKOXzRCigU8lOlYU5laxl2tDJcUO1ZggU5orptp0gJ8Xs9nPLTWR7TWf9daN8TcmX4jJtfuNsyNIXiM+47Wuitmp7kSeBO4EPg0iFZyV5mrtdaquL8S5hMuYVuHHlJ9Byil7JgburyuMq00nWmYE1lfjxs3l2ut1xZX8SBkATWtA0+w9Vmkte6NuWi6BPOTXVvgv54/C2qtd2mt/4rZgc/GXJgdwlzQTQqybmB6RyluO/BNw3LdMOJqDb8WcwHueyNJWb4/X5rAF/nhOsGFs76lLbvIdmsJVCcnuLclX8Wtl9IE4qHKxmz7/uoWaDnLKtByDcSc9Kdprc/RWt+ktb5faz2Zsl9wny6u40SgdVde67Qk4dxvAu4HHsfLQCJ5HilNGU7K/5jmK9TlaVfCuSGUG5V9lfs+qZRqBczDpHP+SWvt70L2RkwgPkVr3UVrPVZrPdGqx6xw1MMSciwQDpUpGH8LcyU2JED+k1uI+V6rrddeAT6/2Hr1dzcyWuvNWus3Mb0oHMdsuP7GO6q1Xqy1HoMJKGtigvKArBb29UBbpVTN4sYtI9dPiqVpLYdi1qF1NdueU90x+rrIz7AeVl1W+/nsFaybvzC54jbCc0BYjdkf/H0nF1rlBNoGTmit/6e1/gfwGCYn8Qo/42mt9Xqt9YuYnhXA3O1dkh+s155BjOtpLuagcZ1SKgoTlBdibu7y5FrPPQIEZMXuAz6OYHph8WKl5bT3M35ptr0y7bNloU2O/2YgXSnV3M8ogerkyv8ssm6I/APKXNv+BX4+CyZ/2FNZjyUZ1utcP5/5O1ZURO79yfcDpVRj/G8Dp0M49xvXOMUdv0N1Os4jpSnjCJDqLzgj8L7rpPT7AAS/PKU9N4SiXPdJq1FyEab1fohv7rufeswJoR6lPb+UKhYoi0oTjGutt2Pu0I0BFiml/O4EVjc/H4cw6+8wPU/0UEpd7TOvqzEb+e9YLfNKqaZKqWZ+5lMD8xNJjsf0Fyul/LVau37iCOZJVM9glvk/1sHCi1KqhjLd3pWFK++rUSmnfw9zofQ3pVSGz2cPY/pJfi9Azv4DSil3LpVSKg74l/X2Ld+RtdabMD3r9MP0A3oUk75SVv+xXv9l5eq76pOA6U4JzK8aruEXltCSeNIar61Syl9LmNd4JZiP6Wd2nFLqT/5GUEp186w3uH9J+ACT2vV3zP0Hi7XW+33G24XpdrEJJpXKc75dMDekHcG0XJRkBdBIKdXXZ/hEPLow83AEc3EVyrYX0j5bDt7CHDufsC5yXGU3xfzq4Y8rT9br52Sl1CUUvcn2dHvHen3E894XpVQy5r6UUJTm+/S03Xrt5TnQOuY+4TtyBTUDc9H7N+vXO8DdheS/CBAYKKWWWDmwvcqpXuHcb6ZZr/d7NhT5HL9DdTrOI6UpYwWmZdy3+8rRmO79/DlE2S66gl2etzDnwAeVUkVuQFdKRYVhe9puvXrNJxz7pLVcCzC9tdystf6yFPXoQOCbhksT24QUC4RLZcoZR2v9mBUAPQisVEp9j0n0P44Jbi7EpI0E3de01lorpUZhgpFZSqn5mJSTlphWy2PA9R43ErQD5iqlVmKunvdgcroHYvrG9Nw45wHHlVI/YDYkhTngnYe54eCLIOr3H6VUJ0ze+Ral1KeYXi9qYn6yuRCzQ94S7DL78RvmJsMRSqkCTM6WBt61bjgqqY7blVLjMQ+M+Ukp9QEmp+wizA0mv3LqLmRfG4H1SinP/lSbY66U3w0wzcuY/sZTMT0WFOmpJFRa6xlKqYHAMKs+H2HWwVWY9TxLe/dA8AKmdfQ7Tj0kpxOmz9M/OHWB0Ad4Sim1DHOi24+54XQgpvXkqSDqVqCUGozpfnCRtd2vwQTyDTHbUzPMT6y+wf3bmJ/3/uXx3p9bMCfrp6xAehWn+hl3Yh5cEEzPL//G5MXPV0rNwuT0XYBZh0vwOZBqrY8rpZYDPZVS0zHryAEs8Mlr95wm1H023J62yhmC2d4/xfxcPQzTNdgAP9O8BfwTuFcp1Q5zI3gLzC8o86x5Rco7wAjM/QTrlFILMMeyIZgczZZYaTYlKc336cPVT/I/lFLnYFqpGmEuvhdR+iD/tNFab1GmR4jHgLXWfuDqZ7wmpg/2c/1M6rqw85e7H456hW2/0Vp/p5R6EfgbZpvxPH4fIXBOdnHzLPfzSCnLeBETiL9iXTzvxLSgdwP+i9k2fX2JOZ8uxLSiFgDfaK2/CXJ1BLs8h6wLqXnAD8rcJ7Qec+5qaNWxFuam1NIqz33ydswzU7ZidVDgZ5xpVmPsO5hj6HNKqYsxz0Q4y6rHXEz3nL6+tKaZqpSag9nGj2qtXwpUoVLEAuGhQ+wHsyL8YW7kfJFTT8DMx+z8H2NSF/w+gbOEebbEbOR7MRv/XsxVdEuf8RpgDrLfYW5EycN0t/gxcIXPuLdgdpKtnHoy2mrMgyJK7F/aZ179MDv+fmt592Gu2B+haH+pAfvyJEC/m5iA7kvMScOJRx+hBOgH2c+8+2IeHnDEWi+bMV3lpfgZd4k1T98njW3FuiGkmHJsmAOoBtqWYvtZgp9+fjEnw7GYQPSk9fcjMI6iT/cahunybxPmYjDb2h4fBer4bKvPWPM8YC3jdsxDAS4Isd51MVfm66y6HbfK/xDTZZc9wHSbrHV1iABPcLPGS8ekAf1hbWMHMQ9uOc/PuAG3CUwwugrzc+8hzIVJ42K2vQzMAf+Qx7Y32vqsl/V+cmn3WWvcyZ7btM9nTQjiGOEzjeupmLs59QTOOwnwBE5rmrbAYswJ4bi1HV4UaF1STP/GxS0Tpdv/44CHOLUfbre25XRr/I9CWDel+j49pm+I6a1oN+aXxvWYY6bd37KFaz0Eqhul6CPe+uzPmON9Lmbffw/zXIB1mIDAc1xlra9tBNiPw7VNE8J+U0L5ridwbuTU06X/jyCewFnCfMv9PBJKGdb4PTAX2icxx/pFmAuqQNteXcwvJJmYi9Fit/kwLE8TzMO6NlnbWzbmmPQucFUwx4AS9oFy2Sc9xivur5fH+G0wLen7OfX0zRspfnv/B6e2UU3wT+AMKhYozbHG35+yRhbitFJKLcE8wCbkm0+tn8c2A99prcszV06IM5pSqg8maHlca11S/9GiBEqpJEyAtkZr3c1j+LmYFvNxWuugnswsynYeqYiq2vKI4FWanHEhPNyFaZUJ+FOTECJ4Sqn6fobV4lSOZDD3CwiLUqqO7w1/Vorl05hfIXzX50WYIP0/CCHOOJUqZ1ycuZRSjTA3Ep6Fyd9bC8yOaKWEqDqesXLZv8ekVDTA5LPXBF7TWgd8SI/wawjwkFLqC0yOsav3rBaY+z1e9BxZmx6WXvSdiRDizCDBuKgsmmFuQjyJuQHpVl1+N+gJcaaZi7khuj/mZtRcTF7om5RDzwFngOWYXkku5NSDWbZh8vCf0GG46VwIUXVIzrgQQgghhBARIjnjQgghhBBCREiVS1OpXbu2btKkSaSrIYQQQgghqrgff/zxoNa6TlnmUeWC8SZNmrBqVdDP/BFCCCGEEKJUlFIlPhyxJJKmIoQQQgghRIRIMC6EEEIIIUSESDAuhBBCCCFEhEgwLoQQQgghRIRUmWBcKdVfKfV6VlZWpKsihBBCCCFEUKpMbypa64XAws6dO4+JdF2EEEIIX9nZ2ezfv5+CgoJIV0UIUYLo6Gjq1q1LUlJSuZdVZYJxIYQQoqLKzs4mMzOT9PR04uPjUUpFukpCiAC01uTk5LB7926Acg/Iq0yaihBCCFFR7d+/n/T0dBISEiQQF6KCU0qRkJBAeno6+/fvL/fyJBgXQgghyllBQQHx8fGRroYQIgTx8fGnJa1MgnEhhBDiNJAWcSEql9O1z0owLoQQQgghRIRIMC6EEEIIIUSESDAuhBBCiGIppUr8W7JkSZnLSUtLY+LEiSFNk5ubi1KKN954o8zlB6tr165cd911p628iuDVV19FKUVhYWFI082YMYP33nuvyPAzcR0GIl0bCiGEEKJYy5Ytc/+fk5ND7969mThxIldeeaV7eJs2bcpczuLFi6lbt25I08TGxrJs2TKaN29e5vJF+M2YMYPCwsIigfebb75JXFxchGpVsUgwLoQQQohide3a1f3/8ePHAWjevLnX8EByc3ODDro6duwYct2UUkHVQ1Qsbdu2jXQVKgxJUxFCCCFEWLhSGX766Sd69uxJfHw8L774Ilpr7rzzTs4++2wSExNp2LAho0aN4sCBA17T+6apjBgxgh49erB48WLatm1LtWrVuOiii/jtt9/c4/hLU3GlQLz99ts0a9aMpKQk+vfvz759+7zK27p1K3369CE+Pp7mzZszY8YM+vXrx+WXXx7ysn/22Wecd955xMXFkZaWxu23305OTo5XPcePH0/Dhg2JjY0lPT2dIUOG4HQ6ATh06BCjR4+mXr16xMXF0bhxY8aNG1diuR9++CEdO3YkLi6O+vXrc//99+NwOAD45JNPUEqxZcsWr2n279+P3W73Sh+ZPn06bdu2JTY2lkaNGjF58mT3fPxxzXvz5s1ewz3TT0aMGMGiRYv49NNP3elMjz/+eJHxgl2HrjK/++47Bg0aRGJiIs2bNz+tKUrlQYLxcuB0arTWka6GEEIIERHDhw9nyJAhLF68mL59++J0Ojl8+DATJ05k8eLFPP3002zYsIE+ffqUeL7cvHkzEydOZPLkybz33nvs3LmTa665psQ6fPPNN7z55ps899xzvPzyyyxbtoyxY8e6P3c6nfTr149t27Yxbdo0nnzySR5//HHWrFkT8vKuXr2aK6+8kvT0dObOncsDDzzAW2+9xciRI93jPPTQQ8yZM4fHHnuMzz//nGeeeYaEhAT38v/tb39j1apVvPDCC3z66ac88sgjJa6bd955h+HDh9OzZ08WLFjAvffeywsvvMCDDz4IwKWXXkqtWrX44IMPvKb78MMPiYmJYeDAgQAsXLiQ6667jm7durFgwQJuueUWHn30Ue68886Q14WnRx55hO7du9O1a1eWLVvGsmXLuP766/2OG8w6dPnLX/5Cly5d+Oijj+jWrRtjxoxh7dq1ZaprJFWZNBWlVH+gf0ZGRkTrobWmxxP/45LWqTx81dkRrYsQQoiKa8rC9WzYkx2RstvUT+LB/uWXJnDXXXdx8803ew1766233P87HA46depERkYGK1eu5Pzzzw84r8OHD7N8+XIaN24MmBbmkSNHsn37dpo0aRJwuhMnTrBo0SKqV68OwK5du5g4cSKFhYXY7XbmzZvHxo0bWbt2Leeeey5g0mQyMjI4++zQzt9TpkyhRYsWzJ07l6go085ZvXp1Ro0axerVq+nQoQMrVqzg+uuv589//rN7uuHDh7v/X7FiBffccw9Dhw51D/Mc15fD4eCee+7hpptu4vnnnwegb9++2Gw27r77bu6++26SkpIYMmQIs2bN4t5773VPO2vWLP70pz+5180DDzzA5Zdf7m5hvuyyyygsLOThhx/mvvvuCzmP3yUjI4OUlBQKCwtLTCUKZh26jBo1igkTJgDQs2dP/vvf/zJv3jzatWtXqnpGWpVpGddaL9Ra35ScnBzReuw/lseerFze/eEPsnLK/6lNQgghREXjeWOny4IFC+jatSvJycnY7XZcjWe///57sfNq0aKFOxCHUzeK7tq1q9jpunXr5g42XdM5HA53qsrKlStp0qSJOxAHaNq0Keecc04JS1fUihUrGDJkiDuIBBg2bBhKKZYuXQpA+/btmTp1Kk8//TTr1q0rMo/27dvzr3/9i1dffbVI6oc/69atY9++fQwdOpTCwkL3X+/evTlx4gQbN24ETMC/du1ad2rPnj17WLp0qftCIC8vj59//tnrIsA1XWFhIcuXLw95fZRGMOvQpW/fvu7/4+LiaNasWYnbQ0VWZVrGK4rf9h1z/7/94AnaNUyJYG2EEEJUVOXZMh1pqampXu9dOb4jRozg/vvvp06dOhQUFHDhhReSm5tb7LxSUrzPozExMQBlnm7fvn3UqVOnyHT+hhVHa01mZmaRZY6LiyMpKYnDhw8D8PDDDxMTE8Pzzz/PXXfdRcOGDbn33nu59dZbAXj99deZOHEikyZN4tZbb6Vly5Y89thjDB482G+5Bw8eBOCSSy7x+/nOnTvp0qULvXr1Ii0tjVmzZjFp0iRmz55NQkIC/fr1c68HrXWR+rveu+pfnoJdhy7+vtuStoeKrMq0jFcUv2eeCsb3ZuUUM6YQQghRNfk+RnzOnDk0atSI6dOn079/f7p27Vrq1IdwSUtLK3IDKeB3WHGUUqSmprJ//36v4bm5uWRnZ1OzZk0A4uPjeeyxx9ixYwe//vorAwcOZOzYse7+2WvWrMnLL79MZmYmq1evpl27dm5u01YAACAASURBVAwbNixgK7lrvm+//TYrV64s8ucK0qOiorj66quZNWsWYFJU+vfvT3x8vHs9KKWK1D8zM9OrHF+uHnLy8/O9hh85cqTkleYj2HVYVUkwHmZ7s05dme0+Wnmv0oQQQohwycnJcbdMu0yfPj1CtTHOO+88tm/fzs8//+wetm3bNn755ZeQ59WlSxfmzJnjdcPl7NmzzX1kPXoUGb9ly5Y8++yzREVFsWHDBq/PlFK0b9+exx9/HIfDETCN55xzzqFOnTr88ccfdO7cuchfjRo13OOOGDGCDRs2sGjRIn744QdGjBjh/iw2NpZ27doxe/Zsr/l/8MEHREdH06VLF7/lN2jQAMCdDgOwZcuWIj23BNtqHeo6rEokTSXMsnIKqJccx5GT+ew5Ki3jQgghRJ8+fXj11Vf55z//yeWXX84333zDzJkzI1qnQYMG0apVKwYPHsxjjz2G3W5n8uTJpKWleeUtB2PSpEmcd955DBkyhDFjxrBt2zYmTJjAwIED3TceXnnllXTv3p327dsTGxvLzJkzsdls9OzZEzDB6IgRI2jbti1aa1555RWSkpLo1KmT3zLtdjtPPfUUY8aM4fDhw/Tt2xe73c6WLVuYN28eixcvxmazAXDBBRfQsGFDxowZQ1JSUpGuG6dMmcLAgQO56aabuPrqq/npp594+OGHGTt2bMBfMDIyMjjnnHO49957sdvt5Ofn89hjj1GrVi2v8Vq1asVLL73EggULqF+/Pg0aNCAtLa1U67CqkpbxMMvKKSA5Ppr6yfGSpiKEEEIAgwcP5uGHH2b69OkMGDCA5cuX89FHH0W0TlFRUSxatIgmTZpw/fXX849//IO///3vNG/enKSkpJDm1aFDBxYtWsSOHTu46qqrmDJlCqNHj2bGjBnucbp3786HH37IiBEjGDRoEOvWreOjjz5y3zDarVs33nzzTQYPHsyIESM4duwYn376aZE8ak+jRo1izpw5LF++nCFDhjBkyBBef/11unbt6nVBoZRi2LBh7N27l0GDBhX5lWLAgAG8++67LF26lH79+vF///d/3HfffTz99NPFLvesWbNITU3lmmuu4cEHH+TRRx+ladOmXuPccccd9OrVi1GjRnHeeecxbdq0Uq/DqkpVtf6wO3furFetWhWx8oe9Zh4ZrLXGHhXF+zfJU8GEEOJMt3HjRlq3bh3paogSHDp0iGbNmjFhwgSvrgDFmaukfVcp9aPWunNZypA0lTDLzimgYc0EtIbdkqYihBBCVFgvvfQScXFxZGRkkJmZyVNPPQWYFmchThcJxsMs20pTAdiwJyvCtRFCCCFEIDExMTz11FPs2LEDm81Gly5d+PLLL6lfv36kqybOIBKMh5krZ1wBR+WhP0IIIUSFddNNN3HTTTdFuhriDCfBeBgVOJycyHeQHB9NlIKT+Q7yCh3E2m2RrpoQQgghhKiApDeVMDqWWwhAUpyd5ARzp3KWtI4LIYQQQogAJBgPo5P5JhhPiLWTYuWNZ52UYFwIIYQQQvgnwXgY5RY4AIiLtrlv4pS8cSGEEEIIEYgE42GUW+AEID7aRvU4k45/3EpdEUIIIYQQwleVCcaVUv2VUq9nZUWuO8Ecd8t4FNVirWA8T4JxIYQQQgjhX5UJxrXWC7XWNyUnJ0esDq40lfhoGwlWMO7KIxdCCCEqq/79+7sf2+7PbbfdRkpKCnl5eUHNb/PmzSil+OSTT9zDGjRowIQJE4qdbs2aNSilWLp0aXAVt7z66qssWLCgyPBgygyXwsJClFK8+uqrp6W8iuK6666ja9fQn0b++OOP880333gNq6rrsMoE4xVBTv6pnPFqMa6WcUckqySEEEKU2ciRI1m3bh0bNmwo8pnD4eDDDz9k8ODBxMbGlrqMhQsXMm7cuLJUM6BAwXh5linKxl8wbrfbWbZsGYMHD45QrcqHBONhlFtocsbjom0kxpq+xU9ImooQQohKbuDAgSQkJPD+++8X+eyrr74iMzOTkSNHlqmMDh060LBhwzLNozKUKcqma9eu1K1bN9LVCCsJxsMoN/9UzrjdFkWsPUqCcSGEEJVeYmIi/fv3Z9asWUU+mzlzJnXr1qV3794A7N69mxtuuIGmTZsSHx9PixYtePDBBykoKL53MX8pIy+++CINGzYkMTGRgQMHsm/fviLTPfXUU3Tu3JmkpCRSU1MZOHAgW7ZscX/eo0cP1q5dy5tvvolSCqUU7733XsAyZ86cydlnn01sbCyNGjVi0qRJOBynfuV+4403UEqxfv16Lr30UhITE2ndujXz588vYS3698ILL5CRkUFsbCxnnXUWL7zwgtfnO3bs4Oqrr6ZOnTrEx8eTkZHB5MmT3Z//8ssvXHbZZdSoUYNq1arRpk2bEtM4HA4Hjz76KM2bNyc2NpaWLVvy7rvvuj+fOHEi6enpaK29pps/fz5KKbZv3+6ezwMPPEDDhg2JjY3l7LPPZubMmcWWPXHiRNLS0ryG+aafNGjQgKysLB544AH3d7Z06dKAaSolrUNXmatWraJLly4kJCTQsWNHvv/++2LrerpIMB5GuYWncsYBqsXa5QZOIYQQVcLIkSPZtGkTP/74o3tYQUEBc+fOZdiwYdhs5tx34MABateuzXPPPccnn3zCnXfeydSpUxk/fnxI5c2ZM4fbb7+dgQMHMnfuXFq3bs2YMWOKjLdr1y5uv/12FixYwOuvv05eXh7du3fn2LFjALz++uucddZZDBgwgGXLlrFs2TIuv/xyv2UuXryYkSNHcv755zN//nzGjh3L448/zh133OF3fVx11VXMmzePpk2bMnz4cPbu3RvSMr7yyiuMHz+eQYMGsXDhQgYPHsz48eP597//7R7nuuuuY+/evbzxxhssXryYe++9l9zcXAC01vTr14/Y2FhmzJjB/PnzGTduHNnZ2cWW61quW2+9lUWLFjFgwABGjRrlzuEfPnw4e/bsKZKbP2vWLLp06UKTJk0AuO+++3jiiSe49dZbWbBgAV26dGHkyJHMnj07pPXga+HChVSrVo2bb77Z/Z21a9fO77jBrEOA48ePc8MNN3DrrbcyZ84c7HY7gwYNcq/LiNJaV6m/Tp066Uh5dclm3fie/+rjuQVaa617PPGlvuP9nyJWHyGEEBXDhg0bIl2FMsvLy9MpKSn6rrvucg9buHChBvR3330XcLqCggL99ttv6/j4eF1QYM6PmzZt0oD++OOP3eOlp6fre+65x/2+Q4cOul+/fl7zGj16tAb0t99+67eswsJCfeLECZ2QkKCnT5/uHt6uXTv917/+tcj4vmV26tRJX3rppV7jPProo9pms+k9e/ZorbWeOnWqBvTbb7/tHiczM1MrpfTUqVOLXQ+AfuWVV9zvU1NT9Y033ug13pgxY3RKSorOy8vTWmsdGxurFy9e7Heee/fu1UBI29evv/6qAf3ee+95DR85cqTu2rWr+32bNm30uHHj3O9Pnjypq1Wrpp999lmttdYHDhzQcXFx+pFHHvGaT58+fXSbNm3c76+99lrdpUsX9/v7779fp6amek3ju2601jo5OVk//PDDxY4X7Dq8//77NaC//vpr9zgrV67UgP78888DrSqtdcn7LrBKlzF2tUfmEqBqyvF46A9AYoxdbuAUQgjh38cTYN8vkSk77Ry44vGQJomJiWHw4MF88MEHPPnkkyilmDVrFo0bN6Zbt27u8ZxOJ88++yxvvPEG27dv92p53LVrl7tVtTj5+fmsXbuWsWPHeg0fPHgw06ZN8xr2/fffM2nSJFavXs3hw4fdw3///feQlq+goIA1a9bw8ssvew0fPnw4999/Pz/88AODBg1yD+/bt6/7/7p161K7dm127doVdHk7duwgMzOToUOHFilv6tSprF+/ng4dOtC+fXvuuece9u/fT+/evb1y3OvUqUN6ejo333wzt912G7169Soxn/qLL74gOjqagQMHUlh46tf7Sy65hHHjxuF0OomKimL48OG8/PLLPP/889hsNhYtWsTJkyfd9f3555/Jzc31W/8bb7yRw4cPU7NmzaDXR2kEuw4B4uLi6Nmzp3ucNm3aAIT0nZUXSVMJo9wCJzG2KGxRCjBpKtK1oRBCiKpi5MiR7Nixg2XLlpGbm8v8+fMZMWIESin3OE8//TT33HMPQ4cOZcGCBaxYscKdwxtsSsD+/ftxOp1FAkvf99u2beOyyy7DZrPx+uuv891337Fy5Upq1qwZcvrB/v37cTgcpKameg13vfcM9AFSUlK83sfExIRUpiulpaTyPvzwQ9q3b88dd9xBo0aN6NixI1999RUANpuNzz77jNq1a3PDDTdQr149LrzwQtauXRuw3IMHD1JQUED16tWJjo52/914443k5eWxf/9+AEaMGEFmZiZff/01YFJUevToQXp6elD1P3LkSNDrorSCXYcAycnJXttpTEwMEPw2WZ6kZTyMcgscxEWfur5JjLVz9GR+BGskhBCiwgqxZboiuPjii0lNTWXmzJns3buXY8eOFelFZfbs2YwYMYKHHnrIPeznn38OqZy6desSFRXlDgxdfN9//PHH5OXl8dFHHxEfHw+YVvWjR4+GVJ6rTJvNVqSMzMxMgLC38tarVw8ouky+5TVo0IB33nkHh8PBihUrmDRpEgMGDGDnzp2kpKTQpk0b5s6dS35+Pt9++y133303/fr1Y+fOnX7LrVmzJjExMSxdutQrOHWpVasWAC1atKB9+/bMmjWL888/n0WLFnnlYXvW3/MZL67616hRw2/5cXFx5Od7x0alDdyDXYcVnbSMh5EJxm3u93IDpxBCiKrEZrMxbNgwZs+ezYwZM2jdunWRG+tycnKK9Dc+ffr0kMqJiYnh3HPPLdJDydy5c4uUZbPZsNtPtS3OnDkTp9NZZH4ltYBGR0fToUOHIjcffvDBB9hstlI9uKY4jRs3JjU11W95NWrUoG3btl7DbTYb3bp1Y9KkSRw/fpwdO3Z4fR4TE8Mll1zC+PHj2bVrV8CbOHv37k1+fj7Hjx+nc+fORf6io6Pd444YMYK5c+cyb9488vPzufrqq92fnXvuucTFxfmtf5s2bQIGwg0aNODIkSPugBngs88+KzJeMN9ZqOuwopKW8TDK8QnGE2JsnJCccSGEEFXIyJEjefHFF5k3bx5Tpkwp8nmfPn145ZVX6Ny5M82aNeOdd95xd4UXivvuu49hw4Zx2223MWDAAP73v//xxRdfeI1zySWXcPfdd3PDDTdwww038Msvv/Dss8+SlJTkNV6rVq346quv+Oyzz6hZsybNmjXzGyxOmTKFK6+8khtvvJGhQ4eydu1aJk+ezC233OJuhQ0Xm83Ggw8+yLhx46hRowaXXHIJX331FVOnTuXJJ58kJiaGQ4cO0b9/f/785z/TokULcnJy+Pe//039+vVp2bIlP/30E/feey/Dhw+nadOmHD58mKeeeopOnToVWQcubdu2ZcyYMQwdOpS7776bTp06kZOTw/r169m6dSuvvfaae9zhw4czYcIE7rnnHi6++GKvNKHatWtz++23M2XKFKKioujYsSOzZ8/ms88+44MPPgi43FdccQVxcXGMHj2av//972zZssVvV4ytWrXiv//9L5deeinVqlWjVatWxMXFhbwOK4Wy3gFa0f4i2ZvKLe+u0n2eWeJ+/+D8dfrsSZ9ErD5CCCEqhqrQm4qnJk2aaEBv2rSpyGfZ2dn6+uuv1ykpKbpGjRp6zJgx+qOPPtKA3rhxo9Y6uN5UtNb6ueee0/Xr19fx8fH6yiuv1B9//HGR3lTeeust3bRpUx0XF6e7deumV65cWWRemzZt0r1799ZJSUka0O+++27AMmfMmKHbtm2ro6OjdXp6up44caIuLCx0f+7qTSUnJ8drOn/z8uSvxxDXMjZr1kxHR0fr5s2b6+eee8792cmTJ/Vf//pX3aJFCx0fH69r166t+/fvr9etW6e1Nr2pXHvttbpp06Y6NjZWp6Wl6WuuuUbv3LkzYD201trhcOinn35at27dWsfExOjatWvriy66yL1ePHXp0kUD+o033vC7TBMnTtTp6ek6Ojpat23bVs+YMcNrHN/eVLQ2vfC0bt1ax8XF6QsvvFCvW7euyLpZsWKFPv/883VCQoL7Oy/NOtQ6+B5c/DkdvakoM5+qo3PnznrVqlURKfvGt1eyNyuXRbebu3X//elvvLxkM1se+5PfvCwhhBBnho0bN9K6detIV0MIEaKS9l2l1I9a685lKUNyxsMo36GJtnnfwOnUppcVIYQQQgghfEkwHkYFhaZrQ5dqsSZ/XG7iFEIIIYQQ/kgwHkYFDifR9lPpKImx5v7YExKMCyGEEEIIPyQYD6N8h9MrTSUhxgTj0jIuhBBCCCH8kWA8jPILvYPxatIyLoQQQgghilFlgnGlVH+l1OtZWVkRq0OBwztnPNHKGT+RL8G4EEKc6apa72VCVHWna5+tMsG41nqh1vomz0eynm4FDk2MvWjL+HF58I8QQpzRoqOjycnJiXQ1hBAhyMnJ8XoiaXmpMsF4RVDgcBJtkxs4hRBCeKtbty67d+/m5MmT0kIuRAWntebkyZPs3r3b66mj5cVe7iWcQQp8buBMtG7gPJkvLeNCCHEmcz2afM+ePRQUFES4NkKIkkRHR5Oamured8uTBONh5HsDZ4IrZ1xaxoUQ4oyXlJR0Wk7sQojKRdJUwsg3ZzzaFkWMPSqoGzjzCh0sXLuHzOzc8qyiEEIIIYSoQKRlPIx8c8YBEmNsnAziBs5/f/obU7/dRnpKPJ//40J3H+VCCCGEEKLqkpbxMHE6NYVO7ZWmAubBPyW1jOcWOHj3hz+okRDN7qM5zPlxV3lWVQghhBBCVBASjIdJvsMJUCQYT4y1lZgzvmzLIXILnDw7vD0tUquxYO2ecqunEEIIIYSoOCQYD5MCKxiPKRKM20vsTWX5tsNE2xRdm9Xi8rZp/PjHEbJz5W57IYQQQoiqToLxMClwmH5ji+aM20tsGV+/J4sWqdWJi7bRtXktnBpWbjtcbnUVQgghhBAVgwTjYeJuGbfbvIYnxNg4UcwNnFprNuzJpm19091Vx0Y1iLFHsWzLofKrrBBCCCGEqBAkGA+T/EJXzrh3y3i12OJv4Dx8Ip9DJ/JplWaC8bhoGx0bpbBsqwTjQgghhBBVnQTjYXKqZdynN5VYW7E549sOngCgaZ1E97BuzWqzYW82WTmSNy6EEEIIUZVJMB4mp3LGfW7gLCFnfOsBE4w3q30qGD+vSQ20hp92HCmHmgohhBBCiIpCgvEwKQjQtWFCjJ28QieF1ue+th48QbRNkZ4S7x7WvlEKtijFj9slGBdCCCGEqMokGA8TVz/jdt/eVGLNDZ0nAqSq7Dpykvop8dg9gviEGDtt6iWx6g/pUUUIIYQQoiqTZ66HSaGVpuKvn3GAk/mFJMdHF5luX1Yu9ZLjigzv1LgGM1fuoMDhLNLa7snp1Ly9bDvzVu8GYGinBlzXtTFKqYDTCCGEEEKIikFaxsOk0Glaxm1R3kFwQozVMh6ge8O9WbnUT44vMrxzkxrkFjhZvye72HKnLFzPlIUbsEUplFI8MH8942b8RG5B8Q8aEkIIIYQQkSct42HicJqWcXtU0Yf+AH5v4nQ4NZnZuaT5aRnv3LgmAKu2H6Z9wxS/ZX6ybh9vL/uDv/ZoysQrWwPw2jdbefzjXzlwbDlTr+9MSkJMiXUvcDg5dDyfKAV1qsdKq7oQQgghxGkiwXiYFFrBeJRvMG6lqfjra/zg8TwKnZp6KUVbxtOS40hPiWfV9iPc2LNoedm5BUyav47W9ZKYcEUrdwB9y0XNSU+J584P1nLF89/y76Ht6J5R22tah1OzZudRPt+QyTe/H2DT/mPu3mDio200rZ1Iq3rV6dasFt2a1yI9JR6lFFknC/h1Xza/ZR7j4PF8FBAfY6NlWnXOrp9MneqxIa83IYQQQogzmQTjYeIM1DJu3cB50k+ayt6sXADqJRVtGQfo2qwWX/6aicOpi6S/vPS/zRw4nsfU6zsXySnv364+jWslMH7WGq59YznNaiea1nVlctR/3pXF8bxC7FGK85vW5K89mtGoZgIOp5NtB0+y9eBxvv7tAHN/MnnotavFoDUcOpFf7DqoWz2WtvWTaFs/2f2aXiO+SN2FEEIIIYQhwXiYuFrGi+aMB24Z35eVA0C9FP/BeM+zajPnp12s251FO49Uld1Hc5j2/XYGd2jgNdzTuQ1SWPS3nsxcuYNvNx3k+y2HsEUpaleL4aoO9Tm/aS0ualHH702lYC4uft9/jOVbD7NhTzZRUYrGtRJolVadVmlJpCaZVvDs3EI27s1m/Z5s1u/JYv3ubL7ZdNCdtuNKfalbPY5a1WJIjo8mxhZFfIyNc9KT6XFWber5yZkXQgghhDgTSDAeJqdyxr1bqau50lT8tIzvOWq1jAcIRi9sUQdblOKT9fu8gu6nPvkVgH/0bVFsneJjbNzQvSk3dG8a5FKcEhWlaJWWRKu0pGLHS46PpmuzWnRtVss9LLfAwW/7jrFhbzZ7juawPzuPzGO5HDqez9YDJyhwODmeW8g7y/5AKeiRUZtbezXngua1iylJCCGEEKLqqTLBuFKqP9A/IyMjIuUHbBl3pan4axnPziXWHkWNBP+t0zUTY+ieUZsFa/ZwZ58W2G1R/PjHYT5as4fbLs7welBQRRIXbaNdw5SArfZwquX9k3X7eH/FDq6ZupzL26bx0MC21A2QtiOEEEIIUdVUma4NtdYLtdY3JScnR6R8h9W1oW/OeEJ04K4N9xzNoV5yXLG9l1zXpRG7j+Ywb/VuDh7P4x8frCU1KZZbezUPY+1PP1fL+/hLW/D1Py/mn5e15Kvf9tPn2W9YsHYPWutIV1EIIYQQotxVmWA80lwP/fFtGbfbooiLjuJ4XkGRacwDf4pv3b60dSodGqUwaf56Bry4lMzsXF69rpO7l5aqIC7axriLM/j4jp40q5PI7e+v5rYZqzlcwg2jQgghhBCVnQTjYeIIkKYCUD0ummO5RdNU9gZ4+qanqCjFK9d2ontGLVKT4/jPqPPo0KhGeCpdwTSrU43ZN3fj7stb8tmGffR99mu+33ww0tUSQgghhCg3Vad5NcIKA3RtCJAUZy8SjLse+BOoJxVPaclxvDHqvPBUtIKz26IY2yuDi1vW5fb3V3P9f1bw0MCzuaZLo0hXTQghhBAi7KRlPEycuviW8exc7zQV1wN/0qRbP79a10ti7tgL6HFWbe6b9wvPfP57pKskhBBCCBF2EoyHiStn3LdrQ4DqcXayfVrGXQ/8qV9CmsqZrHpcNG9c35mhnRrwwpebmPPjrkhXSQghhBAirCQYDxN3zrjNT5pKfDTHfFrG9x41D/xJk2C8WHZbFI8NPocLmtfivnm/8HvmsUhXSQghhBAibCQYD5OScsazcwK1jEuaSkmibVE8N6I91ePs3P7+avILnZGukhBCCCFEWEgwHiaufsYD96bi0zKelUOsPYqUAA/8Ed7qVo/jX4PP5dd9x3hz6bZIV0cIIYQQIiwkGA8T9xM4/TzAJynOTl6hk7zCUw/+2ZuVS/2U+GIf+CO89WmTSp82qbzw5SZ2HTkZ6eoIIYQQQpSZBONh4nBqlDL9gvuqHmdavz27N9yblUuaPPY9ZJMHtDWvCzZEuCZCCCGEEGUnwXiYOJzab7444E5FOXry1BMl9x7NCaqPceEtPSWe8ZeexRcbM/nfr5mRro4QQgghRJlIMB4mDqf2my8OUCsxFoDDJ0zeeH6hk33ZuTSokXDa6leV3NC9KU1rJ/Looo0UOORmTiGEEEJUXhKMh0mhU/vtYxygRqJpGT98wrSM78vKxamhQQ3pSaU0YuxR3HtFK7YcOMHMFTsiXR0hhBBCiFKTYDxMimsZr5kYA8ARK03FdfOhBOOl16dNKl2b1eTZLzYVebqpEEIIIURlIcF4mBQ6nQFzxmskmGDc1TK+64h54E9DSVMpNaUUE69sw5GT+fzfV5sjXR0hhBBCiFKRYDxMimsZj4u2kRhjOxWMH80hSsnTN8vq7PRkBndowFtLt7PzsHR1KIQQQojKR4LxMCl0BA7GAWokxni0jJ+kXnI80TZZ/WX1z8taEhUFT3zya6SrIoQQQggRMokGw6S4lnGAutVj2ZeVC5g0lXTJFw+LtOQ4brqwOf/9eS8//nEk0tURQgghhAiJBONh4tCB+xkHSK+RwO6jJld895EcuXkzjG6+sBl1q8fyyKINaK0jXR0hhBBCiKBJMB4mhSW0jKenxLM3K4ecfAd7s3Lk5s0wSoy1c9dlLVm94ygfr9sX6eoIIYQQQgRNgvEwcTgC9zMOkJ4SR4FD893mgzg1tEqrfhprV/UN6diA5nUSeeHLTTid0jouhBBCiMpBgvEwKall3PW0TVfLbet6SaelXmcKW5Tib73P4td9x/h0vbSOCyGEEKJykGA8TBxOJ3Zb4GD83AbJAMz5aRfVYu00qilpKuHWv119mtVO5HlpHRdCCCFEJSHBeJgUOjVRKnAwXqtaLGfVrQZA3zapRBXTii5Kxxal+NslGfy67xifbciMdHWEEEIIIUokwXiYOJzF96YCcN+fWnN+k5r8pUfT01SrM0//c+vTtLbJHZeeVYQQQghR0UkwHiYl9TMOcHGrunxwSzfOTk8+TbU689htUdx2cQYb9mZL67gQQgghKjwJxsPE4dTF5oyL02dg+/o0qZUgreNCCCGEqPAkGA8T05uKrM6KwG6L4rbeZ7F+T7b0Oy6EEEKICk2ixzAJJmdcnD5Xta9Pq7TqPLpoIzn5jkhXRwghhBDCLwnGw6SkfsbF6WW3RTF5QFt2H83hla+3RLo6QgghhBB+STAeJg6nU1rGK5iuzWrRv119Xv16Cxv3Zke6OkIIIYQQRUgwHiaFTi19h1dAD/ZvtKASHwAAIABJREFUQ3J8NH97fzUn8gojXR0hhBBCCC9VJhhXSvVXSr2elZUVkfKdnjnj71wFy1+LSD2Et9rVYnlueHu2HjjOPz9cK72rCCGEEKJCqTLBuNZ6odb6puTkyPTh7c4ZP34Atn4FH98N+SciUhfhrXtGbSZc0YrFv+zj5SWSPy6EEEKIiqPKBOOR5u5N5cDGUwMPbY5chYSXMT2bceU59Xjui9/ZefhkpKsjhBBCCAFIMB427n7G93sE41m7Ilch4UUpxcR+rYlSimc+/z3S1RFCCCGEACQYDxt3y/jRHacGSjBeodRLjmd09yZ8tGY3G/ZI7ypCCCGEiDwJxsOk0OE0OeM5R6F6PbDFQtbOSFdL+Bh7UQbVY+08+emvka6KEEIIIYQE4+HicN3AmXsU4mtAcrq0jFdAyQnRjL04gyW/HWDNzqORro4QQgghznASjIdJoStNJecoxKVAYh04eSjS1RJ+XNe1MdVj7bz13bZIV0UIIYQQZzgJxsPEqV0t41kQn2Jax3OORLpawo9qsXaGdm7Iop/3si8rN9LVEUIIIcQZTILxMHG3jOdaLePxNUwruaiQRl/QBIfWvPfDH5GuihBCCCHOYBKMh4HTqdEa07VhzlFpGa8EGtVK4NLWqUxf/ge5BY5IV0cIIYQQZygJxsOg0GkesR4d5YD8Y1bLeE3IPw6OggjXTgTyl+5NOXKygNk/yo22QgghhIgMCcbDwGEF4/HOE2ZAXLJpHQdJVanAujarSefGNXjxy03kFzojXR0hhBBCnIEkGA+DQqcJ5OKdOWZATKJJUwFJVanAlFLc1juD/cfy+Hjd3khXRwghhBBnIAnGw8DVMh6t882A6HiPlvHDEaqVCMaFZ9WhSa0E3l0mN3IKIYQQ4vSTYDwMXMF4LHlmQHQ8xCab//OORahWIhhRUYrrujZm1R9HWL8nK9LVEUIIIcQZRoLxMHAF4zHaMxivZv6XYLzCG9qpIfHRNmkdF0IIIcRpJ8F4GLh6U4lxWg+QscdDjBWM5x+PUK1EsJITormqQ30+WrOboyfzI10dIYQQQpxBJBgPA7854zGJ5v/8ExGqlQjFqAuakFvg5K3vtke6KkIIIYQ4g0gwHganWsY901Sqm//zpGW8MmiVlsTlbdN47ZstbDkg35kQQgghTg8JxsPAYXVtGO3KGbfHgS0abLHmIUCiUpgysC1x0TZGv7WCpz/7jY9/2UuBQ/ofF0IIIUT5kWA8DNxP4HTljEcnmNfYatIyXomkJsXx0siOJMbY+b+vNnPr9J8Y9toyjuXKU1SFEEIIUT4kGA+DQocJxu3uNJU48xpTTW7grGR6nFWbT8ZfyMaHL+fZ4e34eVcWj3/8a6SrJYQQQogqSoLxMHBqn5Zxe7x5jZGW8coq1m5jUIcGjDy/IbNW7iRbWseFEEIIUQ4kGA8DV5qKzZEHUdFgs5sPYqVlvLK7qn06hU7N178diHRVhBBCCFEFSTAeBg7PnHFXvjhImkoV0KFRDWolxvD5hsxIV0UIIYQQVZAE42Hgyhm3OfJO5YuD3MBZBdiiFL1b1eWr3/aTV+iIdHWEEEIIUcVIMB4GrpZxuzPH9DHuElNdWsargAHt63Mst5CFa/dGuipCCCGEqGIkGA+DQquf8Shngelb3CUmUVrGq4AeGbVpkVqNN5duQ1s36wohhBBChIME42HgahmPchaAPebUB7HVzEN/JICr1JRS/KV7UzbuzWbZ1kMcOJbH699s4YGP1rH4l72SviKEEEKIUrNHugJVgVcwbvMIxmOqgXZCYa53+oqodK7qkM6Tn/7GNVOXkxwfTVZOAXHRUbz7wx/UTIzhhREd6HFW7UhXUwghhBCVjLSMh8GpYDzfOxiPrW5eJVWl0ouLtnHfn1oDcFbdanw6/kJ+mXwZzwxrR51qsfzl7ZVs2JMd4VoKIYQQorKRlvEwKPRqGfe8gbOaec0/BtQ5/RUTYXV1pwZ0z6hFavU4oqIUAIM7NuCiFnW44vlvue39n1h8e0/iom0RrqkQQgghKgtpGQ+DwGkqieZVWsarjHrJ8e5A3KVWtVievPpcth44wexVOyNUMyGEEEJURhKMh4FSUC3WjvINxmNdLeMSjFd1F7WoQ8dGKbz69VYKHM5IV0cIIYQQlYQE42EwsH0666ZcRgyFPi3jkjN+plBKMe7iDHYfzWHh2j2Rro4QQgghKgkJxsPJ4XsDp7SMn0l6t6pLq7TqvLxkC06ndGcphBBCiJIFFYwrpexKqVifYX2VUuOVUh3Lp2qVkMNP14YgwfgZQinFrb2as3n/cT7fmBnp6gghhBCiEgi2ZXwW8IrrjVLqduAT4F/AD0qpfuVQt8rHkQ+26FPvXTdw5p+ITH3EaXflOfVoVDOBZz//nc37j0W6OkIIIYSo4IINxrsCiz3e/xN4WmsdD7wB3B/uilVKvmkq0jJ+xrHborj3ilZsPXiCS5/5hs6PfM7Pu45GulpCCCGEqKCCDcZrAfsAlFLnAPWBV63PZgNtwl+1SshR4N0ybo8xwbncwHlGueKceiyb0Ju7+rbg4PF8nvjk10hXSQghhBAVVLDBeCbQxPr/cuAPrfUW6308IH25QdGWcTCpKsGkqWxdAk80hY8nlEvVxOlVq1ost/U+iwlXtOK7zYfYuFeezimEEEKIooINxmcDTyilngLuAd7x+KwDsCncFat0tAbffsbBpKqUFIxrDYv/CTmHYfkr8Mf35VdPcVqNOK8hcdFRTPtue6SrIoQQQogKKNhgfALwGtAKcyPnYx6fdcLc4HlmcxSYV880FbBaxktIUzn4u/m77F+mb/I1M8qnjuK0S0mIYXDHBny0ZjeHT+RHujpCCCGEqGCCCsa11oVa64e01v211g9orfM9PhustX66/KpYSTjyzKvflvESgvHNX5rX/2fvvuOiutI/jn/O0DuiFGmKIliwY++9xRgTS3rbNLMpZuMmu5v8Nn3NpvcY07ObYhJjNpbEFruJvYsooiIogqCIIHXO74+LCqGNClwGnvfrxes699yZ+aKJPnN47jntr4boMbBvIVil86ehuL1vS/KLrNz00QbeWn6A07lSlAshhBDCYOs64wFKqYhSj5VS6h6l1BtKqfG1F8+OXJgZv4ye8ePbwSsYfEKh9VCjXSVtT+3kFHUuKtCLB4ZEkpSRw2tL9zP+nbVsOXJKNgYSQgghhM1tKp8Bj5R6/CzwHsbNnPOUUrfXbCw7VFwy21muTcWGnvHUXdC8k/HriAHG8dCams0nTDVjVDR7nh3N9/f1IfNsAde9v547P99EsRTkQgghRKNmazHeDfgVQCllAe4D/qG1bgu8AEyvnXh25EIxXtHMeBVtKkX5kB4PgTHGY59QaBIBh6UYb4hiW/qx6rEh3D+4NSvj01mw85jZkYQQQghhIluLcR8go+TX3QE/4MuSx78CkTWcy/6cb1NxdCl73sWz6nXGTx0GXQz+0RfPRQyAw+vAWlzjMYX5mnm6MGNkNK39PfjPb0fMjiOEEEIIE9lajCdzcWOfccA+rXVKyWMfIK+mg9mdSttUqukZz0gwjk1bXzzXoj/kZ0FaXM1mFPWGxaK4pksIm4+cIjVL/vcRQgghGitbi/FPgJeUUt8BjwGzS431BqRqrLRNxROKzlU+y32+GPcrVYyH9zKOSb/VbEZRr4zsEATAyvg0k5MIIYQQwiy2Lm04E3gQSC05vlVq2A/4qOaj2ZmqVlOBymfHMxPBvSm4+V4859sCvJpD0u81n1PUG1GBngR5u7LmwMlyY1m5hdz3ny3M/DlOVl0RQgghGjBHWy/UWn9B2Z03z5+/r0YT2avzxbjFoex5Z0/jWHAWXL3LPy8rxbhpszSlILw3HN1g23trDWfTwMmt4vcQ9ZJSigFtmrFk7wmKrRoHiwIgJ7+IqbN/Y19qNgCdQnwZ16m5mVGFEEIIUUtsbVNBKeWolJqqlHpbKfVlyXGKUsrmgr5BsxYZR0sFSxtC5TPjZ46Bd2j582G9IesonD5a9ftmHIQPh8KrUfDvFvC/P0PhuUvLLkwzMMqfrHOF7Eg+feHccwv2En8im09ujyXcz52P1yaamFAIIYQQtcnmTX+AzcDXGDdwtio5fgNsUkr511pCe3GhGP/DZ5MLbSqVrKhyJhm8g8ufD+9tHKuaHc85CZ9fbazIMuI56HE3bPsvfHYV5GZeUnxyM+FkQvVroosa1T+yGUrBmv1Gq8qmw5l8s+ko9w1qzdC2gdzZryVbk06zLemUyUmFEEIIURtsnRl/DWgK9NZat9Ja99FatwJ6lZx/rTbCKaXaKaVmKaW+V0pNq433qDHnb9CstBivoMjNPwt5WRUX44Ex4ORR9U2cS56EsyfglnnQ7yEY+xJM/a+xidCnY41Z96qkbIEf/wwvR8JLEfBOd/hXMLzbG9a+DqeTqn6+uGJNPJzpFOLD6gPpALy1/ADNPJ15aGgbACbFhuHu7MCcTdX8hEQIIYQQdsnWFpOxwANa642lT2qtNyml/g68besbKqU+Aa4C0rTWMaXOjwbeBByAj7TWL2qt44D7SjYa+gJ439b3qXMXZsb/8PnmfJtKRWuNZx83jn/sGQdwcDRWValsJ85Dq2HH1zBgBgR3uXi+3Xi46Tv45kb4YCBc9Tq0vcroQwej+E9YBps/NTYWcvaC6DHGa7g3haxkOLAElj1tfIX2hJjrIKijkTfrqFGkZ6VAYa6xioy2gpsfePiDRzPj6BUEPmHG9+YVVL6XXlwwon0gryzZz4erE1lz4CR/H9MWN2fj98vTxZHRMUEs2nWcFyZ2vNBXLoQQQoiGwdZi3AXIrmQsG3CuZKwinwHvUOpmUKWUA/AuMAJjTfNNSqmftNZ7lVJXA9OA/1zCe9S9ytpUXErdwPlHWcnGsaKZcYDWQ43Z76zksgV7UT4seASatISBM8o/r9UguGsZfHc7zLkZ3JtB00ijcE7dBdZC8AqGkc9D99vBxavs8wfOMFpfdv9gfP3yeNlxtyZGHmdPcHQ1Cv3s48Zr56Qbr1+axdH4Hn3CLxbnDk5GpqCO4N+2URfrN/ZqwfsrD/LCojiiAj25pU+LMuODowP4YWsKu1Oy6BzmW8mrCCGEEMIe2VqM/w48rpT6VWt9od9CKeUBPF4ybhOt9WqlVMs/nO4JJGitE0te9xtgArBXa/0T8JNSaiHwla3vU+f0ZbSpnG8jqawYjxxhFOPxP0PPuy+eX/uGsT75zXONFVQqEtAO7lsLe+bBoVWQeRicXKH3NGg7DkJ7VF0AN2kJA/5ifKXvh6wk8A4xiuk/Fu+laQ15pyE71fgQcTrJOGYdNY6H1xqtNbrYmFEHo0iPvQN63nPxw0sj4ufhzLf39WHZ3jRu7h2Ou3PZ/4b6tGoKwMr4dCnGhRBCiAbG1mL8UWAFcFQptQQ4AQQAowAFDL7CHCFA6abYZKCXUmowcC3GzPyiyp6slLoHuAcgPDz8CqNcpmpv4KyiGPeqpBgPaAsBHWDHNxeL8YyDsOZV6HAtRA6vOpODE3SaYnxdCf8o48sWShkz525NjA8ElSkuMj5QHNsK27+C5c8YrTMT3jFm9huZDsE+dAj2qXDM38uF3q38+GFbMg8Ni0QpaVURQgghGgpbN/3ZDrTB2HnTH6OdJACYBbTRWu+ojXBa65Va64e01vdqrd+t4rrZWutYrXWsv79JC7tUegNnFW0qZ1KMFhIn18pft9utkLIZDq+DogL4cRo4usDomTWT2ywOjsaHjS43wu0L4M7Fxvf1xQRY8n/G9youmNQ9jCMZuWw+IquqCCGEEA2JzeuMa61Paq3/prUeprVuX3L8h9a6/PaBly4FCCv1OLTknP24MDP+h9YPBydwcIH8Clruz6RU3qJyXrdbjPaQH+6Bz8cbSx1e9brRd92QhPeGe1cb7Srr34KPhkF6vNmp6o0xMUG4OzvwydpDZkcRQgghRA2yuRivZZuANkqpCKWUM3A98JPJmS5NZW0qYOyKmX+m/PkzxypeSaU0Zw+Y8h9QFkjfBxPehY6TrjxvfeTsbnzQuP5r44PKB4Ng08dGH3oj5+HiyH2DWvPz7lRW7083O44QQgghakilPeNKqU2AzVWQ1rqnLdcppb7G6DFvppRKBp7SWn+slHoAWIyxtOEnWus9tr53vVBVMe7iDXkVFeMpFzf3qUpod5i+8+LyhA1d27EQst5oyVn4F2Mpxus+Nor1Ruyega2Yty2FGd/t4Mu7etEmsIobaYUQQghhF6q6gXMPl1CM20prfUMl5xdRxU2a9d75nnFVwQolrj7lZ8YLcuHcqerbVM5rLIX4eV5BcNNc2PA+LH4Cvr8Dpn5p9Jo3Uq5ODjw3IYZbP9nA1e+s44f7+9KuubfZsYQQQghxBSqtbLTWt9dhDvtXWc84GG0qeVllz11Y1rCaNpXGzGKBPn82buxc+Kixiszgx6t/XgPWv00zFj08gNs+2cj1s3/n9r4tmTa4Na5OjXeddiGEEMKe1ZeecftX2WoqUHGbypmS+1NtnRlvzHrcBR2nwKp/Q8oWs9OYrm2QN7NviaWw2Mqbyw8w9s01zF59EC299UIIIYTdabw/869pl3oDpxTjl2bsy3BknbGqzL1rGn3/eOcwX9Y8NoSV8en8a1Ec/1q0j53JWZzKLeDY6TzevbEb7YOlhUUIIYSo7xrMzLhSarxSanZWVlb1F9eGKotx3ypmxkNqN1dD4eYL17xnbBS04gWz09QLTT1duK57KJueGM60wa1ZsvcEmw+f4tDJHP7vf7vNjieEEEIIGzSYYlxrPV9rfY+PT8W7GNa66tpUCnOMXSfPO3MM3JtWveGPKKvVYOh+O/z+PqRKsXmexaJ4fHRbNj0xnG3/HMHT49uz5cgpdiWb9MFUCCGEEDZrMMW46axFgDJuOvwj15J2gdKtKlk2bPgjyhv2lDFLvvAvYLWanaZe8XFzwt3ZkYndQnF2sDB/5zGzIwkhhBCiGjYV40qpuUqpsUopKd4rYy2qeFYcwK2JcTxXaivzM8dkJZXL4e4HI54zdiLd/l+z09RLPm5O9Grlx7K9J8yOIoQQQohq2FpcNwXmA8lKqReVUtG1mMk+WYsqXtYQjHYUgNzMi+eyjoKP9Itfls43QHgfWPpU2d9TccGI9oEknszhYPpZs6MIIYQQogo2FeNa68FAG+AjYCqwVym1Xil1l1JKtgEEo2e8splxdz/jmJthHPOyIO80+Laom2wNjcUC4141fh+XP2N2mnppWLtAAJbK7LgQQghRr9ncdqK1TtRa/1NrHQGMBBKA14HjSqnPlVKDaymjfdDFNsyMlxTjp48aR9/w2s/VUAV2gN7TYMtncHST2WnqnRBfNzoEe7NkT6rZUYQQQghRhcvtAf8NWAHEA+7AUOBXpdR2pVTXmgpnV6rqGS9XjCcZR9+w2s/VkA3+G3g1h4WPlF2pRgAwukMQW5NOS6uKEEIIUY9dUjGulBqklPoUSAVeBTYCPbTWYUAMkAF8UeMp7UFVxbizJzg4V1CMS5vKFXHxgtEvQuou2PSh2WnqnRt6hePp4sibyw6YHUUIIYQQlbB1NZV/KqUSMGbDI4A/A8Fa6/u11lsAtNZ7gf8D2tdW2HqtqmJcKWN2vHQx7uR+ccZcXL72E6DVEFj5YtnVagTNPF24rlsIv+xJJSu30Ow4QgghhKiArTPj9wLfAlFa68Fa6/9orfMquG4fcGeNpbsE5u/AWUXPOICHP5wtuZnu9BGjX1ypusnWkCkFI583buZc86rZaeqd67qHUlBkZcEuWXNcCCGEqI9sLcbDtNb/0FonVHWR1jpTa/15DeS6ZObvwFnFzDiAT5ix0Q8YM+Ny82bNCYqBLjfChg/g1BGz09QrHUN8iAr05OuNSVit2uw4QgghhPgDW5c2tAIopaKVUjcrpf5acmxbu/HsiLUIVBUz4z6hkJVs/FqK8Zo35Anj9//X58xOUq8opbh3YGt2p5zhpx1lZ8czzuaTX1RsUjIhhBBCAFQxlXuRUsob+BC4DqOAPwt4Alal1A/AXVrrM1W8RMNX7cx4KORnQcZBY41xv1Z1l60x8AmBPvcbrSq974eQbmYnqjcmdg3hs/WHmT5nO5k5BXQM9eHxuTtJTM8hwMuFD2+NpXOYr9kxhRBCiEbJ1jaV9zDWFr8V8NBaewMewG3AiJLxxs1qrb4YB4hfZByDOtZ+psam33RwbwZL/wlaWjLOs1gU793Uje4tmvDsgr1MnvUbWbmF3NQrHItSXPv+enYlm3SvhRBCCNHI2TQzDkwAHtFaf3X+hNb6HPClUsodeK02wtkVa1HVN3A2izKO20t+CwNjaj9TY+Pqbaw9vmgG7F8M0aPNTlRvhPm58+VdvVi06zgnz+YzJTYMX3dnHh6ex/BXV/G3H3ZyXbdQdqdk4ebswBPj2uHubOtfD0IIIYS4XLb+a3sWOF7J2DEgp2bi2LHq2lQC2oOrD6TthaZtwN2v7rI1Jt1vhw2zjNnxyOHgIAXlea5ODlzbLbTMuQAvV56f2JG/freDZxfsvXD+5Nl83rqhKy6OVXzAFEIIIcQVs7VN5V1ghlLKrfTJklnxGUibSvXFuMUCkSOMX3e5oW4yNUYOTjD8GTgZD9sa5/5Tl+rqzsHsfHok2/85grhnR/PPq9qzeM8JPlpzyOxoQgghRINn67ShD9AGOKqUWgqkAQEY/eLngM1KqZdKrtVa68drPGl9Zy2uuhgHuPptiLkWWg+rm0yNVdtxEN4XVsyEjpONnTpFlVwcHS7Mgt/ZP4K1CSf5ZO0h7h3YCkeHS9qoVwghhBCXwNZ/ZScBhUA20Bu4uuSYDRSVjE8u9dX4VNczDuDsbhSKTq51k6mxOr8RUE4arH7F7DR2aVL3UDJyCth8RHY1FUIIIWqTTTPjWuuI2g5i96xFYHE3O4U4L7Q7dLkZfnsHOl8PAe3MTmRXBkX54+Jo4ZfdqfRu1bTCa6xWjcUiu8gKIYQQV0J+/lxTtA1tKqJuDX8aXLzhu9shP9vkMPbFw8WRAW38WbInFV1qmUirVfPGsv0MeOlXrpu1vsyYEEIIIS6dzcW4UqqVUup9pdQupVRKyfE9pVS92L1GKTVeKTU7K8uk9ZKru4FT1D1Pf5j8KZw8AN/eCkX5ZieyK2NigjiWlce2o6cBSMvO47pZ63lj2QGOZp5jW9JpfkvMMDmlEEIIYd9sKsaVUt2B7Rg7cG4Cvig5XgdsU0qZvt2h1nq+1voeHx8fcwJYi6vvGRd1r9VgGP8mHPwV5t0rmwFdghEdAnF2tDB/xzH2HjvDsFdXsefYGV6b0pl9z43Gw9mBhTsrW/FUCCGEELawdSr3FWAbMEZrnXv+ZMnShotKxofWfDw7IjPj9Ve3WyD3JCx7GsJ6Q+/7zE5kF7xdnRgS7c+XvyexdO8JPJwdmTutJ1GBxuo0A6P8WR6XxvPXaJSS3nEhhBDictjaptITeKl0IQ5Q8vgVoFdNB7M7UozXb/2mQ5tRsPwZyD5hdhq7MbVHGAXFVlJOn+PF6zpeKMQBBkf7k3omj4PpZ01MKIQQQtg3W4vxc0DFSyqAH5BXM3HsmBTj9ZtSMHqm0Te++mWz09iNoW0DWfBgf5Y+MpDB0QFlxvq2bgbAugTpGxdCCCEul63F+ELgRaVU/9InSx7PBObXdDC7Yy0GJT3j9VrT1kbLypbP4NRhs9PYjZgQHyIDym+cFObnTmgTN9YlnDQhlRBCCNEw2FqM/wVIBFYppY4rpXYopY4Dq4BDwKO1FdBu2LLpjzDfoMeNP6cVM81O0iD0a92M3xMzKLbKjbFCCCHE5bCpGNdaZ2it+wPjgPeAdSXHMVrr/lpr+Tm1VdYZtwvewdDzbtg5B9LizE5j9/q3acaZvCK2yE6dQgghxGWpthhXSrkopZ5QSnXWWv+itX5Oa31/yXFJXYS0C9Izbj/6/wVcvGDli2YnsXtD2gbg7Gjh592yxKEQQghxOaotxrXW+cATgG/tx7FjMjNuP9z9IPYOiJsPWclmp7Frni6ODIry55fdqVilVUUIIYS4ZLb2jG8ATN/Yp16TnnH70uMuQMOmj81OYvfGdgzieFYe6w9Kt5oQQghxqWwtxh8D7ldKPaCUaqWU8lBKuZf+qs2QdkHaVOyLbzhEj4Wtn0OhrMx5JcbENCfYx5VnF+xh9f50ftiazEdrEskrLDY7mhBCCFHv2Vo9big5vgW8Wck1jXtaWIpx+9PzHti3AHbPha43mZ3Gbrk6OfDCxI7c8dkmbv1k44XzWecKeXRktInJhBBCiPrP1urxTqBeN4QqpcYD4yMjI+v+za1WQEubir2JGAj+bWHjB9DlRmNjIHFZhrQNYMGD/Uk5fY42AZ68umQ/H6xK5JquIbT29zQ7nhBCCFFv2VSMa60/q+UcV0xrPR+YHxsbe3edv7m1yDhKMW5flDKWOVz4KBzdCOG9zE5k12JCfIgJ8QHg6as7sDbhJA9+tY1ZN3cnvKl0sgkhhBAVsalnXCmVqJTqXMlYjFIqsWZj2Rld0hsrbSr2p9P14OJjzI6LGuPv5cLrUztz6GQOg19ZwXsrEwA4k1fIzuTTJqcTQggh6g9bq8eWgEslY+5AaI2ksVcXZsalGLc7Lp5Gv/jG2XDqCDRpYXaiBmNo20BWzBjMUz/t5pXF8RxKz2Hl/nTSs/OZdXN3RscEmR1RCCGEMF2lM+NKKW+lVLhSKrzkVND5x6W+ooDrgZQ6SVtfSTFu3/o8ABYno13FajU7TYMS5OPKq1O60C+yGd9tSSbQ24WYEG8e/XY7CWlnzY4nhBBCmK6q6vER4CmMGzc1MK+S6xTwaA3nsi9WaVOxaz4hMPI5WDQDfn0Whj0lN3PWIE8XR764sydHMnIJbeJGWnY+499ey+RZ63l8dFumxIZhscjvtxBCiMapqurxK2AzRrH9EzDZ+ezUAAAgAElEQVQDiP/DNQVAvNY6qXbi2Qm5gdP+9bgLjm+Hta9D3AI4dwqad4KJs8HT3+x0dk8pRctmHgAE+7ox597e/P2HXfzth13sPX6GZyfEmJxQCCGEMEelxbjW+gBwAEApNQTYqrXOrqtgdkXaVOyfUnD1OxDUCfb/AsFdIW4+fDUZ7lwMjpXdMiEuR2SAF9/e24dn5u/ls/WHmdQ9lE6hvmbHEkIIIeqcTaupaK1XnS/ElVIOf9x9s9HvwHm+GFcyM27XlIJe98It8+C6D+G6j+DYNvjtXbOTNUhKKR4dGYW3qyPvrkgwO44QQghhCluXNvRWSr2jlDoG5APZFXw1XtIz3jC1uwoiRxjFuNzYWSu8XJ24vV8Ei/ecID617F8jWmsKi+X3XQghRMNma/X4AXAV8BGwF6NXXJx3oRiXmfEGp+NkSFgKJ3ZB8wqX2hdX6I6+Lfl4TSKvL93PrFu6AzB/xzFeWryPE2fyGd0hiNendsFBbvIUQgjRANlajI8CHtFaf1SbYeyW9Iw3XBEDjWPiKinGa0kTD2fuHxLJy4vjGfHaKo5n5ZFTUESHYG96RzTluy3J9ItsytQe4dW/mBBCCGFnbK0ec4Dk2gxi16QYb7i8m0OzKDi0Cvo9ZHaaBuvega0oLLayMj6dsR2DCPJ2ZdrgSFydLOw5dobP1x+RYlwIIUSDZGv1+Cpwv1JqidZamjj/SIrxhi1iEGz/EoryZVWVWuLoYGH68CimD48qNza1RxhP/bSH+NRsooO8TEgnhBBC1B6bbuAEQoDOQLxSarZS6qU/fP27FjPWf3IDZ8MWPRoKcyH+Z7OTNEpjYoIAWLo31eQkQgghRM2ztXqcBFhLrh9RwbgGHq+pUJdDKTUeGB8ZGVn3by6b/jRsrYaAVzBs+y90uMY4pzUc3QipO43HXW4C58a9wmdtCfB2pUuYL0v2nuCBoW3MjiOEEELUKJuKca11RG0HuVJa6/nA/NjY2Lvr/M2lGG/YLA7Q5UZY+xqcOQbFhfDtrcaOnedt/dzYHMjZw7ycDdjIDoG89Es8x7PO0dzHrdx4XmExj8zZjoNF8fYNXVFKVl4RQghhH2xtUxFVkZ7xhq/LjaCtsPYN+M9EOHUIxr8Fdy2HKV9A6m5Y/ITZKRusMTHNAfhp+7EKxz9dd5ifd6eyYOdxVsan12U0IYQQ4orYXIwrpToppeYopQ4qpfKVUt1Kzr+glBpTexHtgJae8QavaWtjmcONH0D2cbjxO+h+G4TGQvsJ0PdB2PKpsWOnqHERzTzo3qIJ321JRmtdZmzhzuP8+5d99GzpRzNPF77ckGRSSiGEEOLS2boD5xhgCxAEfAE4lRrOBx6s+Wh2RDb9aRyueR86XAu3/gThvcqODZwBTu6w+RNzsjUCk7uHkpB2lu1HT184p7Xm1aXxRDTzYNYt3ZnUPZRf953gSEaOiUmFEEII29k6Mz4T+ExrPQh44Q9j24EuNZrK3kibSuPgEwqTP4WwHuXHXH0g5jrY9T3kZdV9tkZgXKfmODta+F+pVpX4E9kkpudwz8BW+Hk4c2e/ljg6WJi16qCJSYUQQgjb2VqMtwXmlPxa/2HsDOBXY4nskRTjAiD2TmMJxJ3fmp2kQfJydWJItD+Ldh3HajX+GlpV0h8+ONofMFZemRIbyvdbkknPzr/w3FM5BeQXFdd9aCGEEKIathbjaUCrSsY6AI27SVOKcQEQ0g2ad4Ytn5mdpMG6qlMwadn5bDqcCcCq/em0DfIqs8LK7X0jKCzWfLz2ENuSTnHrJxuJfWEZj8zZXtnLCiGEEKaxtRj/BnhWKdW/1DmtlIrCWF/8yxpPZk9k0x9xXtdb4MRuOLHH7CQN0rB2Abg5OTBvWwpn84vYdDiTQVH+Za6JDPDkqk7NmbXqIBPfW8+elCxcHS0s2pXKmgOy0ooQQoj6xdbq8f+A9sAq4Pw2eP/DuKFzCfCvmo9mR87PjCtZKbLR6zARFv8D1r0J18wCi/w3UZPcnR2Z0CX4Qt94YbFmVMkOnaW9OqUzozoEkZNfxOiYINycHRj5+mqe/mkPv0wfiJOD/LkIIYSoH9Qflwmr8mKlhgHDgGZAJrBca720lrJdltjYWL158+a6fVOtjdlxiwPIZiNi6VOw7g3wawUOzjDpUwhsb3aqBiMpI5eJ760jI6eA2BZN+O6+PjZt8rM87gR/+nwzT45rx10DKu66O1dQjJuzrIokhBDCNkqpLVrr2Ct6jUspxu2BKcW4EKVZi2H3XGOZw6TfjNnyyZ+ZnapBSc3K47fEkwxvF4iXq1P1T8BYBvG2TzexOyWLjf8YhuMfZsc3Hc5k8qzfePHajlzfM7w2YgshhGhgaqIYl5/VClHTLA7QaQrc+Qv0exj2/g8yE81O1aAE+bgysWuozYU4gFKKqbFhZOYUsOXIqXLjn647BMDzC+MoKrbWWFYhhBCiKlKMC1Gbek0zbuxd/47ZSQQwKNofR4ti1f6yN3KeKyjm131pBHq7cDa/iPUHM0xKKIQQorGRYlyI2uTdHDpNhe1fQt4Zs9M0ep4ujnQM9WHjocwy55fFnSCv0MrMazvi5uTA8rgTJiUUQgjR2EgxLkRt63YrFOXBnnnGzb7CVL1bNWVH8mlO5RQAcDD9LC8vjqeVvwcD2/jTp3VTVsSn09DupxFCCFE/STEuRG0L7QFBHWH+Q/BqNCx7BrKSL65PL+rU1Z2DKSzWzN2azJxNSVz11lqy8wp58dpOODpYGBztT1JmLodO5pgdVQghRCNgUzGulLpOKfWnUo8jlFLrlVKnlVJzlVK+tRdRCDunFNz0PQz9PwjuCmtfg9c7wMcjoPCc2ekanXbNveneognPL4zj8bm76Bruy88PD6RnhB8Ag6MCAFgZLxsECSGEqH22zow/CXiXevw2xlrjLwLdgBdqOJcQDYtXEAycATd8A1P+A30fgpQtsOEDs5M1Sn/qHwHAbX1a8N8/9SLIx/XCWHhTdyIDPFkmfeNCCCHqgK3FeCtgF4BSygcYCTyitX4ReAIYXzvxbKeUGq+Ump2VlWV2FCEqpxS0vxpGPgctB8DWz6WP3ARjOzZnzzOjeGZCDBZL+Q2DRrYPZMOhTHanyN8nQgghatel9IyfrxgGAcXAspLHyYB/TYa6HFrr+Vrre3x8fMyOIoRtOk4y1h8/scfsJI2Sh4tjpWO39mlJkLcrN320gR+2Jl/S6xYVW7Fa5QOWEEII29hajO8AblJKeQB3ASu01vklY+FAWm2EE6JBazPSOCauNDWGKC/Ix5Wv7+5Ny2Ye/OXbHby8eB/rD57khYV7WbEvje1HT1f4vHUJJ+ny7FKGvLqy3PKJQgghREWULct3KaX6A/Mx+sbPAiO01htLxr4HrFrrKbUZ1FaxsbF68+bNZscQwjZvdYNmbeDGOeXHrMWgLEZrizBFUbGVv3y7g592HCs3dlf/CP4+th0OJW0u8anZTHp/Pe4uDigUadl5vH9zd0a2D0TJn6EQQjRISqktWuvYK3mNyn9OW4rWeq1SKhyIAg5qrUtPC30CJFxJCCEarYgBsPsHKC4Ch1L/O546DJ9fbezeedt88AkxLWJj5uhg4c3ru3DvoFYkZeQS4e/B4ZM5LNlzgo/WHsJiUfxjbDtW7EvjoW+24ebswA/398PL1ZHrP/ide/+zhas6NeftG7pKQS6EEKJCNhXjAFrrbGBL6XNKKV+t9aIaTyVEY9FyAGz5DFJ3Qkg341xRPsy5BU4nARqW/h9M+sTMlI2aUooOwT50CDbuR2kb5M3omOY4O1r4eO0hkjJyWRp3gjYBnrx7UzdCfN0A+OH+vry6JJ4P1xxieLtArukqH6iEEEKUZ+s649OUUo+VetxFKZUMZCiltiilQmstoRANWcsBxvHwmovnlv7TKM6v/woGPQ6750LSBnPyiUr9bUxbYoK9WbI3lUndQvniTz1p7e95YdzVyYG/j2lH++bevLo0noIiq4lphRBC1Fe23sD5IHCm1OO3gGPATSWv8WIN5xKicfAKhGbRcKikGE/eDBtmQa9p0HYs9HsY3JvCmlfMzSnK8XV35sc/92Pvs6P596ROBHi5lrvGYlH8dXQ0RzPPMWdTkgkphRBC1He2FuPhQDyAUsof6Ac8prX+BngOGFo78YRoBCIGwpF1UJADa14FtyYw9EljzNkDut0KCcsh70zVryPqnFIKVyeHKq8ZHOVPzwg/3lyeQG5BUR0lE0IIYS9sLcbzAeeSXw8BcoHzP1fPBHxrOJcQjUfMtVCYC4v+CvGLjFlxl4vtDrQeCroYjqw3L6O4bEopHh8dzcmz+Tz5426Kq1iD/Njpc/xj3i7Ss/MrvUYIIUTDYmsxvhH4s1KqA/AQ8IvWurhkrBVGy4oQ4nKE9YbgbrD9S/BtAb3uKTse2hOcPIxCXdil7i38mDa4NT9sTWHWqoOVXvfkj7v5akMSzy/cW4fphBBCmMnWYvxRoAOwCwgDnig1NhVYV8O5hGg8LBbjZs3RL8Kdi402ldKcXI3+8bifoLjQnIziij02KpqrOjXntaX7SUjLLjeelJHLr/uM/dMW7DzOsdPn6jqiEEIIE9hUjGut92qtW2Nse99Sa72/1PCMki8hxOXybg69pxnHinS4Fs6dgsRVdZtL1BilFE+N74BVaxbuTC03/vWmJCwKvr+vDwp4c9mBug8phBCiztk6Mw6A1joD8FNKtVFKNS05t0trnV4r6YQQhshh4OpjtLIIu+Xv5ULnUF+WxpUtxguKrHy3+ShD2wYS29KPm3u34PutydI7LoQQjYDNxbhSaqpSKg5IA/YBaUqpOKXU5FpLJ4QwOLpA11tg7/8gK9nsNOIKTOgSzO6UM+w4enEj46V7T3DybAE39QoH4Obe4RRbNd9sNJZDLLZq3l2RwL8WxVV5A6gQQgj7Y+umPzcAXwOJwB3A2JJjIvCNUur6WksohDD0uMtYVWXHN2YnEVfguu6heLs68vLi+AuF9VcbjxDi68bAKH8AIgO8GNk+kHdXJpCQls3D32zj5cXxzF6dyKJdx82ML4QQoobZOjP+BDBbaz1Oa/2F1npxyXEc8CHwZO1FFEIA4Bdh7Ni54QM4fdTsNOIyebs68djotqxNOMlLi/exOyWLdQkZXN8jDAeLunDd01d3wKIUw19bzcJdx3l8dFsiAzx5+9cDWGV2XAghGgxbi/FIYG4lY3NLxoUQtW3EM5B3Gj4eAXlZZqcRl+nm3i2YEhvKh6sTufHD32nm6cytfVuWuSbY143Xp3ahZVN33r+pO9MGt+aBIZHsP3GW3xMzzAkuhBCixtlajJ8AYisZiy0ZF0LUtpDucOv/IDsVVsw0O424Ak+Ma89VnYJpE+jFh7fG4uPmVO6aUR2CWPnXIYyOCQJgZIdAnB0tLI2Tv3KFEKKhcLTxuk+Bp5VSDsD3GMV3ADAZo0VFqgIh6kqLvhB7B2x4HxydYdhTYCnZkt1aDClbjaLdckmLJYk65uPmxFs3dL2k57g7O9I/shnL4k7wz6vao5Sq/klCCCHqNVv/tX4WeAX4G7AHOAnsLXn8Ssm4EKKuDH8aPAJg3ZuwcfbF8//7M3w8HFY8b1YyUcuGtwvkaOY54k+U3zioMgfTz7LlSGYtphJCCHG5bN30x6q1fgJj983BwA0lxzCt9ZNaa7mbSIi65OoDf4mD1sPgl7/BJ2Ngy2ew42tjfN1bsgRiAzW8XQBKwZI9ZVtVVu9PZ/Ks9fT/9698XbIk4qGTOTy/YC+j31jNde//xqr9siWEEELUN9UW40opV6XUEqXUYK31Ka31Gq31tyXHU3URUghRAQdHmPIF9LwHktbD/IchoD38eRNYC2UJxAYqwNuV7uFNyixxuGp/Ovd/uZVNh0+RcvocMxfFsS3pFJPeX89Haw/h6+4MwPsrE8yKLYQQohLVFuNa6zygB+BQ+3GEEJfExRPGvgx3r4BrP4LbF4J/FDTvDAnLzE4nasnomCD2pWZz6GQOmTkFTP9mG819XFn3t6F8+adenMkrYuJ768nIKWDutD5semI4T45rx++JmSyXmz+FEKJesfUGzp+Aa4DltZhFCHG5QroZX+dFjoC1r8O50+Dma14uUSvGdGzO8wvj+GZjEsey8sjOK+Lre3oT4utGiK8bH94aS1JmLlGBnnRv4QfArX1a8vXGJF78eR+DowPKrGkuhBDCPLYW44uBl5VSzYFFGKuplOkT11ovquFsl0QpNR4YHxkpS54LQZsRsOYVSFwBHSaanUbUsBBfN67pEswHqxMBmDEyirZB3hfGR7QPLPccZ0cLM0ZGM+3LrczblsKk7qF1llcIIUTllC33XiqlrNVcorXW9aKNJTY2Vm/evNnsGEKYq7gIXm4FbcfDNe+anUbUguy8Qr747QhB3q5c2y3EpmUOtdaMfWstClj08IDaDymEEA2cUmqL1rqyvXhsYuvMeMSVvIkQoo45OELroUbfuNYg61E3OF6uTvx5yKX9JFApxZTYUJ6Zv5fr3l+Pp4sjfx0VTUyITy2lFEIIUR1blzY8Ut1XbQcVQlyi6LFwNhUO/mp2ElGPTI4NY0i0P+nZ+exIPs21763n+QV7yS8qrvD6QydzyMotrOOUQgjReFRajCulmiul5iqlRlVxzaiSawJqJ54Q4rK1nwCeQWU3BRKNnqeLI5/e0ZPVjw1h2V8GcXWXYD5ae4jXluwvd21SRi5j3lzNpFnryckvMiGtEEI0fFXNjM8AWgFLqrhmCUYLy6M1GUoIUQMcXSDmWji4AvLPmp1G1EPNPF14ZXJnbuwVzgerE3no6218u+ko17y7jiMZOTzx4y4UioPpZ3ns+53I/m5CCFHzqirGrwJmVbW7ZsnYB8CEmg4mhKgBbcdBcT4clFVJReWeHNeOG3qGsXDXcR6bu5PtR08z6o3VrDlwkr+Pbctjo9uycNdxZpes3lKZ1Kw8Hpmz/bLWMv9g1UG6PbeU2z7ZKLPwQohGpapivAWw14bXiANa1kgaIUTNCusNbn4Qt8DsJKIec3d2ZOa1nVg8fSCzbu7GS5M64enixFWdmnNzrxbcO7AVYzsG8e9f9rEyPq3C18jJL+L2Tzcyb1sK0+dsJ+1Mnk3vrbXm03WHmPnzPkKbuLHmQDov/ryvJr89IYSo16oqxs8B3lWMn+dZcq0Qor5xcDTWGd/7I2SlmJ1G1HORAZ6MjmnOlNgwNj85nHdu7IbFolBK8dKkzkQHeXPnZ5uIfX4pPV9YxsZDmQAUFVv5y7fb2X8im/+7qj1FxZoXFsXZ9J6zVyfyzPy9DIzy54dpfbmldwu+3HCEfalnavNbFUKIeqOqYnwrcLUNrzGh5FohRH3Uf7qxvOGyp8Fa3ZYBQlTM08WRr+/uxf2DIxnaNgCrhvu/3MKCnceYOvt3Fu85wT/GtuNP/SMY0zGINQdOVttjfq6gmA9WJ9K7lR8f3xaLo4OFR0ZE4eHiyKyVB+voOxNCCHNVtc74e8AcpdR6rfXnFV2glLoVuAOYWhvhhBA1wDccetwFG94HN18Y8xKkbIUja+HMcWh/NbToaxTsv70DaXHQaQpEDJL1yUUZvu7OzBgVDUBC2llu/3QjD3y1DYDXpnRmYtcQAHq3asoPW1M4kHaWqECvSl/vm01JZOYUMGNkNE4OlgvvMbpDEL/sSaWgyIqzo00r8AohhN2qtBjXWs9VSr0JfKqUegD4BUgCNBAOjAJigde11vPqIqwQ4jKNegGK8oxlDuN/gayki2Mb3ocp/4FjW2Ht68a57V/CgEdh2D/NySvqvcgAT5Y/Ooj3Vhyke4smDIzyvzDWLdwXgF3JWZUW4wVFVmavTqRnSz9iW/qVGRvVIYjvtiTze2JGmdcVQoiGqModOLXWjyqlVgLTMZY6dCkZygfWARO01nJnmBD1ncUBxr4MfhGw7UsYMAMiBkBQJ3ivD3x7i3Fd15th2FPw4zRY/zb0fRDcmpibXdRbLo4OPDIiqtz5lk09cHa0EHe88r7vH7encDwrj5nXdiw31r9NM9ydHVi8J1WKcSFEg1dlMQ6gtZ4PzFdKOQJNS05naK1l7Skh7ImDE/R72Pgq7ZZ5sPkTiB4NkcONc0P/D2YPgr3/g+6313lUYd8cHSxEB3qxLzW7wvHkU7m8+PM+YkK8GVRBse3q5EDf1s1Yl3DSpvfTWvPwN9vJzCngXxM7Et7U/YryCyFEXbK5GU9rXaS1PlHyJYW4EA1FYHsY98rFQhygeWfwCYMEWZ9cXJ52zb2IO36mwps4Zy7ax7mCYt6+oRuqkvsSekX4cTgj16YlEhftSuWnHcdYm3CS+/67RTYnEkLYFbkzRghRnlLQahAcWg3WYrPTCDvUNsibjJwC0s/mlzl/NDOXRbuPc2f/lkQ086j0+T0jjD7yjYczq32vn3akEOTtynPXxLD3+Bl2pWRdWXghhKhDUowLISrWagjknYbjO8qP7V8Mu+fWfSZhN9o1N7apiDtetlXl9WX7cVCKm3q1qPL5HYK9cXd2YNOhqovxcwXFrNqfzsgOgYzr2ByA9QczKrx2V3IWczYlca5APmAKIeoPKcaFEBWLGGgcE1dePKc1fHcHfDUFvr8Tzla8G6MQHUK8cbAoNiReLIxX7Evjh60p3D+4NcG+blU+39HBQvcWTdhQTTG++kA6eYVWRnUIws/DmRBfN/YeK3/jqNFXvo3H5+7iXmllEULUI1KMCyEq5hkAgTEXi3Gt4Ze/wZ4foPUw49z2L02LJ+o3b1cnekX4sWjXcQqKrGTlFvKPebtoE+DJn4dG2vQavVs1ZV9qNif/0OpS2uI9qfi4OV1oa2kf7M2eY+XbVOJPZJN4MocQXzdW709na9Lpy/vGhBCihkkxLoSoXKvBkPQ7nDsNPz8OG2ZBz3vgpu8htIe0qogq3da3JYczcnlvZQKPz93JybP5vDK5My6ODjY9v29rYwGvylZVKSy2sjwujWHtAi5sGtQ13JeD6Tmc+MONnz/vSkUp+OruXrg4Wliw89gVfGdCCFFzpBgXQlSu3dVQnA//bgEbP4De9xs7eFosxljqLjgjRY2o2KgOQQxvF8gbyw7wy55Upg+PonOYr83P7xTqS6C3Cz9uS6lwfN7WFLLOFTK+c/CFc0PbBgDw676yLVS/7E6lR0s/WjT1oEdLP9YnVNxXLoQQdU2KcSFE5cJ7wbjXILgbXPsRjJ5prLQCxqw5GCuuCFGJR0dGEezjypBof+4e0OqSnutgUUzuHsbK/emkZZed6S4stvL2igN0DPFhcKm1yqMDvWju48qaA+kXzh1MP0v8iWzGxgQB0DeyKfEnsknPrrz9RQgh6ooU40KIqvX4E9yzAjpNLns+MAbcm5a9wVOIP2jX3Jt1fxvKJ7f3wNnx0v/JGd852LhdYXdqmfM/bE3maOY5pg9vU2atcqUUfVs347eDGVitxk2a5587OsZYbaVf62YA/JYos+NCCPNJMS6EuDwWi7HiSuIq4+ZOISqhlKp0c5/qRAV60jnUh9eX7ic1y5gdLyy28vavCXQK9bnQllJa39ZNOZVbSFyqsarKz7uP0zXclyAfVwBiQnzwdnVk9f70cs8VQoi6JsW4EOLytRoM2ccgLc7sJKKBUkrx2tQu5BdZ+ef/dgMwb1sKyafKz4qf1y+yZOb7YAZxx8+wO+XMhTXIwWh/Gd4ukKV7T1BYbK2bb0QIISohxbgQ4vK1GWUc4xeam0M0aK39PblrQCuWxp0gMf0ss1cn0q65N0Oiy8+KAwT5uBIV6Ml/fj/CzJ/34ebkwOTuYWWuGd8lmKxzhXy89tAl58ktKOLpn/bw9E97LszWCyHE5ZJiXAhx+bybQ0gs7JNiXNSuW3q3wMliYcK760hIO8s9AyOqbH25rW9LjmTksnp/Oo+OjMLH3anM+OAof/pHNuPFn/fx5rID/LzrOEcycsjJL2L+jmOcying5Nl8snILyzzvyw1HGPDvFXy2/jCfrT/MQ19vq9Hv81xBMS8v3sfbyw9QUCSz9kI0Bo5mBxBC2Lm242D5M3D6KPiGVX+9EJfB38uFG3uF89n6w7QN8uKqTsFVXn99j3ACvVzx83SmW3iTcuNKKT65vQcPf7ON15ftB6CJuxMeLo4knzp34To3JwecHS3EhHjTxN2ZBTuP06dVU6YPb8OulCyeXxjHjqOnL2nJxqq8+HMcn/92BICMnAKevrpDjbyuEKL+Ug1tS+DY2Fi9efNms2MI0XicOgxvx0LHSTBxFuSfNZY7jBoFFts2dxHCFlprtiadol1zb9yda2YuyWrVrIhPIzE9hzmbj5JfVMyEziHMXpOIm5MD3cJ98XV3ZvORTI6dzmPaoNZMH94GRwcL2XmF9J35Kz0i/Pjo1lgslqpvUn1j2X6cHCxMG9S6wmtP5RTQ61/Lua57KM4Ois9/O8Kb13fh6s7Bl30DrBCidimltmitY6/kNWRmXAhxZZq0hL4PwtrXIG0vZByEgrMw4lno97DZ6UQDopSiewu/Gn1Ni0UxrF0gw9rB3QMvroN+fc8w/DycLxT9WmvyCq24OV/8gOnl6sTDw9vw/MI4vttylKk9wit9n5Xxabyx7AAAUYFejGgfWO6aBTuPUVBs5dY+LWjZ1IMtSad4+Jvt7D12hr+PbVdT37IQop6RnnEhxJUbOAPaTzB+3WEieATAipmQeek3xwlRH4Q2cS8z+66UKlOIn/en/hG0DfLii5LWkopk5Rby3IK9hPi64evuxNwtyRVetzQujYhmHrRr7o2bswM/3t+Pqzo15/PfDpN1rrDC5wgh7J8U40KIK+fsAVO+gHtXw4R34J6VYHGEeffC2bTqni2E3VJKMbVHGHuOnSEh7Wy58TUH0hny6kqSMnOZeW1HhrUNZNPhTP7YIno2v4jfD2YwrNS66Y4OFu4b1Jq8QmulBbwQwv5JMS6EqHk+ITD+DaM7t5sAACAASURBVDi2Dd7tBQd/NTuRELVmTExzlDJ2BT0vM6eAIxk53P/frTTzdGbe/f0YGOVP13BfMnIKOJp5rsxrrD2QTkGxlWHtyravxIT40DXcl/9uOFKugBdCNAxSjAshakfHSXDfWvBoBv97EArPgdUK506bnUyIGhXk48qYmCC++O0Ip3IKWL0/nd4zlzPo5ZWg4MNbY4kJ8QG4sLLLtqOnyrzG2oSTeDg7ENuy/MovN/YMJzE9h81HTpUbE0LYvwZTjCulxiulZmdlZZkdRQhxnn80jHsVziTDNzfCp2PglSg4vM7sZELUqIeHRZFTUESvmcu547NNOFoUN/UKZ849fWjR1OPCdVGBnrg7O7AtqeyH0p3JWXQM9cHJofw/y2M7NsfJQbFs74la/z6EEHWvwRTjWuv5Wut7fHx8zI4ihCgtYiCMfcVoVUmLg+J8+HIyfDQC/jMR0uPNTijEFYsO8uLega0pKLIyoXMwG/4xjBcmdqR9sHeZ6xwdLHQK9WFr0sVZ7vyiYuKOn6FzaMVrlXu4ONK9RRNWHzhZq9/D5dp8OJNP1h6STYqEuEyytKEQovb1vBtaDYEmLeDMMfhxGuSfMYrzuX+Ce1aDpcHMDYhG6vHR0dzRryWB3q5VXtc1vAkfrk4kr7AYVycH9h3PprBY06mSYhxgQBt/Xl4cT3p2Pv5eLjUd/bIt2HmMB74ydiFdl3CS6CAvWvl7cl23EFkbXQgbyb9+Qoi60SwSHJyMgvyORUY/+bhXIXUXJCwzO50QV0wpVW0hDkbfeJFVszvFaKvcmWy0rHQOq/wnuwPaNAOMgrc6eYXF1c5Sp2Xncednm/hxWwrF1su7MfRsfhFPzNtNt3Bf7h/cmuX70nhv5UFmfLeDv36/U2bKhbCRFONCCPN0mAiegbBxttlJhKgzXcKMGfDzrSrbj2bR1MOZEF+3Sp/TIdgHX3cn1lTTqnI86xwjX1/NiNdXkXwqt8Jr8ouKueeLLfy6L43pc7Yz9s01bD966TdWz99xjKxzhTx5VXv+OiqaudP6sOSRgUwf3obvtyTz9Pw9l/yaQjRGUowLIczj6Ayxd0LCUmPnTiEaAX8vF8L83NiWdBqtNesPnqRnhF+VbR0OFkW/yGasOZBe6RKH2XmFTP9mO0mZuRzJyOXRb3dUeN3n6w+z/ehp3ry+C69P7UzWuUJmfLfjkpZOLLZqPl57iLZBXnQN872wO2pUoBfTh0dxXbdQftyWQl5hsc2vKURjJcW4EMJc3W4D5QBbPit7/tBq+OlBWP8OyPrKooHpGtaErUmn2H/iLMez8hjQxr/a5wyIbEZadj4HKthcyGrVPPb9TjYdzuTlSZ34+5i2bDiUyeGTOReuSTl9jpcX7+PNZQcYEu3PhC4hTOwayqMjo0hIO8sPW1OYv+MYmw5nVpvlqw1HSEg7ywNDIyv8EHFttxByC4pZsU82/RKiOlKMCyHM5d0c2o6Fbf+FonzjXPwv8MUE2P4VLHkCNn1kbkYhalj/yGacOJPPw99sw9nRwoj2gdU/p6RvfPX+9DLntdb87Yed/Lw7lRmjopkcG8b4zsGAcYMlGP3dd32+mVmrEgnzc+eFiR0vPP+ariH0aNmER7/bwYNfb2PyrN/KFPF/lFtQxGtL99O3dVPGdWxe4TW9Ivxo5unMgp3Hq/2+hGjspBgXQpivx11wLhM+HWssezjvXgjqCI8fhrBesGGWzI6LBmVcJ6OI3ZeazdTYMJtWSAlt4k6bAE8W7Spb4K5LyODbzcncP7g10wa1BiDY143uLZowf8dxtNb89bsd7D+RzexbuvPL9IEEl+pPd3Kw8MntPZg+vA1/HRWNUvDj9pRKc3y98Sincgv5y4ioSltrHB2MDxir96df9g2iFYk7foa0M3k19npC1AdSjAshzBcxCIY+CbknISMBrEUw8QNw8YKuNxvnjlfc/yqEPfJwceTzO3syvF0gj4yIsvl5U3uEsTXpdJkbLr/aeIQm7k48PLxNmeJ4UvdQ4k9kM/WD3/l5dyoPDIlkWLuKZ+C9XJ2YPjyKPw+JpE+rpvy4LaXCHvKkjFzeW5FAz5Z+xLb0qzJr71ZNyc4vYu+xMzZ/f1VZf/AkY95cQ++Zy3ns+x0XVqMRwt5JMS6EMJ9SMPCv8PAOeGgb/D0ZAtoZY1FjAAX7fzE1ohA1bVCUPx/dFoufh7PNz5naI4ymHs68tnQ/YCxRuGTPCSZ1D8XF0aHMtZO7h9Irwo+NhzOZ0CWY+0pmzatzTdcQDmfkllthxWrVTJ+zjcJiK/+6Nqba1+kV0RSAjTb0oNvis3WHAYgO8ubbzclc9fZa2ZVUNAhSjAsh6p/SP/r29IfwPrBzDlhl3WLRuHm5OnFT7xasOZBOalYe329Jpsiqub5neLlrHR0sfHV3b9Y8NoQ3r++Km7NDBa9Y3uiYIFwcLczbVrZVZdX+dLYmneaJce2IDPCq9nWCfFwJ9HapkRnso5m5LIs7wf2DWzPn3t58fFssMSHeTJ+zvdIlHIWwF1KMCyHqv553QWaisQRiZbKS4fTRusskhEkmdg0B4Il5u/hk7WF6RfjR2t+zwmsdLIowP/dLen1vVycGR/vz/+3dd3hUVf7H8fdJI9TQQgu9hN4jRUB6F7CuIq6IBaxrXX/q2tuuuva6ImJXxEJX6dK79E7ovQYIhLTz++NMTJs0EjIkfF7P4zNz7z333jOZZ/A7Z77ne6atP/hXqkpCouW/UzcRVroo17Sqmu1rNQ0L+WtRo/NlrasUExTgx5B2NSgVHEj3hhX54KZWnD4Xz/iV+3J1fRFfUzAuIhe/hgOhZBVY9GH6Y3ExMO9teKsxjOoJCfH53z+RfFSrfHGubVWVGRsPkZCYyAuDsk4ZyamO9ULZHxXDdk9VlTlbDrNu30n+2bs+gf7ZDx2ahpUm8kg0p8+d3+cyMdHy/sytLIw8yrMDGqdaGKlGueI0rxrCVKWqSAGnYFxELn7+gdB2OETOTj+Rc+F7MP1Z9/zUftjye753TyS/vXx1E16+ugm/3NOB+pWyThnJqQ51XL73/G1HARj/515CigbSL4NShhlpVjUEa2HdeaSqxCck8vAPK3lj2mb6Na3EDRHV0rXp1bgSq3af4ECUKqxIwaVgXEQKhtbDIKBo+sWB1v4M/kHwwGooHgqrf0h/7rZZcHxHfvRSJF8UCfBnSNsa1Cxf/IJcv1b54lQOCWbB1iOciY1n6vqD9GtaiaCAnIUNTcJCAFiTjWDcWsvmg6eIT0gkMdEydPQSxq3cx/3d6vL+4Fb4+aUvo9i7sasOM21D1qPjcQmJfLlwB+MzKdso4gsBvu6AiEi2FC0NDQfA2p+g978hMBgOb4ZD66HPq1CmBjS5zi0QdHQblPNUjlg/Hn64xaW5PLw+9eRQEfHKGEPHuuUZv2ofz45fx5nYBK5qEZbj64SWLELlkGBW78k8GLfW8uQva/huyW4aVCpJeMWSzN96lKf6N+T2jrUyrGdeJ7QE1coWZfbGQ/y9XY0Mr79uXxT/99Nq1u51ZRbLFAviivCsVz0VyQ8aGReRgqPFYIiJgk1T3Pb6cYCBRgPddscHIaAITH3abe/7E34e4Z6f2ufSXEQkW/7evgax8YmMXb6HW9rXoE2tzOuKZ6RJWEiWFVV+WLab75bspmPd8pyKiWfCqn30alQx00Ac3JeGrvUrsGDbUWLiEry2ORMbz22fL2XfiRhevroJ1csW49+/biQxDxcjEskNBeMiUnDU6gylwmDVd2573Tio3g5KuaW/KVkJOj0MmybDn1/DT3dCsXLw4FooWsaNmmckMRE2TIS4sxf+dYgUAM2qluaTv7dm9LDLeH5g40yD4kyvExZC5JFoTsbEeT0+f+sRnh6/jjY1y/LV7W2Y8UhnJt3fkQ+HtMrWPbvUD+VsXAJLM6hn/vmCHRw8eY6Rt7RmSNsaPNwznA37TzIpzUqmIr6iYFxECg4/f2h2A2ydDktGwqF10Oiq1G3a3QtlasH4e105xAFvQ+lqcNmdsHESHFjr/dobJ8GYm+H7IRf+dYgUEL0aV6Jr/QrnHYgDNK3q8sa9jY6fi0/g2QnrqBwSzEc3u+A7ONCfJmEhBGSzakv72uUpEuDHb2sPpDs2dd0B3p6+hR4NK9K6hhvZH9i8Cg0qleTNqZvSjaaPnBPJG1M3kZCDUfOdR6O1GqjkioJxESlYLr8fytSEKY9CUElofmPq44HBcPs0GPAO3LcU6vV0+9vdDcYf1v3i/bpJKSzbZsDZ3NVFFpFkTcO8B+N7T5zlsR9Xs/XQaZ4b0JhyJYqc1/WLBvlzZbMqjPtzL6dSjL6fionj/35aTe3yxVOtGOrnZ3iyX0N2HD3DOzO2/LX/8KlzvDxlA+/N3MrUdekDe282HzxF/3fnceV783h4zEqOnj53Xq9BLm0KxkWkYClWFob9Bp0fh5vGuImdaZUIhda3Jk/iTDqveruMSx/unA/BnmttnZ7n3Ra5VJUrUYSw0kVZtTs5GB+/ci8dX53J+JX7GNq+Bl0bVMjVPYZeXoPo2ATGLtvz177R83dw/Ewcr13XjAolg1O1vyI8lAHNq/Dlgh1EHj4NwDszNv91fM6Ww1ne01rL0+PWEp+YyDUtw5i0ej8D35/PsejYXL0WufQoGBeRgqdkRej6BNTskLPzanZyaSrnTqXef+40HN4EbUdAcAhs/yPv+ioitKlVlkWRR0lMtOw9cZanfllLo8ql+OaOtjwzoHGur9+samna1CrLC5PW89pvGzlxJpaRcyLp1agizap6+cIO3N+tLv5+hptGLmbmxoN8s3gXt15ek56NKjJv65Es7zlh1T4Wbz/G01c24s0bWjBmRDsOnozhxUnrc/165NKiYFxELh1VIwDrqqykdGC121+lFdToADvm+aJ3IoVWh7rlORody8LIozzyw0oSreWjIa3pULc8/l7qh5+Pd29sSZOwUnw4exvt/j2D6Nh4HuoZnmH78Iol+eaOdhw/E8ttny+jYslgHuoZTse65dl97Cy7jp5J1T4uIfGvUfS4hET+8+tGmoSV4sbLqgPQsnoZ7ulal1/+3Muoedu93vOHpbt5c+omDp7UIkWSTHXGReTSEdbaPe5dAbWuSN6/Z6nneCs4ts2VTozaCyE5r6ssIun1alyR6jOKMeTTxQC8dm0zqpcrlqf3qBQSzNgRl/Poj6s4Hh3Lgz3CaVi5VKbnNK0awrh7OzB13UEGtahCSNFAOtQtD8D8bUeoXs4F2gmJlsGfLGLZzuM82a8BtcqXYH9UDC8MapLqy8T93eqy5eApXpq8ngolizCgeZW/jn23ZBdP/LwGgB+X7+GXeztQsVQwB0/GsGDbEbrVr0hIscA8/ZtIwaBgXEQuHcXKusV/Dm1IvX/HPCgfDiUquFSWpH3Nb8j/PooUQqWCAxl5SwS3fb6Ufk0rcX1E1Qtyn6JB/nxwU6scndOwcqlUQXud0OJUKhXMvK1HGNzGBePj/tzLsp3H8fczvDJlIwBVQoLpUj/1wkGB/n68dUMLjoxazCNjV9G6RhmqlC7Ksh3HeGb8WjqHh/JQz3CGjFxE21dmcEv7Gvy69gCHT52japmi/HT35VQslTq/XQo/pamIyKWlQkO3ameSmCjYMT85CK/YxE3k3DHHN/0TKaTqVyrJ/Me78a/+jXJVKvFCM8Zwed1yLNh6hPiERGLjE3lr+maahoWw6cU+3Hp5TcIrluDtG1sS6KX8YnCgP2/d0AKAYaOXcuT0OZ78ZQ2VQoJ5d3BLWlQrzdd3tCWiRhm+XLgTa+GFQY05Hh3LTSMXsc2TCiOXDo2Mi8ilpUJDWDIPEuLAPxBWfAVx0dDyZnfczw9qdlTeuMglrHfjSvy8Yi8zNh5i1e4T7Dl+lpevbkqAvx/PDcx6wmnVMsX4bOhl3PbFUiJectWZPhrSipCiLg2lZfUyjL2rPduPRFOldFGCA/0Jr1iSe75ZwS2jlvBAj3ociIphUIsqFC8SwMi5kXQOD+XyOuUv6OsW3zDWFq7lYCMiIuyyZct83Q0RuVit/Ql+vA3unOVGwd9r7RYFGjYluc3i/8Gvj8Hw2VClpa96KiI+Ep+QSOfXZ7P3hFuRt3fjinx8c+scj+gv3HaUD2ZtpX2dctzbtW6W7VfvOcH1Hy/kXHwiAIH+bhGkUzHxALSqXpq2tcvRunoZggP9SbSWZlVDKF0sKIevUPKKMWa5tTYiV9dQMC4il5SoPfBWY+jzKsSehpkvwpCfoF6P5DYxUfBOC6jYGIZOhOz+D/jMMVj8MYRFQHivC9N/EckXq/ec4M1pm+lYtzy3d6yVb6k16/ZFsfXQaVpVL8PIuZFsOXia+7rVZc7mw0zbcJCdR8+kWiG0TLFARt16Ga2ql8nRfay1F3W6UEGhYNwLBeMikqW3m4F/EJzYBfX7wt++SN9m8Sfw6z+h0yPQ/ZmsrxkXA6P7wr4VgIEbv4EG/fO86yJyaTsWHcuKncfx9zckJrqFh8qWCGLifR2zHVy/PHk9Py7fQ8ngQEYNjaBexZIXuNeFV14E45rAKSKXnvr94OgW8AuAvq96b3PZ7dDy7zD3DVg9NvPrJcTDz3e4QPyaka5E4o+3u/Nio/O+/yJyySpbPIgejSrStX4FujesyN1d6rB270lW7YnK+mRg3pYjjJy7ndCSRTh+JpYRXy3n9Ln4PO/n6j0n+HrRTnYe1b+BWVEwLiKXnojboF4vGPwdlKzkvY2fPwx4Fyo3hxnPw9njGV9vwTuwYSL0+Q80+xsM/h5KVXEB+qjeEHsm43NFRHLhqpZhFAvy5/P53hcaSuvLhTsoXyKISfd3YuQtEew4Gs2bUzfnaZ8WRx7l6g8X8NS4tXR+fTbPT1xHYcvEyEsKxkXk0hMaDkPGQu3Ombfz84N+b8CpA26kOyEufZuovbDgPRfct7vb7StRAe5dDNd8CgfXuDxyEZELoGRwILe0r8m4lfv4fsmuTNvGxCUwe9NhBjYPIyjAj3a1y3FVyzC+X7qLqLNe/n07T58v2EGp4ADG3duB61tXZfT8HYycG5ln1y9sFIyLiGSm2mXQ/w3YNgPG3grx51Ifn/gPF6T3fDH1fv9AaHY91O3pgvVzqh0sIhfGwz3DuSI8lH+NW8v8rUcybPfnrhPEJiTSoW65v/bd3rEWZ2IT+C6DQD4x0fLJnG088sMqRs/fnuUI99HT55i+4SDXtqpKi2qlee26ZnRvUIF3Z2wl6kzeBfyFiYJxEZGstB4KfV+DjZPg404w53WXJx45G7ZOhy6PQ4UG3s/t8jicPeZKJSYm5mu3ReTSEBTgxwc3taR2+eIMG72UmRsPem23YNsR/AxE1Cz7177GVUK4vE45Pp+/g7iE9P9GfbFwB69M2chPK/bw/MT1jF22J9O+/LRiD3EJlusjqgFuEaUHe4Rz+lw8E1btPf8XWYgpGBcRyY62I+C6z6BYOZj5EnzWy9UrD6kOl92Z8XlVI6Dz47DyG/jiSlf+UEQkj5UMDmTsXe2pVb44L0xcn6r8YZJf1x6gTa2yfy0+lOSOTrU4cDKGKWv2p9ofn5DIp3O3c1nNMmz/dz8aVi7FqHkZj47HxCXw6dzttK9djvqVkiu0NAkrRYNKJRm7PPNAPsmlll+uYFxEJLuaXAu3/eomdp47DaWrww1fQWBw5ud1eRz6vg67l8DPwzMeIT++A769weWoi4jkUOliQTzUsx47jp7hoTEriU5RJWXzwVNsPXSa/k0rpzuvS3gFaocWTxdoT99wkL0nzv5VZ31I2+psOniK9ftPer3/2GW7OXTqHPd3T73AkTGG6yOqsXpPFBsPeD83yfMT19H9zT84Fh3r9fjZ2ARW7znx1/GYuIRMr1cQKBgXEcmp1kPhviWeFTpbZN3eGGg7HHq/AlunwZbfvbeb8hhs/g0Wvp+XvRWRS0jvxpV4qEc4E1fv4+5vVnDijAtaJ63ahzHQu0n6ClJ+fobbOtRi9Z4olmxP/vXux+V7qVQqmJ6N3Dn9m1YmwM8wYeW+VOfHxidy6FQMH83eRkSNMrSvXY60rmpRhQA/k2may4pdxxk9fweRh6N5cMxKEtOM7h88GcOV781l4PvziXhpGhEvTaPhM7+lG9EvaBSMi4jkl9a3QlAJ2OwlGD93CiJnuecrv3WLCImI5JAxhgd61OOVq5uyYOsRur/xB+/N2MKXi3bSOTyUCiW9/5J3bauqlCsexPuztgJwMiaOOVsO07dpJfz93GJCZYoHcUV4KBNX7fsrDWbpjmO0eWU6bV6ewf6TMTzUM9zr4kPlShShd+NKfLt4F1sOnkp3/PS5eN6YuomSwQH8q19D5mw+zIezt/51/ExsPLeMWsKBqBhevbYpN7apzhX1QqlfsSTPTVjHufiCO0Ie4OsOiIhcMgKCoHYXN+nTWjdinmTLNEiIhSv+6SaIrh8HzW/0VU9FpIAb3KY6TcNCeGXKBt6Y5uqIP9qrfobtiwb5c+cVtfnPrxtZvvMYi7cfIzY+katbhqVqd13rqtzzzQomr9nPwOZVeGf6FvyM4f/6NKB1jTK0qVU2gzvAMwMasSjyKCO+Xs4t7WrQtGppWtcow8mYOK76YD6Rh6N58aom3Ny2Omv3RfHmtM10rBdK86oh/OuXtWw+dIovhrXhivBQbrjMXTPy8Gli4hIpEuCf+z+aj5jCliQfERFhly1b5utuiIh4t2w0THoQ7lkEFRom7/+sL0TtgX+sgA/bQ3AI3DnDd/0UkULBWsv3S3cTUjSQfl7yxVOKPhdP1//O5tApV8K1S/1QPh/WJlWbxERLz7f+oGRwIE/1b8h1Hy/k0V7h3NetXrb6szjyKMM+X8qZWDeS/fHNrXlp8nr2HD/Le4NbMqB5FQBOxcTR7Y0/KBbkT5MqIUxes59HeoZzf/fs3Se/GGOWW2sjcnMNpamIiOSner3c47pfkved2A27FkDEMFefvNXfYe8yt19EJBeMMQxuUz3LQBygeJEAvhvejra1ynJd66p8fHPrdG38/Aw3ta3Byt0nuP5/CwkrXZRhHWpluz9ta5dj+sOdeXdwS8oVD+Kur5dz8GQMo4dd9lcgDq46zEdDWhF1No7Ja/bzt4iq3NetbiZXLriUpiIikp9CwlxAvnQUtL0LipVNntDZ4Er3GN4Xpj0Dm351Ez8BNk6B1WOg14uuiouIyAVQJ7QEY0a0z7TNkLbVORB1lsOnzvFwz/oUL5KzcLJK6aIMLF2U0BJFmLf1MD0aVqRl9TLp2kXULMuk+zsSeTiajnXLe81FLwyUpiIikt/2r4KR3dyEzv5vuBSVM0fg3iUuj9xa+KSzm9R571I4tQ/eaQ42EYqWdSkuJSv6+lWIiFzylKYiIlIQVW7uJmf++Y2rnLJrgdtOGvUxxk3kPBYJa3+CGS+A8Ycbv3Orea4f79v+i4hInlEwLiLiC1c8BkHFYNzdUKIiRNye+nj9/lChEfwyHNaMhSsehQb9oHx92DjJN30WEZE8p2BcRMQXytRwiwb1+Q/c9jsULZ36uJ8fdHnCPa/ZCTo96p436A875sGZY4iISMGnYFxExFdKV4d2d0PZDCoRNBoID2+EWyaAv2eCVMMrwSbAlqnZv8+f38C4eyH6aO77LCIieUrBuIjIxaxUZTdKnqRySyhZBTZMzN75MSdhyqOw8muY/e8L00cRETlvCsZFRAoSPz+o3we2zYKEuNTHvFXH+vX/IO4shDaEld+4hYVEROSioWBcRKSgqd0F4qJh7wq3ffqQS0N5s5FbTCgpKN84GVZ9C50fg5vGuP2zXvFVr0VExAsF4yIiBU3NTmD8YPNvkJgI397g0lBO7YOxt8KKL127+e9CmZquckuZGq6u+eoxWtlTROQiomBcRKSgKVYW6vZwNcrH3wv7VsCAd+HpIxDWGhZ+AMd3wO5F0HpY8uTP9ve6x0UfZe8+pw7CdzfBn19fkJchIiIKxkVECqaOD0P0IZeGctkd0OoW8A+EJtfCkU3w83DXrvFVyeeUrgbhfVwqS2Ji1veY8QJsmgwzX74wryGtsye8572LiBRiF3Uwboy5yhgz0hgzxhjTy9f9ERG5aNRoD3fOhOu/gL6vJa/e2XAABATD7sXQ9i6XppJSwwEunWXND5lfP/qoW2wIXPtDG/P8JaTy25Pwag34/EpIiL+w9xIRuYjkezBujPnMGHPIGLM2zf4+xphNxpitxpjHAay146y1dwJ3ATfkd19FRC5qVVq6kW8//+R9pavD8D/g5p/dgkJpNboKqrWDX0bAH69lfO3FH0PCObhlvNvObinF87FxCiz6wK04unMeLBt14e4lInKR8cXI+OdAn5Q7jDH+wAdAX6ARMNgY0yhFk6c8x0VEJCsVGkDd7smj5SkFBrsAu8l1rrLKiV2pjx9YC283hTmvuZSX2l2gahvYMOHC9PXPr+H7wRDawK1IWqcbTHsWNudgUSMRkQIs34Nxa+0cIO06zm2ArdbaSGttLPA9MMg4rwK/WmtX5HdfRUQKpcBg6PGcC9aXf5762NKRLkCPuB0GvOP2NRoIB1bDse1524+4GPj9X1CxiRvJDygCgz6EkKrw6z/zPl1l5kuu8kz0kby9rohILlwsOeNhQMpaW3s8++4HegDXGWPuyuhkY8xwY8wyY8yyw4cPX9ieiogUBqWrQb3esOIriI91+45ug1VjoPlguPJNKFLS7W/Q3z1u/j3za8ZGw5KRMPtV2L006z7smAsxJ9wXg5Awt69UZej+jKsGs2H8ebywDCTEw5zXXTnIac/k3XVFRHLpYgnGvbLWvmutbW2tvcta+3Em7T6x1kZYayNCQ0Pzs4siIgVXxG2uIsvGSZCYAOPugYAgFwynVLY2lKsHWzIJxhMTYMzfYcqjMPsVmPJI1vdfPw4Ci7m66Sk1uBLK1oGleZg7vneZeyxeAVb/AOdO5d21a++b4QAAIABJREFURURy4WIJxvcC1VJsV/XsExGRC6Vud1dtZfZ/YOH7ri5539egVJX0bRsOgMjZcGQrnD3uRpd3LnDHEuJg8iOwbQb0fxO6PAH7V8HJfRnf+/RhWD0Wmv3Npc2k5OfnUmN2L4aYk9l7LbNfhQn3w5m0WZAeW2e4hZL6vwGJce61iIhcBC6WYHwpUM8YU8sYEwTcCFyg2UIiIgK4Kiz933R1yac940aom2VQuKrdPeBfBGa+4EbA578Do/vCcyHwYnlYPhou/wdcdjvU81Si3ZNJqkpStZZ293o/Xqc7JMa7VJasRM52o/ErvoTx93lvs22mWxCpfl9X+nHXoqyvKyKSD3xR2vA7YCFQ3xizxxhzu7U2HrgP+B3YAPxgrV2X330TEbnk1O0O3Z6G8uHQ/VnvFVgASoRC2+GwfrwLkAe8C71egkpNXdWVG76GHs+7thUaAgYOrvd+rc1TYe4b0PgaCA333qZaWwgs7ka0s7J0FBQrDx0ehE1T0leIOXPMrVJap7tbGKlCIzchVUTkIhCQ3ze01g7OYP8UYEo+d0dERK541P2Xla5PQfFQV4awXk+37/L707cLLOryzA95GVNJiIdJD0HFxnDVhxnfKyAIanVyI9qZOXvCTcqMuB1a3wrz33Z1y9ulmPMfORtsovviAe4LxPrxbrXPjL58iIjkk4slTUVERC52AUEu+E4KxDNTsREc2pB+//pxcHIPdP2XC9ozU6c7HN8OxyIzbrNxMiTEQrProWwtKFklebJmkm0zIDgEqrRy25WbuSouUXuyfh3exEbD19fCB+2yrjAjIpIFBeMiIpL3KjR2QXTc2eR9507Db4+7kemkvPLMJI1kb/ot4zZrf3KTUJMC7aqtYddiSEx029bC1plu8SJ/z4/BlZq5x/NJVUmIg5/uhK3TXfnFKf9MvpeIyHlQMC4iInmvQkOXGnJ4Y/K+5aMh+jD0eyM5MM5MuTouyF7xhQuq0zqx26WgNL4mOd2k0VUQtQvW/ey2D2+EU/vcKHuSio0BAwfW5Px1TX0aNk12VWcGvQ8ndsL22Tm/joiIR6EJxo0xA4wxn0RFRfm6KyIiUrGJe9y/yj2ePgR/vO6C4upts3+dFje5gProtvTHpj3jJmRGDEve1/gaCKkO635x20kTQOumCMaDikO5urA/hyPjq76HxR9B27uh7QhX7rFoWVj0kfcvC+fjwBr4uCP88VreXE9ELnqFJhi31k601g4PCQnxdVdERKRcHShVNTmneuaLEHfGjSjnRN0e7nHr9NT7dy5wo98dHoTS1ZP3+/lBnS6wfa6bLLr2J/fFIKRq6vMrNc16ZDz2DMSfc6Pviz6CiQ+48o+9XnTHA4pAx4dgy1Q3ITS3rHULLx1YA7Nehh3zc39NEbnoFZpgXERELiLGuJHjTVNg2WduVLn1rVC+bs6uU7YWVG4O895KXgDIWpj6FJQKgw4PpD8nvA+ci4I//uNKGra4KX2bys1cOktGiwQlJsKoXvBSRfhykMt1L1cXrhvtRuOTtL/PVZjJKhi31o3kr89kCY1dC10ee59X3ReZiQ94/0VARAoVBeMiInJhdPuXK4M46SG33f6e87tO/7fg9AFY8J7b3r0E9i6HTg9DULH07ev1cgHynNehRCVoNTR9m6QJn7uXeL/nhglwcI1bIKjXS/CPlTBijqu3npKfnwv+t06H+Fjv1zq6Dcbf6xZK+uHvcHK/93brfoGAotDqFlf2MfoQvNca5r7pvf3FJPaMe9yzHLZk8rcQkXQUjIuIyIVRpCT0eM7lcA9419UePx9VW0P9fm4CaEI8LP8cgkpCc6/LVriR66v/51JR/vYFFCmRvk21ti7wjZyVer+17vpTn3Ij4U/udeUcy9ZyK5Z6U78fnDsJO72klUx92gXUa36EGh3dvsjZ6dtZ66rG1O7ivmDU7gx3L3STTee+6copXoyij8D3Q+DfVeGra+DTbvDNtfBpdzi23de9EykQFIyLiMiFU78vPLQGWmQQOGdXiyGuEsuG8a5WedNr3UTMjNTtDnfNg+rtvB8PDIY63WD1D8npL+AmfE58wF37yrcyDsBTqt3FjaBv+jX1/i3TYMG77kvDQ2th6EQoWsatYJrWoQ0ubaZ+n+R9IWHQ73WIPQXrxmXdD1+Y9KB7neXquAWaGg6Eqz52VWbGnecvISKXmHxfgVNERCTH6vVygeyPt7ntln/P/TU7PeJGctf8AJfd4UanZ7/iRvJHzHWLHGVHUDGo3dUF431fdQsKfdbHVYEJbQAD3naTPQHCIrxXcdky1fM6e6feX709lKvnyju2HHL+r/VCOLIVNkyEzo9D1ydcDfakfPqTe2DmS678ZOlqvu2nyEVOI+MiInLxCwiCdve65/V6Q1jr3F8zrJULdNd6yiBumepy0a94NPuBeJIG/dzI9sF1MPs/LhCv3RUGf5cciAOE1ocjmyExIfX5B1a7qjClKqfeb4zLId+9GA5t5KKy+nswfm5iLqSe2NrkOve49qd875ZIQaNgXERECobO/4R7FsON3yQv8pMbxkDLm2HnPPj1cbeaZuka3quvZCW8D2Bg7huwZCRE3Aa3jEufJx9aHxLOuTSOlA5thNCG3q/d/Eb3uGFizvt1oSQmwuoxUKtz+i8Q4HLswyIUjItkg4JxEREpOCo0SD0Cm1ttR7iAefFHcO4UXPPJ+V2/RAWo0cHVPg8sCl2f8t4utIF7PLwpeV9CPBzd4l5bRteu3NzlZGdH3Fn3X2aObHWLC/1wC6waAzE5XDBv9yI4sSv5i4I39fu4Ef/oIzm7dkYSE1xFnZkvwa7FbiEpkUKg0ATjWoFTRERyLLAoDJ0E13wKj27OeMJndnR9wpVUvOYTKF7Oe5vy4e4xZTB+fDskxCYH6t7U6QZ7lqSebOpN1F54vw2M6glxMd7bJCbCT7e7xYW2zYJfhsNPd2Z+3bRWfQ+BxaDBlRm3qd3VPW6fk7NrZ2TjJFflZs7r8FkveLupq0AjUsAVmmBcK3CKiMh5CQmDZtfnfsS9Zkd4dAs06J9xm6KlXe3zlMH4oQ3uMdNgvDskxsOOeRm3ObjeLVAUtcsF2os/9t5u9RjYvxKu/gQei4TG17h8+cObYfrzbuQ5MTHj+8SecTXRGw70XjYySeUWrnzknqUZt8mJdb+4Lzt3zHQrr5arB2OGeJ8QK1KAFJpgXERExOeyk8seWt9N8EyS9Dy0fsbnVGsDgcUzTlXZOBlG94Wo3TDoQzeSvvhjVyEmpZP7YfqzbtGjpp4vIL1egqAS8MFlMO9NN/KcWQC9YYKrq94qi4o2/gEuvWbv8szbZUdsNGz+3X0BqNoaej4PQyeA8Yc/v8799UV8SMG4iIhIfqrY2I2GJ8S77UPr3cTRzOqmBxRxI+/egvFj22HsMFeN5a75rgRiw4Fwar9b/TPJtpnwXiuXa937Fbd6KLhfBm740lWo6fki+Ae5gNubxARYOsrl2dfokPVrDWsN+1ZmnDKTXevHQ9wZaHxV8r5iZSG8l+tr2i8dIgWIgnEREZH8VKUVxJ9NHhHfs9yVWcxKnW5wbBsc35F6//LRLoXlpjFQvq7bV7OTe0xaYMhamPaMS/MYPhtqtE9/7TtnQod/QI3LXS65N7894XLXOzyYvV8BanVy1WP2LMm6bUYSE91ofaWmyauYJgnv4750HFp//tcX8TEF4yIiIvmpSkv3uG8FnDrgcryrXpb1eXW6uceUgbK1rk563R5Qqkry/nJ1oGTl5BzzDRNdHvkVj0KVFpnfp2YnOLQufRWUfSthyf+g7d3QemjW/QU3mm/8IXJ29tp7s3M+HIuEy/+RPJqfpE5397h1+vlfX8THFIyLiIjkp7K1oUgI7PszudJItWxUcSlfz60OuubH5H2HN7lgvn7f1G2NcYHwjrluZHn+O27CY/Ns1FCvdYV7TDtZdOH7EFTSVY3JriIloXIzV4rwfK38FoqU8l65pVRlqNhEwbgUaArGRURE8pOfH1RpDntXwKYpULxC8mh5ZoyB9ve6RYoi/3D7tvzuHuv1TN8+vA+cPgjTnoa9y9xKmf4BWd+nSks3WTQpxQXcxM+1P7sR8eAcVi2r1s5N4kyIy9l54Gq/rx8Hja+GoGLe29TtDjsXwrnTWV8vJgrOHMt5P0QuIAXjIiIi+S2stSsvuO4XCO+dPv0iI61vhVJhLocaXIWRCo0hpGr6tg0HurYL33dlE1venL17+Ae6nPLtKYLxDRPAJkCrbKanpFStjcuRP5BJCcL4c7Diq/S56kkTN1sMyfjcOt0hMS71lwdvDm2Ed1vBuy3gwFrvbcbcDG83gxO7M7+WSB5SMC4iIpLfmv4t+XnaFJPMBAZDxG0u8Nw4xeVTp6wwklJAEAydCJ3/D4b96mqcZ1fNTnBkE5w66LY3TYHy9SE0PPvXSFKtrXvcncEkztOHYHQ/mHAffHUVrBuXfGzlt1CurgvoM1K9nRvJzyxVJeYk/HgbxJxwo+Nz/5u+TdQel1t/Yies/TH9cW+shfH3wgvl4dWaMPkRV3FGJAcUjIuIiOS3io2g7+tutDppEmJ2Nb8R/IvA94Nd7vlld2Tctlwd6PqkKwOYE7VSVGNJiHOBdO0uObtGkpAwCKkGu73kjScFswfXwTUj3UJBvz4GZ0+4CaM750OLmzKv3BJQxOW5b5mWcYnDeW/B4Q1w0w+uEsy6ce76Ka0Z67lecOpfBTKzbYarc97wSteHpZ+66jYiOVBognFjzABjzCdRUVG+7oqIiEjW2g6HQR+40e6cCKkK1450C+oMeDvngXZ2VGruJk3umOupE37GjUCfr2pt3STOtMHy2p/c6p89noVmf3OvJ/owTHrQjWSXrAyth2V9/brd3Yj2scj0x+JjYfnnbmXUut2h08PuV4J5bya3sRZWfuf62fLvsGuROy8rK76EYuXcaqbXfwG1OsPv/3KvK60Tu+B/nV0qTMq89fhY2DLdVdaRS1KhCcattROttcNDQnI4sURERKSgaTQIRsyBJtdcmOv7B7h641tnwKyXXRWV2l3O/3rV2sKpfW6FUHALFX03GCY95PLn2wx3+6u0hPb3uVz6Y9vg2k+z92Wjbg/36C1VZcdcOHsMmg9228Eh0OoWl5KStIhS5CyXltNqqPtVIC7alZ7MTPQRlyrU7EaXEmSM+zIRUg1+uiP1yqCJifDzCDdPYMNE+Ohy+OoaF8yP7gvfXAvvt3ETUbMr/pzLg1daTIFXaIJxERERyUPNbnDBc+Qs6Plc7kbg63QD4weLPnaLFn032JVOrNnJjSr7+Se37fEc9PsvDJ3kyjNmR9laULYObJyc/ti6n11OeVKddoAr/ulKPU58wAXVCz90VW2aXpe8sFBWqSorvnATR1NOjC1bG4bPgqptYML9ySugrvwGdi2Age/BHTPdKqfbZrg2+1dCj+ehRCh8OdB9EcnK0lHwTnP4sC18OcjlxOfEmWPui0vSnADxKWML2RKyERERdtmyZb7uhoiISMGWmOhGxSs0dEFqbo2/D/78yj0PKOpWDK3dOffXTfLHa66/I+a4FB5wwea7LaDJtTDo/dTtN/8O36aYSNvtabcoEsBHHdyXj6ETk49HznZ56d2eAr8AeKO+G8m/2UtKyulD8E4LN+H1lvHwvytcOssdM9wIemKCm0i6baZbfbVsbYg+Ct9eD0e3wv1/QvFy6a+bmAgznnN14ys1c79WLPrQvb5rPsne3ykhDj5sD0e3QHBpt/JquTpZn3fmGJw7CWVqZu8+W6bD5l/drytFy0D//7pfQQoZY8xya21Ebq6hkXERERFJz88Puj+dN4E4uCC2fH2o3w/uX5a3gTi4so8lK8Mvd7vt+FgYO9Tlg19+f/r24b1hxFy3mFCbEdDhgeRjNTu5Savx59z2zgVuBHrh+zDnvy715cxRV9nGmxIV4LrPYP9q+E9192tAx4eTJ6L6+btgv+l1LhAHF3wP+sCNco8dChsmpb/urJdcIN5iCNz2O/R60eXUrxsHZ49n7++0YaILxC+/330pmPlS1ucseM+NxL/T3Hs+fFqRf8A317lylSUrwan9MOYWiI3OXh8vMQrGRURE5MIrWQnuWwKDv/NeFz23SlRwAfWhdW4i59KRsGuhGxEPre/9nMrN4MZvoN9rrr56klpXQHwM7Fnqtv941dVsr98f5r/tRvmLlEqd+pJW/T4w4B3wC3RfFBr0z/o1VGjoXsOOuTBmCKwa475MHFwPs16BuW+4fPdBHyQvgtT8Rkg450bts2PLVCha1qXGRAxziyp5m/ia5NBGmPq0WwG2ZBWY/pwboc/M4v9B8VB4fCfc9pvL/T+5x5WqlHQUjIuIiEjhEN4HMPBZX/j9SVc28nxG9mtc7nLct81y1WQiZ7vAdeB7bgGl0weh/xsQWDTz67T6Ozx10AXlmZVnTKnn8/Dkfqh+uZvg+tXV8FF794Wgfn+XT5/yWlVaucB3o5eRdG8iZ0Odrm50vt09YPxdDnpGVn/v2t40Fnq+4KrC7F6UcftTB2Dzb64kZdLfp0YHCItwKTVZBfLb58D05yEhPnuvpxBQMC4iIiKFQ9la0PsVV3s8LAIGvnt+1yla2o16z/0vjOrlcqsvu9Olktw1Dx7f7UoxZkfKyanZFVQMrh/tRvS3/wFt74L7V8Dgb91rS3V9PzfZdv2EjBdWSnLqgEsZqepZRKlUZfc610/IuEb7Ns+E1OLl3AJVAUVhTSaLIs1/17Na6y3J+4yB9ve4EfjNv2V8rrVu4aR5b8LkhzPuUyGjYFxEREQKj/b3wIOr4c4ZuUuH6f6sq7BSoQEMm5K8gqkxySkiF1LJSm5y5RN7oe+rmU+y7PwYlK4GPwx1k0czcmCNe6zUNHlfwwEQtQv2r0rfPvqo21+nq9suUsIF5OvHea/DfnCdG/1uPSx9fxsOcmUf57+TcZC9fyUc2ewmeq74wuWqp3X6sLsPuF8tRvWGTZkE+AWAgnERERGRtCo3g0c2wp2zoGJj3/Qhu4F/cAjc8LWrpz7hHxkHu0mrjlZqkryvfl+XkrNhYvr222cDFmp3Td7X4iY3eXX9uPTtF7wPQSWg+zPpj/kHQMeHXIpLRik1O+a5xxu+dhN9/3jVBd9Jdi6AD9u5Ou0vlIdPurjrTX4E4mK8X7MAUDAuIiIi4o2f//mlmfhC5ebQ9UlXTnD7H97b7FoAFRq54D1J8fJu5dBV37myhyltmwVFQlwJxyR1ukOZWrDq+9Rt42Nh02RoNDDjmvSthrr7T30quVJNSpF/uHrxpaq4/PS4s/D7E2711lG93QJJxg/a3euq4bQdAf9Y6cpH5nQl24uIgnERERGRwqDNCChREZaMTH8sIc4Ftd4WUmo7Ak7uhfXjk/dZ6yZ71urkRrWT+Pm50fQd8yD2jNt35hgs+Z+rnd7oqoz75x8AvV5ypR7np8nnjznpvkSE93Hb5etBxwdhzVj4rJcrx9j9Gbh7AfR5xVXB6fuqmydQvm52/joXrYCsm4iIiIjIRS8w2AXKa35yI9UBQcnH9q2EuGhX2SSter3diHTSAkLGuNztqN0utSStBv1d24Xvu1H2Xx9z+6u1hXo9M+9j3e7Q+BpXM93PHzo97PYvHQkJsdA4RTDf/RkICHZfCq76MPsLDhUwhWZk3BgzwBjzSVRUlK+7IiIiIuIb9XpB7CkXwKa0Y6579BaM+/lBu7th73LYvdjt2zDBPdbvm759zY4uaJ/1sgvEa3SAQR+61UizU8Lxqg/dOfPfcekqcTEw7x2XJ16tTeq2nR9zE2gLaSAOhSgYt9ZOtNYODwkJybqxiIiISGFUtycUKw+LP049kXPLVKjQGEqEej+vxU3uvFmvuLSTxf+DGh1d/rY3gz50FWe6PwM3/QAth0CRktnrY2BRN+Iec8L1a90vcC4K2gzP2WstJApNMC4iIiJyyQsIcrnW22bA5t/dvhO73WqkTa7O+Lyg4tDpEZe3/Xl/OHsc+v4n4/aBwS7FpNMjruRhTtXu6kpHznkdfv0/qNTMrXx6CVIwLiIiIlKYtL3bLV2/8H03Or7Ws0hPk2szPy/iNreiZ3wM9H0tdT3yvOYf4AL5/avcqPiAtwtO5Zo8pgmcIiIiIoWJfwB0+Af89jh83AmObHKraJatnfl5gcEwfFb+9BGg3V0u4I8/6xb6uUQpGBcREREpbNqMgOgjnvSUa6HLE77ukXc1vUwovcQoGBcREREpbPz8oPvTvu6FZINyxkVEREREfETBuIiIiIiIjygYFxERERHxEQXjIiIiIiI+omBcRERERMRHFIyLiIiIiPiIgnERERERER9RMC4iIiIi4iMKxkVEREREfKTQBOPGmAHGmE+ioqJ83RURERERkWwpNMG4tXaitXZ4SEiIr7siIiIiIpIthSYYFxEREREpaBSMi4iIiIj4iIJxEREREREfUTAuIiIiIuIjCsZFRERERHxEwbiIiIiIiI8oGBcRERER8RFjrfV1H/KUMeYwsNMHty4PHPHBfSVv6X0sHPQ+Fnx6DwsHvY+Fg97HjNWw1obm5gKFLhj3FWPMMmtthK/7Ibmj97Fw0PtY8Ok9LBz0PhYOeh8vLKWpiIiIiIj4iIJxEREREREfUTCedz7xdQckT+h9LBz0PhZ8eg8LB72PhYPexwtIOeMiIiIiIj6ikXERERERER9RMJ4HjDF9jDGbjDFbjTGP+7o/4p0xppoxZpYxZr0xZp0x5gHP/rLGmGnGmC2exzKe/cYY867nfV1tjGnl21cgKRlj/I0xfxpjJnm2axljFnverzHGmCDP/iKe7a2e4zV92W9JZowpbYz50Riz0RizwRjTXp/HgsUY85Dn39O1xpjvjDHB+ixe/IwxnxljDhlj1qbYl+PPnjFmqKf9FmPMUF+8lsJAwXguGWP8gQ+AvkAjYLAxppFveyUZiAcesdY2AtoB93req8eBGdbaesAMzza497Se57/hwEf532XJxAPAhhTbrwJvWWvrAseB2z37bweOe/a/5WknF4d3gN+stQ2A5rj3U5/HAsIYEwb8A4iw1jYB/IEb0WexIPgc6JNmX44+e8aYssCzQFugDfBsUgAvOaNgPPfaAFuttZHW2ljge2CQj/skXlhr91trV3ien8L9jz8M93594Wn2BXCV5/kg4EvrLAJKG2Mq53O3xQtjTFWgP/CpZ9sA3YAfPU3Svo9J7++PQHdPe/EhY0wIcAUwCsBaG2utPYE+jwVNAFDUGBMAFAP2o8/iRc9aOwc4lmZ3Tj97vYFp1tpj1trjwDTSB/iSDQrGcy8M2J1ie49nn1zEPD+PtgQWAxWttfs9hw4AFT3P9d5evN4GHgMSPdvlgBPW2njPdsr36q/30XM8ytNefKsWcBgY7Uk3+tQYUxx9HgsMa+1e4L/ALlwQHgUsR5/Fgiqnnz19JvOIgnG55BhjSgA/AQ9aa0+mPGZdeSGVGLqIGWOuBA5Za5f7ui+SKwFAK+Aja21LIJrkn8UBfR4vdp6UhEG4L1ZVgOJoZLRQ0GcvfykYz729QLUU21U9++QiZIwJxAXi31hrf/bsPpj0c7fn8ZBnv97bi1MHYKAxZgcuLawbLve4tOenckj9Xv31PnqOhwBH87PD4tUeYI+1drFn+0dccK7PY8HRA9hurT1srY0DfsZ9PvVZLJhy+tnTZzKPKBjPvaVAPc/s8SDc5JUJPu6TeOHJTRwFbLDWvpni0AQgaRb4UGB8iv23eGaStwOiUvyEJz5irX3CWlvVWlsT93mbaa0dAswCrvM0S/s+Jr2/13naa8THx6y1B4Ddxpj6nl3dgfXo81iQ7ALaGWOKef59TXoP9VksmHL62fsd6GWMKeP5laSXZ5/kkBb9yQPGmH64HFZ/4DNr7cs+7pJ4YYzpCMwF1pCca/wkLm/8B6A6sBP4m7X2mOd/Lu/jfnY9Awyz1i7L945LhowxXYBHrbVXGmNq40bKywJ/Ajdba88ZY4KBr3BzBI4BN1prI33VZ0lmjGmBm4QbBEQCw3CDRPo8FhDGmOeBG3DVqv4E7sDlDeuzeBEzxnwHdAHKAwdxVVHGkcPPnjHmNtz/RwFettaOzs/XUVgoGBcRERER8RGlqYiIiIiI+IiCcRERERERH1EwLiIiIiLiIwrGRURERER8RMG4iIiIiIiPKBgXEfEwxnxujFmWYruNMeY5H/VluDHmKi/7dxhj/uuLPvmKMaaLMcYaY5r4ui8iInktIOsmIiKXjBeBoim22+Dq7z7ng74MB9biav+mdDVatVBEpNBQMC4i4mGt3XYhr2+MKWqtPZuba1hr/8yr/ohjjAm21sb4uh8icmlSmoqIiEfKNBVjzK3Ae57n1vPf7BRtmxhjJhtjTnn+G2uMqZTieFJqRW9jzARjzGncKnYYYx4xxiw1xkQZYw4aYyYaY+qmOHc20BoYmuLet3qOpUtTMcb8zRizxhhzzhiz2xjzsjEmIMXxWz3XaGqMmWaMiTbGbDTGXJONv4k1xjxgjHnFGHPYGHPIGPOBMaZIijbPGWOOZHDufSm2dxhj/muMedwYs9/z+t/wLLPdzxizzvO3HOdZXjutKsaYSZ7+7zLG3OXlnp2MMX8YY84YY44aY0YaY0p6+Vu0McbMNsacBf6Z1d9BRORCUTAuIuLdZOANz/P2nv/uAfAEzvOBYOBm4FagMTDRs3R0SqOAVcBAz3OAqrjAfBBwJ+APLDDGhHiO3wNsBKakuPdkb500xvQCxgArPNd7D3jUc/20vgUm4FJdtgDfG2OqZvWHAB4Bqnhe6+vACOCBbJznzY249J9hwGvAw8CbuBShp4G7gM7Av72cOwpYDVyD+9t8ZIy5MumgMaYDMB04AFwHPAj0A7wt0f0dMNFzfNJ5vhYRkVxTmoqIiBfW2sPGmB2e54vSHH4WF/D1tdbGAhhjVuMC6H6kDpyIkgAxAAADqElEQVTHWmufTnPth5KeG2P8gWnAIVww/aW1dr0xJho47OXeab0AzLbWDvVs/+b5PvBvY8xL1to9Kdq+Za39zHPf5cBB4Erg4yzuscNae6vn+e+eoPcaXDCdUzHA9dbaBE9fBwH3A/Wstds9fWsODMUF5in9aq19MkU/6gBPkRxM/wdYYK29IekEY8xeYIYxpom1dm2Ka71rrX3nPPovIpKnNDIuIpJzPYBfgERjTIAnJWQ7sAOISNM23Yi2MaadJ13kKBAPnAFKAOE56YQnkG8FjE1zaAzu3/f2afZPTXpirT2K+wKQnZHxqWm212fzPG9mewLxJFtxwf72NPtCjTFBac79Jc32z0BrY4y/MaYY7vX+kPSeeN6XeUAcLu0nJa+/NIiI5DcF4yIiOVce+D9ckJfyv9pAtTRtD6bcMMZUxwW3Bpfu0QG4DBcYB59HPwLT3iPFdtk0+0+k2Y7N5j3P97zsXsvbPgOkDcYPedkOwP0dyuDSfT4k9XtyDvc3yvR9ERHxFaWpiIjk3DHcKO2nXo6lncho02z3AYoBg6y10QCeEdy0gXN2HMEFnBXS7K+Yop/5IYY0gXMGEzBzK+3rrID7ZeEI7suBxZWhnOLl3H1pttO+LyIiPqFgXEQkY0n54GlL383ATdhcbq3NaVBXFEjEBZFJ/kb6f4+zHH221iZ4cr+vBz5Kc71EYGEO+3a+9gAljTFh1tq9nn29LsB9rgZ+TbO93JP2Em2MWQTUt9a+cAHuLSJyQSgYFxHJ2EbP4wPGmJnASWvtJtzo6xJgsjHmM9zIbBjQE/jcWjs7k2vOxKVTjDbGjMIF9Y+SPlVjI9DbGNMbt8jPdk+ed1rP4iYzjga+B5riKpOMTDN580L6DTgLfGaMeQOoRfrJl3mhrzHmZeAP3ATSnrhJr0kew03WTAR+BE4B1YH+wL+stZsvQJ9ERHJFOeMiIhmbiyvl9wCwGPgfgCeoa4ebePkJbrT2eVx+8tbMLmitXYMrhdgWVwXkJtzIdlSapi8BG4AfgKXAgAyuNxVXLjACV6rvQVxJxvu8tb8QrLVHgGtxkzrH4Uog3nQBbnUHbsLqOFwVmHuttRNS9GMecAUQCnyF+3s8BuxGOeIicpEyOf+FVURERERE8oJGxkVEREREfETBuIiIiIiIjygYFxERERHxEQXjIiIiIiI+omBcRERERMRHFIyLiIiIiPiIgnERERERER9RMC4iIiIi4iMKxkVEREREfOT/Af5GoKw7A5U2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.plot_loss_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1\t training loss: 1038.8574\tvalidation loss: 347.6607\t validation accuracy: 0.0978\n",
      "iteration number: 2\t training loss: 1244.8550\tvalidation loss: 417.1646\t validation accuracy: 0.0978\n",
      "iteration number: 3\t training loss: 1540.1971\tvalidation loss: 516.8967\t validation accuracy: 0.0978\n",
      "iteration number: 4\t training loss: 1901.4492\tvalidation loss: 639.2026\t validation accuracy: 0.0978\n",
      "iteration number: 5\t training loss: 2288.5847\tvalidation loss: 769.4916\t validation accuracy: 0.0822\n",
      "iteration number: 6\t training loss: 2659.3944\tvalidation loss: 893.6334\t validation accuracy: 0.0822\n",
      "iteration number: 7\t training loss: 2972.5724\tvalidation loss: 998.7390\t validation accuracy: 0.0822\n",
      "iteration number: 8\t training loss: 3203.0097\tvalidation loss: 1075.3432\t validation accuracy: 0.0822\n",
      "iteration number: 9\t training loss: 3331.3033\tvalidation loss: 1118.4789\t validation accuracy: 0.0822\n",
      "iteration number: 10\t training loss: 3356.3276\tvalidation loss: 1127.0221\t validation accuracy: 0.0822\n",
      "iteration number: 11\t training loss: 3283.0687\tvalidation loss: 1102.9357\t validation accuracy: 0.0822\n",
      "iteration number: 12\t training loss: 3134.8231\tvalidation loss: 1053.5449\t validation accuracy: 0.0822\n",
      "iteration number: 13\t training loss: 2936.6064\tvalidation loss: 987.0686\t validation accuracy: 0.0822\n",
      "iteration number: 14\t training loss: 2717.1035\tvalidation loss: 913.2819\t validation accuracy: 0.0822\n",
      "iteration number: 15\t training loss: 2500.3322\tvalidation loss: 840.4051\t validation accuracy: 0.0822\n",
      "iteration number: 16\t training loss: 2310.4672\tvalidation loss: 776.0628\t validation accuracy: 0.0822\n",
      "iteration number: 17\t training loss: 2157.8111\tvalidation loss: 724.1578\t validation accuracy: 0.0822\n",
      "iteration number: 18\t training loss: 2041.6549\tvalidation loss: 684.3849\t validation accuracy: 0.0822\n",
      "iteration number: 19\t training loss: 1960.8941\tvalidation loss: 656.7393\t validation accuracy: 0.0822\n",
      "iteration number: 20\t training loss: 1911.3572\tvalidation loss: 639.9229\t validation accuracy: 0.0822\n",
      "iteration number: 21\t training loss: 1888.2344\tvalidation loss: 631.8538\t validation accuracy: 0.0822\n",
      "iteration number: 22\t training loss: 1888.0524\tvalidation loss: 631.3201\t validation accuracy: 0.0822\n",
      "iteration number: 23\t training loss: 1905.3345\tvalidation loss: 636.7803\t validation accuracy: 0.1156\n",
      "iteration number: 24\t training loss: 1938.8199\tvalidation loss: 647.6257\t validation accuracy: 0.1156\n",
      "iteration number: 25\t training loss: 1986.6503\tvalidation loss: 663.3739\t validation accuracy: 0.1156\n",
      "iteration number: 26\t training loss: 2048.3110\tvalidation loss: 683.7367\t validation accuracy: 0.1156\n",
      "iteration number: 27\t training loss: 2120.0901\tvalidation loss: 707.5140\t validation accuracy: 0.1156\n",
      "iteration number: 28\t training loss: 2197.6348\tvalidation loss: 733.1913\t validation accuracy: 0.1156\n",
      "iteration number: 29\t training loss: 2277.4133\tvalidation loss: 759.8433\t validation accuracy: 0.1156\n",
      "iteration number: 30\t training loss: 2356.1423\tvalidation loss: 786.1140\t validation accuracy: 0.1156\n",
      "iteration number: 31\t training loss: 2430.9325\tvalidation loss: 811.1677\t validation accuracy: 0.1156\n",
      "iteration number: 32\t training loss: 2499.3068\tvalidation loss: 834.1442\t validation accuracy: 0.1156\n",
      "iteration number: 33\t training loss: 2557.5830\tvalidation loss: 853.5394\t validation accuracy: 0.1467\n",
      "iteration number: 34\t training loss: 2602.4093\tvalidation loss: 868.4891\t validation accuracy: 0.0978\n",
      "iteration number: 35\t training loss: 2631.6795\tvalidation loss: 878.1709\t validation accuracy: 0.1578\n",
      "iteration number: 36\t training loss: 2646.2795\tvalidation loss: 883.1613\t validation accuracy: 0.1489\n",
      "iteration number: 37\t training loss: 2648.0061\tvalidation loss: 883.7923\t validation accuracy: 0.0978\n",
      "iteration number: 38\t training loss: 2636.4890\tvalidation loss: 880.0837\t validation accuracy: 0.1022\n",
      "iteration number: 39\t training loss: 2612.3896\tvalidation loss: 872.1498\t validation accuracy: 0.0778\n",
      "iteration number: 40\t training loss: 2581.2790\tvalidation loss: 862.0582\t validation accuracy: 0.0778\n",
      "iteration number: 41\t training loss: 2546.4851\tvalidation loss: 850.7100\t validation accuracy: 0.0778\n",
      "iteration number: 42\t training loss: 2512.1126\tvalidation loss: 839.5459\t validation accuracy: 0.0778\n",
      "iteration number: 43\t training loss: 2477.9290\tvalidation loss: 828.5887\t validation accuracy: 0.0978\n",
      "iteration number: 44\t training loss: 2445.5739\tvalidation loss: 818.2019\t validation accuracy: 0.0978\n",
      "iteration number: 45\t training loss: 2418.3072\tvalidation loss: 809.4153\t validation accuracy: 0.0978\n",
      "iteration number: 46\t training loss: 2396.2072\tvalidation loss: 802.5340\t validation accuracy: 0.0978\n",
      "iteration number: 47\t training loss: 2379.0965\tvalidation loss: 797.5643\t validation accuracy: 0.0978\n",
      "iteration number: 48\t training loss: 2366.8073\tvalidation loss: 794.1997\t validation accuracy: 0.0978\n",
      "iteration number: 49\t training loss: 2358.3376\tvalidation loss: 792.0525\t validation accuracy: 0.0978\n",
      "iteration number: 50\t training loss: 2354.7469\tvalidation loss: 791.3722\t validation accuracy: 0.0978\n",
      "iteration number: 51\t training loss: 2356.0708\tvalidation loss: 792.2740\t validation accuracy: 0.0978\n",
      "iteration number: 52\t training loss: 2363.3471\tvalidation loss: 795.2277\t validation accuracy: 0.0978\n",
      "iteration number: 53\t training loss: 2374.6044\tvalidation loss: 799.4810\t validation accuracy: 0.0978\n",
      "iteration number: 54\t training loss: 2388.6698\tvalidation loss: 804.7345\t validation accuracy: 0.0978\n",
      "iteration number: 55\t training loss: 2404.4669\tvalidation loss: 810.3040\t validation accuracy: 0.0978\n",
      "iteration number: 56\t training loss: 2422.2802\tvalidation loss: 816.4233\t validation accuracy: 0.0978\n",
      "iteration number: 57\t training loss: 2440.1050\tvalidation loss: 822.5730\t validation accuracy: 0.0978\n",
      "iteration number: 58\t training loss: 2457.7358\tvalidation loss: 828.8283\t validation accuracy: 0.0978\n",
      "iteration number: 59\t training loss: 2472.9094\tvalidation loss: 834.0189\t validation accuracy: 0.0978\n",
      "iteration number: 60\t training loss: 2486.0072\tvalidation loss: 838.4325\t validation accuracy: 0.0711\n",
      "iteration number: 61\t training loss: 2495.7525\tvalidation loss: 841.6636\t validation accuracy: 0.0711\n",
      "iteration number: 62\t training loss: 2502.7807\tvalidation loss: 843.7581\t validation accuracy: 0.0711\n",
      "iteration number: 63\t training loss: 2505.6394\tvalidation loss: 844.2948\t validation accuracy: 0.1400\n",
      "iteration number: 64\t training loss: 2507.1031\tvalidation loss: 844.7105\t validation accuracy: 0.1733\n",
      "iteration number: 65\t training loss: 2505.6207\tvalidation loss: 843.9594\t validation accuracy: 0.1933\n",
      "iteration number: 66\t training loss: 2500.9402\tvalidation loss: 842.2558\t validation accuracy: 0.1778\n",
      "iteration number: 67\t training loss: 2494.4664\tvalidation loss: 839.9432\t validation accuracy: 0.1578\n",
      "iteration number: 68\t training loss: 2485.7237\tvalidation loss: 836.9948\t validation accuracy: 0.1422\n",
      "iteration number: 69\t training loss: 2475.8443\tvalidation loss: 833.8095\t validation accuracy: 0.1422\n",
      "iteration number: 70\t training loss: 2465.5119\tvalidation loss: 830.6230\t validation accuracy: 0.1356\n",
      "iteration number: 71\t training loss: 2455.1681\tvalidation loss: 827.4671\t validation accuracy: 0.1511\n",
      "iteration number: 72\t training loss: 2444.0789\tvalidation loss: 824.1169\t validation accuracy: 0.1533\n",
      "iteration number: 73\t training loss: 2433.6617\tvalidation loss: 820.7301\t validation accuracy: 0.1489\n",
      "iteration number: 74\t training loss: 2425.3110\tvalidation loss: 817.9953\t validation accuracy: 0.1756\n",
      "iteration number: 75\t training loss: 2419.0946\tvalidation loss: 816.0623\t validation accuracy: 0.1333\n",
      "iteration number: 76\t training loss: 2415.4495\tvalidation loss: 814.9359\t validation accuracy: 0.1089\n",
      "iteration number: 77\t training loss: 2413.5079\tvalidation loss: 814.3383\t validation accuracy: 0.0956\n",
      "iteration number: 78\t training loss: 2412.4980\tvalidation loss: 813.9983\t validation accuracy: 0.0800\n",
      "iteration number: 79\t training loss: 2412.9663\tvalidation loss: 814.2260\t validation accuracy: 0.0756\n",
      "iteration number: 80\t training loss: 2413.6293\tvalidation loss: 814.3510\t validation accuracy: 0.0711\n",
      "iteration number: 81\t training loss: 2415.1391\tvalidation loss: 814.6379\t validation accuracy: 0.0711\n",
      "iteration number: 82\t training loss: 2417.2894\tvalidation loss: 815.5549\t validation accuracy: 0.0711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 83\t training loss: 2419.3989\tvalidation loss: 816.2535\t validation accuracy: 0.0711\n",
      "iteration number: 84\t training loss: 2421.7170\tvalidation loss: 816.8369\t validation accuracy: 0.0711\n",
      "iteration number: 85\t training loss: 2423.7861\tvalidation loss: 817.5899\t validation accuracy: 0.0711\n",
      "iteration number: 86\t training loss: 2426.9954\tvalidation loss: 818.5768\t validation accuracy: 0.0711\n",
      "iteration number: 87\t training loss: 2430.5513\tvalidation loss: 819.5204\t validation accuracy: 0.0711\n",
      "iteration number: 88\t training loss: 2435.0563\tvalidation loss: 820.9411\t validation accuracy: 0.0711\n",
      "iteration number: 89\t training loss: 2439.8616\tvalidation loss: 822.7093\t validation accuracy: 0.0711\n",
      "iteration number: 90\t training loss: 2443.6284\tvalidation loss: 824.1350\t validation accuracy: 0.0711\n",
      "iteration number: 91\t training loss: 2445.8630\tvalidation loss: 824.6656\t validation accuracy: 0.0711\n",
      "iteration number: 92\t training loss: 2447.1111\tvalidation loss: 824.7249\t validation accuracy: 0.0711\n",
      "iteration number: 93\t training loss: 2447.9230\tvalidation loss: 824.5411\t validation accuracy: 0.0711\n",
      "iteration number: 94\t training loss: 2447.8456\tvalidation loss: 824.0202\t validation accuracy: 0.0711\n",
      "iteration number: 95\t training loss: 2446.7611\tvalidation loss: 823.1503\t validation accuracy: 0.0711\n",
      "iteration number: 96\t training loss: 2444.8137\tvalidation loss: 821.8832\t validation accuracy: 0.0956\n",
      "iteration number: 97\t training loss: 2442.4533\tvalidation loss: 820.5153\t validation accuracy: 0.1178\n",
      "iteration number: 98\t training loss: 2439.1716\tvalidation loss: 819.0188\t validation accuracy: 0.1356\n",
      "iteration number: 99\t training loss: 2434.4980\tvalidation loss: 817.3485\t validation accuracy: 0.2000\n",
      "iteration number: 100\t training loss: 2428.6847\tvalidation loss: 815.3966\t validation accuracy: 0.2356\n",
      "iteration number: 101\t training loss: 2423.3706\tvalidation loss: 813.6891\t validation accuracy: 0.2200\n",
      "iteration number: 102\t training loss: 2415.7541\tvalidation loss: 811.6383\t validation accuracy: 0.2356\n",
      "iteration number: 103\t training loss: 2408.3185\tvalidation loss: 809.6302\t validation accuracy: 0.2422\n",
      "iteration number: 104\t training loss: 2401.6605\tvalidation loss: 807.8182\t validation accuracy: 0.2311\n",
      "iteration number: 105\t training loss: 2395.0494\tvalidation loss: 806.1788\t validation accuracy: 0.2089\n",
      "iteration number: 106\t training loss: 2389.3526\tvalidation loss: 804.8090\t validation accuracy: 0.1733\n",
      "iteration number: 107\t training loss: 2382.8652\tvalidation loss: 803.0743\t validation accuracy: 0.0956\n",
      "iteration number: 108\t training loss: 2376.9148\tvalidation loss: 801.4573\t validation accuracy: 0.0711\n",
      "iteration number: 109\t training loss: 2371.8794\tvalidation loss: 800.2783\t validation accuracy: 0.0711\n",
      "iteration number: 110\t training loss: 2369.1997\tvalidation loss: 799.8046\t validation accuracy: 0.0711\n",
      "iteration number: 111\t training loss: 2366.8118\tvalidation loss: 799.3100\t validation accuracy: 0.0711\n",
      "iteration number: 112\t training loss: 2364.1543\tvalidation loss: 798.6419\t validation accuracy: 0.0756\n",
      "iteration number: 113\t training loss: 2362.1935\tvalidation loss: 798.1704\t validation accuracy: 0.0778\n",
      "iteration number: 114\t training loss: 2359.3333\tvalidation loss: 797.3085\t validation accuracy: 0.0933\n",
      "iteration number: 115\t training loss: 2356.2497\tvalidation loss: 795.9985\t validation accuracy: 0.1089\n",
      "iteration number: 116\t training loss: 2352.6732\tvalidation loss: 794.7142\t validation accuracy: 0.1222\n",
      "iteration number: 117\t training loss: 2347.5238\tvalidation loss: 792.7836\t validation accuracy: 0.1333\n",
      "iteration number: 118\t training loss: 2341.1308\tvalidation loss: 790.6213\t validation accuracy: 0.1533\n",
      "iteration number: 119\t training loss: 2333.0189\tvalidation loss: 788.2263\t validation accuracy: 0.1733\n",
      "iteration number: 120\t training loss: 2325.0277\tvalidation loss: 785.8358\t validation accuracy: 0.2178\n",
      "iteration number: 121\t training loss: 2316.7746\tvalidation loss: 783.3109\t validation accuracy: 0.2533\n",
      "iteration number: 122\t training loss: 2307.4358\tvalidation loss: 780.6005\t validation accuracy: 0.3000\n",
      "iteration number: 123\t training loss: 2297.0589\tvalidation loss: 777.8677\t validation accuracy: 0.3422\n",
      "iteration number: 124\t training loss: 2288.2079\tvalidation loss: 775.6161\t validation accuracy: 0.3533\n",
      "iteration number: 125\t training loss: 2280.1579\tvalidation loss: 773.3299\t validation accuracy: 0.3356\n",
      "iteration number: 126\t training loss: 2272.5835\tvalidation loss: 771.2912\t validation accuracy: 0.3200\n",
      "iteration number: 127\t training loss: 2265.5662\tvalidation loss: 769.3241\t validation accuracy: 0.2956\n",
      "iteration number: 128\t training loss: 2258.4740\tvalidation loss: 767.1744\t validation accuracy: 0.3022\n",
      "iteration number: 129\t training loss: 2250.5759\tvalidation loss: 764.7262\t validation accuracy: 0.2889\n",
      "iteration number: 130\t training loss: 2241.9211\tvalidation loss: 762.0383\t validation accuracy: 0.3600\n",
      "iteration number: 131\t training loss: 2232.7756\tvalidation loss: 758.8738\t validation accuracy: 0.3800\n",
      "iteration number: 132\t training loss: 2223.5984\tvalidation loss: 755.6082\t validation accuracy: 0.3622\n",
      "iteration number: 133\t training loss: 2214.4759\tvalidation loss: 752.4249\t validation accuracy: 0.3289\n",
      "iteration number: 134\t training loss: 2205.6937\tvalidation loss: 749.6440\t validation accuracy: 0.3533\n",
      "iteration number: 135\t training loss: 2195.1710\tvalidation loss: 746.4160\t validation accuracy: 0.3733\n",
      "iteration number: 136\t training loss: 2184.0533\tvalidation loss: 743.0051\t validation accuracy: 0.3733\n",
      "iteration number: 137\t training loss: 2172.1124\tvalidation loss: 739.1773\t validation accuracy: 0.3711\n",
      "iteration number: 138\t training loss: 2160.9838\tvalidation loss: 735.5495\t validation accuracy: 0.3644\n",
      "iteration number: 139\t training loss: 2148.0188\tvalidation loss: 731.2182\t validation accuracy: 0.3733\n",
      "iteration number: 140\t training loss: 2134.3918\tvalidation loss: 726.4685\t validation accuracy: 0.3933\n",
      "iteration number: 141\t training loss: 2120.2023\tvalidation loss: 721.4631\t validation accuracy: 0.4533\n",
      "iteration number: 142\t training loss: 2107.1771\tvalidation loss: 716.7702\t validation accuracy: 0.4756\n",
      "iteration number: 143\t training loss: 2093.6261\tvalidation loss: 712.1773\t validation accuracy: 0.4622\n",
      "iteration number: 144\t training loss: 2081.6329\tvalidation loss: 707.7179\t validation accuracy: 0.4444\n",
      "iteration number: 145\t training loss: 2070.1696\tvalidation loss: 703.3622\t validation accuracy: 0.4178\n",
      "iteration number: 146\t training loss: 2059.0342\tvalidation loss: 698.9930\t validation accuracy: 0.4044\n",
      "iteration number: 147\t training loss: 2048.2632\tvalidation loss: 694.6293\t validation accuracy: 0.4044\n",
      "iteration number: 148\t training loss: 2037.3079\tvalidation loss: 689.9367\t validation accuracy: 0.4022\n",
      "iteration number: 149\t training loss: 2026.7353\tvalidation loss: 685.5838\t validation accuracy: 0.4067\n",
      "iteration number: 150\t training loss: 2017.7958\tvalidation loss: 682.1605\t validation accuracy: 0.4156\n",
      "iteration number: 151\t training loss: 2009.3704\tvalidation loss: 678.9764\t validation accuracy: 0.4156\n",
      "iteration number: 152\t training loss: 2001.5056\tvalidation loss: 675.9583\t validation accuracy: 0.4511\n",
      "iteration number: 153\t training loss: 1993.5123\tvalidation loss: 672.7606\t validation accuracy: 0.5089\n",
      "iteration number: 154\t training loss: 1985.3127\tvalidation loss: 669.6515\t validation accuracy: 0.5467\n",
      "iteration number: 155\t training loss: 1977.0769\tvalidation loss: 666.5708\t validation accuracy: 0.6111\n",
      "iteration number: 156\t training loss: 1968.7401\tvalidation loss: 663.8192\t validation accuracy: 0.6444\n",
      "iteration number: 157\t training loss: 1959.5806\tvalidation loss: 660.6733\t validation accuracy: 0.6844\n",
      "iteration number: 158\t training loss: 1949.5056\tvalidation loss: 657.4096\t validation accuracy: 0.6844\n",
      "iteration number: 159\t training loss: 1940.0599\tvalidation loss: 654.6586\t validation accuracy: 0.6511\n",
      "iteration number: 160\t training loss: 1930.9730\tvalidation loss: 652.6972\t validation accuracy: 0.5844\n",
      "iteration number: 161\t training loss: 1922.2525\tvalidation loss: 650.7725\t validation accuracy: 0.5622\n",
      "iteration number: 162\t training loss: 1913.2297\tvalidation loss: 648.3025\t validation accuracy: 0.5489\n",
      "iteration number: 163\t training loss: 1904.8416\tvalidation loss: 645.6963\t validation accuracy: 0.5356\n",
      "iteration number: 164\t training loss: 1896.0857\tvalidation loss: 643.2050\t validation accuracy: 0.5200\n",
      "iteration number: 165\t training loss: 1887.1756\tvalidation loss: 640.7662\t validation accuracy: 0.5200\n",
      "iteration number: 166\t training loss: 1879.4916\tvalidation loss: 638.4124\t validation accuracy: 0.4956\n",
      "iteration number: 167\t training loss: 1872.2037\tvalidation loss: 635.8029\t validation accuracy: 0.5156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 168\t training loss: 1865.3564\tvalidation loss: 632.6726\t validation accuracy: 0.5156\n",
      "iteration number: 169\t training loss: 1857.3364\tvalidation loss: 629.1428\t validation accuracy: 0.5200\n",
      "iteration number: 170\t training loss: 1848.7369\tvalidation loss: 625.1374\t validation accuracy: 0.5511\n",
      "iteration number: 171\t training loss: 1839.9083\tvalidation loss: 621.1193\t validation accuracy: 0.5978\n",
      "iteration number: 172\t training loss: 1831.0044\tvalidation loss: 616.9240\t validation accuracy: 0.6644\n",
      "iteration number: 173\t training loss: 1819.8221\tvalidation loss: 612.1031\t validation accuracy: 0.6844\n",
      "iteration number: 174\t training loss: 1809.0003\tvalidation loss: 607.4504\t validation accuracy: 0.7000\n",
      "iteration number: 175\t training loss: 1800.1572\tvalidation loss: 603.4949\t validation accuracy: 0.7244\n",
      "iteration number: 176\t training loss: 1793.0231\tvalidation loss: 600.1767\t validation accuracy: 0.7467\n",
      "iteration number: 177\t training loss: 1785.9214\tvalidation loss: 597.3627\t validation accuracy: 0.7422\n",
      "iteration number: 178\t training loss: 1776.7377\tvalidation loss: 594.2852\t validation accuracy: 0.7378\n",
      "iteration number: 179\t training loss: 1767.7318\tvalidation loss: 592.0510\t validation accuracy: 0.7156\n",
      "iteration number: 180\t training loss: 1758.4927\tvalidation loss: 590.0130\t validation accuracy: 0.6978\n",
      "iteration number: 181\t training loss: 1747.8224\tvalidation loss: 587.3565\t validation accuracy: 0.6933\n",
      "iteration number: 182\t training loss: 1739.2703\tvalidation loss: 585.2051\t validation accuracy: 0.6867\n",
      "iteration number: 183\t training loss: 1732.3529\tvalidation loss: 583.6590\t validation accuracy: 0.6711\n",
      "iteration number: 184\t training loss: 1726.6230\tvalidation loss: 582.6028\t validation accuracy: 0.6689\n",
      "iteration number: 185\t training loss: 1720.5241\tvalidation loss: 580.8600\t validation accuracy: 0.6911\n",
      "iteration number: 186\t training loss: 1713.5548\tvalidation loss: 578.8211\t validation accuracy: 0.6844\n",
      "iteration number: 187\t training loss: 1709.0357\tvalidation loss: 577.3616\t validation accuracy: 0.6956\n",
      "iteration number: 188\t training loss: 1703.3327\tvalidation loss: 575.1468\t validation accuracy: 0.7111\n",
      "iteration number: 189\t training loss: 1697.2188\tvalidation loss: 572.6526\t validation accuracy: 0.7244\n",
      "iteration number: 190\t training loss: 1689.4127\tvalidation loss: 569.5780\t validation accuracy: 0.7511\n",
      "iteration number: 191\t training loss: 1679.9995\tvalidation loss: 566.0739\t validation accuracy: 0.7422\n",
      "iteration number: 192\t training loss: 1668.1683\tvalidation loss: 561.5310\t validation accuracy: 0.7022\n",
      "iteration number: 193\t training loss: 1654.5630\tvalidation loss: 556.5067\t validation accuracy: 0.6933\n",
      "iteration number: 194\t training loss: 1643.2053\tvalidation loss: 551.8960\t validation accuracy: 0.7000\n",
      "iteration number: 195\t training loss: 1634.2074\tvalidation loss: 548.6484\t validation accuracy: 0.6933\n",
      "iteration number: 196\t training loss: 1628.0964\tvalidation loss: 546.1558\t validation accuracy: 0.7000\n",
      "iteration number: 197\t training loss: 1624.0930\tvalidation loss: 544.2076\t validation accuracy: 0.7089\n",
      "iteration number: 198\t training loss: 1617.0047\tvalidation loss: 541.4312\t validation accuracy: 0.7311\n",
      "iteration number: 199\t training loss: 1607.4793\tvalidation loss: 537.7893\t validation accuracy: 0.7511\n",
      "iteration number: 200\t training loss: 1598.8600\tvalidation loss: 534.6127\t validation accuracy: 0.7622\n",
      "iteration number: 201\t training loss: 1591.3774\tvalidation loss: 531.8652\t validation accuracy: 0.7800\n",
      "iteration number: 202\t training loss: 1587.9989\tvalidation loss: 530.2266\t validation accuracy: 0.7978\n",
      "iteration number: 203\t training loss: 1585.2653\tvalidation loss: 528.9624\t validation accuracy: 0.8222\n",
      "iteration number: 204\t training loss: 1583.6154\tvalidation loss: 528.0131\t validation accuracy: 0.8289\n",
      "iteration number: 205\t training loss: 1580.4440\tvalidation loss: 526.4856\t validation accuracy: 0.8333\n",
      "iteration number: 206\t training loss: 1577.0705\tvalidation loss: 524.7053\t validation accuracy: 0.8422\n",
      "iteration number: 207\t training loss: 1572.8489\tvalidation loss: 522.9909\t validation accuracy: 0.8467\n",
      "iteration number: 208\t training loss: 1567.6679\tvalidation loss: 520.5449\t validation accuracy: 0.8489\n",
      "iteration number: 209\t training loss: 1561.7783\tvalidation loss: 517.8167\t validation accuracy: 0.8556\n",
      "iteration number: 210\t training loss: 1556.7243\tvalidation loss: 515.5478\t validation accuracy: 0.8533\n",
      "iteration number: 211\t training loss: 1552.8655\tvalidation loss: 514.0638\t validation accuracy: 0.8511\n",
      "iteration number: 212\t training loss: 1548.9099\tvalidation loss: 512.3921\t validation accuracy: 0.8489\n",
      "iteration number: 213\t training loss: 1542.6575\tvalidation loss: 510.6670\t validation accuracy: 0.8400\n",
      "iteration number: 214\t training loss: 1536.4282\tvalidation loss: 509.1817\t validation accuracy: 0.8422\n",
      "iteration number: 215\t training loss: 1529.0070\tvalidation loss: 507.2995\t validation accuracy: 0.8444\n",
      "iteration number: 216\t training loss: 1518.4187\tvalidation loss: 504.9364\t validation accuracy: 0.8511\n",
      "iteration number: 217\t training loss: 1504.8162\tvalidation loss: 501.4376\t validation accuracy: 0.8511\n",
      "iteration number: 218\t training loss: 1494.0972\tvalidation loss: 498.3912\t validation accuracy: 0.8578\n",
      "iteration number: 219\t training loss: 1483.8327\tvalidation loss: 495.5790\t validation accuracy: 0.8600\n",
      "iteration number: 220\t training loss: 1476.4165\tvalidation loss: 493.3928\t validation accuracy: 0.8578\n",
      "iteration number: 221\t training loss: 1468.8506\tvalidation loss: 491.1249\t validation accuracy: 0.8578\n",
      "iteration number: 222\t training loss: 1462.1738\tvalidation loss: 489.5683\t validation accuracy: 0.8600\n",
      "iteration number: 223\t training loss: 1457.5780\tvalidation loss: 488.9886\t validation accuracy: 0.8467\n",
      "iteration number: 224\t training loss: 1453.4999\tvalidation loss: 488.7219\t validation accuracy: 0.8400\n",
      "iteration number: 225\t training loss: 1451.3957\tvalidation loss: 488.8700\t validation accuracy: 0.8267\n",
      "iteration number: 226\t training loss: 1449.4878\tvalidation loss: 489.2903\t validation accuracy: 0.8178\n",
      "iteration number: 227\t training loss: 1448.7623\tvalidation loss: 489.1930\t validation accuracy: 0.8111\n",
      "iteration number: 228\t training loss: 1448.0457\tvalidation loss: 488.7781\t validation accuracy: 0.8200\n",
      "iteration number: 229\t training loss: 1446.7009\tvalidation loss: 487.4885\t validation accuracy: 0.8267\n",
      "iteration number: 230\t training loss: 1447.1115\tvalidation loss: 487.0297\t validation accuracy: 0.8356\n",
      "iteration number: 231\t training loss: 1450.3701\tvalidation loss: 487.9569\t validation accuracy: 0.8356\n",
      "iteration number: 232\t training loss: 1456.3607\tvalidation loss: 489.9440\t validation accuracy: 0.8311\n",
      "iteration number: 233\t training loss: 1460.9400\tvalidation loss: 491.6306\t validation accuracy: 0.8400\n",
      "iteration number: 234\t training loss: 1466.9136\tvalidation loss: 493.5879\t validation accuracy: 0.8422\n",
      "iteration number: 235\t training loss: 1467.5091\tvalidation loss: 493.4030\t validation accuracy: 0.8444\n",
      "iteration number: 236\t training loss: 1462.3100\tvalidation loss: 490.7887\t validation accuracy: 0.8467\n",
      "iteration number: 237\t training loss: 1454.6380\tvalidation loss: 486.9291\t validation accuracy: 0.8578\n",
      "iteration number: 238\t training loss: 1442.0750\tvalidation loss: 481.8413\t validation accuracy: 0.8644\n",
      "iteration number: 239\t training loss: 1426.0873\tvalidation loss: 475.3219\t validation accuracy: 0.8667\n",
      "iteration number: 240\t training loss: 1415.0513\tvalidation loss: 470.2978\t validation accuracy: 0.8667\n",
      "iteration number: 241\t training loss: 1404.4799\tvalidation loss: 465.3608\t validation accuracy: 0.8733\n",
      "iteration number: 242\t training loss: 1389.9973\tvalidation loss: 459.4389\t validation accuracy: 0.8644\n",
      "iteration number: 243\t training loss: 1379.1168\tvalidation loss: 454.7191\t validation accuracy: 0.8600\n",
      "iteration number: 244\t training loss: 1367.3385\tvalidation loss: 450.3324\t validation accuracy: 0.8800\n",
      "iteration number: 245\t training loss: 1357.7323\tvalidation loss: 446.9596\t validation accuracy: 0.8867\n",
      "iteration number: 246\t training loss: 1350.8926\tvalidation loss: 444.4011\t validation accuracy: 0.8844\n",
      "iteration number: 247\t training loss: 1343.8412\tvalidation loss: 442.4326\t validation accuracy: 0.8889\n",
      "iteration number: 248\t training loss: 1339.2694\tvalidation loss: 441.1769\t validation accuracy: 0.8867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 249\t training loss: 1337.0912\tvalidation loss: 441.0233\t validation accuracy: 0.8800\n",
      "iteration number: 250\t training loss: 1335.0484\tvalidation loss: 441.3748\t validation accuracy: 0.8778\n",
      "iteration number: 251\t training loss: 1333.6072\tvalidation loss: 442.5126\t validation accuracy: 0.8733\n",
      "iteration number: 252\t training loss: 1334.4973\tvalidation loss: 444.4037\t validation accuracy: 0.8622\n",
      "iteration number: 253\t training loss: 1336.3252\tvalidation loss: 447.0063\t validation accuracy: 0.8489\n",
      "iteration number: 254\t training loss: 1340.0408\tvalidation loss: 449.7953\t validation accuracy: 0.8467\n",
      "iteration number: 255\t training loss: 1342.6560\tvalidation loss: 451.5692\t validation accuracy: 0.8467\n",
      "iteration number: 256\t training loss: 1345.6359\tvalidation loss: 453.3193\t validation accuracy: 0.8511\n",
      "iteration number: 257\t training loss: 1348.0063\tvalidation loss: 454.1914\t validation accuracy: 0.8578\n",
      "iteration number: 258\t training loss: 1349.1477\tvalidation loss: 454.4800\t validation accuracy: 0.8733\n",
      "iteration number: 259\t training loss: 1349.0232\tvalidation loss: 453.8463\t validation accuracy: 0.8800\n",
      "iteration number: 260\t training loss: 1344.4970\tvalidation loss: 451.6717\t validation accuracy: 0.8911\n",
      "iteration number: 261\t training loss: 1342.7055\tvalidation loss: 450.2877\t validation accuracy: 0.8933\n",
      "iteration number: 262\t training loss: 1340.1830\tvalidation loss: 448.6101\t validation accuracy: 0.8956\n",
      "iteration number: 263\t training loss: 1335.5949\tvalidation loss: 446.1099\t validation accuracy: 0.9000\n",
      "iteration number: 264\t training loss: 1328.1599\tvalidation loss: 442.8026\t validation accuracy: 0.9000\n",
      "iteration number: 265\t training loss: 1320.1303\tvalidation loss: 439.2513\t validation accuracy: 0.9044\n",
      "iteration number: 266\t training loss: 1312.4497\tvalidation loss: 435.8519\t validation accuracy: 0.9022\n",
      "iteration number: 267\t training loss: 1304.8473\tvalidation loss: 433.0492\t validation accuracy: 0.9044\n",
      "iteration number: 268\t training loss: 1295.7142\tvalidation loss: 429.8500\t validation accuracy: 0.9044\n",
      "iteration number: 269\t training loss: 1287.1054\tvalidation loss: 427.0787\t validation accuracy: 0.9067\n",
      "iteration number: 270\t training loss: 1276.5496\tvalidation loss: 423.6344\t validation accuracy: 0.9111\n",
      "iteration number: 271\t training loss: 1265.9481\tvalidation loss: 420.5728\t validation accuracy: 0.9200\n",
      "iteration number: 272\t training loss: 1257.6542\tvalidation loss: 418.2005\t validation accuracy: 0.9156\n",
      "iteration number: 273\t training loss: 1252.4139\tvalidation loss: 416.6892\t validation accuracy: 0.9133\n",
      "iteration number: 274\t training loss: 1250.6894\tvalidation loss: 416.2833\t validation accuracy: 0.9178\n",
      "iteration number: 275\t training loss: 1250.0048\tvalidation loss: 416.4082\t validation accuracy: 0.9200\n",
      "iteration number: 276\t training loss: 1250.6799\tvalidation loss: 417.3242\t validation accuracy: 0.9178\n",
      "iteration number: 277\t training loss: 1253.2551\tvalidation loss: 418.7673\t validation accuracy: 0.9111\n",
      "iteration number: 278\t training loss: 1253.2952\tvalidation loss: 419.2686\t validation accuracy: 0.9133\n",
      "iteration number: 279\t training loss: 1253.9882\tvalidation loss: 419.9704\t validation accuracy: 0.9111\n",
      "iteration number: 280\t training loss: 1256.1415\tvalidation loss: 421.0522\t validation accuracy: 0.9133\n",
      "iteration number: 281\t training loss: 1257.8772\tvalidation loss: 421.5032\t validation accuracy: 0.9111\n",
      "iteration number: 282\t training loss: 1259.2240\tvalidation loss: 421.4515\t validation accuracy: 0.9111\n",
      "iteration number: 283\t training loss: 1261.9088\tvalidation loss: 421.4544\t validation accuracy: 0.9133\n",
      "iteration number: 284\t training loss: 1258.9154\tvalidation loss: 419.7735\t validation accuracy: 0.9111\n",
      "iteration number: 285\t training loss: 1252.6915\tvalidation loss: 416.8839\t validation accuracy: 0.9133\n",
      "iteration number: 286\t training loss: 1245.0186\tvalidation loss: 413.8763\t validation accuracy: 0.9133\n",
      "iteration number: 287\t training loss: 1237.5991\tvalidation loss: 411.1360\t validation accuracy: 0.9111\n",
      "iteration number: 288\t training loss: 1229.5539\tvalidation loss: 407.9717\t validation accuracy: 0.9156\n",
      "iteration number: 289\t training loss: 1223.8713\tvalidation loss: 405.4431\t validation accuracy: 0.9067\n",
      "iteration number: 290\t training loss: 1218.8470\tvalidation loss: 403.0018\t validation accuracy: 0.9067\n",
      "iteration number: 291\t training loss: 1214.1339\tvalidation loss: 400.8358\t validation accuracy: 0.9044\n",
      "iteration number: 292\t training loss: 1211.2963\tvalidation loss: 399.5685\t validation accuracy: 0.9044\n",
      "iteration number: 293\t training loss: 1206.9729\tvalidation loss: 397.7371\t validation accuracy: 0.9044\n",
      "iteration number: 294\t training loss: 1204.2659\tvalidation loss: 396.9129\t validation accuracy: 0.9089\n",
      "iteration number: 295\t training loss: 1202.1825\tvalidation loss: 396.6884\t validation accuracy: 0.9111\n",
      "iteration number: 296\t training loss: 1199.8194\tvalidation loss: 396.8042\t validation accuracy: 0.9044\n",
      "iteration number: 297\t training loss: 1197.9085\tvalidation loss: 396.9487\t validation accuracy: 0.9133\n",
      "iteration number: 298\t training loss: 1194.6569\tvalidation loss: 396.3046\t validation accuracy: 0.9156\n",
      "iteration number: 299\t training loss: 1188.9461\tvalidation loss: 395.1898\t validation accuracy: 0.9200\n",
      "iteration number: 300\t training loss: 1181.4661\tvalidation loss: 392.7704\t validation accuracy: 0.9244\n",
      "iteration number: 301\t training loss: 1171.8046\tvalidation loss: 389.7478\t validation accuracy: 0.9222\n",
      "iteration number: 302\t training loss: 1161.0352\tvalidation loss: 385.9619\t validation accuracy: 0.9200\n",
      "iteration number: 303\t training loss: 1150.6468\tvalidation loss: 381.8304\t validation accuracy: 0.9311\n",
      "iteration number: 304\t training loss: 1144.6650\tvalidation loss: 378.8684\t validation accuracy: 0.9289\n",
      "iteration number: 305\t training loss: 1139.8026\tvalidation loss: 376.3571\t validation accuracy: 0.9333\n",
      "iteration number: 306\t training loss: 1137.4536\tvalidation loss: 374.9779\t validation accuracy: 0.9333\n",
      "iteration number: 307\t training loss: 1138.2363\tvalidation loss: 375.0859\t validation accuracy: 0.9333\n",
      "iteration number: 308\t training loss: 1141.9377\tvalidation loss: 376.1774\t validation accuracy: 0.9333\n",
      "iteration number: 309\t training loss: 1147.2918\tvalidation loss: 377.8390\t validation accuracy: 0.9267\n",
      "iteration number: 310\t training loss: 1151.0659\tvalidation loss: 378.8105\t validation accuracy: 0.9289\n",
      "iteration number: 311\t training loss: 1154.2112\tvalidation loss: 379.6678\t validation accuracy: 0.9356\n",
      "iteration number: 312\t training loss: 1154.5375\tvalidation loss: 380.0217\t validation accuracy: 0.9333\n",
      "iteration number: 313\t training loss: 1153.3409\tvalidation loss: 380.0815\t validation accuracy: 0.9289\n",
      "iteration number: 314\t training loss: 1150.8938\tvalidation loss: 379.5003\t validation accuracy: 0.9267\n",
      "iteration number: 315\t training loss: 1153.3211\tvalidation loss: 380.7281\t validation accuracy: 0.9311\n",
      "iteration number: 316\t training loss: 1156.5566\tvalidation loss: 382.0192\t validation accuracy: 0.9311\n",
      "iteration number: 317\t training loss: 1159.0491\tvalidation loss: 383.0992\t validation accuracy: 0.9333\n",
      "iteration number: 318\t training loss: 1158.2887\tvalidation loss: 383.1560\t validation accuracy: 0.9311\n",
      "iteration number: 319\t training loss: 1157.2245\tvalidation loss: 382.9219\t validation accuracy: 0.9311\n",
      "iteration number: 320\t training loss: 1151.7526\tvalidation loss: 381.3638\t validation accuracy: 0.9311\n",
      "iteration number: 321\t training loss: 1145.2807\tvalidation loss: 379.3931\t validation accuracy: 0.9267\n",
      "iteration number: 322\t training loss: 1136.7122\tvalidation loss: 376.7367\t validation accuracy: 0.9267\n",
      "iteration number: 323\t training loss: 1126.3472\tvalidation loss: 373.4368\t validation accuracy: 0.9267\n",
      "iteration number: 324\t training loss: 1114.6415\tvalidation loss: 369.6517\t validation accuracy: 0.9267\n",
      "iteration number: 325\t training loss: 1103.8253\tvalidation loss: 366.1503\t validation accuracy: 0.9244\n",
      "iteration number: 326\t training loss: 1097.1777\tvalidation loss: 363.9627\t validation accuracy: 0.9133\n",
      "iteration number: 327\t training loss: 1091.6432\tvalidation loss: 361.9458\t validation accuracy: 0.9133\n",
      "iteration number: 328\t training loss: 1087.1784\tvalidation loss: 360.2849\t validation accuracy: 0.9133\n",
      "iteration number: 329\t training loss: 1083.5133\tvalidation loss: 359.2226\t validation accuracy: 0.9133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 330\t training loss: 1080.6589\tvalidation loss: 358.3014\t validation accuracy: 0.9111\n",
      "iteration number: 331\t training loss: 1081.3095\tvalidation loss: 358.7074\t validation accuracy: 0.9133\n",
      "iteration number: 332\t training loss: 1083.1268\tvalidation loss: 359.4157\t validation accuracy: 0.9178\n",
      "iteration number: 333\t training loss: 1084.7199\tvalidation loss: 359.8203\t validation accuracy: 0.9244\n",
      "iteration number: 334\t training loss: 1088.1562\tvalidation loss: 360.9187\t validation accuracy: 0.9333\n",
      "iteration number: 335\t training loss: 1091.3490\tvalidation loss: 362.1762\t validation accuracy: 0.9356\n",
      "iteration number: 336\t training loss: 1095.3179\tvalidation loss: 363.7893\t validation accuracy: 0.9378\n",
      "iteration number: 337\t training loss: 1101.9456\tvalidation loss: 366.1699\t validation accuracy: 0.9400\n",
      "iteration number: 338\t training loss: 1107.8273\tvalidation loss: 368.0263\t validation accuracy: 0.9400\n",
      "iteration number: 339\t training loss: 1110.7671\tvalidation loss: 369.1200\t validation accuracy: 0.9378\n",
      "iteration number: 340\t training loss: 1108.4594\tvalidation loss: 368.4723\t validation accuracy: 0.9422\n",
      "iteration number: 341\t training loss: 1104.3608\tvalidation loss: 367.5818\t validation accuracy: 0.9422\n",
      "iteration number: 342\t training loss: 1102.0040\tvalidation loss: 367.0896\t validation accuracy: 0.9422\n",
      "iteration number: 343\t training loss: 1100.0526\tvalidation loss: 366.7828\t validation accuracy: 0.9422\n",
      "iteration number: 344\t training loss: 1097.2285\tvalidation loss: 366.3886\t validation accuracy: 0.9400\n",
      "iteration number: 345\t training loss: 1094.9150\tvalidation loss: 366.1611\t validation accuracy: 0.9378\n",
      "iteration number: 346\t training loss: 1090.3015\tvalidation loss: 365.0432\t validation accuracy: 0.9333\n",
      "iteration number: 347\t training loss: 1081.7710\tvalidation loss: 362.7348\t validation accuracy: 0.9289\n",
      "iteration number: 348\t training loss: 1073.2183\tvalidation loss: 360.2833\t validation accuracy: 0.9222\n",
      "iteration number: 349\t training loss: 1064.0803\tvalidation loss: 357.4776\t validation accuracy: 0.9178\n",
      "iteration number: 350\t training loss: 1056.8231\tvalidation loss: 355.0847\t validation accuracy: 0.9111\n",
      "iteration number: 351\t training loss: 1051.5031\tvalidation loss: 353.1468\t validation accuracy: 0.9044\n",
      "iteration number: 352\t training loss: 1048.7252\tvalidation loss: 352.0403\t validation accuracy: 0.9044\n",
      "iteration number: 353\t training loss: 1046.8561\tvalidation loss: 351.4291\t validation accuracy: 0.9022\n",
      "iteration number: 354\t training loss: 1048.1228\tvalidation loss: 351.4057\t validation accuracy: 0.9022\n",
      "iteration number: 355\t training loss: 1050.2866\tvalidation loss: 351.4791\t validation accuracy: 0.9044\n",
      "iteration number: 356\t training loss: 1053.1679\tvalidation loss: 351.6988\t validation accuracy: 0.9111\n",
      "iteration number: 357\t training loss: 1055.5434\tvalidation loss: 351.4341\t validation accuracy: 0.9178\n",
      "iteration number: 358\t training loss: 1058.5911\tvalidation loss: 351.5777\t validation accuracy: 0.9244\n",
      "iteration number: 359\t training loss: 1058.3928\tvalidation loss: 350.5706\t validation accuracy: 0.9333\n",
      "iteration number: 360\t training loss: 1057.7386\tvalidation loss: 349.2821\t validation accuracy: 0.9378\n",
      "iteration number: 361\t training loss: 1056.4330\tvalidation loss: 348.0223\t validation accuracy: 0.9400\n",
      "iteration number: 362\t training loss: 1054.4150\tvalidation loss: 346.9439\t validation accuracy: 0.9378\n",
      "iteration number: 363\t training loss: 1051.8879\tvalidation loss: 346.1291\t validation accuracy: 0.9333\n",
      "iteration number: 364\t training loss: 1046.8223\tvalidation loss: 344.8989\t validation accuracy: 0.9333\n",
      "iteration number: 365\t training loss: 1042.5984\tvalidation loss: 344.2938\t validation accuracy: 0.9333\n",
      "iteration number: 366\t training loss: 1038.6835\tvalidation loss: 343.9890\t validation accuracy: 0.9311\n",
      "iteration number: 367\t training loss: 1033.5965\tvalidation loss: 343.2243\t validation accuracy: 0.9311\n",
      "iteration number: 368\t training loss: 1025.8128\tvalidation loss: 341.4267\t validation accuracy: 0.9311\n",
      "iteration number: 369\t training loss: 1019.3029\tvalidation loss: 339.9268\t validation accuracy: 0.9311\n",
      "iteration number: 370\t training loss: 1012.9046\tvalidation loss: 338.6599\t validation accuracy: 0.9356\n",
      "iteration number: 371\t training loss: 1010.4916\tvalidation loss: 338.7186\t validation accuracy: 0.9289\n",
      "iteration number: 372\t training loss: 1011.2149\tvalidation loss: 339.6629\t validation accuracy: 0.9244\n",
      "iteration number: 373\t training loss: 1012.6689\tvalidation loss: 340.7534\t validation accuracy: 0.9267\n",
      "iteration number: 374\t training loss: 1016.6087\tvalidation loss: 342.3759\t validation accuracy: 0.9244\n",
      "iteration number: 375\t training loss: 1023.4902\tvalidation loss: 344.8476\t validation accuracy: 0.9200\n",
      "iteration number: 376\t training loss: 1030.9323\tvalidation loss: 347.2315\t validation accuracy: 0.9200\n",
      "iteration number: 377\t training loss: 1037.0110\tvalidation loss: 348.9947\t validation accuracy: 0.9200\n",
      "iteration number: 378\t training loss: 1042.9432\tvalidation loss: 350.7949\t validation accuracy: 0.9178\n",
      "iteration number: 379\t training loss: 1044.8147\tvalidation loss: 350.8180\t validation accuracy: 0.9178\n",
      "iteration number: 380\t training loss: 1045.1056\tvalidation loss: 350.2085\t validation accuracy: 0.9200\n",
      "iteration number: 381\t training loss: 1041.7144\tvalidation loss: 348.7626\t validation accuracy: 0.9267\n",
      "iteration number: 382\t training loss: 1037.8252\tvalidation loss: 346.9559\t validation accuracy: 0.9333\n",
      "iteration number: 383\t training loss: 1031.0719\tvalidation loss: 344.2653\t validation accuracy: 0.9356\n",
      "iteration number: 384\t training loss: 1023.3885\tvalidation loss: 341.1429\t validation accuracy: 0.9378\n",
      "iteration number: 385\t training loss: 1014.3319\tvalidation loss: 338.0087\t validation accuracy: 0.9378\n",
      "iteration number: 386\t training loss: 1007.5275\tvalidation loss: 335.4722\t validation accuracy: 0.9444\n",
      "iteration number: 387\t training loss: 1002.2841\tvalidation loss: 333.5421\t validation accuracy: 0.9444\n",
      "iteration number: 388\t training loss: 997.2095\tvalidation loss: 331.5984\t validation accuracy: 0.9422\n",
      "iteration number: 389\t training loss: 990.8961\tvalidation loss: 329.6534\t validation accuracy: 0.9422\n",
      "iteration number: 390\t training loss: 988.8005\tvalidation loss: 329.2607\t validation accuracy: 0.9422\n",
      "iteration number: 391\t training loss: 988.3812\tvalidation loss: 329.3844\t validation accuracy: 0.9444\n",
      "iteration number: 392\t training loss: 985.4132\tvalidation loss: 328.6289\t validation accuracy: 0.9422\n",
      "iteration number: 393\t training loss: 982.8691\tvalidation loss: 327.8174\t validation accuracy: 0.9356\n",
      "iteration number: 394\t training loss: 978.3520\tvalidation loss: 326.6924\t validation accuracy: 0.9378\n",
      "iteration number: 395\t training loss: 974.2071\tvalidation loss: 325.9188\t validation accuracy: 0.9378\n",
      "iteration number: 396\t training loss: 966.8684\tvalidation loss: 324.1949\t validation accuracy: 0.9400\n",
      "iteration number: 397\t training loss: 962.9894\tvalidation loss: 323.6532\t validation accuracy: 0.9444\n",
      "iteration number: 398\t training loss: 960.5620\tvalidation loss: 323.0848\t validation accuracy: 0.9467\n",
      "iteration number: 399\t training loss: 959.6533\tvalidation loss: 322.9593\t validation accuracy: 0.9400\n",
      "iteration number: 400\t training loss: 959.5868\tvalidation loss: 322.8024\t validation accuracy: 0.9422\n",
      "iteration number: 401\t training loss: 960.0894\tvalidation loss: 322.4716\t validation accuracy: 0.9422\n",
      "iteration number: 402\t training loss: 962.3153\tvalidation loss: 322.8311\t validation accuracy: 0.9422\n",
      "iteration number: 403\t training loss: 964.6857\tvalidation loss: 323.2520\t validation accuracy: 0.9400\n",
      "iteration number: 404\t training loss: 968.0758\tvalidation loss: 324.1045\t validation accuracy: 0.9422\n",
      "iteration number: 405\t training loss: 971.3273\tvalidation loss: 325.1684\t validation accuracy: 0.9422\n",
      "iteration number: 406\t training loss: 973.4565\tvalidation loss: 325.9167\t validation accuracy: 0.9400\n",
      "iteration number: 407\t training loss: 973.8900\tvalidation loss: 326.4513\t validation accuracy: 0.9356\n",
      "iteration number: 408\t training loss: 975.1632\tvalidation loss: 327.2860\t validation accuracy: 0.9356\n",
      "iteration number: 409\t training loss: 977.6420\tvalidation loss: 328.5309\t validation accuracy: 0.9356\n",
      "iteration number: 410\t training loss: 980.4197\tvalidation loss: 329.5086\t validation accuracy: 0.9356\n",
      "iteration number: 411\t training loss: 982.2604\tvalidation loss: 329.7595\t validation accuracy: 0.9356\n",
      "iteration number: 412\t training loss: 983.6885\tvalidation loss: 329.6556\t validation accuracy: 0.9356\n",
      "iteration number: 413\t training loss: 984.1375\tvalidation loss: 329.2141\t validation accuracy: 0.9400\n",
      "iteration number: 414\t training loss: 983.5507\tvalidation loss: 328.3062\t validation accuracy: 0.9422\n",
      "iteration number: 415\t training loss: 979.4487\tvalidation loss: 326.7111\t validation accuracy: 0.9444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 416\t training loss: 975.3341\tvalidation loss: 325.2731\t validation accuracy: 0.9444\n",
      "iteration number: 417\t training loss: 969.8984\tvalidation loss: 323.4820\t validation accuracy: 0.9400\n",
      "iteration number: 418\t training loss: 963.1778\tvalidation loss: 321.1259\t validation accuracy: 0.9422\n",
      "iteration number: 419\t training loss: 954.2011\tvalidation loss: 317.9640\t validation accuracy: 0.9422\n",
      "iteration number: 420\t training loss: 946.7197\tvalidation loss: 315.3997\t validation accuracy: 0.9378\n",
      "iteration number: 421\t training loss: 941.1032\tvalidation loss: 313.2242\t validation accuracy: 0.9378\n",
      "iteration number: 422\t training loss: 936.4475\tvalidation loss: 311.3761\t validation accuracy: 0.9378\n",
      "iteration number: 423\t training loss: 929.9547\tvalidation loss: 309.1969\t validation accuracy: 0.9400\n",
      "iteration number: 424\t training loss: 924.1018\tvalidation loss: 307.2542\t validation accuracy: 0.9400\n",
      "iteration number: 425\t training loss: 919.9509\tvalidation loss: 305.9638\t validation accuracy: 0.9422\n",
      "iteration number: 426\t training loss: 917.7178\tvalidation loss: 305.3279\t validation accuracy: 0.9422\n",
      "iteration number: 427\t training loss: 918.0132\tvalidation loss: 305.3670\t validation accuracy: 0.9378\n",
      "iteration number: 428\t training loss: 917.4219\tvalidation loss: 305.5160\t validation accuracy: 0.9378\n",
      "iteration number: 429\t training loss: 917.3696\tvalidation loss: 305.9223\t validation accuracy: 0.9378\n",
      "iteration number: 430\t training loss: 916.1914\tvalidation loss: 305.8587\t validation accuracy: 0.9400\n",
      "iteration number: 431\t training loss: 915.7050\tvalidation loss: 306.0396\t validation accuracy: 0.9422\n",
      "iteration number: 432\t training loss: 917.9789\tvalidation loss: 307.0114\t validation accuracy: 0.9422\n",
      "iteration number: 433\t training loss: 920.0862\tvalidation loss: 307.9582\t validation accuracy: 0.9356\n",
      "iteration number: 434\t training loss: 921.6614\tvalidation loss: 308.5243\t validation accuracy: 0.9400\n",
      "iteration number: 435\t training loss: 919.9324\tvalidation loss: 308.1229\t validation accuracy: 0.9400\n",
      "iteration number: 436\t training loss: 917.5625\tvalidation loss: 307.6150\t validation accuracy: 0.9400\n",
      "iteration number: 437\t training loss: 916.1987\tvalidation loss: 307.5342\t validation accuracy: 0.9400\n",
      "iteration number: 438\t training loss: 915.6260\tvalidation loss: 307.6117\t validation accuracy: 0.9422\n",
      "iteration number: 439\t training loss: 916.5868\tvalidation loss: 308.1106\t validation accuracy: 0.9400\n",
      "iteration number: 440\t training loss: 919.1043\tvalidation loss: 309.3187\t validation accuracy: 0.9400\n",
      "iteration number: 441\t training loss: 920.6863\tvalidation loss: 309.7917\t validation accuracy: 0.9400\n",
      "iteration number: 442\t training loss: 922.6688\tvalidation loss: 310.4938\t validation accuracy: 0.9444\n",
      "iteration number: 443\t training loss: 922.2416\tvalidation loss: 310.3964\t validation accuracy: 0.9444\n",
      "iteration number: 444\t training loss: 922.1006\tvalidation loss: 310.3900\t validation accuracy: 0.9467\n",
      "iteration number: 445\t training loss: 920.5573\tvalidation loss: 309.8582\t validation accuracy: 0.9467\n",
      "iteration number: 446\t training loss: 920.5688\tvalidation loss: 309.9791\t validation accuracy: 0.9489\n",
      "iteration number: 447\t training loss: 920.4356\tvalidation loss: 310.1594\t validation accuracy: 0.9444\n",
      "iteration number: 448\t training loss: 921.0496\tvalidation loss: 310.6358\t validation accuracy: 0.9444\n",
      "iteration number: 449\t training loss: 920.0356\tvalidation loss: 310.4300\t validation accuracy: 0.9444\n",
      "iteration number: 450\t training loss: 918.1182\tvalidation loss: 309.8562\t validation accuracy: 0.9467\n",
      "iteration number: 451\t training loss: 916.5011\tvalidation loss: 309.5507\t validation accuracy: 0.9467\n",
      "iteration number: 452\t training loss: 912.7308\tvalidation loss: 308.4037\t validation accuracy: 0.9489\n",
      "iteration number: 453\t training loss: 910.0498\tvalidation loss: 307.4117\t validation accuracy: 0.9511\n",
      "iteration number: 454\t training loss: 906.9758\tvalidation loss: 305.9712\t validation accuracy: 0.9489\n",
      "iteration number: 455\t training loss: 900.1244\tvalidation loss: 303.4760\t validation accuracy: 0.9489\n",
      "iteration number: 456\t training loss: 892.0880\tvalidation loss: 300.7170\t validation accuracy: 0.9511\n",
      "iteration number: 457\t training loss: 884.0501\tvalidation loss: 298.0805\t validation accuracy: 0.9511\n",
      "iteration number: 458\t training loss: 876.8968\tvalidation loss: 295.6340\t validation accuracy: 0.9511\n",
      "iteration number: 459\t training loss: 869.8823\tvalidation loss: 292.9922\t validation accuracy: 0.9489\n",
      "iteration number: 460\t training loss: 866.8421\tvalidation loss: 291.6909\t validation accuracy: 0.9489\n",
      "iteration number: 461\t training loss: 862.9439\tvalidation loss: 289.9379\t validation accuracy: 0.9489\n",
      "iteration number: 462\t training loss: 858.0859\tvalidation loss: 288.3059\t validation accuracy: 0.9511\n",
      "iteration number: 463\t training loss: 854.3722\tvalidation loss: 286.9737\t validation accuracy: 0.9489\n",
      "iteration number: 464\t training loss: 852.7946\tvalidation loss: 286.7150\t validation accuracy: 0.9467\n",
      "iteration number: 465\t training loss: 850.5153\tvalidation loss: 286.1219\t validation accuracy: 0.9444\n",
      "iteration number: 466\t training loss: 848.5389\tvalidation loss: 285.6225\t validation accuracy: 0.9422\n",
      "iteration number: 467\t training loss: 850.1454\tvalidation loss: 286.4772\t validation accuracy: 0.9400\n",
      "iteration number: 468\t training loss: 850.5005\tvalidation loss: 286.7858\t validation accuracy: 0.9467\n",
      "iteration number: 469\t training loss: 850.6124\tvalidation loss: 286.8579\t validation accuracy: 0.9467\n",
      "iteration number: 470\t training loss: 849.3272\tvalidation loss: 286.0386\t validation accuracy: 0.9467\n",
      "iteration number: 471\t training loss: 848.9908\tvalidation loss: 285.6646\t validation accuracy: 0.9444\n",
      "iteration number: 472\t training loss: 847.5728\tvalidation loss: 284.9375\t validation accuracy: 0.9444\n",
      "iteration number: 473\t training loss: 848.7303\tvalidation loss: 285.2000\t validation accuracy: 0.9444\n",
      "iteration number: 474\t training loss: 852.4438\tvalidation loss: 286.0749\t validation accuracy: 0.9467\n",
      "iteration number: 475\t training loss: 857.9646\tvalidation loss: 287.4678\t validation accuracy: 0.9467\n",
      "iteration number: 476\t training loss: 860.0425\tvalidation loss: 287.7611\t validation accuracy: 0.9489\n",
      "iteration number: 477\t training loss: 860.5609\tvalidation loss: 287.6003\t validation accuracy: 0.9556\n",
      "iteration number: 478\t training loss: 860.5026\tvalidation loss: 287.2569\t validation accuracy: 0.9578\n",
      "iteration number: 479\t training loss: 862.9689\tvalidation loss: 287.6828\t validation accuracy: 0.9556\n",
      "iteration number: 480\t training loss: 865.5680\tvalidation loss: 288.3303\t validation accuracy: 0.9533\n",
      "iteration number: 481\t training loss: 866.8701\tvalidation loss: 288.6367\t validation accuracy: 0.9556\n",
      "iteration number: 482\t training loss: 866.3877\tvalidation loss: 288.6365\t validation accuracy: 0.9556\n",
      "iteration number: 483\t training loss: 867.5650\tvalidation loss: 289.2872\t validation accuracy: 0.9556\n",
      "iteration number: 484\t training loss: 866.3015\tvalidation loss: 289.2557\t validation accuracy: 0.9578\n",
      "iteration number: 485\t training loss: 864.4766\tvalidation loss: 289.2715\t validation accuracy: 0.9578\n",
      "iteration number: 486\t training loss: 862.4026\tvalidation loss: 289.6648\t validation accuracy: 0.9556\n",
      "iteration number: 487\t training loss: 862.1136\tvalidation loss: 290.4790\t validation accuracy: 0.9578\n",
      "iteration number: 488\t training loss: 858.8309\tvalidation loss: 290.2092\t validation accuracy: 0.9578\n",
      "iteration number: 489\t training loss: 855.8327\tvalidation loss: 289.9212\t validation accuracy: 0.9578\n",
      "iteration number: 490\t training loss: 853.1095\tvalidation loss: 289.6502\t validation accuracy: 0.9533\n",
      "iteration number: 491\t training loss: 851.8758\tvalidation loss: 289.7536\t validation accuracy: 0.9533\n",
      "iteration number: 492\t training loss: 849.8000\tvalidation loss: 289.1782\t validation accuracy: 0.9533\n",
      "iteration number: 493\t training loss: 847.5833\tvalidation loss: 288.3057\t validation accuracy: 0.9533\n",
      "iteration number: 494\t training loss: 846.1103\tvalidation loss: 287.6638\t validation accuracy: 0.9511\n",
      "iteration number: 495\t training loss: 844.5473\tvalidation loss: 286.8560\t validation accuracy: 0.9511\n",
      "iteration number: 496\t training loss: 841.2353\tvalidation loss: 285.0779\t validation accuracy: 0.9511\n",
      "iteration number: 497\t training loss: 838.7918\tvalidation loss: 283.8919\t validation accuracy: 0.9511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 498\t training loss: 837.6624\tvalidation loss: 282.8898\t validation accuracy: 0.9533\n",
      "iteration number: 499\t training loss: 839.0626\tvalidation loss: 282.8393\t validation accuracy: 0.9533\n",
      "iteration number: 500\t training loss: 840.5408\tvalidation loss: 282.6334\t validation accuracy: 0.9556\n",
      "iteration number: 501\t training loss: 841.0743\tvalidation loss: 282.2330\t validation accuracy: 0.9556\n",
      "iteration number: 502\t training loss: 842.0684\tvalidation loss: 282.1228\t validation accuracy: 0.9533\n",
      "iteration number: 503\t training loss: 840.0042\tvalidation loss: 281.3524\t validation accuracy: 0.9556\n",
      "iteration number: 504\t training loss: 841.1237\tvalidation loss: 281.6664\t validation accuracy: 0.9556\n",
      "iteration number: 505\t training loss: 843.9407\tvalidation loss: 282.5828\t validation accuracy: 0.9556\n",
      "iteration number: 506\t training loss: 845.5277\tvalidation loss: 283.0026\t validation accuracy: 0.9556\n",
      "iteration number: 507\t training loss: 845.6054\tvalidation loss: 283.0707\t validation accuracy: 0.9556\n",
      "iteration number: 508\t training loss: 842.7199\tvalidation loss: 282.1088\t validation accuracy: 0.9556\n",
      "iteration number: 509\t training loss: 838.0402\tvalidation loss: 280.5621\t validation accuracy: 0.9556\n",
      "iteration number: 510\t training loss: 833.1949\tvalidation loss: 279.1740\t validation accuracy: 0.9556\n",
      "iteration number: 511\t training loss: 829.1668\tvalidation loss: 277.9945\t validation accuracy: 0.9556\n",
      "iteration number: 512\t training loss: 826.0033\tvalidation loss: 277.2944\t validation accuracy: 0.9578\n",
      "iteration number: 513\t training loss: 822.3797\tvalidation loss: 276.4451\t validation accuracy: 0.9578\n",
      "iteration number: 514\t training loss: 819.9286\tvalidation loss: 275.8022\t validation accuracy: 0.9578\n",
      "iteration number: 515\t training loss: 817.9071\tvalidation loss: 275.3513\t validation accuracy: 0.9600\n",
      "iteration number: 516\t training loss: 816.7850\tvalidation loss: 275.3263\t validation accuracy: 0.9622\n",
      "iteration number: 517\t training loss: 815.0722\tvalidation loss: 275.1542\t validation accuracy: 0.9622\n",
      "iteration number: 518\t training loss: 814.1739\tvalidation loss: 275.2233\t validation accuracy: 0.9600\n",
      "iteration number: 519\t training loss: 813.1570\tvalidation loss: 275.4033\t validation accuracy: 0.9600\n",
      "iteration number: 520\t training loss: 812.4126\tvalidation loss: 275.5404\t validation accuracy: 0.9578\n",
      "iteration number: 521\t training loss: 811.2751\tvalidation loss: 275.5433\t validation accuracy: 0.9600\n",
      "iteration number: 522\t training loss: 810.5264\tvalidation loss: 275.4268\t validation accuracy: 0.9600\n",
      "iteration number: 523\t training loss: 811.1540\tvalidation loss: 275.4525\t validation accuracy: 0.9600\n",
      "iteration number: 524\t training loss: 813.6454\tvalidation loss: 275.9291\t validation accuracy: 0.9622\n",
      "iteration number: 525\t training loss: 816.4550\tvalidation loss: 276.4247\t validation accuracy: 0.9622\n",
      "iteration number: 526\t training loss: 818.8537\tvalidation loss: 276.9181\t validation accuracy: 0.9622\n",
      "iteration number: 527\t training loss: 819.2884\tvalidation loss: 276.8360\t validation accuracy: 0.9600\n",
      "iteration number: 528\t training loss: 820.5200\tvalidation loss: 276.9269\t validation accuracy: 0.9578\n",
      "iteration number: 529\t training loss: 821.8898\tvalidation loss: 277.2595\t validation accuracy: 0.9600\n",
      "iteration number: 530\t training loss: 822.3283\tvalidation loss: 277.1572\t validation accuracy: 0.9600\n",
      "iteration number: 531\t training loss: 822.5104\tvalidation loss: 277.0390\t validation accuracy: 0.9600\n",
      "iteration number: 532\t training loss: 824.4599\tvalidation loss: 277.6059\t validation accuracy: 0.9578\n",
      "iteration number: 533\t training loss: 824.8719\tvalidation loss: 277.6196\t validation accuracy: 0.9578\n",
      "iteration number: 534\t training loss: 824.7801\tvalidation loss: 277.4823\t validation accuracy: 0.9556\n",
      "iteration number: 535\t training loss: 828.2446\tvalidation loss: 278.4795\t validation accuracy: 0.9533\n",
      "iteration number: 536\t training loss: 829.4951\tvalidation loss: 278.9488\t validation accuracy: 0.9533\n",
      "iteration number: 537\t training loss: 826.8888\tvalidation loss: 278.2818\t validation accuracy: 0.9511\n",
      "iteration number: 538\t training loss: 822.4982\tvalidation loss: 277.0348\t validation accuracy: 0.9511\n",
      "iteration number: 539\t training loss: 817.6368\tvalidation loss: 275.5245\t validation accuracy: 0.9511\n",
      "iteration number: 540\t training loss: 814.5780\tvalidation loss: 274.6497\t validation accuracy: 0.9489\n",
      "iteration number: 541\t training loss: 811.0624\tvalidation loss: 273.6959\t validation accuracy: 0.9511\n",
      "iteration number: 542\t training loss: 805.0608\tvalidation loss: 271.9219\t validation accuracy: 0.9511\n",
      "iteration number: 543\t training loss: 799.5157\tvalidation loss: 270.3292\t validation accuracy: 0.9489\n",
      "iteration number: 544\t training loss: 794.5005\tvalidation loss: 268.8058\t validation accuracy: 0.9511\n",
      "iteration number: 545\t training loss: 788.2795\tvalidation loss: 266.8606\t validation accuracy: 0.9578\n",
      "iteration number: 546\t training loss: 781.1670\tvalidation loss: 264.4423\t validation accuracy: 0.9578\n",
      "iteration number: 547\t training loss: 774.0072\tvalidation loss: 261.9784\t validation accuracy: 0.9600\n",
      "iteration number: 548\t training loss: 768.5241\tvalidation loss: 260.0013\t validation accuracy: 0.9600\n",
      "iteration number: 549\t training loss: 765.2711\tvalidation loss: 258.7522\t validation accuracy: 0.9556\n",
      "iteration number: 550\t training loss: 762.7049\tvalidation loss: 257.5845\t validation accuracy: 0.9578\n",
      "iteration number: 551\t training loss: 761.4275\tvalidation loss: 256.9891\t validation accuracy: 0.9600\n",
      "iteration number: 552\t training loss: 763.6411\tvalidation loss: 257.7191\t validation accuracy: 0.9600\n",
      "iteration number: 553\t training loss: 766.3474\tvalidation loss: 258.7571\t validation accuracy: 0.9600\n",
      "iteration number: 554\t training loss: 770.8763\tvalidation loss: 260.3568\t validation accuracy: 0.9600\n",
      "iteration number: 555\t training loss: 774.4468\tvalidation loss: 261.6378\t validation accuracy: 0.9578\n",
      "iteration number: 556\t training loss: 776.8562\tvalidation loss: 262.6158\t validation accuracy: 0.9556\n",
      "iteration number: 557\t training loss: 777.7957\tvalidation loss: 263.1017\t validation accuracy: 0.9578\n",
      "iteration number: 558\t training loss: 777.7310\tvalidation loss: 263.3231\t validation accuracy: 0.9578\n",
      "iteration number: 559\t training loss: 779.3772\tvalidation loss: 264.1052\t validation accuracy: 0.9578\n",
      "iteration number: 560\t training loss: 779.4047\tvalidation loss: 264.2354\t validation accuracy: 0.9578\n",
      "iteration number: 561\t training loss: 779.7901\tvalidation loss: 264.5431\t validation accuracy: 0.9578\n",
      "iteration number: 562\t training loss: 779.8209\tvalidation loss: 264.5666\t validation accuracy: 0.9578\n",
      "iteration number: 563\t training loss: 779.9274\tvalidation loss: 264.7214\t validation accuracy: 0.9556\n",
      "iteration number: 564\t training loss: 780.3850\tvalidation loss: 265.0297\t validation accuracy: 0.9556\n",
      "iteration number: 565\t training loss: 781.8558\tvalidation loss: 265.6221\t validation accuracy: 0.9556\n",
      "iteration number: 566\t training loss: 781.2261\tvalidation loss: 265.6065\t validation accuracy: 0.9556\n",
      "iteration number: 567\t training loss: 781.3884\tvalidation loss: 265.8365\t validation accuracy: 0.9556\n",
      "iteration number: 568\t training loss: 781.6981\tvalidation loss: 266.0031\t validation accuracy: 0.9556\n",
      "iteration number: 569\t training loss: 783.6526\tvalidation loss: 266.5261\t validation accuracy: 0.9556\n",
      "iteration number: 570\t training loss: 784.3620\tvalidation loss: 266.6928\t validation accuracy: 0.9556\n",
      "iteration number: 571\t training loss: 783.0797\tvalidation loss: 266.1513\t validation accuracy: 0.9556\n",
      "iteration number: 572\t training loss: 781.1093\tvalidation loss: 265.5006\t validation accuracy: 0.9556\n",
      "iteration number: 573\t training loss: 780.1956\tvalidation loss: 265.2353\t validation accuracy: 0.9533\n",
      "iteration number: 574\t training loss: 777.9316\tvalidation loss: 264.3111\t validation accuracy: 0.9556\n",
      "iteration number: 575\t training loss: 775.6552\tvalidation loss: 263.3359\t validation accuracy: 0.9578\n",
      "iteration number: 576\t training loss: 773.2266\tvalidation loss: 262.3679\t validation accuracy: 0.9578\n",
      "iteration number: 577\t training loss: 772.1294\tvalidation loss: 261.9901\t validation accuracy: 0.9578\n",
      "iteration number: 578\t training loss: 769.6831\tvalidation loss: 261.2225\t validation accuracy: 0.9578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 579\t training loss: 767.3077\tvalidation loss: 260.5710\t validation accuracy: 0.9578\n",
      "iteration number: 580\t training loss: 764.5781\tvalidation loss: 259.8540\t validation accuracy: 0.9600\n",
      "iteration number: 581\t training loss: 762.5148\tvalidation loss: 259.3551\t validation accuracy: 0.9600\n",
      "iteration number: 582\t training loss: 758.9040\tvalidation loss: 258.2838\t validation accuracy: 0.9644\n",
      "iteration number: 583\t training loss: 755.7138\tvalidation loss: 257.2904\t validation accuracy: 0.9644\n",
      "iteration number: 584\t training loss: 752.2469\tvalidation loss: 256.0245\t validation accuracy: 0.9644\n",
      "iteration number: 585\t training loss: 749.4363\tvalidation loss: 255.1649\t validation accuracy: 0.9644\n",
      "iteration number: 586\t training loss: 745.4436\tvalidation loss: 253.9412\t validation accuracy: 0.9667\n",
      "iteration number: 587\t training loss: 743.9193\tvalidation loss: 253.9004\t validation accuracy: 0.9667\n",
      "iteration number: 588\t training loss: 743.8597\tvalidation loss: 254.4640\t validation accuracy: 0.9667\n",
      "iteration number: 589\t training loss: 745.8350\tvalidation loss: 255.5524\t validation accuracy: 0.9667\n",
      "iteration number: 590\t training loss: 749.1573\tvalidation loss: 256.9585\t validation accuracy: 0.9600\n",
      "iteration number: 591\t training loss: 751.0133\tvalidation loss: 257.8564\t validation accuracy: 0.9600\n",
      "iteration number: 592\t training loss: 751.5629\tvalidation loss: 258.1723\t validation accuracy: 0.9600\n",
      "iteration number: 593\t training loss: 752.5306\tvalidation loss: 258.4448\t validation accuracy: 0.9600\n",
      "iteration number: 594\t training loss: 754.3327\tvalidation loss: 258.9487\t validation accuracy: 0.9622\n",
      "iteration number: 595\t training loss: 756.6392\tvalidation loss: 259.5054\t validation accuracy: 0.9622\n",
      "iteration number: 596\t training loss: 756.6918\tvalidation loss: 259.1753\t validation accuracy: 0.9644\n",
      "iteration number: 597\t training loss: 757.4723\tvalidation loss: 259.1144\t validation accuracy: 0.9644\n",
      "iteration number: 598\t training loss: 758.2841\tvalidation loss: 259.0117\t validation accuracy: 0.9644\n",
      "iteration number: 599\t training loss: 758.2118\tvalidation loss: 258.4515\t validation accuracy: 0.9622\n",
      "iteration number: 600\t training loss: 757.8271\tvalidation loss: 257.9694\t validation accuracy: 0.9622\n",
      "iteration number: 601\t training loss: 755.0107\tvalidation loss: 257.0262\t validation accuracy: 0.9600\n",
      "iteration number: 602\t training loss: 752.6345\tvalidation loss: 256.3216\t validation accuracy: 0.9600\n",
      "iteration number: 603\t training loss: 752.4126\tvalidation loss: 256.1765\t validation accuracy: 0.9600\n",
      "iteration number: 604\t training loss: 752.5896\tvalidation loss: 256.1730\t validation accuracy: 0.9600\n",
      "iteration number: 605\t training loss: 753.7730\tvalidation loss: 256.6834\t validation accuracy: 0.9622\n",
      "iteration number: 606\t training loss: 755.2491\tvalidation loss: 257.1701\t validation accuracy: 0.9578\n",
      "iteration number: 607\t training loss: 756.9036\tvalidation loss: 257.6918\t validation accuracy: 0.9578\n",
      "iteration number: 608\t training loss: 758.9642\tvalidation loss: 258.3971\t validation accuracy: 0.9578\n",
      "iteration number: 609\t training loss: 760.6049\tvalidation loss: 258.9510\t validation accuracy: 0.9600\n",
      "iteration number: 610\t training loss: 763.2062\tvalidation loss: 259.6848\t validation accuracy: 0.9600\n",
      "iteration number: 611\t training loss: 764.7683\tvalidation loss: 260.2333\t validation accuracy: 0.9578\n",
      "iteration number: 612\t training loss: 767.1786\tvalidation loss: 261.2530\t validation accuracy: 0.9622\n",
      "iteration number: 613\t training loss: 769.2898\tvalidation loss: 262.1335\t validation accuracy: 0.9622\n",
      "iteration number: 614\t training loss: 770.9864\tvalidation loss: 262.9006\t validation accuracy: 0.9622\n",
      "iteration number: 615\t training loss: 771.0688\tvalidation loss: 262.9726\t validation accuracy: 0.9622\n",
      "iteration number: 616\t training loss: 767.1081\tvalidation loss: 261.5438\t validation accuracy: 0.9622\n",
      "iteration number: 617\t training loss: 764.0205\tvalidation loss: 260.5685\t validation accuracy: 0.9622\n",
      "iteration number: 618\t training loss: 759.2675\tvalidation loss: 259.1774\t validation accuracy: 0.9622\n",
      "iteration number: 619\t training loss: 753.4781\tvalidation loss: 257.4200\t validation accuracy: 0.9644\n",
      "iteration number: 620\t training loss: 747.7121\tvalidation loss: 255.7140\t validation accuracy: 0.9622\n",
      "iteration number: 621\t training loss: 742.4795\tvalidation loss: 254.1054\t validation accuracy: 0.9622\n",
      "iteration number: 622\t training loss: 736.9385\tvalidation loss: 252.3992\t validation accuracy: 0.9622\n",
      "iteration number: 623\t training loss: 732.9360\tvalidation loss: 251.1577\t validation accuracy: 0.9622\n",
      "iteration number: 624\t training loss: 731.4351\tvalidation loss: 250.8203\t validation accuracy: 0.9622\n",
      "iteration number: 625\t training loss: 730.9148\tvalidation loss: 250.7912\t validation accuracy: 0.9600\n",
      "iteration number: 626\t training loss: 730.2929\tvalidation loss: 250.5601\t validation accuracy: 0.9600\n",
      "iteration number: 627\t training loss: 728.4052\tvalidation loss: 249.7907\t validation accuracy: 0.9600\n",
      "iteration number: 628\t training loss: 727.2006\tvalidation loss: 249.2878\t validation accuracy: 0.9600\n",
      "iteration number: 629\t training loss: 725.5336\tvalidation loss: 248.6223\t validation accuracy: 0.9600\n",
      "iteration number: 630\t training loss: 726.8024\tvalidation loss: 248.9378\t validation accuracy: 0.9622\n",
      "iteration number: 631\t training loss: 728.2574\tvalidation loss: 249.1780\t validation accuracy: 0.9622\n",
      "iteration number: 632\t training loss: 729.3854\tvalidation loss: 249.2251\t validation accuracy: 0.9644\n",
      "iteration number: 633\t training loss: 730.7102\tvalidation loss: 249.4379\t validation accuracy: 0.9622\n",
      "iteration number: 634\t training loss: 731.4267\tvalidation loss: 249.4917\t validation accuracy: 0.9622\n",
      "iteration number: 635\t training loss: 733.3452\tvalidation loss: 249.9706\t validation accuracy: 0.9600\n",
      "iteration number: 636\t training loss: 734.4907\tvalidation loss: 250.0840\t validation accuracy: 0.9622\n",
      "iteration number: 637\t training loss: 737.3834\tvalidation loss: 250.7556\t validation accuracy: 0.9622\n",
      "iteration number: 638\t training loss: 738.9155\tvalidation loss: 250.8700\t validation accuracy: 0.9622\n",
      "iteration number: 639\t training loss: 739.3359\tvalidation loss: 250.5827\t validation accuracy: 0.9622\n",
      "iteration number: 640\t training loss: 740.0890\tvalidation loss: 250.7032\t validation accuracy: 0.9644\n",
      "iteration number: 641\t training loss: 739.7319\tvalidation loss: 250.5908\t validation accuracy: 0.9644\n",
      "iteration number: 642\t training loss: 739.9041\tvalidation loss: 250.8204\t validation accuracy: 0.9644\n",
      "iteration number: 643\t training loss: 741.9977\tvalidation loss: 251.7897\t validation accuracy: 0.9622\n",
      "iteration number: 644\t training loss: 745.2575\tvalidation loss: 253.0402\t validation accuracy: 0.9600\n",
      "iteration number: 645\t training loss: 748.2355\tvalidation loss: 254.2505\t validation accuracy: 0.9600\n",
      "iteration number: 646\t training loss: 750.0190\tvalidation loss: 255.3049\t validation accuracy: 0.9600\n",
      "iteration number: 647\t training loss: 750.5450\tvalidation loss: 256.0519\t validation accuracy: 0.9644\n",
      "iteration number: 648\t training loss: 750.7270\tvalidation loss: 256.6755\t validation accuracy: 0.9644\n",
      "iteration number: 649\t training loss: 752.5074\tvalidation loss: 257.7653\t validation accuracy: 0.9644\n",
      "iteration number: 650\t training loss: 753.3686\tvalidation loss: 258.6730\t validation accuracy: 0.9622\n",
      "iteration number: 651\t training loss: 751.5373\tvalidation loss: 258.6993\t validation accuracy: 0.9578\n",
      "iteration number: 652\t training loss: 748.6002\tvalidation loss: 258.2640\t validation accuracy: 0.9556\n",
      "iteration number: 653\t training loss: 744.2587\tvalidation loss: 257.1587\t validation accuracy: 0.9533\n",
      "iteration number: 654\t training loss: 739.8155\tvalidation loss: 256.0914\t validation accuracy: 0.9533\n",
      "iteration number: 655\t training loss: 735.3490\tvalidation loss: 254.8158\t validation accuracy: 0.9533\n",
      "iteration number: 656\t training loss: 731.6562\tvalidation loss: 253.6062\t validation accuracy: 0.9533\n",
      "iteration number: 657\t training loss: 727.7026\tvalidation loss: 252.0904\t validation accuracy: 0.9556\n",
      "iteration number: 658\t training loss: 723.1952\tvalidation loss: 250.1688\t validation accuracy: 0.9600\n",
      "iteration number: 659\t training loss: 718.7721\tvalidation loss: 248.2720\t validation accuracy: 0.9622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 660\t training loss: 714.2947\tvalidation loss: 246.2931\t validation accuracy: 0.9622\n",
      "iteration number: 661\t training loss: 711.9411\tvalidation loss: 245.0867\t validation accuracy: 0.9600\n",
      "iteration number: 662\t training loss: 708.3798\tvalidation loss: 243.3366\t validation accuracy: 0.9578\n",
      "iteration number: 663\t training loss: 703.6420\tvalidation loss: 241.2246\t validation accuracy: 0.9578\n",
      "iteration number: 664\t training loss: 701.5816\tvalidation loss: 240.0246\t validation accuracy: 0.9578\n",
      "iteration number: 665\t training loss: 700.2026\tvalidation loss: 239.1092\t validation accuracy: 0.9600\n",
      "iteration number: 666\t training loss: 698.9964\tvalidation loss: 238.2760\t validation accuracy: 0.9600\n",
      "iteration number: 667\t training loss: 697.2492\tvalidation loss: 237.4287\t validation accuracy: 0.9600\n",
      "iteration number: 668\t training loss: 695.4680\tvalidation loss: 236.6979\t validation accuracy: 0.9622\n",
      "iteration number: 669\t training loss: 693.4080\tvalidation loss: 236.0836\t validation accuracy: 0.9622\n",
      "iteration number: 670\t training loss: 689.8397\tvalidation loss: 235.1269\t validation accuracy: 0.9622\n",
      "iteration number: 671\t training loss: 688.2709\tvalidation loss: 234.7368\t validation accuracy: 0.9644\n",
      "iteration number: 672\t training loss: 687.0611\tvalidation loss: 234.5021\t validation accuracy: 0.9644\n",
      "iteration number: 673\t training loss: 685.4484\tvalidation loss: 234.2363\t validation accuracy: 0.9622\n",
      "iteration number: 674\t training loss: 683.7955\tvalidation loss: 233.6654\t validation accuracy: 0.9622\n",
      "iteration number: 675\t training loss: 685.3790\tvalidation loss: 234.1134\t validation accuracy: 0.9622\n",
      "iteration number: 676\t training loss: 683.9403\tvalidation loss: 233.9706\t validation accuracy: 0.9622\n",
      "iteration number: 677\t training loss: 682.8404\tvalidation loss: 233.9678\t validation accuracy: 0.9622\n",
      "iteration number: 678\t training loss: 680.4730\tvalidation loss: 233.3228\t validation accuracy: 0.9600\n",
      "iteration number: 679\t training loss: 679.4072\tvalidation loss: 233.1436\t validation accuracy: 0.9600\n",
      "iteration number: 680\t training loss: 678.9213\tvalidation loss: 233.2085\t validation accuracy: 0.9600\n",
      "iteration number: 681\t training loss: 677.9971\tvalidation loss: 233.3345\t validation accuracy: 0.9622\n",
      "iteration number: 682\t training loss: 678.1421\tvalidation loss: 233.6113\t validation accuracy: 0.9644\n",
      "iteration number: 683\t training loss: 677.8563\tvalidation loss: 233.8617\t validation accuracy: 0.9644\n",
      "iteration number: 684\t training loss: 676.9507\tvalidation loss: 233.7563\t validation accuracy: 0.9644\n",
      "iteration number: 685\t training loss: 676.0301\tvalidation loss: 233.6883\t validation accuracy: 0.9644\n",
      "iteration number: 686\t training loss: 676.2404\tvalidation loss: 233.7722\t validation accuracy: 0.9644\n",
      "iteration number: 687\t training loss: 676.9661\tvalidation loss: 233.9839\t validation accuracy: 0.9644\n",
      "iteration number: 688\t training loss: 681.0742\tvalidation loss: 235.3117\t validation accuracy: 0.9644\n",
      "iteration number: 689\t training loss: 686.0828\tvalidation loss: 236.8555\t validation accuracy: 0.9644\n",
      "iteration number: 690\t training loss: 690.4576\tvalidation loss: 238.1279\t validation accuracy: 0.9644\n",
      "iteration number: 691\t training loss: 697.1186\tvalidation loss: 240.0304\t validation accuracy: 0.9644\n",
      "iteration number: 692\t training loss: 702.8157\tvalidation loss: 241.7867\t validation accuracy: 0.9644\n",
      "iteration number: 693\t training loss: 707.1645\tvalidation loss: 242.9127\t validation accuracy: 0.9644\n",
      "iteration number: 694\t training loss: 710.3798\tvalidation loss: 243.5725\t validation accuracy: 0.9600\n",
      "iteration number: 695\t training loss: 713.1442\tvalidation loss: 244.1640\t validation accuracy: 0.9578\n",
      "iteration number: 696\t training loss: 715.0844\tvalidation loss: 244.5798\t validation accuracy: 0.9600\n",
      "iteration number: 697\t training loss: 716.1203\tvalidation loss: 244.6417\t validation accuracy: 0.9578\n",
      "iteration number: 698\t training loss: 717.2385\tvalidation loss: 244.7258\t validation accuracy: 0.9578\n",
      "iteration number: 699\t training loss: 716.4063\tvalidation loss: 244.3441\t validation accuracy: 0.9600\n",
      "iteration number: 700\t training loss: 712.8713\tvalidation loss: 243.2224\t validation accuracy: 0.9600\n",
      "iteration number: 701\t training loss: 708.6003\tvalidation loss: 241.7058\t validation accuracy: 0.9622\n",
      "iteration number: 702\t training loss: 705.3924\tvalidation loss: 240.5356\t validation accuracy: 0.9600\n",
      "iteration number: 703\t training loss: 701.9756\tvalidation loss: 239.3466\t validation accuracy: 0.9622\n",
      "iteration number: 704\t training loss: 698.0785\tvalidation loss: 238.1223\t validation accuracy: 0.9622\n",
      "iteration number: 705\t training loss: 694.6859\tvalidation loss: 236.9522\t validation accuracy: 0.9622\n",
      "iteration number: 706\t training loss: 691.8615\tvalidation loss: 236.0445\t validation accuracy: 0.9622\n",
      "iteration number: 707\t training loss: 686.7272\tvalidation loss: 234.3599\t validation accuracy: 0.9622\n",
      "iteration number: 708\t training loss: 680.2603\tvalidation loss: 232.4676\t validation accuracy: 0.9644\n",
      "iteration number: 709\t training loss: 673.6955\tvalidation loss: 230.3921\t validation accuracy: 0.9622\n",
      "iteration number: 710\t training loss: 665.3856\tvalidation loss: 227.7828\t validation accuracy: 0.9600\n",
      "iteration number: 711\t training loss: 659.3872\tvalidation loss: 226.1575\t validation accuracy: 0.9600\n",
      "iteration number: 712\t training loss: 655.3665\tvalidation loss: 225.2572\t validation accuracy: 0.9622\n",
      "iteration number: 713\t training loss: 654.3684\tvalidation loss: 225.4235\t validation accuracy: 0.9644\n",
      "iteration number: 714\t training loss: 653.5423\tvalidation loss: 225.5619\t validation accuracy: 0.9667\n",
      "iteration number: 715\t training loss: 654.2578\tvalidation loss: 226.0623\t validation accuracy: 0.9667\n",
      "iteration number: 716\t training loss: 657.2473\tvalidation loss: 227.2409\t validation accuracy: 0.9667\n",
      "iteration number: 717\t training loss: 661.1647\tvalidation loss: 228.6839\t validation accuracy: 0.9622\n",
      "iteration number: 718\t training loss: 665.5103\tvalidation loss: 230.1695\t validation accuracy: 0.9600\n",
      "iteration number: 719\t training loss: 671.5430\tvalidation loss: 232.3501\t validation accuracy: 0.9600\n",
      "iteration number: 720\t training loss: 677.6396\tvalidation loss: 234.4519\t validation accuracy: 0.9600\n",
      "iteration number: 721\t training loss: 682.9226\tvalidation loss: 236.3103\t validation accuracy: 0.9600\n",
      "iteration number: 722\t training loss: 686.0302\tvalidation loss: 237.2179\t validation accuracy: 0.9622\n",
      "iteration number: 723\t training loss: 690.3293\tvalidation loss: 238.4150\t validation accuracy: 0.9689\n",
      "iteration number: 724\t training loss: 694.5136\tvalidation loss: 239.5608\t validation accuracy: 0.9689\n",
      "iteration number: 725\t training loss: 697.9756\tvalidation loss: 240.5251\t validation accuracy: 0.9689\n",
      "iteration number: 726\t training loss: 701.8346\tvalidation loss: 241.4524\t validation accuracy: 0.9711\n",
      "iteration number: 727\t training loss: 704.3525\tvalidation loss: 242.1106\t validation accuracy: 0.9711\n",
      "iteration number: 728\t training loss: 706.0583\tvalidation loss: 242.3901\t validation accuracy: 0.9667\n",
      "iteration number: 729\t training loss: 707.5562\tvalidation loss: 242.6848\t validation accuracy: 0.9667\n",
      "iteration number: 730\t training loss: 708.1740\tvalidation loss: 242.7449\t validation accuracy: 0.9644\n",
      "iteration number: 731\t training loss: 706.8997\tvalidation loss: 242.2912\t validation accuracy: 0.9644\n",
      "iteration number: 732\t training loss: 704.3052\tvalidation loss: 241.3990\t validation accuracy: 0.9667\n",
      "iteration number: 733\t training loss: 698.6988\tvalidation loss: 239.5201\t validation accuracy: 0.9667\n",
      "iteration number: 734\t training loss: 694.3817\tvalidation loss: 238.1053\t validation accuracy: 0.9667\n",
      "iteration number: 735\t training loss: 691.7404\tvalidation loss: 237.3308\t validation accuracy: 0.9622\n",
      "iteration number: 736\t training loss: 689.4725\tvalidation loss: 236.6974\t validation accuracy: 0.9622\n",
      "iteration number: 737\t training loss: 686.4964\tvalidation loss: 235.7897\t validation accuracy: 0.9600\n",
      "iteration number: 738\t training loss: 683.1065\tvalidation loss: 234.6157\t validation accuracy: 0.9622\n",
      "iteration number: 739\t training loss: 679.0276\tvalidation loss: 232.9940\t validation accuracy: 0.9622\n",
      "iteration number: 740\t training loss: 674.9705\tvalidation loss: 231.3288\t validation accuracy: 0.9644\n",
      "iteration number: 741\t training loss: 669.4421\tvalidation loss: 229.3536\t validation accuracy: 0.9644\n",
      "iteration number: 742\t training loss: 663.2457\tvalidation loss: 227.2466\t validation accuracy: 0.9644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 743\t training loss: 658.2203\tvalidation loss: 225.5182\t validation accuracy: 0.9644\n",
      "iteration number: 744\t training loss: 653.7199\tvalidation loss: 224.1491\t validation accuracy: 0.9622\n",
      "iteration number: 745\t training loss: 650.1125\tvalidation loss: 223.1724\t validation accuracy: 0.9622\n",
      "iteration number: 746\t training loss: 647.8231\tvalidation loss: 222.6828\t validation accuracy: 0.9622\n",
      "iteration number: 747\t training loss: 646.2763\tvalidation loss: 222.4444\t validation accuracy: 0.9644\n",
      "iteration number: 748\t training loss: 644.7447\tvalidation loss: 222.0920\t validation accuracy: 0.9622\n",
      "iteration number: 749\t training loss: 643.0688\tvalidation loss: 221.8142\t validation accuracy: 0.9578\n",
      "iteration number: 750\t training loss: 641.6540\tvalidation loss: 221.5620\t validation accuracy: 0.9578\n",
      "iteration number: 751\t training loss: 640.2423\tvalidation loss: 221.3110\t validation accuracy: 0.9622\n",
      "iteration number: 752\t training loss: 638.3708\tvalidation loss: 220.8217\t validation accuracy: 0.9622\n",
      "iteration number: 753\t training loss: 635.7035\tvalidation loss: 219.8407\t validation accuracy: 0.9622\n",
      "iteration number: 754\t training loss: 634.9011\tvalidation loss: 219.5368\t validation accuracy: 0.9622\n",
      "iteration number: 755\t training loss: 633.6806\tvalidation loss: 219.1677\t validation accuracy: 0.9600\n",
      "iteration number: 756\t training loss: 633.2224\tvalidation loss: 218.8684\t validation accuracy: 0.9578\n",
      "iteration number: 757\t training loss: 633.2399\tvalidation loss: 218.6532\t validation accuracy: 0.9533\n",
      "iteration number: 758\t training loss: 634.8742\tvalidation loss: 218.8936\t validation accuracy: 0.9533\n",
      "iteration number: 759\t training loss: 636.2960\tvalidation loss: 219.0139\t validation accuracy: 0.9556\n",
      "iteration number: 760\t training loss: 636.9915\tvalidation loss: 218.9394\t validation accuracy: 0.9600\n",
      "iteration number: 761\t training loss: 638.8845\tvalidation loss: 219.1986\t validation accuracy: 0.9644\n",
      "iteration number: 762\t training loss: 641.0984\tvalidation loss: 219.5630\t validation accuracy: 0.9644\n",
      "iteration number: 763\t training loss: 644.4698\tvalidation loss: 220.3935\t validation accuracy: 0.9644\n",
      "iteration number: 764\t training loss: 648.0193\tvalidation loss: 221.3991\t validation accuracy: 0.9644\n",
      "iteration number: 765\t training loss: 650.7781\tvalidation loss: 221.9874\t validation accuracy: 0.9644\n",
      "iteration number: 766\t training loss: 652.9597\tvalidation loss: 222.3997\t validation accuracy: 0.9622\n",
      "iteration number: 767\t training loss: 654.5158\tvalidation loss: 222.5940\t validation accuracy: 0.9644\n",
      "iteration number: 768\t training loss: 656.6748\tvalidation loss: 223.2686\t validation accuracy: 0.9622\n",
      "iteration number: 769\t training loss: 660.0759\tvalidation loss: 224.3529\t validation accuracy: 0.9644\n",
      "iteration number: 770\t training loss: 663.4598\tvalidation loss: 225.4349\t validation accuracy: 0.9667\n",
      "iteration number: 771\t training loss: 666.4510\tvalidation loss: 226.4769\t validation accuracy: 0.9667\n",
      "iteration number: 772\t training loss: 667.9447\tvalidation loss: 227.0028\t validation accuracy: 0.9644\n",
      "iteration number: 773\t training loss: 668.2846\tvalidation loss: 227.3358\t validation accuracy: 0.9667\n",
      "iteration number: 774\t training loss: 667.3227\tvalidation loss: 227.2835\t validation accuracy: 0.9644\n",
      "iteration number: 775\t training loss: 664.8978\tvalidation loss: 226.8700\t validation accuracy: 0.9622\n",
      "iteration number: 776\t training loss: 660.6521\tvalidation loss: 225.8275\t validation accuracy: 0.9622\n",
      "iteration number: 777\t training loss: 656.7881\tvalidation loss: 224.8622\t validation accuracy: 0.9644\n",
      "iteration number: 778\t training loss: 653.6295\tvalidation loss: 224.1544\t validation accuracy: 0.9644\n",
      "iteration number: 779\t training loss: 651.3884\tvalidation loss: 223.7133\t validation accuracy: 0.9644\n",
      "iteration number: 780\t training loss: 650.5471\tvalidation loss: 223.8320\t validation accuracy: 0.9600\n",
      "iteration number: 781\t training loss: 649.4728\tvalidation loss: 223.7991\t validation accuracy: 0.9600\n",
      "iteration number: 782\t training loss: 647.5895\tvalidation loss: 223.5572\t validation accuracy: 0.9600\n",
      "iteration number: 783\t training loss: 645.4446\tvalidation loss: 223.2231\t validation accuracy: 0.9644\n",
      "iteration number: 784\t training loss: 643.9500\tvalidation loss: 222.9897\t validation accuracy: 0.9644\n",
      "iteration number: 785\t training loss: 642.1898\tvalidation loss: 222.5321\t validation accuracy: 0.9667\n",
      "iteration number: 786\t training loss: 641.1598\tvalidation loss: 222.1814\t validation accuracy: 0.9667\n",
      "iteration number: 787\t training loss: 640.5867\tvalidation loss: 222.1444\t validation accuracy: 0.9667\n",
      "iteration number: 788\t training loss: 639.8988\tvalidation loss: 221.8371\t validation accuracy: 0.9667\n",
      "iteration number: 789\t training loss: 640.8346\tvalidation loss: 222.0461\t validation accuracy: 0.9667\n",
      "iteration number: 790\t training loss: 643.2492\tvalidation loss: 222.5350\t validation accuracy: 0.9667\n",
      "iteration number: 791\t training loss: 645.6476\tvalidation loss: 223.0267\t validation accuracy: 0.9667\n",
      "iteration number: 792\t training loss: 649.5498\tvalidation loss: 223.9121\t validation accuracy: 0.9667\n",
      "iteration number: 793\t training loss: 654.2159\tvalidation loss: 225.0057\t validation accuracy: 0.9667\n",
      "iteration number: 794\t training loss: 658.6231\tvalidation loss: 225.9939\t validation accuracy: 0.9644\n",
      "iteration number: 795\t training loss: 662.3020\tvalidation loss: 226.7652\t validation accuracy: 0.9644\n",
      "iteration number: 796\t training loss: 664.3744\tvalidation loss: 227.1078\t validation accuracy: 0.9644\n",
      "iteration number: 797\t training loss: 665.5424\tvalidation loss: 227.1804\t validation accuracy: 0.9644\n",
      "iteration number: 798\t training loss: 665.8939\tvalidation loss: 227.0385\t validation accuracy: 0.9667\n",
      "iteration number: 799\t training loss: 666.1627\tvalidation loss: 226.9649\t validation accuracy: 0.9667\n",
      "iteration number: 800\t training loss: 666.1750\tvalidation loss: 226.8933\t validation accuracy: 0.9667\n",
      "iteration number: 801\t training loss: 665.9377\tvalidation loss: 226.9239\t validation accuracy: 0.9622\n",
      "iteration number: 802\t training loss: 665.9518\tvalidation loss: 227.1176\t validation accuracy: 0.9622\n",
      "iteration number: 803\t training loss: 663.9720\tvalidation loss: 226.7197\t validation accuracy: 0.9622\n",
      "iteration number: 804\t training loss: 662.4403\tvalidation loss: 226.4226\t validation accuracy: 0.9622\n",
      "iteration number: 805\t training loss: 659.1621\tvalidation loss: 225.4630\t validation accuracy: 0.9622\n",
      "iteration number: 806\t training loss: 656.2756\tvalidation loss: 224.6419\t validation accuracy: 0.9644\n",
      "iteration number: 807\t training loss: 653.8867\tvalidation loss: 224.2857\t validation accuracy: 0.9667\n",
      "iteration number: 808\t training loss: 651.6082\tvalidation loss: 223.9639\t validation accuracy: 0.9667\n",
      "iteration number: 809\t training loss: 649.5318\tvalidation loss: 223.7501\t validation accuracy: 0.9644\n",
      "iteration number: 810\t training loss: 646.3029\tvalidation loss: 223.2102\t validation accuracy: 0.9644\n",
      "iteration number: 811\t training loss: 643.2623\tvalidation loss: 222.3773\t validation accuracy: 0.9644\n",
      "iteration number: 812\t training loss: 640.1721\tvalidation loss: 221.5722\t validation accuracy: 0.9622\n",
      "iteration number: 813\t training loss: 637.2657\tvalidation loss: 220.8096\t validation accuracy: 0.9622\n",
      "iteration number: 814\t training loss: 635.7588\tvalidation loss: 220.5872\t validation accuracy: 0.9644\n",
      "iteration number: 815\t training loss: 633.5200\tvalidation loss: 219.9210\t validation accuracy: 0.9644\n",
      "iteration number: 816\t training loss: 631.1463\tvalidation loss: 219.1665\t validation accuracy: 0.9644\n",
      "iteration number: 817\t training loss: 629.1150\tvalidation loss: 218.5214\t validation accuracy: 0.9622\n",
      "iteration number: 818\t training loss: 627.9614\tvalidation loss: 218.1414\t validation accuracy: 0.9667\n",
      "iteration number: 819\t training loss: 625.6580\tvalidation loss: 217.3573\t validation accuracy: 0.9667\n",
      "iteration number: 820\t training loss: 623.1173\tvalidation loss: 216.3985\t validation accuracy: 0.9667\n",
      "iteration number: 821\t training loss: 622.2949\tvalidation loss: 215.9819\t validation accuracy: 0.9667\n",
      "iteration number: 822\t training loss: 621.8583\tvalidation loss: 215.6776\t validation accuracy: 0.9667\n",
      "iteration number: 823\t training loss: 621.5681\tvalidation loss: 215.4327\t validation accuracy: 0.9644\n",
      "iteration number: 824\t training loss: 621.7684\tvalidation loss: 215.3524\t validation accuracy: 0.9622\n",
      "iteration number: 825\t training loss: 621.2002\tvalidation loss: 214.9393\t validation accuracy: 0.9622\n",
      "iteration number: 826\t training loss: 621.9122\tvalidation loss: 214.9404\t validation accuracy: 0.9622\n",
      "iteration number: 827\t training loss: 622.5966\tvalidation loss: 214.8005\t validation accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 828\t training loss: 624.4517\tvalidation loss: 215.0215\t validation accuracy: 0.9622\n",
      "iteration number: 829\t training loss: 626.1425\tvalidation loss: 215.2993\t validation accuracy: 0.9622\n",
      "iteration number: 830\t training loss: 629.1195\tvalidation loss: 216.1773\t validation accuracy: 0.9644\n",
      "iteration number: 831\t training loss: 631.3482\tvalidation loss: 216.7955\t validation accuracy: 0.9644\n",
      "iteration number: 832\t training loss: 634.1153\tvalidation loss: 217.7062\t validation accuracy: 0.9644\n",
      "iteration number: 833\t training loss: 635.6191\tvalidation loss: 218.2258\t validation accuracy: 0.9644\n",
      "iteration number: 834\t training loss: 637.1203\tvalidation loss: 218.7827\t validation accuracy: 0.9622\n",
      "iteration number: 835\t training loss: 638.2983\tvalidation loss: 219.4335\t validation accuracy: 0.9644\n",
      "iteration number: 836\t training loss: 638.7819\tvalidation loss: 219.7596\t validation accuracy: 0.9644\n",
      "iteration number: 837\t training loss: 639.5660\tvalidation loss: 220.1059\t validation accuracy: 0.9644\n",
      "iteration number: 838\t training loss: 640.2711\tvalidation loss: 220.4842\t validation accuracy: 0.9644\n",
      "iteration number: 839\t training loss: 639.8558\tvalidation loss: 220.6890\t validation accuracy: 0.9644\n",
      "iteration number: 840\t training loss: 639.1735\tvalidation loss: 220.7798\t validation accuracy: 0.9644\n",
      "iteration number: 841\t training loss: 638.0952\tvalidation loss: 220.5936\t validation accuracy: 0.9644\n",
      "iteration number: 842\t training loss: 636.6122\tvalidation loss: 220.2944\t validation accuracy: 0.9600\n",
      "iteration number: 843\t training loss: 636.2109\tvalidation loss: 220.3789\t validation accuracy: 0.9600\n",
      "iteration number: 844\t training loss: 635.4900\tvalidation loss: 220.2236\t validation accuracy: 0.9600\n",
      "iteration number: 845\t training loss: 635.3515\tvalidation loss: 220.2947\t validation accuracy: 0.9622\n",
      "iteration number: 846\t training loss: 634.7122\tvalidation loss: 220.2438\t validation accuracy: 0.9667\n",
      "iteration number: 847\t training loss: 634.3276\tvalidation loss: 220.2411\t validation accuracy: 0.9667\n",
      "iteration number: 848\t training loss: 633.1429\tvalidation loss: 219.8376\t validation accuracy: 0.9667\n",
      "iteration number: 849\t training loss: 631.1874\tvalidation loss: 219.1040\t validation accuracy: 0.9667\n",
      "iteration number: 850\t training loss: 630.4612\tvalidation loss: 218.4992\t validation accuracy: 0.9667\n",
      "iteration number: 851\t training loss: 630.4651\tvalidation loss: 218.2562\t validation accuracy: 0.9667\n",
      "iteration number: 852\t training loss: 630.3000\tvalidation loss: 218.2209\t validation accuracy: 0.9644\n",
      "iteration number: 853\t training loss: 629.5303\tvalidation loss: 218.0278\t validation accuracy: 0.9644\n",
      "iteration number: 854\t training loss: 627.9132\tvalidation loss: 217.5690\t validation accuracy: 0.9644\n",
      "iteration number: 855\t training loss: 626.9169\tvalidation loss: 217.2779\t validation accuracy: 0.9667\n",
      "iteration number: 856\t training loss: 625.4293\tvalidation loss: 216.7712\t validation accuracy: 0.9667\n",
      "iteration number: 857\t training loss: 623.0013\tvalidation loss: 215.8736\t validation accuracy: 0.9667\n",
      "iteration number: 858\t training loss: 619.8377\tvalidation loss: 214.7145\t validation accuracy: 0.9667\n",
      "iteration number: 859\t training loss: 615.5915\tvalidation loss: 213.1915\t validation accuracy: 0.9689\n",
      "iteration number: 860\t training loss: 611.5861\tvalidation loss: 212.0260\t validation accuracy: 0.9667\n",
      "iteration number: 861\t training loss: 607.6631\tvalidation loss: 210.9319\t validation accuracy: 0.9667\n",
      "iteration number: 862\t training loss: 605.4046\tvalidation loss: 210.2420\t validation accuracy: 0.9667\n",
      "iteration number: 863\t training loss: 605.4705\tvalidation loss: 210.3716\t validation accuracy: 0.9667\n",
      "iteration number: 864\t training loss: 604.9415\tvalidation loss: 210.2097\t validation accuracy: 0.9689\n",
      "iteration number: 865\t training loss: 604.2664\tvalidation loss: 209.9990\t validation accuracy: 0.9689\n",
      "iteration number: 866\t training loss: 602.5422\tvalidation loss: 209.5448\t validation accuracy: 0.9667\n",
      "iteration number: 867\t training loss: 600.8636\tvalidation loss: 209.0977\t validation accuracy: 0.9667\n",
      "iteration number: 868\t training loss: 601.1957\tvalidation loss: 209.3174\t validation accuracy: 0.9667\n",
      "iteration number: 869\t training loss: 599.8635\tvalidation loss: 208.7986\t validation accuracy: 0.9667\n",
      "iteration number: 870\t training loss: 598.6251\tvalidation loss: 208.3251\t validation accuracy: 0.9667\n",
      "iteration number: 871\t training loss: 597.5332\tvalidation loss: 207.7525\t validation accuracy: 0.9667\n",
      "iteration number: 872\t training loss: 598.6271\tvalidation loss: 208.0543\t validation accuracy: 0.9667\n",
      "iteration number: 873\t training loss: 600.9414\tvalidation loss: 208.6195\t validation accuracy: 0.9667\n",
      "iteration number: 874\t training loss: 603.3841\tvalidation loss: 209.2388\t validation accuracy: 0.9644\n",
      "iteration number: 875\t training loss: 604.5569\tvalidation loss: 209.4436\t validation accuracy: 0.9644\n",
      "iteration number: 876\t training loss: 605.9459\tvalidation loss: 209.7067\t validation accuracy: 0.9644\n",
      "iteration number: 877\t training loss: 608.4679\tvalidation loss: 210.2939\t validation accuracy: 0.9600\n",
      "iteration number: 878\t training loss: 609.6111\tvalidation loss: 210.4796\t validation accuracy: 0.9622\n",
      "iteration number: 879\t training loss: 609.3381\tvalidation loss: 210.1372\t validation accuracy: 0.9622\n",
      "iteration number: 880\t training loss: 608.1139\tvalidation loss: 209.5226\t validation accuracy: 0.9622\n",
      "iteration number: 881\t training loss: 607.0292\tvalidation loss: 209.0238\t validation accuracy: 0.9622\n",
      "iteration number: 882\t training loss: 605.8145\tvalidation loss: 208.3567\t validation accuracy: 0.9600\n",
      "iteration number: 883\t training loss: 604.9081\tvalidation loss: 207.8545\t validation accuracy: 0.9644\n",
      "iteration number: 884\t training loss: 604.7077\tvalidation loss: 207.5772\t validation accuracy: 0.9667\n",
      "iteration number: 885\t training loss: 604.3604\tvalidation loss: 207.3703\t validation accuracy: 0.9667\n",
      "iteration number: 886\t training loss: 606.4746\tvalidation loss: 207.9915\t validation accuracy: 0.9667\n",
      "iteration number: 887\t training loss: 607.4385\tvalidation loss: 208.2208\t validation accuracy: 0.9667\n",
      "iteration number: 888\t training loss: 607.8140\tvalidation loss: 208.2210\t validation accuracy: 0.9667\n",
      "iteration number: 889\t training loss: 609.1051\tvalidation loss: 208.6225\t validation accuracy: 0.9667\n",
      "iteration number: 890\t training loss: 610.1894\tvalidation loss: 208.7967\t validation accuracy: 0.9644\n",
      "iteration number: 891\t training loss: 610.9404\tvalidation loss: 208.9099\t validation accuracy: 0.9644\n",
      "iteration number: 892\t training loss: 610.3225\tvalidation loss: 208.6395\t validation accuracy: 0.9644\n",
      "iteration number: 893\t training loss: 610.1700\tvalidation loss: 208.5373\t validation accuracy: 0.9667\n",
      "iteration number: 894\t training loss: 609.6971\tvalidation loss: 208.3578\t validation accuracy: 0.9644\n",
      "iteration number: 895\t training loss: 608.5876\tvalidation loss: 208.1034\t validation accuracy: 0.9644\n",
      "iteration number: 896\t training loss: 605.8630\tvalidation loss: 207.4302\t validation accuracy: 0.9667\n",
      "iteration number: 897\t training loss: 601.6396\tvalidation loss: 206.3583\t validation accuracy: 0.9689\n",
      "iteration number: 898\t training loss: 595.7234\tvalidation loss: 204.9578\t validation accuracy: 0.9689\n",
      "iteration number: 899\t training loss: 591.8759\tvalidation loss: 204.1570\t validation accuracy: 0.9711\n",
      "iteration number: 900\t training loss: 588.2278\tvalidation loss: 203.2479\t validation accuracy: 0.9711\n",
      "iteration number: 901\t training loss: 584.1899\tvalidation loss: 202.1427\t validation accuracy: 0.9711\n",
      "iteration number: 902\t training loss: 581.1647\tvalidation loss: 201.3403\t validation accuracy: 0.9689\n",
      "iteration number: 903\t training loss: 578.3889\tvalidation loss: 200.5732\t validation accuracy: 0.9689\n",
      "iteration number: 904\t training loss: 576.8464\tvalidation loss: 200.2095\t validation accuracy: 0.9689\n",
      "iteration number: 905\t training loss: 577.0845\tvalidation loss: 200.4835\t validation accuracy: 0.9667\n",
      "iteration number: 906\t training loss: 578.7993\tvalidation loss: 201.2783\t validation accuracy: 0.9644\n",
      "iteration number: 907\t training loss: 580.6627\tvalidation loss: 202.1871\t validation accuracy: 0.9644\n",
      "iteration number: 908\t training loss: 582.2822\tvalidation loss: 203.0952\t validation accuracy: 0.9622\n",
      "iteration number: 909\t training loss: 584.2046\tvalidation loss: 204.0731\t validation accuracy: 0.9644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 910\t training loss: 585.2611\tvalidation loss: 204.7515\t validation accuracy: 0.9667\n",
      "iteration number: 911\t training loss: 586.3364\tvalidation loss: 205.3783\t validation accuracy: 0.9667\n",
      "iteration number: 912\t training loss: 587.6590\tvalidation loss: 206.0417\t validation accuracy: 0.9689\n",
      "iteration number: 913\t training loss: 591.2254\tvalidation loss: 207.2041\t validation accuracy: 0.9689\n",
      "iteration number: 914\t training loss: 594.4742\tvalidation loss: 208.2291\t validation accuracy: 0.9689\n",
      "iteration number: 915\t training loss: 597.3420\tvalidation loss: 209.0446\t validation accuracy: 0.9689\n",
      "iteration number: 916\t training loss: 597.4007\tvalidation loss: 208.7673\t validation accuracy: 0.9711\n",
      "iteration number: 917\t training loss: 597.5632\tvalidation loss: 208.5676\t validation accuracy: 0.9711\n",
      "iteration number: 918\t training loss: 598.3511\tvalidation loss: 208.6957\t validation accuracy: 0.9689\n",
      "iteration number: 919\t training loss: 597.4311\tvalidation loss: 208.1804\t validation accuracy: 0.9689\n",
      "iteration number: 920\t training loss: 596.7900\tvalidation loss: 207.8115\t validation accuracy: 0.9689\n",
      "iteration number: 921\t training loss: 596.4583\tvalidation loss: 207.6028\t validation accuracy: 0.9667\n",
      "iteration number: 922\t training loss: 594.5530\tvalidation loss: 206.8553\t validation accuracy: 0.9622\n",
      "iteration number: 923\t training loss: 591.8503\tvalidation loss: 205.9565\t validation accuracy: 0.9622\n",
      "iteration number: 924\t training loss: 588.3765\tvalidation loss: 204.7333\t validation accuracy: 0.9622\n",
      "iteration number: 925\t training loss: 585.2596\tvalidation loss: 203.6102\t validation accuracy: 0.9622\n",
      "iteration number: 926\t training loss: 581.9430\tvalidation loss: 202.5687\t validation accuracy: 0.9622\n",
      "iteration number: 927\t training loss: 578.9175\tvalidation loss: 201.5725\t validation accuracy: 0.9622\n",
      "iteration number: 928\t training loss: 575.8091\tvalidation loss: 200.4933\t validation accuracy: 0.9622\n",
      "iteration number: 929\t training loss: 571.1564\tvalidation loss: 198.9565\t validation accuracy: 0.9622\n",
      "iteration number: 930\t training loss: 566.9996\tvalidation loss: 197.6937\t validation accuracy: 0.9622\n",
      "iteration number: 931\t training loss: 563.9230\tvalidation loss: 196.7109\t validation accuracy: 0.9622\n",
      "iteration number: 932\t training loss: 562.3559\tvalidation loss: 196.2319\t validation accuracy: 0.9622\n",
      "iteration number: 933\t training loss: 561.8025\tvalidation loss: 195.9665\t validation accuracy: 0.9622\n",
      "iteration number: 934\t training loss: 562.4781\tvalidation loss: 196.2061\t validation accuracy: 0.9644\n",
      "iteration number: 935\t training loss: 564.2901\tvalidation loss: 196.7789\t validation accuracy: 0.9689\n",
      "iteration number: 936\t training loss: 567.4192\tvalidation loss: 197.9087\t validation accuracy: 0.9689\n",
      "iteration number: 937\t training loss: 571.7768\tvalidation loss: 199.4212\t validation accuracy: 0.9689\n",
      "iteration number: 938\t training loss: 577.1997\tvalidation loss: 201.2645\t validation accuracy: 0.9689\n",
      "iteration number: 939\t training loss: 582.9948\tvalidation loss: 203.3461\t validation accuracy: 0.9667\n",
      "iteration number: 940\t training loss: 587.8951\tvalidation loss: 205.1326\t validation accuracy: 0.9644\n",
      "iteration number: 941\t training loss: 590.7533\tvalidation loss: 206.1434\t validation accuracy: 0.9644\n",
      "iteration number: 942\t training loss: 593.9410\tvalidation loss: 207.2980\t validation accuracy: 0.9644\n",
      "iteration number: 943\t training loss: 596.4300\tvalidation loss: 208.1216\t validation accuracy: 0.9644\n",
      "iteration number: 944\t training loss: 598.3541\tvalidation loss: 208.7260\t validation accuracy: 0.9644\n",
      "iteration number: 945\t training loss: 599.3574\tvalidation loss: 208.9840\t validation accuracy: 0.9644\n",
      "iteration number: 946\t training loss: 598.5555\tvalidation loss: 208.6091\t validation accuracy: 0.9667\n",
      "iteration number: 947\t training loss: 598.4328\tvalidation loss: 208.4523\t validation accuracy: 0.9667\n",
      "iteration number: 948\t training loss: 598.9000\tvalidation loss: 208.4216\t validation accuracy: 0.9667\n",
      "iteration number: 949\t training loss: 599.0153\tvalidation loss: 208.2621\t validation accuracy: 0.9667\n",
      "iteration number: 950\t training loss: 600.0146\tvalidation loss: 208.3908\t validation accuracy: 0.9667\n",
      "iteration number: 951\t training loss: 600.3884\tvalidation loss: 208.3304\t validation accuracy: 0.9644\n",
      "iteration number: 952\t training loss: 599.0479\tvalidation loss: 207.5685\t validation accuracy: 0.9644\n",
      "iteration number: 953\t training loss: 597.5089\tvalidation loss: 206.8362\t validation accuracy: 0.9644\n",
      "iteration number: 954\t training loss: 594.4090\tvalidation loss: 205.7133\t validation accuracy: 0.9644\n",
      "iteration number: 955\t training loss: 587.8983\tvalidation loss: 203.4975\t validation accuracy: 0.9667\n",
      "iteration number: 956\t training loss: 583.0916\tvalidation loss: 201.7452\t validation accuracy: 0.9667\n",
      "iteration number: 957\t training loss: 577.8801\tvalidation loss: 199.8944\t validation accuracy: 0.9667\n",
      "iteration number: 958\t training loss: 573.0380\tvalidation loss: 198.4266\t validation accuracy: 0.9689\n",
      "iteration number: 959\t training loss: 569.1722\tvalidation loss: 197.2240\t validation accuracy: 0.9689\n",
      "iteration number: 960\t training loss: 564.1118\tvalidation loss: 195.4745\t validation accuracy: 0.9689\n",
      "iteration number: 961\t training loss: 559.6961\tvalidation loss: 194.0106\t validation accuracy: 0.9689\n",
      "iteration number: 962\t training loss: 556.2643\tvalidation loss: 192.7720\t validation accuracy: 0.9711\n",
      "iteration number: 963\t training loss: 554.3271\tvalidation loss: 192.0003\t validation accuracy: 0.9689\n",
      "iteration number: 964\t training loss: 554.1289\tvalidation loss: 191.8637\t validation accuracy: 0.9689\n",
      "iteration number: 965\t training loss: 553.2755\tvalidation loss: 191.5389\t validation accuracy: 0.9733\n",
      "iteration number: 966\t training loss: 552.9923\tvalidation loss: 191.4545\t validation accuracy: 0.9733\n",
      "iteration number: 967\t training loss: 553.7719\tvalidation loss: 191.7463\t validation accuracy: 0.9733\n",
      "iteration number: 968\t training loss: 554.2280\tvalidation loss: 192.1902\t validation accuracy: 0.9733\n",
      "iteration number: 969\t training loss: 554.7592\tvalidation loss: 192.6642\t validation accuracy: 0.9733\n",
      "iteration number: 970\t training loss: 555.2336\tvalidation loss: 193.2102\t validation accuracy: 0.9667\n",
      "iteration number: 971\t training loss: 556.2619\tvalidation loss: 193.9090\t validation accuracy: 0.9667\n",
      "iteration number: 972\t training loss: 557.4969\tvalidation loss: 194.8373\t validation accuracy: 0.9667\n",
      "iteration number: 973\t training loss: 558.2220\tvalidation loss: 195.6053\t validation accuracy: 0.9644\n",
      "iteration number: 974\t training loss: 559.7583\tvalidation loss: 196.5871\t validation accuracy: 0.9622\n",
      "iteration number: 975\t training loss: 562.9416\tvalidation loss: 198.0255\t validation accuracy: 0.9600\n",
      "iteration number: 976\t training loss: 565.3012\tvalidation loss: 199.1141\t validation accuracy: 0.9600\n",
      "iteration number: 977\t training loss: 567.5167\tvalidation loss: 200.0373\t validation accuracy: 0.9622\n",
      "iteration number: 978\t training loss: 571.0289\tvalidation loss: 201.3754\t validation accuracy: 0.9622\n",
      "iteration number: 979\t training loss: 573.9479\tvalidation loss: 202.3868\t validation accuracy: 0.9622\n",
      "iteration number: 980\t training loss: 575.6174\tvalidation loss: 202.9875\t validation accuracy: 0.9600\n",
      "iteration number: 981\t training loss: 576.9519\tvalidation loss: 203.4342\t validation accuracy: 0.9644\n",
      "iteration number: 982\t training loss: 578.0234\tvalidation loss: 203.7755\t validation accuracy: 0.9667\n",
      "iteration number: 983\t training loss: 578.4763\tvalidation loss: 203.8050\t validation accuracy: 0.9667\n",
      "iteration number: 984\t training loss: 578.4747\tvalidation loss: 203.6507\t validation accuracy: 0.9667\n",
      "iteration number: 985\t training loss: 576.6953\tvalidation loss: 202.9314\t validation accuracy: 0.9667\n",
      "iteration number: 986\t training loss: 575.8701\tvalidation loss: 202.4049\t validation accuracy: 0.9667\n",
      "iteration number: 987\t training loss: 575.1020\tvalidation loss: 201.8126\t validation accuracy: 0.9689\n",
      "iteration number: 988\t training loss: 573.3552\tvalidation loss: 200.9632\t validation accuracy: 0.9711\n",
      "iteration number: 989\t training loss: 570.4173\tvalidation loss: 199.8425\t validation accuracy: 0.9711\n",
      "iteration number: 990\t training loss: 568.1979\tvalidation loss: 198.9068\t validation accuracy: 0.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 991\t training loss: 567.4466\tvalidation loss: 198.5530\t validation accuracy: 0.9711\n",
      "iteration number: 992\t training loss: 566.3383\tvalidation loss: 198.1098\t validation accuracy: 0.9711\n",
      "iteration number: 993\t training loss: 565.1840\tvalidation loss: 197.5440\t validation accuracy: 0.9711\n",
      "iteration number: 994\t training loss: 564.0382\tvalidation loss: 196.9190\t validation accuracy: 0.9711\n",
      "iteration number: 995\t training loss: 561.8191\tvalidation loss: 195.9914\t validation accuracy: 0.9711\n",
      "iteration number: 996\t training loss: 561.8854\tvalidation loss: 195.8001\t validation accuracy: 0.9711\n",
      "iteration number: 997\t training loss: 561.4682\tvalidation loss: 195.4492\t validation accuracy: 0.9711\n",
      "iteration number: 998\t training loss: 562.1071\tvalidation loss: 195.6769\t validation accuracy: 0.9711\n",
      "iteration number: 999\t training loss: 563.6231\tvalidation loss: 196.3810\t validation accuracy: 0.9711\n",
      "iteration number: 1000\t training loss: 564.9064\tvalidation loss: 197.2643\t validation accuracy: 0.9711\n",
      "iteration number: 1001\t training loss: 566.7689\tvalidation loss: 198.3036\t validation accuracy: 0.9711\n",
      "iteration number: 1002\t training loss: 568.4291\tvalidation loss: 199.2704\t validation accuracy: 0.9711\n",
      "iteration number: 1003\t training loss: 570.5369\tvalidation loss: 200.2935\t validation accuracy: 0.9644\n",
      "iteration number: 1004\t training loss: 572.0840\tvalidation loss: 201.1059\t validation accuracy: 0.9667\n",
      "iteration number: 1005\t training loss: 572.4047\tvalidation loss: 201.5390\t validation accuracy: 0.9667\n",
      "iteration number: 1006\t training loss: 573.8160\tvalidation loss: 202.2743\t validation accuracy: 0.9667\n",
      "iteration number: 1007\t training loss: 576.6869\tvalidation loss: 203.3970\t validation accuracy: 0.9667\n",
      "iteration number: 1008\t training loss: 578.9532\tvalidation loss: 204.1744\t validation accuracy: 0.9689\n",
      "iteration number: 1009\t training loss: 582.9159\tvalidation loss: 205.4152\t validation accuracy: 0.9689\n",
      "iteration number: 1010\t training loss: 586.0396\tvalidation loss: 206.4575\t validation accuracy: 0.9667\n",
      "iteration number: 1011\t training loss: 587.1466\tvalidation loss: 206.8614\t validation accuracy: 0.9667\n",
      "iteration number: 1012\t training loss: 586.6440\tvalidation loss: 206.7941\t validation accuracy: 0.9667\n",
      "iteration number: 1013\t training loss: 584.7306\tvalidation loss: 206.1091\t validation accuracy: 0.9689\n",
      "iteration number: 1014\t training loss: 581.2487\tvalidation loss: 204.9540\t validation accuracy: 0.9711\n",
      "iteration number: 1015\t training loss: 577.5592\tvalidation loss: 203.6445\t validation accuracy: 0.9733\n",
      "iteration number: 1016\t training loss: 573.7664\tvalidation loss: 202.5520\t validation accuracy: 0.9733\n",
      "iteration number: 1017\t training loss: 569.1268\tvalidation loss: 201.1169\t validation accuracy: 0.9733\n",
      "iteration number: 1018\t training loss: 566.1267\tvalidation loss: 200.2169\t validation accuracy: 0.9689\n",
      "iteration number: 1019\t training loss: 564.2412\tvalidation loss: 199.7347\t validation accuracy: 0.9689\n",
      "iteration number: 1020\t training loss: 562.2203\tvalidation loss: 199.2647\t validation accuracy: 0.9689\n",
      "iteration number: 1021\t training loss: 561.6090\tvalidation loss: 199.1705\t validation accuracy: 0.9711\n",
      "iteration number: 1022\t training loss: 561.1342\tvalidation loss: 199.0984\t validation accuracy: 0.9711\n",
      "iteration number: 1023\t training loss: 560.8827\tvalidation loss: 199.1531\t validation accuracy: 0.9689\n",
      "iteration number: 1024\t training loss: 560.3336\tvalidation loss: 199.1777\t validation accuracy: 0.9689\n",
      "iteration number: 1025\t training loss: 559.5393\tvalidation loss: 199.0760\t validation accuracy: 0.9689\n",
      "iteration number: 1026\t training loss: 559.4586\tvalidation loss: 199.2514\t validation accuracy: 0.9644\n",
      "iteration number: 1027\t training loss: 560.5766\tvalidation loss: 199.9944\t validation accuracy: 0.9622\n",
      "iteration number: 1028\t training loss: 561.6925\tvalidation loss: 200.6802\t validation accuracy: 0.9622\n",
      "iteration number: 1029\t training loss: 562.8849\tvalidation loss: 201.3408\t validation accuracy: 0.9622\n",
      "iteration number: 1030\t training loss: 563.8478\tvalidation loss: 201.8439\t validation accuracy: 0.9622\n",
      "iteration number: 1031\t training loss: 566.0261\tvalidation loss: 202.7020\t validation accuracy: 0.9622\n",
      "iteration number: 1032\t training loss: 567.8690\tvalidation loss: 203.3213\t validation accuracy: 0.9644\n",
      "iteration number: 1033\t training loss: 568.0418\tvalidation loss: 203.2390\t validation accuracy: 0.9667\n",
      "iteration number: 1034\t training loss: 568.3155\tvalidation loss: 203.2062\t validation accuracy: 0.9667\n",
      "iteration number: 1035\t training loss: 568.1719\tvalidation loss: 202.9862\t validation accuracy: 0.9689\n",
      "iteration number: 1036\t training loss: 568.5727\tvalidation loss: 202.9223\t validation accuracy: 0.9689\n",
      "iteration number: 1037\t training loss: 569.0741\tvalidation loss: 202.6784\t validation accuracy: 0.9644\n",
      "iteration number: 1038\t training loss: 567.4571\tvalidation loss: 201.6610\t validation accuracy: 0.9622\n",
      "iteration number: 1039\t training loss: 566.9478\tvalidation loss: 200.9661\t validation accuracy: 0.9622\n",
      "iteration number: 1040\t training loss: 565.7763\tvalidation loss: 200.1664\t validation accuracy: 0.9600\n",
      "iteration number: 1041\t training loss: 563.6664\tvalidation loss: 198.9676\t validation accuracy: 0.9622\n",
      "iteration number: 1042\t training loss: 561.4906\tvalidation loss: 197.8165\t validation accuracy: 0.9622\n",
      "iteration number: 1043\t training loss: 559.3149\tvalidation loss: 196.7820\t validation accuracy: 0.9600\n",
      "iteration number: 1044\t training loss: 557.7837\tvalidation loss: 196.0403\t validation accuracy: 0.9578\n",
      "iteration number: 1045\t training loss: 555.3900\tvalidation loss: 194.8794\t validation accuracy: 0.9600\n",
      "iteration number: 1046\t training loss: 550.9886\tvalidation loss: 193.2119\t validation accuracy: 0.9600\n",
      "iteration number: 1047\t training loss: 547.2872\tvalidation loss: 191.8660\t validation accuracy: 0.9600\n",
      "iteration number: 1048\t training loss: 544.3321\tvalidation loss: 190.7490\t validation accuracy: 0.9600\n",
      "iteration number: 1049\t training loss: 541.1077\tvalidation loss: 189.5737\t validation accuracy: 0.9622\n",
      "iteration number: 1050\t training loss: 538.4257\tvalidation loss: 188.7881\t validation accuracy: 0.9644\n",
      "iteration number: 1051\t training loss: 537.1201\tvalidation loss: 188.3771\t validation accuracy: 0.9644\n",
      "iteration number: 1052\t training loss: 535.2704\tvalidation loss: 187.8000\t validation accuracy: 0.9667\n",
      "iteration number: 1053\t training loss: 534.2885\tvalidation loss: 187.5783\t validation accuracy: 0.9667\n",
      "iteration number: 1054\t training loss: 535.1660\tvalidation loss: 187.9577\t validation accuracy: 0.9689\n",
      "iteration number: 1055\t training loss: 535.9521\tvalidation loss: 188.3317\t validation accuracy: 0.9689\n",
      "iteration number: 1056\t training loss: 536.4682\tvalidation loss: 188.5947\t validation accuracy: 0.9711\n",
      "iteration number: 1057\t training loss: 537.4405\tvalidation loss: 188.9754\t validation accuracy: 0.9711\n",
      "iteration number: 1058\t training loss: 538.8864\tvalidation loss: 189.5702\t validation accuracy: 0.9711\n",
      "iteration number: 1059\t training loss: 541.2331\tvalidation loss: 190.5946\t validation accuracy: 0.9733\n",
      "iteration number: 1060\t training loss: 543.5846\tvalidation loss: 191.5695\t validation accuracy: 0.9733\n",
      "iteration number: 1061\t training loss: 545.1978\tvalidation loss: 192.2526\t validation accuracy: 0.9733\n",
      "iteration number: 1062\t training loss: 545.9645\tvalidation loss: 192.5686\t validation accuracy: 0.9733\n",
      "iteration number: 1063\t training loss: 547.7415\tvalidation loss: 193.2234\t validation accuracy: 0.9711\n",
      "iteration number: 1064\t training loss: 548.7389\tvalidation loss: 193.7416\t validation accuracy: 0.9711\n",
      "iteration number: 1065\t training loss: 550.3189\tvalidation loss: 194.4917\t validation accuracy: 0.9711\n",
      "iteration number: 1066\t training loss: 551.2505\tvalidation loss: 195.1239\t validation accuracy: 0.9711\n",
      "iteration number: 1067\t training loss: 552.1254\tvalidation loss: 195.7524\t validation accuracy: 0.9711\n",
      "iteration number: 1068\t training loss: 553.0585\tvalidation loss: 196.2762\t validation accuracy: 0.9689\n",
      "iteration number: 1069\t training loss: 552.8880\tvalidation loss: 196.4491\t validation accuracy: 0.9689\n",
      "iteration number: 1070\t training loss: 554.8287\tvalidation loss: 197.4626\t validation accuracy: 0.9689\n",
      "iteration number: 1071\t training loss: 557.2046\tvalidation loss: 198.5788\t validation accuracy: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1072\t training loss: 559.0697\tvalidation loss: 199.4411\t validation accuracy: 0.9689\n",
      "iteration number: 1073\t training loss: 560.8997\tvalidation loss: 200.3505\t validation accuracy: 0.9689\n",
      "iteration number: 1074\t training loss: 563.0970\tvalidation loss: 201.3167\t validation accuracy: 0.9689\n",
      "iteration number: 1075\t training loss: 564.9481\tvalidation loss: 202.0931\t validation accuracy: 0.9622\n",
      "iteration number: 1076\t training loss: 565.8937\tvalidation loss: 202.4833\t validation accuracy: 0.9622\n",
      "iteration number: 1077\t training loss: 567.0242\tvalidation loss: 202.8057\t validation accuracy: 0.9622\n",
      "iteration number: 1078\t training loss: 566.9669\tvalidation loss: 202.6254\t validation accuracy: 0.9600\n",
      "iteration number: 1079\t training loss: 566.6013\tvalidation loss: 202.2528\t validation accuracy: 0.9578\n",
      "iteration number: 1080\t training loss: 566.9216\tvalidation loss: 202.1172\t validation accuracy: 0.9578\n",
      "iteration number: 1081\t training loss: 567.3899\tvalidation loss: 202.1076\t validation accuracy: 0.9578\n",
      "iteration number: 1082\t training loss: 568.7890\tvalidation loss: 202.5374\t validation accuracy: 0.9600\n",
      "iteration number: 1083\t training loss: 569.3354\tvalidation loss: 202.7760\t validation accuracy: 0.9622\n",
      "iteration number: 1084\t training loss: 570.1302\tvalidation loss: 202.9340\t validation accuracy: 0.9622\n",
      "iteration number: 1085\t training loss: 569.6340\tvalidation loss: 202.4816\t validation accuracy: 0.9622\n",
      "iteration number: 1086\t training loss: 566.2526\tvalidation loss: 200.9915\t validation accuracy: 0.9622\n",
      "iteration number: 1087\t training loss: 561.1358\tvalidation loss: 198.8105\t validation accuracy: 0.9622\n",
      "iteration number: 1088\t training loss: 558.3242\tvalidation loss: 197.3733\t validation accuracy: 0.9644\n",
      "iteration number: 1089\t training loss: 556.1146\tvalidation loss: 196.1283\t validation accuracy: 0.9644\n",
      "iteration number: 1090\t training loss: 554.4975\tvalidation loss: 195.1471\t validation accuracy: 0.9667\n",
      "iteration number: 1091\t training loss: 552.1446\tvalidation loss: 193.9234\t validation accuracy: 0.9667\n",
      "iteration number: 1092\t training loss: 551.1902\tvalidation loss: 193.3138\t validation accuracy: 0.9667\n",
      "iteration number: 1093\t training loss: 550.2285\tvalidation loss: 192.8116\t validation accuracy: 0.9644\n",
      "iteration number: 1094\t training loss: 549.2772\tvalidation loss: 192.3578\t validation accuracy: 0.9622\n",
      "iteration number: 1095\t training loss: 549.4050\tvalidation loss: 192.2442\t validation accuracy: 0.9622\n",
      "iteration number: 1096\t training loss: 549.0391\tvalidation loss: 192.0711\t validation accuracy: 0.9622\n",
      "iteration number: 1097\t training loss: 549.3042\tvalidation loss: 191.9540\t validation accuracy: 0.9622\n",
      "iteration number: 1098\t training loss: 549.9692\tvalidation loss: 192.0141\t validation accuracy: 0.9622\n",
      "iteration number: 1099\t training loss: 551.3519\tvalidation loss: 192.3192\t validation accuracy: 0.9622\n",
      "iteration number: 1100\t training loss: 552.1888\tvalidation loss: 192.5435\t validation accuracy: 0.9644\n",
      "iteration number: 1101\t training loss: 553.3443\tvalidation loss: 192.9648\t validation accuracy: 0.9644\n",
      "iteration number: 1102\t training loss: 554.2024\tvalidation loss: 193.4002\t validation accuracy: 0.9622\n",
      "iteration number: 1103\t training loss: 555.1414\tvalidation loss: 193.9049\t validation accuracy: 0.9622\n",
      "iteration number: 1104\t training loss: 556.1164\tvalidation loss: 194.4477\t validation accuracy: 0.9622\n",
      "iteration number: 1105\t training loss: 556.9722\tvalidation loss: 194.8777\t validation accuracy: 0.9644\n",
      "iteration number: 1106\t training loss: 556.6778\tvalidation loss: 194.9396\t validation accuracy: 0.9644\n",
      "iteration number: 1107\t training loss: 556.6094\tvalidation loss: 195.0012\t validation accuracy: 0.9667\n",
      "iteration number: 1108\t training loss: 558.5583\tvalidation loss: 195.6227\t validation accuracy: 0.9644\n",
      "iteration number: 1109\t training loss: 558.6980\tvalidation loss: 195.5959\t validation accuracy: 0.9644\n",
      "iteration number: 1110\t training loss: 558.9171\tvalidation loss: 195.6529\t validation accuracy: 0.9644\n",
      "iteration number: 1111\t training loss: 559.7791\tvalidation loss: 195.9261\t validation accuracy: 0.9667\n",
      "iteration number: 1112\t training loss: 559.5832\tvalidation loss: 195.9415\t validation accuracy: 0.9667\n",
      "iteration number: 1113\t training loss: 558.1003\tvalidation loss: 195.5317\t validation accuracy: 0.9667\n",
      "iteration number: 1114\t training loss: 556.3941\tvalidation loss: 195.1607\t validation accuracy: 0.9711\n",
      "iteration number: 1115\t training loss: 556.0655\tvalidation loss: 195.1796\t validation accuracy: 0.9689\n",
      "iteration number: 1116\t training loss: 554.7093\tvalidation loss: 194.8595\t validation accuracy: 0.9711\n",
      "iteration number: 1117\t training loss: 553.7956\tvalidation loss: 194.6313\t validation accuracy: 0.9711\n",
      "iteration number: 1118\t training loss: 552.4770\tvalidation loss: 194.2475\t validation accuracy: 0.9711\n",
      "iteration number: 1119\t training loss: 549.4837\tvalidation loss: 193.3164\t validation accuracy: 0.9689\n",
      "iteration number: 1120\t training loss: 545.1520\tvalidation loss: 191.9758\t validation accuracy: 0.9689\n",
      "iteration number: 1121\t training loss: 541.0236\tvalidation loss: 190.8266\t validation accuracy: 0.9689\n",
      "iteration number: 1122\t training loss: 536.6840\tvalidation loss: 189.6091\t validation accuracy: 0.9689\n",
      "iteration number: 1123\t training loss: 534.2254\tvalidation loss: 188.9258\t validation accuracy: 0.9667\n",
      "iteration number: 1124\t training loss: 530.7028\tvalidation loss: 187.8642\t validation accuracy: 0.9667\n",
      "iteration number: 1125\t training loss: 527.1726\tvalidation loss: 186.7833\t validation accuracy: 0.9667\n",
      "iteration number: 1126\t training loss: 523.9195\tvalidation loss: 185.8094\t validation accuracy: 0.9667\n",
      "iteration number: 1127\t training loss: 519.8586\tvalidation loss: 184.5029\t validation accuracy: 0.9667\n",
      "iteration number: 1128\t training loss: 515.8023\tvalidation loss: 183.0745\t validation accuracy: 0.9667\n",
      "iteration number: 1129\t training loss: 512.6116\tvalidation loss: 181.8830\t validation accuracy: 0.9667\n",
      "iteration number: 1130\t training loss: 511.3312\tvalidation loss: 181.2644\t validation accuracy: 0.9689\n",
      "iteration number: 1131\t training loss: 511.6568\tvalidation loss: 181.2615\t validation accuracy: 0.9711\n",
      "iteration number: 1132\t training loss: 512.2950\tvalidation loss: 181.2153\t validation accuracy: 0.9711\n",
      "iteration number: 1133\t training loss: 512.8503\tvalidation loss: 181.1807\t validation accuracy: 0.9711\n",
      "iteration number: 1134\t training loss: 514.0715\tvalidation loss: 181.4242\t validation accuracy: 0.9711\n",
      "iteration number: 1135\t training loss: 515.3552\tvalidation loss: 181.6840\t validation accuracy: 0.9711\n",
      "iteration number: 1136\t training loss: 517.7861\tvalidation loss: 182.4771\t validation accuracy: 0.9711\n",
      "iteration number: 1137\t training loss: 520.9031\tvalidation loss: 183.6101\t validation accuracy: 0.9711\n",
      "iteration number: 1138\t training loss: 523.8674\tvalidation loss: 184.6968\t validation accuracy: 0.9711\n",
      "iteration number: 1139\t training loss: 526.6393\tvalidation loss: 185.6982\t validation accuracy: 0.9711\n",
      "iteration number: 1140\t training loss: 528.0275\tvalidation loss: 186.2689\t validation accuracy: 0.9711\n",
      "iteration number: 1141\t training loss: 531.0397\tvalidation loss: 187.2668\t validation accuracy: 0.9711\n",
      "iteration number: 1142\t training loss: 533.9233\tvalidation loss: 188.1755\t validation accuracy: 0.9711\n",
      "iteration number: 1143\t training loss: 534.9965\tvalidation loss: 188.5472\t validation accuracy: 0.9733\n",
      "iteration number: 1144\t training loss: 536.4489\tvalidation loss: 189.1755\t validation accuracy: 0.9689\n",
      "iteration number: 1145\t training loss: 537.0805\tvalidation loss: 189.4670\t validation accuracy: 0.9689\n",
      "iteration number: 1146\t training loss: 538.8124\tvalidation loss: 190.2441\t validation accuracy: 0.9689\n",
      "iteration number: 1147\t training loss: 540.0331\tvalidation loss: 190.7363\t validation accuracy: 0.9667\n",
      "iteration number: 1148\t training loss: 541.4627\tvalidation loss: 191.3175\t validation accuracy: 0.9689\n",
      "iteration number: 1149\t training loss: 542.0800\tvalidation loss: 191.8348\t validation accuracy: 0.9689\n",
      "iteration number: 1150\t training loss: 543.3119\tvalidation loss: 192.5370\t validation accuracy: 0.9689\n",
      "iteration number: 1151\t training loss: 543.4858\tvalidation loss: 192.8723\t validation accuracy: 0.9689\n",
      "iteration number: 1152\t training loss: 544.4432\tvalidation loss: 193.2996\t validation accuracy: 0.9689\n",
      "iteration number: 1153\t training loss: 546.4327\tvalidation loss: 193.9172\t validation accuracy: 0.9689\n",
      "iteration number: 1154\t training loss: 548.0514\tvalidation loss: 194.4485\t validation accuracy: 0.9689\n",
      "iteration number: 1155\t training loss: 549.1570\tvalidation loss: 194.7384\t validation accuracy: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1156\t training loss: 549.7926\tvalidation loss: 194.8782\t validation accuracy: 0.9689\n",
      "iteration number: 1157\t training loss: 550.5085\tvalidation loss: 195.0102\t validation accuracy: 0.9689\n",
      "iteration number: 1158\t training loss: 550.5201\tvalidation loss: 194.9669\t validation accuracy: 0.9711\n",
      "iteration number: 1159\t training loss: 551.5994\tvalidation loss: 195.3861\t validation accuracy: 0.9711\n",
      "iteration number: 1160\t training loss: 552.0680\tvalidation loss: 195.4223\t validation accuracy: 0.9711\n",
      "iteration number: 1161\t training loss: 552.1918\tvalidation loss: 195.3787\t validation accuracy: 0.9733\n",
      "iteration number: 1162\t training loss: 552.9855\tvalidation loss: 195.6054\t validation accuracy: 0.9733\n",
      "iteration number: 1163\t training loss: 552.5592\tvalidation loss: 195.4713\t validation accuracy: 0.9733\n",
      "iteration number: 1164\t training loss: 552.4865\tvalidation loss: 195.4345\t validation accuracy: 0.9733\n",
      "iteration number: 1165\t training loss: 552.0196\tvalidation loss: 195.3233\t validation accuracy: 0.9733\n",
      "iteration number: 1166\t training loss: 552.1481\tvalidation loss: 195.3442\t validation accuracy: 0.9733\n",
      "iteration number: 1167\t training loss: 552.4375\tvalidation loss: 195.4575\t validation accuracy: 0.9733\n",
      "iteration number: 1168\t training loss: 552.1610\tvalidation loss: 195.4337\t validation accuracy: 0.9711\n",
      "iteration number: 1169\t training loss: 552.8539\tvalidation loss: 195.7295\t validation accuracy: 0.9711\n",
      "iteration number: 1170\t training loss: 552.9065\tvalidation loss: 195.8015\t validation accuracy: 0.9689\n",
      "iteration number: 1171\t training loss: 551.3163\tvalidation loss: 195.3162\t validation accuracy: 0.9689\n",
      "iteration number: 1172\t training loss: 549.6942\tvalidation loss: 194.8052\t validation accuracy: 0.9689\n",
      "iteration number: 1173\t training loss: 548.7165\tvalidation loss: 194.3888\t validation accuracy: 0.9689\n",
      "iteration number: 1174\t training loss: 547.8582\tvalidation loss: 194.0231\t validation accuracy: 0.9711\n",
      "iteration number: 1175\t training loss: 547.9140\tvalidation loss: 193.9277\t validation accuracy: 0.9711\n",
      "iteration number: 1176\t training loss: 546.4814\tvalidation loss: 193.3269\t validation accuracy: 0.9711\n",
      "iteration number: 1177\t training loss: 544.4774\tvalidation loss: 192.6199\t validation accuracy: 0.9711\n",
      "iteration number: 1178\t training loss: 541.8751\tvalidation loss: 191.6585\t validation accuracy: 0.9711\n",
      "iteration number: 1179\t training loss: 539.0589\tvalidation loss: 190.6651\t validation accuracy: 0.9689\n",
      "iteration number: 1180\t training loss: 535.7107\tvalidation loss: 189.3492\t validation accuracy: 0.9689\n",
      "iteration number: 1181\t training loss: 532.0472\tvalidation loss: 187.8951\t validation accuracy: 0.9711\n",
      "iteration number: 1182\t training loss: 528.6308\tvalidation loss: 186.4789\t validation accuracy: 0.9711\n",
      "iteration number: 1183\t training loss: 525.7411\tvalidation loss: 185.2808\t validation accuracy: 0.9711\n",
      "iteration number: 1184\t training loss: 522.6398\tvalidation loss: 183.9888\t validation accuracy: 0.9711\n",
      "iteration number: 1185\t training loss: 519.5325\tvalidation loss: 182.7761\t validation accuracy: 0.9711\n",
      "iteration number: 1186\t training loss: 516.6797\tvalidation loss: 181.6887\t validation accuracy: 0.9711\n",
      "iteration number: 1187\t training loss: 514.2476\tvalidation loss: 180.7552\t validation accuracy: 0.9711\n",
      "iteration number: 1188\t training loss: 512.2038\tvalidation loss: 180.0856\t validation accuracy: 0.9711\n",
      "iteration number: 1189\t training loss: 511.8675\tvalidation loss: 180.0115\t validation accuracy: 0.9733\n",
      "iteration number: 1190\t training loss: 512.7919\tvalidation loss: 180.3916\t validation accuracy: 0.9733\n",
      "iteration number: 1191\t training loss: 513.7197\tvalidation loss: 180.8120\t validation accuracy: 0.9711\n",
      "iteration number: 1192\t training loss: 515.0681\tvalidation loss: 181.4584\t validation accuracy: 0.9711\n",
      "iteration number: 1193\t training loss: 517.0331\tvalidation loss: 182.2394\t validation accuracy: 0.9689\n",
      "iteration number: 1194\t training loss: 519.7681\tvalidation loss: 183.2907\t validation accuracy: 0.9689\n",
      "iteration number: 1195\t training loss: 521.7604\tvalidation loss: 184.1806\t validation accuracy: 0.9689\n",
      "iteration number: 1196\t training loss: 522.9998\tvalidation loss: 184.7994\t validation accuracy: 0.9711\n",
      "iteration number: 1197\t training loss: 525.9995\tvalidation loss: 185.9093\t validation accuracy: 0.9711\n",
      "iteration number: 1198\t training loss: 528.8174\tvalidation loss: 186.8185\t validation accuracy: 0.9711\n",
      "iteration number: 1199\t training loss: 532.7888\tvalidation loss: 188.2712\t validation accuracy: 0.9689\n",
      "iteration number: 1200\t training loss: 536.6792\tvalidation loss: 189.5847\t validation accuracy: 0.9667\n",
      "iteration number: 1201\t training loss: 541.0477\tvalidation loss: 191.0478\t validation accuracy: 0.9667\n",
      "iteration number: 1202\t training loss: 544.9508\tvalidation loss: 192.2640\t validation accuracy: 0.9667\n",
      "iteration number: 1203\t training loss: 547.2023\tvalidation loss: 192.9500\t validation accuracy: 0.9667\n",
      "iteration number: 1204\t training loss: 547.9323\tvalidation loss: 193.1528\t validation accuracy: 0.9667\n",
      "iteration number: 1205\t training loss: 546.0915\tvalidation loss: 192.3971\t validation accuracy: 0.9667\n",
      "iteration number: 1206\t training loss: 543.3094\tvalidation loss: 191.3401\t validation accuracy: 0.9667\n",
      "iteration number: 1207\t training loss: 538.7501\tvalidation loss: 189.8121\t validation accuracy: 0.9689\n",
      "iteration number: 1208\t training loss: 532.9169\tvalidation loss: 188.0160\t validation accuracy: 0.9689\n",
      "iteration number: 1209\t training loss: 528.5943\tvalidation loss: 186.6272\t validation accuracy: 0.9711\n",
      "iteration number: 1210\t training loss: 524.6459\tvalidation loss: 185.5057\t validation accuracy: 0.9711\n",
      "iteration number: 1211\t training loss: 520.0198\tvalidation loss: 184.0236\t validation accuracy: 0.9711\n",
      "iteration number: 1212\t training loss: 514.7249\tvalidation loss: 182.4152\t validation accuracy: 0.9733\n",
      "iteration number: 1213\t training loss: 510.5821\tvalidation loss: 181.1663\t validation accuracy: 0.9733\n",
      "iteration number: 1214\t training loss: 507.4579\tvalidation loss: 180.1627\t validation accuracy: 0.9711\n",
      "iteration number: 1215\t training loss: 504.8797\tvalidation loss: 179.3456\t validation accuracy: 0.9733\n",
      "iteration number: 1216\t training loss: 502.9072\tvalidation loss: 178.7984\t validation accuracy: 0.9733\n",
      "iteration number: 1217\t training loss: 501.5421\tvalidation loss: 178.4109\t validation accuracy: 0.9733\n",
      "iteration number: 1218\t training loss: 501.7202\tvalidation loss: 178.5741\t validation accuracy: 0.9733\n",
      "iteration number: 1219\t training loss: 503.1223\tvalidation loss: 179.1360\t validation accuracy: 0.9711\n",
      "iteration number: 1220\t training loss: 505.3669\tvalidation loss: 179.9670\t validation accuracy: 0.9711\n",
      "iteration number: 1221\t training loss: 507.0656\tvalidation loss: 180.6032\t validation accuracy: 0.9667\n",
      "iteration number: 1222\t training loss: 508.3170\tvalidation loss: 180.9640\t validation accuracy: 0.9667\n",
      "iteration number: 1223\t training loss: 509.5083\tvalidation loss: 181.2271\t validation accuracy: 0.9667\n",
      "iteration number: 1224\t training loss: 509.8029\tvalidation loss: 181.2652\t validation accuracy: 0.9622\n",
      "iteration number: 1225\t training loss: 510.2170\tvalidation loss: 181.4558\t validation accuracy: 0.9644\n",
      "iteration number: 1226\t training loss: 510.8885\tvalidation loss: 181.5840\t validation accuracy: 0.9644\n",
      "iteration number: 1227\t training loss: 512.4576\tvalidation loss: 182.0860\t validation accuracy: 0.9644\n",
      "iteration number: 1228\t training loss: 512.9858\tvalidation loss: 182.0870\t validation accuracy: 0.9644\n",
      "iteration number: 1229\t training loss: 513.7400\tvalidation loss: 182.1572\t validation accuracy: 0.9644\n",
      "iteration number: 1230\t training loss: 515.0316\tvalidation loss: 182.4781\t validation accuracy: 0.9622\n",
      "iteration number: 1231\t training loss: 516.0729\tvalidation loss: 182.7890\t validation accuracy: 0.9622\n",
      "iteration number: 1232\t training loss: 517.2666\tvalidation loss: 183.1081\t validation accuracy: 0.9622\n",
      "iteration number: 1233\t training loss: 519.2143\tvalidation loss: 183.6244\t validation accuracy: 0.9622\n",
      "iteration number: 1234\t training loss: 521.8386\tvalidation loss: 184.5459\t validation accuracy: 0.9622\n",
      "iteration number: 1235\t training loss: 524.3248\tvalidation loss: 185.5563\t validation accuracy: 0.9644\n",
      "iteration number: 1236\t training loss: 526.5925\tvalidation loss: 186.5592\t validation accuracy: 0.9644\n",
      "iteration number: 1237\t training loss: 528.0751\tvalidation loss: 187.3526\t validation accuracy: 0.9644\n",
      "iteration number: 1238\t training loss: 529.4431\tvalidation loss: 188.0022\t validation accuracy: 0.9644\n",
      "iteration number: 1239\t training loss: 530.1955\tvalidation loss: 188.3697\t validation accuracy: 0.9689\n",
      "iteration number: 1240\t training loss: 529.9173\tvalidation loss: 188.4505\t validation accuracy: 0.9689\n",
      "iteration number: 1241\t training loss: 529.3036\tvalidation loss: 188.3666\t validation accuracy: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1242\t training loss: 529.4304\tvalidation loss: 188.6183\t validation accuracy: 0.9689\n",
      "iteration number: 1243\t training loss: 529.8358\tvalidation loss: 188.9247\t validation accuracy: 0.9689\n",
      "iteration number: 1244\t training loss: 530.4537\tvalidation loss: 189.2404\t validation accuracy: 0.9689\n",
      "iteration number: 1245\t training loss: 530.8576\tvalidation loss: 189.4063\t validation accuracy: 0.9711\n",
      "iteration number: 1246\t training loss: 531.9971\tvalidation loss: 189.7219\t validation accuracy: 0.9733\n",
      "iteration number: 1247\t training loss: 532.6657\tvalidation loss: 189.8523\t validation accuracy: 0.9756\n",
      "iteration number: 1248\t training loss: 532.9746\tvalidation loss: 189.9253\t validation accuracy: 0.9756\n",
      "iteration number: 1249\t training loss: 532.6260\tvalidation loss: 189.8543\t validation accuracy: 0.9756\n",
      "iteration number: 1250\t training loss: 531.5692\tvalidation loss: 189.6155\t validation accuracy: 0.9756\n",
      "iteration number: 1251\t training loss: 528.7287\tvalidation loss: 188.7247\t validation accuracy: 0.9756\n",
      "iteration number: 1252\t training loss: 524.8487\tvalidation loss: 187.5083\t validation accuracy: 0.9756\n",
      "iteration number: 1253\t training loss: 521.2530\tvalidation loss: 186.5379\t validation accuracy: 0.9756\n",
      "iteration number: 1254\t training loss: 517.6062\tvalidation loss: 185.5746\t validation accuracy: 0.9778\n",
      "iteration number: 1255\t training loss: 514.9222\tvalidation loss: 184.8571\t validation accuracy: 0.9778\n",
      "iteration number: 1256\t training loss: 511.6456\tvalidation loss: 183.8526\t validation accuracy: 0.9733\n",
      "iteration number: 1257\t training loss: 509.0116\tvalidation loss: 183.0720\t validation accuracy: 0.9756\n",
      "iteration number: 1258\t training loss: 506.6833\tvalidation loss: 182.3127\t validation accuracy: 0.9733\n",
      "iteration number: 1259\t training loss: 505.3163\tvalidation loss: 181.8624\t validation accuracy: 0.9733\n",
      "iteration number: 1260\t training loss: 504.6871\tvalidation loss: 181.5456\t validation accuracy: 0.9711\n",
      "iteration number: 1261\t training loss: 504.6347\tvalidation loss: 181.5851\t validation accuracy: 0.9711\n",
      "iteration number: 1262\t training loss: 504.7886\tvalidation loss: 181.7899\t validation accuracy: 0.9689\n",
      "iteration number: 1263\t training loss: 507.3695\tvalidation loss: 182.8235\t validation accuracy: 0.9689\n",
      "iteration number: 1264\t training loss: 508.7246\tvalidation loss: 183.3238\t validation accuracy: 0.9711\n",
      "iteration number: 1265\t training loss: 510.8400\tvalidation loss: 184.0828\t validation accuracy: 0.9711\n",
      "iteration number: 1266\t training loss: 512.4157\tvalidation loss: 184.7064\t validation accuracy: 0.9689\n",
      "iteration number: 1267\t training loss: 512.9216\tvalidation loss: 184.8588\t validation accuracy: 0.9689\n",
      "iteration number: 1268\t training loss: 511.5726\tvalidation loss: 184.4462\t validation accuracy: 0.9733\n",
      "iteration number: 1269\t training loss: 509.5707\tvalidation loss: 183.7382\t validation accuracy: 0.9733\n",
      "iteration number: 1270\t training loss: 508.3788\tvalidation loss: 183.4223\t validation accuracy: 0.9733\n",
      "iteration number: 1271\t training loss: 507.7312\tvalidation loss: 183.1686\t validation accuracy: 0.9733\n",
      "iteration number: 1272\t training loss: 507.3934\tvalidation loss: 183.0571\t validation accuracy: 0.9689\n",
      "iteration number: 1273\t training loss: 505.7340\tvalidation loss: 182.4765\t validation accuracy: 0.9667\n",
      "iteration number: 1274\t training loss: 505.1002\tvalidation loss: 182.2948\t validation accuracy: 0.9667\n",
      "iteration number: 1275\t training loss: 504.3709\tvalidation loss: 181.9457\t validation accuracy: 0.9667\n",
      "iteration number: 1276\t training loss: 503.2289\tvalidation loss: 181.4074\t validation accuracy: 0.9689\n",
      "iteration number: 1277\t training loss: 502.1597\tvalidation loss: 180.7844\t validation accuracy: 0.9689\n",
      "iteration number: 1278\t training loss: 500.9834\tvalidation loss: 180.1582\t validation accuracy: 0.9733\n",
      "iteration number: 1279\t training loss: 498.7878\tvalidation loss: 179.1422\t validation accuracy: 0.9733\n",
      "iteration number: 1280\t training loss: 497.2666\tvalidation loss: 178.3208\t validation accuracy: 0.9711\n",
      "iteration number: 1281\t training loss: 495.4815\tvalidation loss: 177.5129\t validation accuracy: 0.9733\n",
      "iteration number: 1282\t training loss: 494.2582\tvalidation loss: 176.9489\t validation accuracy: 0.9733\n",
      "iteration number: 1283\t training loss: 492.3472\tvalidation loss: 176.2977\t validation accuracy: 0.9733\n",
      "iteration number: 1284\t training loss: 490.3513\tvalidation loss: 175.5457\t validation accuracy: 0.9711\n",
      "iteration number: 1285\t training loss: 488.5148\tvalidation loss: 174.7151\t validation accuracy: 0.9711\n",
      "iteration number: 1286\t training loss: 486.0721\tvalidation loss: 173.7980\t validation accuracy: 0.9711\n",
      "iteration number: 1287\t training loss: 482.7608\tvalidation loss: 172.7281\t validation accuracy: 0.9711\n",
      "iteration number: 1288\t training loss: 480.5971\tvalidation loss: 171.9765\t validation accuracy: 0.9711\n",
      "iteration number: 1289\t training loss: 477.0965\tvalidation loss: 171.0758\t validation accuracy: 0.9667\n",
      "iteration number: 1290\t training loss: 474.9585\tvalidation loss: 170.6450\t validation accuracy: 0.9667\n",
      "iteration number: 1291\t training loss: 473.6378\tvalidation loss: 170.4502\t validation accuracy: 0.9689\n",
      "iteration number: 1292\t training loss: 472.5327\tvalidation loss: 170.2810\t validation accuracy: 0.9689\n",
      "iteration number: 1293\t training loss: 472.0898\tvalidation loss: 170.4636\t validation accuracy: 0.9711\n",
      "iteration number: 1294\t training loss: 472.4188\tvalidation loss: 170.8093\t validation accuracy: 0.9711\n",
      "iteration number: 1295\t training loss: 473.1037\tvalidation loss: 171.3055\t validation accuracy: 0.9711\n",
      "iteration number: 1296\t training loss: 473.5030\tvalidation loss: 171.6640\t validation accuracy: 0.9711\n",
      "iteration number: 1297\t training loss: 475.2142\tvalidation loss: 172.4983\t validation accuracy: 0.9711\n",
      "iteration number: 1298\t training loss: 478.0295\tvalidation loss: 173.6081\t validation accuracy: 0.9689\n",
      "iteration number: 1299\t training loss: 480.3297\tvalidation loss: 174.5093\t validation accuracy: 0.9689\n",
      "iteration number: 1300\t training loss: 483.1633\tvalidation loss: 175.6311\t validation accuracy: 0.9711\n",
      "iteration number: 1301\t training loss: 484.3695\tvalidation loss: 176.0997\t validation accuracy: 0.9733\n",
      "iteration number: 1302\t training loss: 484.8959\tvalidation loss: 176.2477\t validation accuracy: 0.9733\n",
      "iteration number: 1303\t training loss: 484.6160\tvalidation loss: 176.0413\t validation accuracy: 0.9733\n",
      "iteration number: 1304\t training loss: 483.8275\tvalidation loss: 175.5934\t validation accuracy: 0.9733\n",
      "iteration number: 1305\t training loss: 483.1835\tvalidation loss: 175.1759\t validation accuracy: 0.9733\n",
      "iteration number: 1306\t training loss: 482.0889\tvalidation loss: 174.5892\t validation accuracy: 0.9733\n",
      "iteration number: 1307\t training loss: 480.7139\tvalidation loss: 173.9159\t validation accuracy: 0.9733\n",
      "iteration number: 1308\t training loss: 478.8309\tvalidation loss: 173.1129\t validation accuracy: 0.9711\n",
      "iteration number: 1309\t training loss: 476.9854\tvalidation loss: 172.3067\t validation accuracy: 0.9711\n",
      "iteration number: 1310\t training loss: 477.1901\tvalidation loss: 172.2120\t validation accuracy: 0.9733\n",
      "iteration number: 1311\t training loss: 477.1961\tvalidation loss: 171.9353\t validation accuracy: 0.9733\n",
      "iteration number: 1312\t training loss: 478.4675\tvalidation loss: 172.1791\t validation accuracy: 0.9733\n",
      "iteration number: 1313\t training loss: 479.2309\tvalidation loss: 172.2209\t validation accuracy: 0.9733\n",
      "iteration number: 1314\t training loss: 481.1335\tvalidation loss: 172.7394\t validation accuracy: 0.9733\n",
      "iteration number: 1315\t training loss: 484.6035\tvalidation loss: 173.8386\t validation accuracy: 0.9756\n",
      "iteration number: 1316\t training loss: 488.0907\tvalidation loss: 174.9946\t validation accuracy: 0.9756\n",
      "iteration number: 1317\t training loss: 491.3815\tvalidation loss: 176.1004\t validation accuracy: 0.9756\n",
      "iteration number: 1318\t training loss: 494.9304\tvalidation loss: 177.3521\t validation accuracy: 0.9756\n",
      "iteration number: 1319\t training loss: 499.1262\tvalidation loss: 178.7766\t validation accuracy: 0.9778\n",
      "iteration number: 1320\t training loss: 504.0577\tvalidation loss: 180.4449\t validation accuracy: 0.9778\n",
      "iteration number: 1321\t training loss: 508.2511\tvalidation loss: 181.7107\t validation accuracy: 0.9778\n",
      "iteration number: 1322\t training loss: 512.7236\tvalidation loss: 183.1664\t validation accuracy: 0.9778\n",
      "iteration number: 1323\t training loss: 514.7844\tvalidation loss: 183.7154\t validation accuracy: 0.9778\n",
      "iteration number: 1324\t training loss: 515.1469\tvalidation loss: 183.5805\t validation accuracy: 0.9756\n",
      "iteration number: 1325\t training loss: 515.2541\tvalidation loss: 183.2794\t validation accuracy: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1326\t training loss: 515.3711\tvalidation loss: 183.1888\t validation accuracy: 0.9756\n",
      "iteration number: 1327\t training loss: 515.6600\tvalidation loss: 183.1920\t validation accuracy: 0.9756\n",
      "iteration number: 1328\t training loss: 516.0648\tvalidation loss: 183.2491\t validation accuracy: 0.9733\n",
      "iteration number: 1329\t training loss: 516.0727\tvalidation loss: 183.1566\t validation accuracy: 0.9733\n",
      "iteration number: 1330\t training loss: 514.8262\tvalidation loss: 182.7762\t validation accuracy: 0.9711\n",
      "iteration number: 1331\t training loss: 514.0626\tvalidation loss: 182.4963\t validation accuracy: 0.9711\n",
      "iteration number: 1332\t training loss: 513.4351\tvalidation loss: 182.3456\t validation accuracy: 0.9667\n",
      "iteration number: 1333\t training loss: 512.2140\tvalidation loss: 181.9513\t validation accuracy: 0.9667\n",
      "iteration number: 1334\t training loss: 510.5568\tvalidation loss: 181.3170\t validation accuracy: 0.9689\n",
      "iteration number: 1335\t training loss: 507.2682\tvalidation loss: 180.2628\t validation accuracy: 0.9711\n",
      "iteration number: 1336\t training loss: 502.4378\tvalidation loss: 178.7720\t validation accuracy: 0.9711\n",
      "iteration number: 1337\t training loss: 497.9341\tvalidation loss: 177.4272\t validation accuracy: 0.9711\n",
      "iteration number: 1338\t training loss: 494.2278\tvalidation loss: 176.4389\t validation accuracy: 0.9711\n",
      "iteration number: 1339\t training loss: 489.7374\tvalidation loss: 175.2691\t validation accuracy: 0.9689\n",
      "iteration number: 1340\t training loss: 485.5975\tvalidation loss: 174.1927\t validation accuracy: 0.9689\n",
      "iteration number: 1341\t training loss: 481.7076\tvalidation loss: 173.1893\t validation accuracy: 0.9689\n",
      "iteration number: 1342\t training loss: 479.4787\tvalidation loss: 172.6932\t validation accuracy: 0.9689\n",
      "iteration number: 1343\t training loss: 475.7759\tvalidation loss: 171.7025\t validation accuracy: 0.9711\n",
      "iteration number: 1344\t training loss: 472.6392\tvalidation loss: 170.9634\t validation accuracy: 0.9711\n",
      "iteration number: 1345\t training loss: 470.6535\tvalidation loss: 170.5380\t validation accuracy: 0.9733\n",
      "iteration number: 1346\t training loss: 469.6053\tvalidation loss: 170.3244\t validation accuracy: 0.9733\n",
      "iteration number: 1347\t training loss: 468.7045\tvalidation loss: 170.1474\t validation accuracy: 0.9733\n",
      "iteration number: 1348\t training loss: 467.2260\tvalidation loss: 169.6817\t validation accuracy: 0.9733\n",
      "iteration number: 1349\t training loss: 466.3324\tvalidation loss: 169.3886\t validation accuracy: 0.9733\n",
      "iteration number: 1350\t training loss: 466.8949\tvalidation loss: 169.5997\t validation accuracy: 0.9733\n",
      "iteration number: 1351\t training loss: 467.3653\tvalidation loss: 169.6207\t validation accuracy: 0.9733\n",
      "iteration number: 1352\t training loss: 467.9641\tvalidation loss: 169.6815\t validation accuracy: 0.9756\n",
      "iteration number: 1353\t training loss: 468.8934\tvalidation loss: 169.8884\t validation accuracy: 0.9756\n",
      "iteration number: 1354\t training loss: 468.9394\tvalidation loss: 169.7417\t validation accuracy: 0.9756\n",
      "iteration number: 1355\t training loss: 468.8004\tvalidation loss: 169.4834\t validation accuracy: 0.9778\n",
      "iteration number: 1356\t training loss: 469.0411\tvalidation loss: 169.3998\t validation accuracy: 0.9778\n",
      "iteration number: 1357\t training loss: 470.2831\tvalidation loss: 169.6649\t validation accuracy: 0.9778\n",
      "iteration number: 1358\t training loss: 471.1450\tvalidation loss: 169.7789\t validation accuracy: 0.9778\n",
      "iteration number: 1359\t training loss: 471.2725\tvalidation loss: 169.7312\t validation accuracy: 0.9800\n",
      "iteration number: 1360\t training loss: 472.1604\tvalidation loss: 169.9668\t validation accuracy: 0.9800\n",
      "iteration number: 1361\t training loss: 473.4802\tvalidation loss: 170.4628\t validation accuracy: 0.9800\n",
      "iteration number: 1362\t training loss: 475.1710\tvalidation loss: 171.1509\t validation accuracy: 0.9778\n",
      "iteration number: 1363\t training loss: 477.2357\tvalidation loss: 171.9983\t validation accuracy: 0.9778\n",
      "iteration number: 1364\t training loss: 478.7914\tvalidation loss: 172.5592\t validation accuracy: 0.9778\n",
      "iteration number: 1365\t training loss: 479.7002\tvalidation loss: 172.9457\t validation accuracy: 0.9733\n",
      "iteration number: 1366\t training loss: 481.9065\tvalidation loss: 173.7863\t validation accuracy: 0.9756\n",
      "iteration number: 1367\t training loss: 484.2754\tvalidation loss: 174.6696\t validation accuracy: 0.9733\n",
      "iteration number: 1368\t training loss: 485.9176\tvalidation loss: 175.3215\t validation accuracy: 0.9711\n",
      "iteration number: 1369\t training loss: 487.1449\tvalidation loss: 175.7910\t validation accuracy: 0.9711\n",
      "iteration number: 1370\t training loss: 488.0415\tvalidation loss: 176.1811\t validation accuracy: 0.9711\n",
      "iteration number: 1371\t training loss: 489.7840\tvalidation loss: 176.8132\t validation accuracy: 0.9711\n",
      "iteration number: 1372\t training loss: 490.4246\tvalidation loss: 177.0930\t validation accuracy: 0.9756\n",
      "iteration number: 1373\t training loss: 490.8491\tvalidation loss: 177.3774\t validation accuracy: 0.9756\n",
      "iteration number: 1374\t training loss: 489.2661\tvalidation loss: 177.0459\t validation accuracy: 0.9756\n",
      "iteration number: 1375\t training loss: 487.9879\tvalidation loss: 176.7665\t validation accuracy: 0.9756\n",
      "iteration number: 1376\t training loss: 485.5983\tvalidation loss: 175.9915\t validation accuracy: 0.9733\n",
      "iteration number: 1377\t training loss: 482.7032\tvalidation loss: 174.9405\t validation accuracy: 0.9756\n",
      "iteration number: 1378\t training loss: 480.1304\tvalidation loss: 174.0454\t validation accuracy: 0.9756\n",
      "iteration number: 1379\t training loss: 477.0476\tvalidation loss: 172.8515\t validation accuracy: 0.9778\n",
      "iteration number: 1380\t training loss: 473.8556\tvalidation loss: 171.7024\t validation accuracy: 0.9756\n",
      "iteration number: 1381\t training loss: 469.7238\tvalidation loss: 170.2797\t validation accuracy: 0.9733\n",
      "iteration number: 1382\t training loss: 465.8128\tvalidation loss: 168.9131\t validation accuracy: 0.9733\n",
      "iteration number: 1383\t training loss: 462.0099\tvalidation loss: 167.5011\t validation accuracy: 0.9733\n",
      "iteration number: 1384\t training loss: 459.0145\tvalidation loss: 166.4271\t validation accuracy: 0.9733\n",
      "iteration number: 1385\t training loss: 457.7641\tvalidation loss: 165.9741\t validation accuracy: 0.9733\n",
      "iteration number: 1386\t training loss: 456.6618\tvalidation loss: 165.6578\t validation accuracy: 0.9733\n",
      "iteration number: 1387\t training loss: 455.9393\tvalidation loss: 165.4560\t validation accuracy: 0.9711\n",
      "iteration number: 1388\t training loss: 456.5967\tvalidation loss: 165.6591\t validation accuracy: 0.9711\n",
      "iteration number: 1389\t training loss: 457.7378\tvalidation loss: 166.1086\t validation accuracy: 0.9711\n",
      "iteration number: 1390\t training loss: 458.5895\tvalidation loss: 166.5101\t validation accuracy: 0.9711\n",
      "iteration number: 1391\t training loss: 459.5474\tvalidation loss: 166.9987\t validation accuracy: 0.9711\n",
      "iteration number: 1392\t training loss: 460.5459\tvalidation loss: 167.3745\t validation accuracy: 0.9711\n",
      "iteration number: 1393\t training loss: 461.9438\tvalidation loss: 167.9034\t validation accuracy: 0.9711\n",
      "iteration number: 1394\t training loss: 463.2070\tvalidation loss: 168.3221\t validation accuracy: 0.9733\n",
      "iteration number: 1395\t training loss: 463.2058\tvalidation loss: 168.2503\t validation accuracy: 0.9733\n",
      "iteration number: 1396\t training loss: 463.9913\tvalidation loss: 168.5647\t validation accuracy: 0.9733\n",
      "iteration number: 1397\t training loss: 464.3056\tvalidation loss: 168.6900\t validation accuracy: 0.9733\n",
      "iteration number: 1398\t training loss: 464.3946\tvalidation loss: 168.7369\t validation accuracy: 0.9711\n",
      "iteration number: 1399\t training loss: 465.0414\tvalidation loss: 168.9934\t validation accuracy: 0.9711\n",
      "iteration number: 1400\t training loss: 466.7926\tvalidation loss: 169.5722\t validation accuracy: 0.9711\n",
      "iteration number: 1401\t training loss: 467.2952\tvalidation loss: 169.6556\t validation accuracy: 0.9711\n",
      "iteration number: 1402\t training loss: 467.6851\tvalidation loss: 169.6488\t validation accuracy: 0.9733\n",
      "iteration number: 1403\t training loss: 468.4924\tvalidation loss: 169.7407\t validation accuracy: 0.9733\n",
      "iteration number: 1404\t training loss: 471.3863\tvalidation loss: 170.5164\t validation accuracy: 0.9756\n",
      "iteration number: 1405\t training loss: 474.7105\tvalidation loss: 171.4953\t validation accuracy: 0.9756\n",
      "iteration number: 1406\t training loss: 477.9292\tvalidation loss: 172.4419\t validation accuracy: 0.9756\n",
      "iteration number: 1407\t training loss: 481.1070\tvalidation loss: 173.3711\t validation accuracy: 0.9778\n",
      "iteration number: 1408\t training loss: 484.3307\tvalidation loss: 174.3043\t validation accuracy: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1409\t training loss: 487.5541\tvalidation loss: 175.3209\t validation accuracy: 0.9756\n",
      "iteration number: 1410\t training loss: 489.6764\tvalidation loss: 176.0609\t validation accuracy: 0.9756\n",
      "iteration number: 1411\t training loss: 490.3165\tvalidation loss: 176.3726\t validation accuracy: 0.9756\n",
      "iteration number: 1412\t training loss: 490.9198\tvalidation loss: 176.7854\t validation accuracy: 0.9733\n",
      "iteration number: 1413\t training loss: 490.8391\tvalidation loss: 177.0266\t validation accuracy: 0.9756\n",
      "iteration number: 1414\t training loss: 490.2297\tvalidation loss: 177.1100\t validation accuracy: 0.9756\n",
      "iteration number: 1415\t training loss: 489.3273\tvalidation loss: 177.0225\t validation accuracy: 0.9756\n",
      "iteration number: 1416\t training loss: 488.9770\tvalidation loss: 177.0941\t validation accuracy: 0.9756\n",
      "iteration number: 1417\t training loss: 489.6220\tvalidation loss: 177.4955\t validation accuracy: 0.9756\n",
      "iteration number: 1418\t training loss: 488.8728\tvalidation loss: 177.3501\t validation accuracy: 0.9756\n",
      "iteration number: 1419\t training loss: 486.7913\tvalidation loss: 176.7605\t validation accuracy: 0.9756\n",
      "iteration number: 1420\t training loss: 485.1901\tvalidation loss: 176.3561\t validation accuracy: 0.9733\n",
      "iteration number: 1421\t training loss: 484.0651\tvalidation loss: 176.0469\t validation accuracy: 0.9711\n",
      "iteration number: 1422\t training loss: 482.2603\tvalidation loss: 175.5501\t validation accuracy: 0.9711\n",
      "iteration number: 1423\t training loss: 480.0429\tvalidation loss: 174.7555\t validation accuracy: 0.9711\n",
      "iteration number: 1424\t training loss: 477.4440\tvalidation loss: 173.7135\t validation accuracy: 0.9733\n",
      "iteration number: 1425\t training loss: 475.3595\tvalidation loss: 172.8931\t validation accuracy: 0.9733\n",
      "iteration number: 1426\t training loss: 474.0689\tvalidation loss: 172.3860\t validation accuracy: 0.9733\n",
      "iteration number: 1427\t training loss: 472.0884\tvalidation loss: 171.5452\t validation accuracy: 0.9711\n",
      "iteration number: 1428\t training loss: 470.3991\tvalidation loss: 170.9395\t validation accuracy: 0.9711\n",
      "iteration number: 1429\t training loss: 469.3828\tvalidation loss: 170.6505\t validation accuracy: 0.9711\n",
      "iteration number: 1430\t training loss: 469.2196\tvalidation loss: 170.6153\t validation accuracy: 0.9733\n",
      "iteration number: 1431\t training loss: 468.7528\tvalidation loss: 170.4474\t validation accuracy: 0.9733\n",
      "iteration number: 1432\t training loss: 468.2283\tvalidation loss: 170.2059\t validation accuracy: 0.9733\n",
      "iteration number: 1433\t training loss: 467.9243\tvalidation loss: 170.0770\t validation accuracy: 0.9711\n",
      "iteration number: 1434\t training loss: 468.7023\tvalidation loss: 170.4283\t validation accuracy: 0.9689\n",
      "iteration number: 1435\t training loss: 469.7930\tvalidation loss: 170.9995\t validation accuracy: 0.9689\n",
      "iteration number: 1436\t training loss: 471.0776\tvalidation loss: 171.5211\t validation accuracy: 0.9689\n",
      "iteration number: 1437\t training loss: 472.1289\tvalidation loss: 172.0052\t validation accuracy: 0.9689\n",
      "iteration number: 1438\t training loss: 473.2291\tvalidation loss: 172.5055\t validation accuracy: 0.9689\n",
      "iteration number: 1439\t training loss: 474.2876\tvalidation loss: 172.9529\t validation accuracy: 0.9689\n",
      "iteration number: 1440\t training loss: 475.5149\tvalidation loss: 173.3987\t validation accuracy: 0.9689\n",
      "iteration number: 1441\t training loss: 477.5499\tvalidation loss: 174.1200\t validation accuracy: 0.9689\n",
      "iteration number: 1442\t training loss: 479.2214\tvalidation loss: 174.7268\t validation accuracy: 0.9689\n",
      "iteration number: 1443\t training loss: 480.7214\tvalidation loss: 175.3104\t validation accuracy: 0.9689\n",
      "iteration number: 1444\t training loss: 481.1891\tvalidation loss: 175.5492\t validation accuracy: 0.9689\n",
      "iteration number: 1445\t training loss: 481.7057\tvalidation loss: 175.7006\t validation accuracy: 0.9689\n",
      "iteration number: 1446\t training loss: 482.2375\tvalidation loss: 175.7523\t validation accuracy: 0.9689\n",
      "iteration number: 1447\t training loss: 482.2607\tvalidation loss: 175.6890\t validation accuracy: 0.9689\n",
      "iteration number: 1448\t training loss: 481.8185\tvalidation loss: 175.4950\t validation accuracy: 0.9711\n",
      "iteration number: 1449\t training loss: 480.5301\tvalidation loss: 175.0243\t validation accuracy: 0.9711\n",
      "iteration number: 1450\t training loss: 479.5762\tvalidation loss: 174.7403\t validation accuracy: 0.9711\n",
      "iteration number: 1451\t training loss: 480.1647\tvalidation loss: 175.0471\t validation accuracy: 0.9711\n",
      "iteration number: 1452\t training loss: 480.2598\tvalidation loss: 175.1689\t validation accuracy: 0.9711\n",
      "iteration number: 1453\t training loss: 479.2278\tvalidation loss: 174.9072\t validation accuracy: 0.9711\n",
      "iteration number: 1454\t training loss: 478.9442\tvalidation loss: 174.9752\t validation accuracy: 0.9689\n",
      "iteration number: 1455\t training loss: 477.9232\tvalidation loss: 174.8942\t validation accuracy: 0.9689\n",
      "iteration number: 1456\t training loss: 475.8878\tvalidation loss: 174.3776\t validation accuracy: 0.9689\n",
      "iteration number: 1457\t training loss: 474.9963\tvalidation loss: 174.1933\t validation accuracy: 0.9711\n",
      "iteration number: 1458\t training loss: 473.3555\tvalidation loss: 173.7184\t validation accuracy: 0.9711\n",
      "iteration number: 1459\t training loss: 472.7693\tvalidation loss: 173.5865\t validation accuracy: 0.9711\n",
      "iteration number: 1460\t training loss: 472.2066\tvalidation loss: 173.5248\t validation accuracy: 0.9711\n",
      "iteration number: 1461\t training loss: 471.4641\tvalidation loss: 173.3455\t validation accuracy: 0.9733\n",
      "iteration number: 1462\t training loss: 469.6574\tvalidation loss: 172.7571\t validation accuracy: 0.9733\n",
      "iteration number: 1463\t training loss: 467.2868\tvalidation loss: 172.0635\t validation accuracy: 0.9733\n",
      "iteration number: 1464\t training loss: 465.3427\tvalidation loss: 171.5758\t validation accuracy: 0.9733\n",
      "iteration number: 1465\t training loss: 461.9574\tvalidation loss: 170.5030\t validation accuracy: 0.9733\n",
      "iteration number: 1466\t training loss: 458.6856\tvalidation loss: 169.5019\t validation accuracy: 0.9733\n",
      "iteration number: 1467\t training loss: 456.1148\tvalidation loss: 168.7672\t validation accuracy: 0.9733\n",
      "iteration number: 1468\t training loss: 453.6855\tvalidation loss: 168.0282\t validation accuracy: 0.9756\n",
      "iteration number: 1469\t training loss: 451.1017\tvalidation loss: 167.2720\t validation accuracy: 0.9756\n",
      "iteration number: 1470\t training loss: 449.7986\tvalidation loss: 166.8890\t validation accuracy: 0.9711\n",
      "iteration number: 1471\t training loss: 449.5972\tvalidation loss: 166.8511\t validation accuracy: 0.9689\n",
      "iteration number: 1472\t training loss: 449.3947\tvalidation loss: 166.8441\t validation accuracy: 0.9689\n",
      "iteration number: 1473\t training loss: 450.0826\tvalidation loss: 167.1719\t validation accuracy: 0.9689\n",
      "iteration number: 1474\t training loss: 449.9598\tvalidation loss: 167.1102\t validation accuracy: 0.9689\n",
      "iteration number: 1475\t training loss: 450.6471\tvalidation loss: 167.2916\t validation accuracy: 0.9711\n",
      "iteration number: 1476\t training loss: 451.1689\tvalidation loss: 167.3634\t validation accuracy: 0.9711\n",
      "iteration number: 1477\t training loss: 452.2281\tvalidation loss: 167.6336\t validation accuracy: 0.9733\n",
      "iteration number: 1478\t training loss: 453.7278\tvalidation loss: 167.9148\t validation accuracy: 0.9733\n",
      "iteration number: 1479\t training loss: 454.0796\tvalidation loss: 167.7109\t validation accuracy: 0.9756\n",
      "iteration number: 1480\t training loss: 452.4562\tvalidation loss: 166.7148\t validation accuracy: 0.9756\n",
      "iteration number: 1481\t training loss: 452.6718\tvalidation loss: 166.3385\t validation accuracy: 0.9733\n",
      "iteration number: 1482\t training loss: 453.3466\tvalidation loss: 166.1874\t validation accuracy: 0.9733\n",
      "iteration number: 1483\t training loss: 453.5053\tvalidation loss: 165.9790\t validation accuracy: 0.9733\n",
      "iteration number: 1484\t training loss: 453.6908\tvalidation loss: 165.8807\t validation accuracy: 0.9756\n",
      "iteration number: 1485\t training loss: 453.5825\tvalidation loss: 165.7490\t validation accuracy: 0.9756\n",
      "iteration number: 1486\t training loss: 453.5706\tvalidation loss: 165.7581\t validation accuracy: 0.9756\n",
      "iteration number: 1487\t training loss: 453.9762\tvalidation loss: 165.8689\t validation accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "mlp = MultiLayerPerceptron(X, Y, hidden_size=50, activation='sigmoid',dropout=True, dropout_rate=0.35)\n",
    "mlp.train(momentum = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.plot_loss_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1\t training loss: 6488.8875\tvalidation loss: 2194.4479\t validation accuracy: 0.1067\n",
      "iteration number: 2\t training loss: 4871.8526\tvalidation loss: 1629.7539\t validation accuracy: 0.0978\n",
      "iteration number: 3\t training loss: 4010.4858\tvalidation loss: 1342.7287\t validation accuracy: 0.0978\n",
      "iteration number: 4\t training loss: 3453.5548\tvalidation loss: 1158.2845\t validation accuracy: 0.0889\n",
      "iteration number: 5\t training loss: 3071.1378\tvalidation loss: 1028.8177\t validation accuracy: 0.0933\n",
      "iteration number: 6\t training loss: 2802.3217\tvalidation loss: 937.8322\t validation accuracy: 0.0933\n",
      "iteration number: 7\t training loss: 2623.0596\tvalidation loss: 876.8890\t validation accuracy: 0.0933\n",
      "iteration number: 8\t training loss: 2520.2888\tvalidation loss: 840.7812\t validation accuracy: 0.0933\n",
      "iteration number: 9\t training loss: 2484.0454\tvalidation loss: 826.7820\t validation accuracy: 0.0933\n",
      "iteration number: 10\t training loss: 2505.6489\tvalidation loss: 832.2459\t validation accuracy: 0.0933\n",
      "iteration number: 11\t training loss: 2578.7212\tvalidation loss: 855.8660\t validation accuracy: 0.1244\n",
      "iteration number: 12\t training loss: 2698.3947\tvalidation loss: 895.6799\t validation accuracy: 0.1244\n",
      "iteration number: 13\t training loss: 2858.7110\tvalidation loss: 950.0369\t validation accuracy: 0.1244\n",
      "iteration number: 14\t training loss: 3049.3369\tvalidation loss: 1016.0171\t validation accuracy: 0.1244\n",
      "iteration number: 15\t training loss: 3269.5876\tvalidation loss: 1092.2344\t validation accuracy: 0.1244\n",
      "iteration number: 16\t training loss: 3492.7622\tvalidation loss: 1169.8518\t validation accuracy: 0.0733\n",
      "iteration number: 17\t training loss: 3689.9546\tvalidation loss: 1239.0845\t validation accuracy: 0.0733\n",
      "iteration number: 18\t training loss: 3823.9052\tvalidation loss: 1287.4162\t validation accuracy: 0.0978\n",
      "iteration number: 19\t training loss: 3864.2752\tvalidation loss: 1303.5253\t validation accuracy: 0.0978\n",
      "iteration number: 20\t training loss: 3778.2488\tvalidation loss: 1276.2930\t validation accuracy: 0.0889\n",
      "iteration number: 21\t training loss: 3615.0098\tvalidation loss: 1221.7100\t validation accuracy: 0.0889\n",
      "iteration number: 22\t training loss: 3417.3370\tvalidation loss: 1153.9027\t validation accuracy: 0.0889\n",
      "iteration number: 23\t training loss: 3238.5160\tvalidation loss: 1090.9492\t validation accuracy: 0.0889\n",
      "iteration number: 24\t training loss: 3092.4491\tvalidation loss: 1038.7804\t validation accuracy: 0.1844\n",
      "iteration number: 25\t training loss: 2982.8990\tvalidation loss: 998.4232\t validation accuracy: 0.1089\n",
      "iteration number: 26\t training loss: 2903.3182\tvalidation loss: 969.3940\t validation accuracy: 0.1889\n",
      "iteration number: 27\t training loss: 2849.3517\tvalidation loss: 949.9907\t validation accuracy: 0.0933\n",
      "iteration number: 28\t training loss: 2822.8758\tvalidation loss: 938.9892\t validation accuracy: 0.1333\n",
      "iteration number: 29\t training loss: 2824.8131\tvalidation loss: 937.8209\t validation accuracy: 0.1533\n",
      "iteration number: 30\t training loss: 2848.9791\tvalidation loss: 944.5352\t validation accuracy: 0.1711\n",
      "iteration number: 31\t training loss: 2892.3007\tvalidation loss: 957.8013\t validation accuracy: 0.3400\n",
      "iteration number: 32\t training loss: 2941.0979\tvalidation loss: 975.3962\t validation accuracy: 0.1933\n",
      "iteration number: 33\t training loss: 2995.5390\tvalidation loss: 993.9178\t validation accuracy: 0.1933\n",
      "iteration number: 34\t training loss: 3051.1339\tvalidation loss: 1013.9084\t validation accuracy: 0.1800\n",
      "iteration number: 35\t training loss: 3104.1147\tvalidation loss: 1033.1753\t validation accuracy: 0.2267\n",
      "iteration number: 36\t training loss: 3143.7799\tvalidation loss: 1051.9833\t validation accuracy: 0.3467\n",
      "iteration number: 37\t training loss: 3177.9605\tvalidation loss: 1069.2247\t validation accuracy: 0.2400\n",
      "iteration number: 38\t training loss: 3194.8539\tvalidation loss: 1078.9675\t validation accuracy: 0.1600\n",
      "iteration number: 39\t training loss: 3187.7496\tvalidation loss: 1079.9388\t validation accuracy: 0.1000\n",
      "iteration number: 40\t training loss: 3156.3048\tvalidation loss: 1069.7116\t validation accuracy: 0.0933\n",
      "iteration number: 41\t training loss: 3106.9454\tvalidation loss: 1051.5378\t validation accuracy: 0.0933\n",
      "iteration number: 42\t training loss: 3045.9063\tvalidation loss: 1028.0780\t validation accuracy: 0.0933\n",
      "iteration number: 43\t training loss: 2987.0886\tvalidation loss: 1004.5891\t validation accuracy: 0.0933\n",
      "iteration number: 44\t training loss: 2932.8861\tvalidation loss: 983.8281\t validation accuracy: 0.1711\n",
      "iteration number: 45\t training loss: 2883.8989\tvalidation loss: 965.8720\t validation accuracy: 0.3200\n",
      "iteration number: 46\t training loss: 2841.5231\tvalidation loss: 949.9928\t validation accuracy: 0.3689\n",
      "iteration number: 47\t training loss: 2817.2060\tvalidation loss: 939.6301\t validation accuracy: 0.2222\n",
      "iteration number: 48\t training loss: 2811.8444\tvalidation loss: 935.5888\t validation accuracy: 0.2422\n",
      "iteration number: 49\t training loss: 2817.0105\tvalidation loss: 935.0979\t validation accuracy: 0.1889\n",
      "iteration number: 50\t training loss: 2815.4183\tvalidation loss: 933.7240\t validation accuracy: 0.1956\n",
      "iteration number: 51\t training loss: 2813.2096\tvalidation loss: 933.5841\t validation accuracy: 0.1867\n",
      "iteration number: 52\t training loss: 2811.4143\tvalidation loss: 933.0837\t validation accuracy: 0.1533\n",
      "iteration number: 53\t training loss: 2797.7890\tvalidation loss: 930.1769\t validation accuracy: 0.1444\n",
      "iteration number: 54\t training loss: 2788.8760\tvalidation loss: 928.8416\t validation accuracy: 0.1689\n",
      "iteration number: 55\t training loss: 2778.6129\tvalidation loss: 928.3858\t validation accuracy: 0.3178\n",
      "iteration number: 56\t training loss: 2765.6595\tvalidation loss: 926.7075\t validation accuracy: 0.5244\n",
      "iteration number: 57\t training loss: 2744.2105\tvalidation loss: 922.3486\t validation accuracy: 0.5778\n",
      "iteration number: 58\t training loss: 2718.8024\tvalidation loss: 914.7600\t validation accuracy: 0.5222\n",
      "iteration number: 59\t training loss: 2690.2896\tvalidation loss: 905.1060\t validation accuracy: 0.4822\n",
      "iteration number: 60\t training loss: 2651.9194\tvalidation loss: 891.7685\t validation accuracy: 0.4800\n",
      "iteration number: 61\t training loss: 2606.4015\tvalidation loss: 876.4841\t validation accuracy: 0.5267\n",
      "iteration number: 62\t training loss: 2549.8179\tvalidation loss: 856.6686\t validation accuracy: 0.5956\n",
      "iteration number: 63\t training loss: 2501.5948\tvalidation loss: 839.2863\t validation accuracy: 0.6511\n",
      "iteration number: 64\t training loss: 2459.2978\tvalidation loss: 823.5601\t validation accuracy: 0.6867\n",
      "iteration number: 65\t training loss: 2422.1767\tvalidation loss: 809.3240\t validation accuracy: 0.7089\n",
      "iteration number: 66\t training loss: 2388.5874\tvalidation loss: 795.6420\t validation accuracy: 0.7222\n",
      "iteration number: 67\t training loss: 2360.2488\tvalidation loss: 784.4093\t validation accuracy: 0.7089\n",
      "iteration number: 68\t training loss: 2333.7936\tvalidation loss: 774.0954\t validation accuracy: 0.6889\n",
      "iteration number: 69\t training loss: 2307.2816\tvalidation loss: 765.2977\t validation accuracy: 0.6578\n",
      "iteration number: 70\t training loss: 2285.2523\tvalidation loss: 758.5583\t validation accuracy: 0.6489\n",
      "iteration number: 71\t training loss: 2265.4920\tvalidation loss: 753.8194\t validation accuracy: 0.6244\n",
      "iteration number: 72\t training loss: 2241.2035\tvalidation loss: 748.8331\t validation accuracy: 0.6333\n",
      "iteration number: 73\t training loss: 2215.9434\tvalidation loss: 744.3202\t validation accuracy: 0.6511\n",
      "iteration number: 74\t training loss: 2189.8419\tvalidation loss: 739.3614\t validation accuracy: 0.6689\n",
      "iteration number: 75\t training loss: 2166.7650\tvalidation loss: 735.5703\t validation accuracy: 0.6756\n",
      "iteration number: 76\t training loss: 2146.7226\tvalidation loss: 731.7219\t validation accuracy: 0.6822\n",
      "iteration number: 77\t training loss: 2127.0637\tvalidation loss: 726.8669\t validation accuracy: 0.6711\n",
      "iteration number: 78\t training loss: 2106.4133\tvalidation loss: 720.1413\t validation accuracy: 0.6622\n",
      "iteration number: 79\t training loss: 2081.4946\tvalidation loss: 710.0563\t validation accuracy: 0.6889\n",
      "iteration number: 80\t training loss: 2057.0131\tvalidation loss: 699.1828\t validation accuracy: 0.7622\n",
      "iteration number: 81\t training loss: 2029.7164\tvalidation loss: 686.3426\t validation accuracy: 0.8244\n",
      "iteration number: 82\t training loss: 2005.4206\tvalidation loss: 675.5257\t validation accuracy: 0.8467\n",
      "iteration number: 83\t training loss: 1982.5309\tvalidation loss: 666.0329\t validation accuracy: 0.8378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 84\t training loss: 1964.2892\tvalidation loss: 658.7026\t validation accuracy: 0.8467\n",
      "iteration number: 85\t training loss: 1959.6534\tvalidation loss: 653.4578\t validation accuracy: 0.8644\n",
      "iteration number: 86\t training loss: 1940.6527\tvalidation loss: 647.4228\t validation accuracy: 0.8533\n",
      "iteration number: 87\t training loss: 1920.0250\tvalidation loss: 641.4007\t validation accuracy: 0.8578\n",
      "iteration number: 88\t training loss: 1902.7486\tvalidation loss: 636.4286\t validation accuracy: 0.8556\n",
      "iteration number: 89\t training loss: 1898.0920\tvalidation loss: 633.4688\t validation accuracy: 0.8578\n",
      "iteration number: 90\t training loss: 1889.8170\tvalidation loss: 631.8593\t validation accuracy: 0.8533\n",
      "iteration number: 91\t training loss: 1903.1673\tvalidation loss: 632.7373\t validation accuracy: 0.8556\n",
      "iteration number: 92\t training loss: 1889.8023\tvalidation loss: 630.9679\t validation accuracy: 0.8467\n",
      "iteration number: 93\t training loss: 1860.7186\tvalidation loss: 623.4664\t validation accuracy: 0.8422\n",
      "iteration number: 94\t training loss: 1842.8798\tvalidation loss: 615.3274\t validation accuracy: 0.8578\n",
      "iteration number: 95\t training loss: 1826.6729\tvalidation loss: 609.0273\t validation accuracy: 0.8511\n",
      "iteration number: 96\t training loss: 1792.3409\tvalidation loss: 602.5896\t validation accuracy: 0.8444\n",
      "iteration number: 97\t training loss: 1776.8983\tvalidation loss: 597.3186\t validation accuracy: 0.8244\n",
      "iteration number: 98\t training loss: 1754.7531\tvalidation loss: 591.2457\t validation accuracy: 0.8267\n",
      "iteration number: 99\t training loss: 1736.4673\tvalidation loss: 585.3739\t validation accuracy: 0.8200\n",
      "iteration number: 100\t training loss: 1721.0565\tvalidation loss: 581.7000\t validation accuracy: 0.8022\n",
      "iteration number: 101\t training loss: 1707.0530\tvalidation loss: 576.4507\t validation accuracy: 0.7978\n",
      "iteration number: 102\t training loss: 1696.2064\tvalidation loss: 586.3955\t validation accuracy: 0.8022\n",
      "iteration number: 103\t training loss: 1688.7882\tvalidation loss: 585.1256\t validation accuracy: 0.8133\n",
      "iteration number: 104\t training loss: 1670.3181\tvalidation loss: 596.0892\t validation accuracy: 0.8156\n",
      "iteration number: 105\t training loss: 1689.8767\tvalidation loss: 593.0177\t validation accuracy: 0.8111\n",
      "iteration number: 106\t training loss: 1694.9360\tvalidation loss: 590.8762\t validation accuracy: 0.8156\n",
      "iteration number: 107\t training loss: 1675.7068\tvalidation loss: 615.0334\t validation accuracy: 0.8311\n",
      "iteration number: 108\t training loss: 1665.2433\tvalidation loss: 616.4867\t validation accuracy: 0.8444\n",
      "iteration number: 109\t training loss: 1661.5736\tvalidation loss: 619.3344\t validation accuracy: 0.8333\n",
      "iteration number: 110\t training loss: 1669.2001\tvalidation loss: 617.9599\t validation accuracy: 0.8244\n",
      "iteration number: 111\t training loss: 1670.6467\tvalidation loss: 618.5121\t validation accuracy: 0.7889\n",
      "iteration number: 112\t training loss: 1678.0671\tvalidation loss: 617.3174\t validation accuracy: 0.7800\n",
      "iteration number: 113\t training loss: 1659.5172\tvalidation loss: 589.6437\t validation accuracy: 0.7800\n",
      "iteration number: 114\t training loss: 1662.7794\tvalidation loss: 608.2725\t validation accuracy: 0.7733\n",
      "iteration number: 115\t training loss: 1671.6169\tvalidation loss: 589.3542\t validation accuracy: 0.7911\n",
      "iteration number: 116\t training loss: 1693.5785\tvalidation loss: 584.6988\t validation accuracy: 0.8156\n",
      "iteration number: 117\t training loss: 1676.7267\tvalidation loss: 579.4825\t validation accuracy: 0.8422\n",
      "iteration number: 118\t training loss: 1672.0853\tvalidation loss: 578.1158\t validation accuracy: 0.8467\n",
      "iteration number: 119\t training loss: 1612.9970\tvalidation loss: 592.2664\t validation accuracy: 0.8444\n",
      "iteration number: 120\t training loss: 1640.8054\tvalidation loss: 594.5397\t validation accuracy: 0.8356\n",
      "iteration number: 121\t training loss: 1643.9118\tvalidation loss: 606.5448\t validation accuracy: 0.8356\n",
      "iteration number: 122\t training loss: 1672.5975\tvalidation loss: 604.9259\t validation accuracy: 0.8378\n",
      "iteration number: 123\t training loss: 1713.9430\tvalidation loss: 603.5023\t validation accuracy: 0.8400\n",
      "iteration number: 124\t training loss: 1719.0890\tvalidation loss: 614.8046\t validation accuracy: 0.8311\n",
      "iteration number: 125\t training loss: 1694.2039\tvalidation loss: 597.2739\t validation accuracy: 0.8333\n",
      "iteration number: 126\t training loss: 1618.1417\tvalidation loss: 586.9232\t validation accuracy: 0.8378\n",
      "iteration number: 127\t training loss: 1584.2182\tvalidation loss: 580.4623\t validation accuracy: 0.8444\n",
      "iteration number: 128\t training loss: 1541.8653\tvalidation loss: 577.2764\t validation accuracy: 0.8444\n",
      "iteration number: 129\t training loss: 1527.7270\tvalidation loss: 573.2550\t validation accuracy: 0.8556\n",
      "iteration number: 130\t training loss: 1514.0924\tvalidation loss: 572.0500\t validation accuracy: 0.8533\n",
      "iteration number: 131\t training loss: 1507.5973\tvalidation loss: 573.0935\t validation accuracy: 0.8533\n",
      "iteration number: 132\t training loss: 1515.6312\tvalidation loss: 563.3514\t validation accuracy: 0.8533\n",
      "iteration number: 133\t training loss: 1548.8088\tvalidation loss: 553.9052\t validation accuracy: 0.8356\n",
      "iteration number: 134\t training loss: 1625.2786\tvalidation loss: 575.0256\t validation accuracy: 0.8244\n",
      "iteration number: 135\t training loss: 1662.6661\tvalidation loss: 571.1114\t validation accuracy: 0.7911\n",
      "iteration number: 136\t training loss: 1720.9290\tvalidation loss: 589.0085\t validation accuracy: 0.7800\n",
      "iteration number: 137\t training loss: 1742.3527\tvalidation loss: 590.9998\t validation accuracy: 0.7822\n",
      "iteration number: 138\t training loss: 1732.0797\tvalidation loss: 563.6163\t validation accuracy: 0.7911\n",
      "iteration number: 139\t training loss: 1679.2926\tvalidation loss: 553.0830\t validation accuracy: 0.8133\n",
      "iteration number: 140\t training loss: 1586.8536\tvalidation loss: 570.6760\t validation accuracy: 0.8222\n",
      "iteration number: 141\t training loss: 1551.3617\tvalidation loss: 581.2438\t validation accuracy: 0.8333\n",
      "iteration number: 142\t training loss: 1516.2793\tvalidation loss: 600.3195\t validation accuracy: 0.8444\n",
      "iteration number: 143\t training loss: 1511.4229\tvalidation loss: 596.2129\t validation accuracy: 0.8511\n",
      "iteration number: 144\t training loss: 1517.4406\tvalidation loss: 596.4727\t validation accuracy: 0.8422\n",
      "iteration number: 145\t training loss: 1522.2539\tvalidation loss: 610.8017\t validation accuracy: 0.8444\n",
      "iteration number: 146\t training loss: 1576.5486\tvalidation loss: 639.6693\t validation accuracy: 0.8444\n",
      "iteration number: 147\t training loss: 1552.4431\tvalidation loss: 610.6485\t validation accuracy: 0.8422\n",
      "iteration number: 148\t training loss: 1538.0931\tvalidation loss: 604.4668\t validation accuracy: 0.8422\n",
      "iteration number: 149\t training loss: 1516.5370\tvalidation loss: 598.4816\t validation accuracy: 0.8489\n",
      "iteration number: 150\t training loss: 1451.7271\tvalidation loss: 592.9213\t validation accuracy: 0.8467\n",
      "iteration number: 151\t training loss: 1409.8149\tvalidation loss: 558.5477\t validation accuracy: 0.8489\n",
      "iteration number: 152\t training loss: 1373.4301\tvalidation loss: 534.8367\t validation accuracy: 0.8556\n",
      "iteration number: 153\t training loss: 1358.3200\tvalidation loss: 527.9026\t validation accuracy: 0.8644\n",
      "iteration number: 154\t training loss: 1334.8660\tvalidation loss: 498.3150\t validation accuracy: 0.8733\n",
      "iteration number: 155\t training loss: 1326.9510\tvalidation loss: 462.8724\t validation accuracy: 0.8822\n",
      "iteration number: 156\t training loss: 1322.6975\tvalidation loss: 457.7675\t validation accuracy: 0.8844\n",
      "iteration number: 157\t training loss: 1333.4442\tvalidation loss: 441.9236\t validation accuracy: 0.8911\n",
      "iteration number: 158\t training loss: 1326.2367\tvalidation loss: 437.5755\t validation accuracy: 0.9000\n",
      "iteration number: 159\t training loss: 1334.6513\tvalidation loss: 438.4828\t validation accuracy: 0.8978\n",
      "iteration number: 160\t training loss: 1351.5236\tvalidation loss: 457.5386\t validation accuracy: 0.9000\n",
      "iteration number: 161\t training loss: 1357.3640\tvalidation loss: 477.4402\t validation accuracy: 0.8933\n",
      "iteration number: 162\t training loss: 1374.4098\tvalidation loss: 504.5418\t validation accuracy: 0.8889\n",
      "iteration number: 163\t training loss: 1402.4478\tvalidation loss: 566.7854\t validation accuracy: 0.8711\n",
      "iteration number: 164\t training loss: 1465.0319\tvalidation loss: 584.2926\t validation accuracy: 0.8444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 165\t training loss: 1510.8187\tvalidation loss: 612.0730\t validation accuracy: 0.8178\n",
      "iteration number: 166\t training loss: 1594.2169\tvalidation loss: 650.8546\t validation accuracy: 0.7822\n",
      "iteration number: 167\t training loss: 1622.2971\tvalidation loss: 682.5899\t validation accuracy: 0.7711\n",
      "iteration number: 168\t training loss: 1610.4798\tvalidation loss: 692.3450\t validation accuracy: 0.7778\n",
      "iteration number: 169\t training loss: 1613.3654\tvalidation loss: 689.6890\t validation accuracy: 0.7822\n",
      "iteration number: 170\t training loss: 1601.3318\tvalidation loss: 685.6405\t validation accuracy: 0.7978\n",
      "iteration number: 171\t training loss: 1550.4661\tvalidation loss: 663.6408\t validation accuracy: 0.8111\n",
      "iteration number: 172\t training loss: 1504.5168\tvalidation loss: 611.1581\t validation accuracy: 0.8311\n",
      "iteration number: 173\t training loss: 1424.2880\tvalidation loss: 582.8759\t validation accuracy: 0.8422\n",
      "iteration number: 174\t training loss: 1335.9745\tvalidation loss: 537.6027\t validation accuracy: 0.8578\n",
      "iteration number: 175\t training loss: 1292.7098\tvalidation loss: 510.7682\t validation accuracy: 0.8644\n",
      "iteration number: 176\t training loss: 1251.9733\tvalidation loss: 491.4497\t validation accuracy: 0.8778\n",
      "iteration number: 177\t training loss: 1239.5862\tvalidation loss: 446.7694\t validation accuracy: 0.8844\n",
      "iteration number: 178\t training loss: 1231.9741\tvalidation loss: 439.6221\t validation accuracy: 0.8844\n",
      "iteration number: 179\t training loss: 1216.0851\tvalidation loss: 440.1472\t validation accuracy: 0.8778\n",
      "iteration number: 180\t training loss: 1220.9280\tvalidation loss: 470.0679\t validation accuracy: 0.8733\n",
      "iteration number: 181\t training loss: 1243.8455\tvalidation loss: 499.7468\t validation accuracy: 0.8644\n",
      "iteration number: 182\t training loss: 1281.9944\tvalidation loss: 500.7737\t validation accuracy: 0.8644\n",
      "iteration number: 183\t training loss: 1284.9307\tvalidation loss: 502.6295\t validation accuracy: 0.8711\n",
      "iteration number: 184\t training loss: 1284.8816\tvalidation loss: 502.6816\t validation accuracy: 0.8733\n",
      "iteration number: 185\t training loss: 1294.4087\tvalidation loss: 506.2845\t validation accuracy: 0.8711\n",
      "iteration number: 186\t training loss: 1330.9040\tvalidation loss: 524.4820\t validation accuracy: 0.8622\n",
      "iteration number: 187\t training loss: 1336.4190\tvalidation loss: 527.0158\t validation accuracy: 0.8622\n",
      "iteration number: 188\t training loss: 1334.3363\tvalidation loss: 525.5136\t validation accuracy: 0.8578\n",
      "iteration number: 189\t training loss: 1320.7292\tvalidation loss: 510.7124\t validation accuracy: 0.8644\n",
      "iteration number: 190\t training loss: 1321.0456\tvalidation loss: 509.9376\t validation accuracy: 0.8644\n",
      "iteration number: 191\t training loss: 1328.2665\tvalidation loss: 512.4750\t validation accuracy: 0.8578\n",
      "iteration number: 192\t training loss: 1330.9235\tvalidation loss: 512.7662\t validation accuracy: 0.8578\n",
      "iteration number: 193\t training loss: 1303.3183\tvalidation loss: 510.8916\t validation accuracy: 0.8578\n",
      "iteration number: 194\t training loss: 1280.9598\tvalidation loss: 481.7614\t validation accuracy: 0.8644\n",
      "iteration number: 195\t training loss: 1277.4444\tvalidation loss: 479.3484\t validation accuracy: 0.8733\n",
      "iteration number: 196\t training loss: 1275.9619\tvalidation loss: 479.8096\t validation accuracy: 0.8733\n",
      "iteration number: 197\t training loss: 1297.9799\tvalidation loss: 506.5016\t validation accuracy: 0.8733\n",
      "iteration number: 198\t training loss: 1296.3612\tvalidation loss: 507.9173\t validation accuracy: 0.8711\n",
      "iteration number: 199\t training loss: 1295.3079\tvalidation loss: 510.4819\t validation accuracy: 0.8667\n",
      "iteration number: 200\t training loss: 1290.7750\tvalidation loss: 523.8222\t validation accuracy: 0.8689\n",
      "iteration number: 201\t training loss: 1300.1079\tvalidation loss: 524.4175\t validation accuracy: 0.8756\n",
      "iteration number: 202\t training loss: 1312.0727\tvalidation loss: 527.6079\t validation accuracy: 0.8756\n",
      "iteration number: 203\t training loss: 1315.0113\tvalidation loss: 528.3196\t validation accuracy: 0.8667\n",
      "iteration number: 204\t training loss: 1304.4376\tvalidation loss: 526.0315\t validation accuracy: 0.8578\n",
      "iteration number: 205\t training loss: 1306.5675\tvalidation loss: 525.3890\t validation accuracy: 0.8511\n",
      "iteration number: 206\t training loss: 1296.8892\tvalidation loss: 523.3286\t validation accuracy: 0.8489\n",
      "iteration number: 207\t training loss: 1284.3442\tvalidation loss: 511.4487\t validation accuracy: 0.8489\n",
      "iteration number: 208\t training loss: 1278.6796\tvalidation loss: 503.9067\t validation accuracy: 0.8556\n",
      "iteration number: 209\t training loss: 1258.8337\tvalidation loss: 486.2846\t validation accuracy: 0.8556\n",
      "iteration number: 210\t training loss: 1238.5179\tvalidation loss: 440.3140\t validation accuracy: 0.8622\n",
      "iteration number: 211\t training loss: 1223.4164\tvalidation loss: 417.6328\t validation accuracy: 0.8711\n",
      "iteration number: 212\t training loss: 1198.5383\tvalidation loss: 406.9070\t validation accuracy: 0.8911\n",
      "iteration number: 213\t training loss: 1167.4017\tvalidation loss: 401.6952\t validation accuracy: 0.9022\n",
      "iteration number: 214\t training loss: 1149.0197\tvalidation loss: 402.4885\t validation accuracy: 0.9022\n",
      "iteration number: 215\t training loss: 1147.3109\tvalidation loss: 457.7064\t validation accuracy: 0.9000\n",
      "iteration number: 216\t training loss: 1164.2030\tvalidation loss: 474.8676\t validation accuracy: 0.9000\n",
      "iteration number: 217\t training loss: 1199.0154\tvalidation loss: 493.5157\t validation accuracy: 0.8978\n",
      "iteration number: 218\t training loss: 1219.5212\tvalidation loss: 499.2271\t validation accuracy: 0.8933\n",
      "iteration number: 219\t training loss: 1222.0484\tvalidation loss: 498.8451\t validation accuracy: 0.8933\n",
      "iteration number: 220\t training loss: 1230.9549\tvalidation loss: 501.0355\t validation accuracy: 0.8956\n",
      "iteration number: 221\t training loss: 1201.4927\tvalidation loss: 499.1120\t validation accuracy: 0.8933\n",
      "iteration number: 222\t training loss: 1208.7618\tvalidation loss: 487.7397\t validation accuracy: 0.8889\n",
      "iteration number: 223\t training loss: 1214.9850\tvalidation loss: 488.2068\t validation accuracy: 0.8956\n",
      "iteration number: 224\t training loss: 1216.5086\tvalidation loss: 459.6181\t validation accuracy: 0.8933\n",
      "iteration number: 225\t training loss: 1220.9454\tvalidation loss: 443.3890\t validation accuracy: 0.8889\n",
      "iteration number: 226\t training loss: 1222.6556\tvalidation loss: 412.5083\t validation accuracy: 0.8844\n",
      "iteration number: 227\t training loss: 1231.7301\tvalidation loss: 414.3721\t validation accuracy: 0.8778\n",
      "iteration number: 228\t training loss: 1230.7951\tvalidation loss: 414.0949\t validation accuracy: 0.8778\n",
      "iteration number: 229\t training loss: 1228.4598\tvalidation loss: 415.8434\t validation accuracy: 0.8756\n",
      "iteration number: 230\t training loss: 1222.9023\tvalidation loss: 444.3931\t validation accuracy: 0.8756\n",
      "iteration number: 231\t training loss: 1206.7043\tvalidation loss: 465.5842\t validation accuracy: 0.8800\n",
      "iteration number: 232\t training loss: 1215.8805\tvalidation loss: 474.6612\t validation accuracy: 0.8822\n",
      "iteration number: 233\t training loss: 1215.9706\tvalidation loss: 505.7424\t validation accuracy: 0.8778\n",
      "iteration number: 234\t training loss: 1227.6415\tvalidation loss: 527.7228\t validation accuracy: 0.8711\n",
      "iteration number: 235\t training loss: 1297.9609\tvalidation loss: 575.5940\t validation accuracy: 0.8622\n",
      "iteration number: 236\t training loss: 1351.9770\tvalidation loss: 607.7989\t validation accuracy: 0.8622\n",
      "iteration number: 237\t training loss: 1410.1001\tvalidation loss: 614.1720\t validation accuracy: 0.8578\n",
      "iteration number: 238\t training loss: 1412.7485\tvalidation loss: 615.3272\t validation accuracy: 0.8489\n",
      "iteration number: 239\t training loss: 1373.5347\tvalidation loss: 614.8033\t validation accuracy: 0.8444\n",
      "iteration number: 240\t training loss: 1354.4611\tvalidation loss: 601.7211\t validation accuracy: 0.8356\n",
      "iteration number: 241\t training loss: 1314.6118\tvalidation loss: 583.4679\t validation accuracy: 0.8333\n",
      "iteration number: 242\t training loss: 1241.3659\tvalidation loss: 547.1408\t validation accuracy: 0.8489\n",
      "iteration number: 243\t training loss: 1215.6983\tvalidation loss: 510.4503\t validation accuracy: 0.8533\n",
      "iteration number: 244\t training loss: 1187.2648\tvalidation loss: 469.9451\t validation accuracy: 0.8756\n",
      "iteration number: 245\t training loss: 1165.0374\tvalidation loss: 457.7133\t validation accuracy: 0.8844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 246\t training loss: 1132.2189\tvalidation loss: 422.9937\t validation accuracy: 0.9067\n",
      "iteration number: 247\t training loss: 1113.8214\tvalidation loss: 384.0816\t validation accuracy: 0.9133\n",
      "iteration number: 248\t training loss: 1106.1646\tvalidation loss: 377.3798\t validation accuracy: 0.9133\n",
      "iteration number: 249\t training loss: 1096.3408\tvalidation loss: 372.1435\t validation accuracy: 0.9156\n",
      "iteration number: 250\t training loss: 1085.6243\tvalidation loss: 367.2554\t validation accuracy: 0.9200\n",
      "iteration number: 251\t training loss: 1085.8953\tvalidation loss: 368.9412\t validation accuracy: 0.9267\n",
      "iteration number: 252\t training loss: 1091.3596\tvalidation loss: 373.8956\t validation accuracy: 0.9244\n",
      "iteration number: 253\t training loss: 1105.3826\tvalidation loss: 386.3163\t validation accuracy: 0.9156\n",
      "iteration number: 254\t training loss: 1120.2635\tvalidation loss: 419.7508\t validation accuracy: 0.9111\n",
      "iteration number: 255\t training loss: 1135.4107\tvalidation loss: 453.9884\t validation accuracy: 0.9044\n",
      "iteration number: 256\t training loss: 1150.6653\tvalidation loss: 475.6390\t validation accuracy: 0.8956\n",
      "iteration number: 257\t training loss: 1176.0143\tvalidation loss: 478.4379\t validation accuracy: 0.8911\n",
      "iteration number: 258\t training loss: 1191.1169\tvalidation loss: 484.4785\t validation accuracy: 0.8822\n",
      "iteration number: 259\t training loss: 1208.2226\tvalidation loss: 492.5339\t validation accuracy: 0.8711\n",
      "iteration number: 260\t training loss: 1225.1077\tvalidation loss: 492.0782\t validation accuracy: 0.8778\n",
      "iteration number: 261\t training loss: 1223.1921\tvalidation loss: 489.5896\t validation accuracy: 0.8844\n",
      "iteration number: 262\t training loss: 1208.9032\tvalidation loss: 487.7408\t validation accuracy: 0.8800\n",
      "iteration number: 263\t training loss: 1187.9111\tvalidation loss: 472.0440\t validation accuracy: 0.8778\n",
      "iteration number: 264\t training loss: 1193.2265\tvalidation loss: 474.0531\t validation accuracy: 0.8756\n",
      "iteration number: 265\t training loss: 1225.9101\tvalidation loss: 490.0747\t validation accuracy: 0.8756\n",
      "iteration number: 266\t training loss: 1223.8322\tvalidation loss: 489.8333\t validation accuracy: 0.8733\n",
      "iteration number: 267\t training loss: 1244.3877\tvalidation loss: 502.4828\t validation accuracy: 0.8733\n",
      "iteration number: 268\t training loss: 1257.1128\tvalidation loss: 517.9276\t validation accuracy: 0.8644\n",
      "iteration number: 269\t training loss: 1251.9090\tvalidation loss: 517.5883\t validation accuracy: 0.8578\n",
      "iteration number: 270\t training loss: 1246.3835\tvalidation loss: 516.8991\t validation accuracy: 0.8600\n",
      "iteration number: 271\t training loss: 1238.4415\tvalidation loss: 514.1620\t validation accuracy: 0.8622\n",
      "iteration number: 272\t training loss: 1226.9534\tvalidation loss: 510.2851\t validation accuracy: 0.8689\n",
      "iteration number: 273\t training loss: 1217.7477\tvalidation loss: 506.7710\t validation accuracy: 0.8711\n",
      "iteration number: 274\t training loss: 1201.7291\tvalidation loss: 499.7096\t validation accuracy: 0.8822\n",
      "iteration number: 275\t training loss: 1155.0569\tvalidation loss: 476.6892\t validation accuracy: 0.8911\n",
      "iteration number: 276\t training loss: 1094.5900\tvalidation loss: 440.2909\t validation accuracy: 0.9022\n",
      "iteration number: 277\t training loss: 1071.2104\tvalidation loss: 409.8519\t validation accuracy: 0.9111\n",
      "iteration number: 278\t training loss: 1076.6107\tvalidation loss: 390.4048\t validation accuracy: 0.9156\n",
      "iteration number: 279\t training loss: 1078.3349\tvalidation loss: 389.2994\t validation accuracy: 0.9156\n",
      "iteration number: 280\t training loss: 1083.0457\tvalidation loss: 389.9861\t validation accuracy: 0.9133\n",
      "iteration number: 281\t training loss: 1095.3262\tvalidation loss: 395.8446\t validation accuracy: 0.9067\n",
      "iteration number: 282\t training loss: 1109.4112\tvalidation loss: 403.0514\t validation accuracy: 0.8978\n",
      "iteration number: 283\t training loss: 1131.1760\tvalidation loss: 423.2133\t validation accuracy: 0.8911\n",
      "iteration number: 284\t training loss: 1153.3907\tvalidation loss: 441.8251\t validation accuracy: 0.8911\n",
      "iteration number: 285\t training loss: 1169.4859\tvalidation loss: 468.7685\t validation accuracy: 0.8867\n",
      "iteration number: 286\t training loss: 1159.9792\tvalidation loss: 471.2016\t validation accuracy: 0.8867\n",
      "iteration number: 287\t training loss: 1158.3205\tvalidation loss: 471.4748\t validation accuracy: 0.8889\n",
      "iteration number: 288\t training loss: 1173.2527\tvalidation loss: 483.9201\t validation accuracy: 0.8867\n",
      "iteration number: 289\t training loss: 1179.7938\tvalidation loss: 485.9930\t validation accuracy: 0.8844\n",
      "iteration number: 290\t training loss: 1207.2666\tvalidation loss: 488.2088\t validation accuracy: 0.8844\n",
      "iteration number: 291\t training loss: 1209.3486\tvalidation loss: 490.1088\t validation accuracy: 0.8822\n",
      "iteration number: 292\t training loss: 1205.1845\tvalidation loss: 500.1028\t validation accuracy: 0.8844\n",
      "iteration number: 293\t training loss: 1199.3141\tvalidation loss: 485.1153\t validation accuracy: 0.8867\n",
      "iteration number: 294\t training loss: 1199.3361\tvalidation loss: 483.7853\t validation accuracy: 0.8889\n",
      "iteration number: 295\t training loss: 1184.5150\tvalidation loss: 482.2617\t validation accuracy: 0.8844\n",
      "iteration number: 296\t training loss: 1168.6326\tvalidation loss: 469.1918\t validation accuracy: 0.8822\n",
      "iteration number: 297\t training loss: 1162.1013\tvalidation loss: 454.2067\t validation accuracy: 0.8822\n",
      "iteration number: 298\t training loss: 1136.4949\tvalidation loss: 438.9795\t validation accuracy: 0.8844\n",
      "iteration number: 299\t training loss: 1101.8629\tvalidation loss: 435.4430\t validation accuracy: 0.8933\n",
      "iteration number: 300\t training loss: 1088.6395\tvalidation loss: 431.6560\t validation accuracy: 0.8956\n",
      "iteration number: 301\t training loss: 1084.2209\tvalidation loss: 430.3057\t validation accuracy: 0.8978\n",
      "iteration number: 302\t training loss: 1081.6401\tvalidation loss: 429.5051\t validation accuracy: 0.8956\n",
      "iteration number: 303\t training loss: 1078.3371\tvalidation loss: 428.5015\t validation accuracy: 0.8978\n",
      "iteration number: 304\t training loss: 1075.3391\tvalidation loss: 426.9392\t validation accuracy: 0.8978\n",
      "iteration number: 305\t training loss: 1064.1227\tvalidation loss: 422.5189\t validation accuracy: 0.9089\n",
      "iteration number: 306\t training loss: 1062.9278\tvalidation loss: 435.3250\t validation accuracy: 0.9089\n",
      "iteration number: 307\t training loss: 1061.2586\tvalidation loss: 434.9520\t validation accuracy: 0.9200\n",
      "iteration number: 308\t training loss: 1063.3101\tvalidation loss: 435.7124\t validation accuracy: 0.9178\n",
      "iteration number: 309\t training loss: 1069.3637\tvalidation loss: 437.3843\t validation accuracy: 0.9200\n",
      "iteration number: 310\t training loss: 1090.1011\tvalidation loss: 441.9694\t validation accuracy: 0.9200\n",
      "iteration number: 311\t training loss: 1088.5432\tvalidation loss: 460.7770\t validation accuracy: 0.9178\n",
      "iteration number: 312\t training loss: 1123.9817\tvalidation loss: 477.3450\t validation accuracy: 0.9156\n",
      "iteration number: 313\t training loss: 1136.7670\tvalidation loss: 469.8234\t validation accuracy: 0.9022\n",
      "iteration number: 314\t training loss: 1165.0862\tvalidation loss: 474.3124\t validation accuracy: 0.8956\n",
      "iteration number: 315\t training loss: 1191.2995\tvalidation loss: 478.4250\t validation accuracy: 0.8889\n",
      "iteration number: 316\t training loss: 1204.1228\tvalidation loss: 482.8135\t validation accuracy: 0.8800\n",
      "iteration number: 317\t training loss: 1221.2237\tvalidation loss: 485.0308\t validation accuracy: 0.8756\n",
      "iteration number: 318\t training loss: 1222.3568\tvalidation loss: 498.3030\t validation accuracy: 0.8778\n",
      "iteration number: 319\t training loss: 1217.3415\tvalidation loss: 483.3689\t validation accuracy: 0.8844\n",
      "iteration number: 320\t training loss: 1190.1022\tvalidation loss: 481.3359\t validation accuracy: 0.8867\n",
      "iteration number: 321\t training loss: 1181.6817\tvalidation loss: 480.9195\t validation accuracy: 0.8911\n",
      "iteration number: 322\t training loss: 1163.3672\tvalidation loss: 478.2205\t validation accuracy: 0.8911\n",
      "iteration number: 323\t training loss: 1159.8974\tvalidation loss: 477.3384\t validation accuracy: 0.8911\n",
      "iteration number: 324\t training loss: 1158.1903\tvalidation loss: 477.1850\t validation accuracy: 0.8889\n",
      "iteration number: 325\t training loss: 1153.7554\tvalidation loss: 462.0255\t validation accuracy: 0.8911\n",
      "iteration number: 326\t training loss: 1122.4215\tvalidation loss: 445.7714\t validation accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 327\t training loss: 1115.1908\tvalidation loss: 453.0024\t validation accuracy: 0.9000\n",
      "iteration number: 328\t training loss: 1113.3147\tvalidation loss: 424.9174\t validation accuracy: 0.9000\n",
      "iteration number: 329\t training loss: 1110.5065\tvalidation loss: 408.2215\t validation accuracy: 0.9022\n",
      "iteration number: 330\t training loss: 1102.8181\tvalidation loss: 404.2363\t validation accuracy: 0.9022\n",
      "iteration number: 331\t training loss: 1096.9002\tvalidation loss: 389.1655\t validation accuracy: 0.9044\n",
      "iteration number: 332\t training loss: 1091.7411\tvalidation loss: 392.8176\t validation accuracy: 0.9000\n",
      "iteration number: 333\t training loss: 1090.9296\tvalidation loss: 417.2437\t validation accuracy: 0.8911\n",
      "iteration number: 334\t training loss: 1091.6241\tvalidation loss: 431.7128\t validation accuracy: 0.8911\n",
      "iteration number: 335\t training loss: 1097.5652\tvalidation loss: 448.7459\t validation accuracy: 0.8822\n",
      "iteration number: 336\t training loss: 1129.6968\tvalidation loss: 470.7596\t validation accuracy: 0.8711\n",
      "iteration number: 337\t training loss: 1130.5441\tvalidation loss: 483.7810\t validation accuracy: 0.8800\n",
      "iteration number: 338\t training loss: 1128.5951\tvalidation loss: 484.1589\t validation accuracy: 0.8778\n",
      "iteration number: 339\t training loss: 1118.7434\tvalidation loss: 479.5504\t validation accuracy: 0.8844\n",
      "iteration number: 340\t training loss: 1108.4470\tvalidation loss: 460.8442\t validation accuracy: 0.8889\n",
      "iteration number: 341\t training loss: 1066.2627\tvalidation loss: 444.0052\t validation accuracy: 0.8978\n",
      "iteration number: 342\t training loss: 1054.6964\tvalidation loss: 438.6716\t validation accuracy: 0.8978\n",
      "iteration number: 343\t training loss: 1054.6499\tvalidation loss: 405.4661\t validation accuracy: 0.8978\n",
      "iteration number: 344\t training loss: 1046.5384\tvalidation loss: 400.2798\t validation accuracy: 0.9067\n",
      "iteration number: 345\t training loss: 1041.1987\tvalidation loss: 384.4895\t validation accuracy: 0.9111\n",
      "iteration number: 346\t training loss: 1037.3467\tvalidation loss: 368.6062\t validation accuracy: 0.9111\n",
      "iteration number: 347\t training loss: 1032.7387\tvalidation loss: 363.8232\t validation accuracy: 0.9156\n",
      "iteration number: 348\t training loss: 1044.1347\tvalidation loss: 361.8918\t validation accuracy: 0.9178\n",
      "iteration number: 349\t training loss: 1048.0052\tvalidation loss: 365.3344\t validation accuracy: 0.9133\n",
      "iteration number: 350\t training loss: 1048.9143\tvalidation loss: 368.1007\t validation accuracy: 0.9133\n",
      "iteration number: 351\t training loss: 1039.5300\tvalidation loss: 371.6032\t validation accuracy: 0.9133\n",
      "iteration number: 352\t training loss: 1033.4940\tvalidation loss: 397.3612\t validation accuracy: 0.9133\n",
      "iteration number: 353\t training loss: 1033.8436\tvalidation loss: 400.2427\t validation accuracy: 0.9089\n",
      "iteration number: 354\t training loss: 1030.6924\tvalidation loss: 399.8874\t validation accuracy: 0.9133\n",
      "iteration number: 355\t training loss: 1032.4491\tvalidation loss: 414.5124\t validation accuracy: 0.9067\n",
      "iteration number: 356\t training loss: 1033.1691\tvalidation loss: 416.7394\t validation accuracy: 0.9067\n",
      "iteration number: 357\t training loss: 1040.9916\tvalidation loss: 433.2732\t validation accuracy: 0.9000\n",
      "iteration number: 358\t training loss: 1082.9110\tvalidation loss: 449.0545\t validation accuracy: 0.8933\n",
      "iteration number: 359\t training loss: 1088.9726\tvalidation loss: 456.8355\t validation accuracy: 0.8889\n",
      "iteration number: 360\t training loss: 1092.8954\tvalidation loss: 483.8778\t validation accuracy: 0.8867\n",
      "iteration number: 361\t training loss: 1091.7337\tvalidation loss: 483.5410\t validation accuracy: 0.8889\n",
      "iteration number: 362\t training loss: 1084.9252\tvalidation loss: 480.3200\t validation accuracy: 0.8956\n",
      "iteration number: 363\t training loss: 1076.7217\tvalidation loss: 451.1295\t validation accuracy: 0.8933\n",
      "iteration number: 364\t training loss: 1069.9684\tvalidation loss: 443.5097\t validation accuracy: 0.8933\n",
      "iteration number: 365\t training loss: 1040.1361\tvalidation loss: 429.0448\t validation accuracy: 0.8956\n",
      "iteration number: 366\t training loss: 1023.3468\tvalidation loss: 425.4144\t validation accuracy: 0.8978\n",
      "iteration number: 367\t training loss: 1017.8178\tvalidation loss: 410.2641\t validation accuracy: 0.9000\n",
      "iteration number: 368\t training loss: 1016.1089\tvalidation loss: 406.7631\t validation accuracy: 0.9000\n",
      "iteration number: 369\t training loss: 1012.9520\tvalidation loss: 364.8715\t validation accuracy: 0.9044\n",
      "iteration number: 370\t training loss: 1010.2139\tvalidation loss: 361.4018\t validation accuracy: 0.9089\n",
      "iteration number: 371\t training loss: 1005.8576\tvalidation loss: 358.7471\t validation accuracy: 0.9089\n",
      "iteration number: 372\t training loss: 1003.5457\tvalidation loss: 357.0799\t validation accuracy: 0.9133\n",
      "iteration number: 373\t training loss: 1003.8129\tvalidation loss: 370.3085\t validation accuracy: 0.9133\n",
      "iteration number: 374\t training loss: 1004.9415\tvalidation loss: 371.0344\t validation accuracy: 0.9133\n",
      "iteration number: 375\t training loss: 1003.7592\tvalidation loss: 370.9390\t validation accuracy: 0.9222\n",
      "iteration number: 376\t training loss: 1006.7908\tvalidation loss: 373.7593\t validation accuracy: 0.9200\n",
      "iteration number: 377\t training loss: 1004.4020\tvalidation loss: 372.6597\t validation accuracy: 0.9222\n",
      "iteration number: 378\t training loss: 1005.2693\tvalidation loss: 372.7738\t validation accuracy: 0.9222\n",
      "iteration number: 379\t training loss: 1016.7710\tvalidation loss: 372.5520\t validation accuracy: 0.9222\n",
      "iteration number: 380\t training loss: 1018.4327\tvalidation loss: 372.6613\t validation accuracy: 0.9222\n",
      "iteration number: 381\t training loss: 1028.7095\tvalidation loss: 372.1129\t validation accuracy: 0.9244\n",
      "iteration number: 382\t training loss: 1031.7362\tvalidation loss: 374.2050\t validation accuracy: 0.9222\n",
      "iteration number: 383\t training loss: 1042.3959\tvalidation loss: 406.2922\t validation accuracy: 0.9222\n",
      "iteration number: 384\t training loss: 1067.5841\tvalidation loss: 424.0603\t validation accuracy: 0.9111\n",
      "iteration number: 385\t training loss: 1093.4821\tvalidation loss: 434.7909\t validation accuracy: 0.9022\n",
      "iteration number: 386\t training loss: 1103.4793\tvalidation loss: 449.4454\t validation accuracy: 0.8911\n",
      "iteration number: 387\t training loss: 1109.4518\tvalidation loss: 452.0337\t validation accuracy: 0.8822\n",
      "iteration number: 388\t training loss: 1117.6778\tvalidation loss: 455.4091\t validation accuracy: 0.8800\n",
      "iteration number: 389\t training loss: 1124.3658\tvalidation loss: 457.4401\t validation accuracy: 0.8756\n",
      "iteration number: 390\t training loss: 1125.0938\tvalidation loss: 443.3225\t validation accuracy: 0.8733\n",
      "iteration number: 391\t training loss: 1108.7171\tvalidation loss: 440.2068\t validation accuracy: 0.8756\n",
      "iteration number: 392\t training loss: 1089.6895\tvalidation loss: 410.3483\t validation accuracy: 0.8778\n",
      "iteration number: 393\t training loss: 1072.8933\tvalidation loss: 390.2742\t validation accuracy: 0.8867\n",
      "iteration number: 394\t training loss: 1058.7859\tvalidation loss: 382.1434\t validation accuracy: 0.8956\n",
      "iteration number: 395\t training loss: 1049.1056\tvalidation loss: 378.1458\t validation accuracy: 0.9067\n",
      "iteration number: 396\t training loss: 1042.4414\tvalidation loss: 376.8565\t validation accuracy: 0.9111\n",
      "iteration number: 397\t training loss: 1039.4788\tvalidation loss: 388.6163\t validation accuracy: 0.9156\n",
      "iteration number: 398\t training loss: 1064.9045\tvalidation loss: 390.4180\t validation accuracy: 0.9067\n",
      "iteration number: 399\t training loss: 1064.3799\tvalidation loss: 394.0520\t validation accuracy: 0.9044\n",
      "iteration number: 400\t training loss: 1060.0518\tvalidation loss: 417.2616\t validation accuracy: 0.9111\n",
      "iteration number: 401\t training loss: 1057.1377\tvalidation loss: 416.4164\t validation accuracy: 0.9156\n",
      "iteration number: 402\t training loss: 1052.0546\tvalidation loss: 393.8509\t validation accuracy: 0.9178\n",
      "iteration number: 403\t training loss: 1047.1720\tvalidation loss: 383.9789\t validation accuracy: 0.9178\n",
      "iteration number: 404\t training loss: 1043.9316\tvalidation loss: 380.7015\t validation accuracy: 0.9156\n",
      "iteration number: 405\t training loss: 1039.6955\tvalidation loss: 376.4393\t validation accuracy: 0.9200\n",
      "iteration number: 406\t training loss: 1011.9060\tvalidation loss: 373.7400\t validation accuracy: 0.9222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 407\t training loss: 1009.1758\tvalidation loss: 360.2262\t validation accuracy: 0.9244\n",
      "iteration number: 408\t training loss: 997.3213\tvalidation loss: 358.3453\t validation accuracy: 0.9244\n",
      "iteration number: 409\t training loss: 1001.8628\tvalidation loss: 359.5871\t validation accuracy: 0.9156\n",
      "iteration number: 410\t training loss: 996.3487\tvalidation loss: 362.4694\t validation accuracy: 0.9133\n",
      "iteration number: 411\t training loss: 1002.5444\tvalidation loss: 365.4333\t validation accuracy: 0.9089\n",
      "iteration number: 412\t training loss: 1006.2691\tvalidation loss: 367.3561\t validation accuracy: 0.9067\n",
      "iteration number: 413\t training loss: 1023.8775\tvalidation loss: 370.2662\t validation accuracy: 0.9000\n",
      "iteration number: 414\t training loss: 1026.2020\tvalidation loss: 372.1318\t validation accuracy: 0.8978\n",
      "iteration number: 415\t training loss: 1036.8718\tvalidation loss: 372.7589\t validation accuracy: 0.8978\n",
      "iteration number: 416\t training loss: 1017.2492\tvalidation loss: 369.4685\t validation accuracy: 0.9089\n",
      "iteration number: 417\t training loss: 1010.7578\tvalidation loss: 367.1246\t validation accuracy: 0.9178\n",
      "iteration number: 418\t training loss: 1007.4781\tvalidation loss: 366.1993\t validation accuracy: 0.9178\n",
      "iteration number: 419\t training loss: 1018.6782\tvalidation loss: 366.6307\t validation accuracy: 0.9178\n",
      "iteration number: 420\t training loss: 1016.5574\tvalidation loss: 366.1971\t validation accuracy: 0.9178\n",
      "iteration number: 421\t training loss: 1018.1640\tvalidation loss: 367.7400\t validation accuracy: 0.9178\n",
      "iteration number: 422\t training loss: 1016.8556\tvalidation loss: 367.4864\t validation accuracy: 0.9178\n",
      "iteration number: 423\t training loss: 1019.5251\tvalidation loss: 369.9568\t validation accuracy: 0.9200\n",
      "iteration number: 424\t training loss: 1036.1216\tvalidation loss: 386.0407\t validation accuracy: 0.9178\n",
      "iteration number: 425\t training loss: 1037.4256\tvalidation loss: 399.3152\t validation accuracy: 0.9178\n",
      "iteration number: 426\t training loss: 1021.5591\tvalidation loss: 383.3056\t validation accuracy: 0.9200\n",
      "iteration number: 427\t training loss: 1017.2768\tvalidation loss: 366.9751\t validation accuracy: 0.9244\n",
      "iteration number: 428\t training loss: 1016.1943\tvalidation loss: 365.0664\t validation accuracy: 0.9267\n",
      "iteration number: 429\t training loss: 1016.4747\tvalidation loss: 365.1741\t validation accuracy: 0.9244\n",
      "iteration number: 430\t training loss: 1018.9307\tvalidation loss: 366.9091\t validation accuracy: 0.9222\n",
      "iteration number: 431\t training loss: 1023.6970\tvalidation loss: 384.1312\t validation accuracy: 0.9156\n",
      "iteration number: 432\t training loss: 1048.5141\tvalidation loss: 401.9094\t validation accuracy: 0.8889\n",
      "iteration number: 433\t training loss: 1069.9467\tvalidation loss: 411.5278\t validation accuracy: 0.8822\n",
      "iteration number: 434\t training loss: 1073.9667\tvalidation loss: 425.3365\t validation accuracy: 0.8800\n",
      "iteration number: 435\t training loss: 1071.8439\tvalidation loss: 425.3329\t validation accuracy: 0.8800\n",
      "iteration number: 436\t training loss: 1066.9347\tvalidation loss: 423.0157\t validation accuracy: 0.8800\n",
      "iteration number: 437\t training loss: 1063.3814\tvalidation loss: 421.2944\t validation accuracy: 0.8822\n",
      "iteration number: 438\t training loss: 1058.1100\tvalidation loss: 406.5563\t validation accuracy: 0.8911\n",
      "iteration number: 439\t training loss: 1057.0699\tvalidation loss: 405.1535\t validation accuracy: 0.8911\n",
      "iteration number: 440\t training loss: 1053.6037\tvalidation loss: 401.5538\t validation accuracy: 0.8956\n",
      "iteration number: 441\t training loss: 1036.6209\tvalidation loss: 399.0811\t validation accuracy: 0.9044\n",
      "iteration number: 442\t training loss: 1016.2907\tvalidation loss: 382.1410\t validation accuracy: 0.9178\n",
      "iteration number: 443\t training loss: 1008.6054\tvalidation loss: 364.8995\t validation accuracy: 0.9200\n",
      "iteration number: 444\t training loss: 1003.8550\tvalidation loss: 361.6299\t validation accuracy: 0.9222\n",
      "iteration number: 445\t training loss: 997.5786\tvalidation loss: 358.1196\t validation accuracy: 0.9222\n",
      "iteration number: 446\t training loss: 991.6760\tvalidation loss: 356.0499\t validation accuracy: 0.9289\n",
      "iteration number: 447\t training loss: 990.3678\tvalidation loss: 358.0421\t validation accuracy: 0.9333\n",
      "iteration number: 448\t training loss: 1005.8654\tvalidation loss: 372.4052\t validation accuracy: 0.9267\n",
      "iteration number: 449\t training loss: 1023.2555\tvalidation loss: 388.2152\t validation accuracy: 0.9200\n",
      "iteration number: 450\t training loss: 1024.4390\tvalidation loss: 389.2507\t validation accuracy: 0.9200\n",
      "iteration number: 451\t training loss: 1025.9760\tvalidation loss: 391.1064\t validation accuracy: 0.9178\n",
      "iteration number: 452\t training loss: 1026.4206\tvalidation loss: 390.8119\t validation accuracy: 0.9200\n",
      "iteration number: 453\t training loss: 1030.1949\tvalidation loss: 393.4462\t validation accuracy: 0.9156\n",
      "iteration number: 454\t training loss: 1034.8746\tvalidation loss: 395.9983\t validation accuracy: 0.9044\n",
      "iteration number: 455\t training loss: 1036.8200\tvalidation loss: 396.7064\t validation accuracy: 0.9067\n",
      "iteration number: 456\t training loss: 1038.0835\tvalidation loss: 395.2122\t validation accuracy: 0.9067\n",
      "iteration number: 457\t training loss: 1024.3709\tvalidation loss: 393.5963\t validation accuracy: 0.9044\n",
      "iteration number: 458\t training loss: 1009.4441\tvalidation loss: 379.9151\t validation accuracy: 0.9022\n",
      "iteration number: 459\t training loss: 1005.7823\tvalidation loss: 362.6179\t validation accuracy: 0.9000\n",
      "iteration number: 460\t training loss: 993.7607\tvalidation loss: 362.1666\t validation accuracy: 0.9000\n",
      "iteration number: 461\t training loss: 993.9473\tvalidation loss: 361.9026\t validation accuracy: 0.8978\n",
      "iteration number: 462\t training loss: 991.9220\tvalidation loss: 361.3784\t validation accuracy: 0.9000\n",
      "iteration number: 463\t training loss: 989.5742\tvalidation loss: 360.7516\t validation accuracy: 0.9022\n",
      "iteration number: 464\t training loss: 988.6629\tvalidation loss: 361.2179\t validation accuracy: 0.9044\n",
      "iteration number: 465\t training loss: 987.3226\tvalidation loss: 361.9275\t validation accuracy: 0.9044\n",
      "iteration number: 466\t training loss: 986.1246\tvalidation loss: 363.4546\t validation accuracy: 0.9067\n",
      "iteration number: 467\t training loss: 995.9547\tvalidation loss: 376.6489\t validation accuracy: 0.9111\n",
      "iteration number: 468\t training loss: 998.4539\tvalidation loss: 381.6046\t validation accuracy: 0.9111\n",
      "iteration number: 469\t training loss: 1018.0523\tvalidation loss: 412.0527\t validation accuracy: 0.9044\n",
      "iteration number: 470\t training loss: 1034.5198\tvalidation loss: 429.3315\t validation accuracy: 0.8956\n",
      "iteration number: 471\t training loss: 1050.2893\tvalidation loss: 434.5980\t validation accuracy: 0.8933\n",
      "iteration number: 472\t training loss: 1046.9093\tvalidation loss: 432.5275\t validation accuracy: 0.8978\n",
      "iteration number: 473\t training loss: 1030.7331\tvalidation loss: 429.1486\t validation accuracy: 0.8911\n",
      "iteration number: 474\t training loss: 1029.5238\tvalidation loss: 428.3953\t validation accuracy: 0.8933\n",
      "iteration number: 475\t training loss: 1021.5636\tvalidation loss: 424.5109\t validation accuracy: 0.8933\n",
      "iteration number: 476\t training loss: 1014.7365\tvalidation loss: 420.7097\t validation accuracy: 0.9022\n",
      "iteration number: 477\t training loss: 995.0286\tvalidation loss: 403.7163\t validation accuracy: 0.9089\n",
      "iteration number: 478\t training loss: 979.5827\tvalidation loss: 401.5433\t validation accuracy: 0.9111\n",
      "iteration number: 479\t training loss: 971.4653\tvalidation loss: 372.3636\t validation accuracy: 0.9178\n",
      "iteration number: 480\t training loss: 949.3175\tvalidation loss: 364.0388\t validation accuracy: 0.9200\n",
      "iteration number: 481\t training loss: 931.7696\tvalidation loss: 346.7200\t validation accuracy: 0.9178\n",
      "iteration number: 482\t training loss: 927.5608\tvalidation loss: 342.7168\t validation accuracy: 0.9244\n",
      "iteration number: 483\t training loss: 928.3134\tvalidation loss: 342.0169\t validation accuracy: 0.9222\n",
      "iteration number: 484\t training loss: 934.1725\tvalidation loss: 344.3934\t validation accuracy: 0.9178\n",
      "iteration number: 485\t training loss: 944.9227\tvalidation loss: 349.3895\t validation accuracy: 0.9133\n",
      "iteration number: 486\t training loss: 955.1851\tvalidation loss: 354.6461\t validation accuracy: 0.9067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 487\t training loss: 966.1088\tvalidation loss: 361.3826\t validation accuracy: 0.9044\n",
      "iteration number: 488\t training loss: 985.1468\tvalidation loss: 377.3377\t validation accuracy: 0.9000\n",
      "iteration number: 489\t training loss: 999.1915\tvalidation loss: 378.9039\t validation accuracy: 0.9022\n",
      "iteration number: 490\t training loss: 996.4425\tvalidation loss: 378.9026\t validation accuracy: 0.9111\n",
      "iteration number: 491\t training loss: 997.6836\tvalidation loss: 393.2040\t validation accuracy: 0.9133\n",
      "iteration number: 492\t training loss: 996.1496\tvalidation loss: 381.4026\t validation accuracy: 0.9133\n",
      "iteration number: 493\t training loss: 986.7179\tvalidation loss: 381.1464\t validation accuracy: 0.9178\n",
      "iteration number: 494\t training loss: 988.9680\tvalidation loss: 381.8588\t validation accuracy: 0.9133\n",
      "iteration number: 495\t training loss: 994.4665\tvalidation loss: 383.2149\t validation accuracy: 0.9089\n",
      "iteration number: 496\t training loss: 999.9715\tvalidation loss: 385.3616\t validation accuracy: 0.8933\n",
      "iteration number: 497\t training loss: 1002.5539\tvalidation loss: 386.5240\t validation accuracy: 0.8911\n",
      "iteration number: 498\t training loss: 1019.1337\tvalidation loss: 379.7790\t validation accuracy: 0.8822\n",
      "iteration number: 499\t training loss: 1020.2427\tvalidation loss: 391.3842\t validation accuracy: 0.8711\n",
      "iteration number: 500\t training loss: 1025.2545\tvalidation loss: 407.0981\t validation accuracy: 0.8644\n",
      "iteration number: 501\t training loss: 1056.2073\tvalidation loss: 424.4959\t validation accuracy: 0.8622\n",
      "iteration number: 502\t training loss: 1059.5233\tvalidation loss: 439.3376\t validation accuracy: 0.8489\n",
      "iteration number: 503\t training loss: 1054.6095\tvalidation loss: 437.5998\t validation accuracy: 0.8489\n",
      "iteration number: 504\t training loss: 1040.0841\tvalidation loss: 431.6344\t validation accuracy: 0.8556\n",
      "iteration number: 505\t training loss: 1015.3274\tvalidation loss: 425.8620\t validation accuracy: 0.8644\n",
      "iteration number: 506\t training loss: 991.2744\tvalidation loss: 409.5106\t validation accuracy: 0.8733\n",
      "iteration number: 507\t training loss: 979.1987\tvalidation loss: 404.0258\t validation accuracy: 0.8778\n",
      "iteration number: 508\t training loss: 967.5177\tvalidation loss: 386.5468\t validation accuracy: 0.8844\n",
      "iteration number: 509\t training loss: 946.6005\tvalidation loss: 368.4420\t validation accuracy: 0.8889\n",
      "iteration number: 510\t training loss: 934.2360\tvalidation loss: 362.0958\t validation accuracy: 0.8978\n",
      "iteration number: 511\t training loss: 915.8754\tvalidation loss: 359.5476\t validation accuracy: 0.9022\n",
      "iteration number: 512\t training loss: 911.8669\tvalidation loss: 358.3120\t validation accuracy: 0.9067\n",
      "iteration number: 513\t training loss: 914.5344\tvalidation loss: 360.1032\t validation accuracy: 0.9111\n",
      "iteration number: 514\t training loss: 915.9335\tvalidation loss: 360.9930\t validation accuracy: 0.9089\n",
      "iteration number: 515\t training loss: 920.4685\tvalidation loss: 363.4146\t validation accuracy: 0.9067\n",
      "iteration number: 516\t training loss: 924.3677\tvalidation loss: 352.4533\t validation accuracy: 0.9044\n",
      "iteration number: 517\t training loss: 927.4208\tvalidation loss: 365.6051\t validation accuracy: 0.9089\n",
      "iteration number: 518\t training loss: 927.8015\tvalidation loss: 365.1905\t validation accuracy: 0.9089\n",
      "iteration number: 519\t training loss: 933.7651\tvalidation loss: 367.7344\t validation accuracy: 0.9000\n",
      "iteration number: 520\t training loss: 935.1016\tvalidation loss: 355.4747\t validation accuracy: 0.8978\n",
      "iteration number: 521\t training loss: 937.6994\tvalidation loss: 356.3787\t validation accuracy: 0.9044\n",
      "iteration number: 522\t training loss: 941.6062\tvalidation loss: 370.9117\t validation accuracy: 0.8978\n",
      "iteration number: 523\t training loss: 942.0647\tvalidation loss: 371.4173\t validation accuracy: 0.8956\n",
      "iteration number: 524\t training loss: 944.4848\tvalidation loss: 372.3011\t validation accuracy: 0.8933\n",
      "iteration number: 525\t training loss: 942.5464\tvalidation loss: 371.2795\t validation accuracy: 0.8978\n",
      "iteration number: 526\t training loss: 940.9831\tvalidation loss: 371.1517\t validation accuracy: 0.9067\n",
      "iteration number: 527\t training loss: 941.4350\tvalidation loss: 371.4879\t validation accuracy: 0.9022\n",
      "iteration number: 528\t training loss: 940.8052\tvalidation loss: 370.9323\t validation accuracy: 0.9022\n",
      "iteration number: 529\t training loss: 940.2117\tvalidation loss: 370.5636\t validation accuracy: 0.9044\n",
      "iteration number: 530\t training loss: 938.9868\tvalidation loss: 369.7500\t validation accuracy: 0.9067\n",
      "iteration number: 531\t training loss: 935.0056\tvalidation loss: 367.6825\t validation accuracy: 0.9089\n",
      "iteration number: 532\t training loss: 933.0186\tvalidation loss: 366.9761\t validation accuracy: 0.9067\n",
      "iteration number: 533\t training loss: 935.8708\tvalidation loss: 368.5425\t validation accuracy: 0.9044\n",
      "iteration number: 534\t training loss: 942.5676\tvalidation loss: 372.8241\t validation accuracy: 0.8933\n",
      "iteration number: 535\t training loss: 964.2267\tvalidation loss: 390.6353\t validation accuracy: 0.8778\n",
      "iteration number: 536\t training loss: 973.4972\tvalidation loss: 408.9974\t validation accuracy: 0.8733\n",
      "iteration number: 537\t training loss: 978.3266\tvalidation loss: 411.3183\t validation accuracy: 0.8667\n",
      "iteration number: 538\t training loss: 978.6857\tvalidation loss: 411.0506\t validation accuracy: 0.8667\n",
      "iteration number: 539\t training loss: 967.6946\tvalidation loss: 407.6259\t validation accuracy: 0.8667\n",
      "iteration number: 540\t training loss: 960.6468\tvalidation loss: 404.5585\t validation accuracy: 0.8733\n",
      "iteration number: 541\t training loss: 955.0079\tvalidation loss: 389.9293\t validation accuracy: 0.8800\n",
      "iteration number: 542\t training loss: 951.0433\tvalidation loss: 387.4684\t validation accuracy: 0.8889\n",
      "iteration number: 543\t training loss: 944.0859\tvalidation loss: 383.5864\t validation accuracy: 0.8956\n",
      "iteration number: 544\t training loss: 937.4898\tvalidation loss: 379.7906\t validation accuracy: 0.9000\n",
      "iteration number: 545\t training loss: 929.3816\tvalidation loss: 362.6163\t validation accuracy: 0.9089\n",
      "iteration number: 546\t training loss: 913.1440\tvalidation loss: 359.9518\t validation accuracy: 0.9111\n",
      "iteration number: 547\t training loss: 908.1646\tvalidation loss: 357.6881\t validation accuracy: 0.9111\n",
      "iteration number: 548\t training loss: 904.8006\tvalidation loss: 356.0174\t validation accuracy: 0.9111\n",
      "iteration number: 549\t training loss: 904.3380\tvalidation loss: 355.7615\t validation accuracy: 0.9133\n",
      "iteration number: 550\t training loss: 908.2672\tvalidation loss: 357.8251\t validation accuracy: 0.9067\n",
      "iteration number: 551\t training loss: 927.1392\tvalidation loss: 361.1281\t validation accuracy: 0.8956\n",
      "iteration number: 552\t training loss: 931.8210\tvalidation loss: 363.4984\t validation accuracy: 0.8933\n",
      "iteration number: 553\t training loss: 935.0678\tvalidation loss: 365.2620\t validation accuracy: 0.8911\n",
      "iteration number: 554\t training loss: 936.8205\tvalidation loss: 366.6714\t validation accuracy: 0.8844\n",
      "iteration number: 555\t training loss: 937.0325\tvalidation loss: 365.7716\t validation accuracy: 0.8778\n",
      "iteration number: 556\t training loss: 919.1440\tvalidation loss: 362.2505\t validation accuracy: 0.8800\n",
      "iteration number: 557\t training loss: 916.9704\tvalidation loss: 346.9493\t validation accuracy: 0.8844\n",
      "iteration number: 558\t training loss: 913.5738\tvalidation loss: 344.3274\t validation accuracy: 0.8911\n",
      "iteration number: 559\t training loss: 914.5616\tvalidation loss: 344.0472\t validation accuracy: 0.8822\n",
      "iteration number: 560\t training loss: 914.6501\tvalidation loss: 344.1906\t validation accuracy: 0.8822\n",
      "iteration number: 561\t training loss: 914.1346\tvalidation loss: 344.2047\t validation accuracy: 0.8844\n",
      "iteration number: 562\t training loss: 913.4003\tvalidation loss: 344.3769\t validation accuracy: 0.8889\n",
      "iteration number: 563\t training loss: 908.1621\tvalidation loss: 342.1298\t validation accuracy: 0.8933\n",
      "iteration number: 564\t training loss: 903.9373\tvalidation loss: 340.9515\t validation accuracy: 0.8933\n",
      "iteration number: 565\t training loss: 900.6579\tvalidation loss: 340.4740\t validation accuracy: 0.8933\n",
      "iteration number: 566\t training loss: 897.3238\tvalidation loss: 340.3910\t validation accuracy: 0.8956\n",
      "iteration number: 567\t training loss: 892.9292\tvalidation loss: 339.9699\t validation accuracy: 0.9022\n",
      "iteration number: 568\t training loss: 886.3393\tvalidation loss: 337.1624\t validation accuracy: 0.9044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 569\t training loss: 880.7508\tvalidation loss: 334.7985\t validation accuracy: 0.9178\n",
      "iteration number: 570\t training loss: 874.9758\tvalidation loss: 330.1956\t validation accuracy: 0.9244\n",
      "iteration number: 571\t training loss: 876.0306\tvalidation loss: 331.1479\t validation accuracy: 0.9267\n",
      "iteration number: 572\t training loss: 876.8979\tvalidation loss: 333.9076\t validation accuracy: 0.9267\n",
      "iteration number: 573\t training loss: 878.5072\tvalidation loss: 344.5259\t validation accuracy: 0.9267\n",
      "iteration number: 574\t training loss: 880.2997\tvalidation loss: 345.4718\t validation accuracy: 0.9267\n",
      "iteration number: 575\t training loss: 886.4888\tvalidation loss: 348.5566\t validation accuracy: 0.9267\n",
      "iteration number: 576\t training loss: 896.3162\tvalidation loss: 353.4916\t validation accuracy: 0.9244\n",
      "iteration number: 577\t training loss: 910.2434\tvalidation loss: 358.8624\t validation accuracy: 0.9044\n",
      "iteration number: 578\t training loss: 932.8153\tvalidation loss: 364.8716\t validation accuracy: 0.8933\n",
      "iteration number: 579\t training loss: 940.4927\tvalidation loss: 369.1639\t validation accuracy: 0.8911\n",
      "iteration number: 580\t training loss: 939.3322\tvalidation loss: 367.7751\t validation accuracy: 0.8933\n",
      "iteration number: 581\t training loss: 917.5815\tvalidation loss: 362.2522\t validation accuracy: 0.9000\n",
      "iteration number: 582\t training loss: 907.3201\tvalidation loss: 357.1570\t validation accuracy: 0.9067\n",
      "iteration number: 583\t training loss: 902.9422\tvalidation loss: 341.2474\t validation accuracy: 0.9156\n",
      "iteration number: 584\t training loss: 897.3460\tvalidation loss: 336.6820\t validation accuracy: 0.9156\n",
      "iteration number: 585\t training loss: 893.1926\tvalidation loss: 333.7604\t validation accuracy: 0.9222\n",
      "iteration number: 586\t training loss: 892.3162\tvalidation loss: 333.4391\t validation accuracy: 0.9200\n",
      "iteration number: 587\t training loss: 883.7457\tvalidation loss: 336.8737\t validation accuracy: 0.9178\n",
      "iteration number: 588\t training loss: 887.1818\tvalidation loss: 352.6818\t validation accuracy: 0.9156\n",
      "iteration number: 589\t training loss: 901.6564\tvalidation loss: 355.1345\t validation accuracy: 0.9000\n",
      "iteration number: 590\t training loss: 903.3052\tvalidation loss: 357.9483\t validation accuracy: 0.8956\n",
      "iteration number: 591\t training loss: 915.1222\tvalidation loss: 360.6009\t validation accuracy: 0.8956\n",
      "iteration number: 592\t training loss: 911.9569\tvalidation loss: 373.6381\t validation accuracy: 0.8933\n",
      "iteration number: 593\t training loss: 902.3920\tvalidation loss: 356.4193\t validation accuracy: 0.8956\n",
      "iteration number: 594\t training loss: 878.5018\tvalidation loss: 348.8309\t validation accuracy: 0.9000\n",
      "iteration number: 595\t training loss: 853.4537\tvalidation loss: 330.2405\t validation accuracy: 0.9111\n",
      "iteration number: 596\t training loss: 845.3412\tvalidation loss: 323.9473\t validation accuracy: 0.9200\n",
      "iteration number: 597\t training loss: 851.4119\tvalidation loss: 319.0570\t validation accuracy: 0.9267\n",
      "iteration number: 598\t training loss: 847.8664\tvalidation loss: 303.0658\t validation accuracy: 0.9267\n",
      "iteration number: 599\t training loss: 848.1910\tvalidation loss: 302.2376\t validation accuracy: 0.9267\n",
      "iteration number: 600\t training loss: 849.2423\tvalidation loss: 301.6554\t validation accuracy: 0.9244\n",
      "iteration number: 601\t training loss: 852.0398\tvalidation loss: 302.7230\t validation accuracy: 0.9244\n",
      "iteration number: 602\t training loss: 853.7500\tvalidation loss: 303.4390\t validation accuracy: 0.9156\n",
      "iteration number: 603\t training loss: 856.4963\tvalidation loss: 304.5034\t validation accuracy: 0.9156\n",
      "iteration number: 604\t training loss: 859.6974\tvalidation loss: 306.0852\t validation accuracy: 0.9133\n",
      "iteration number: 605\t training loss: 863.2047\tvalidation loss: 308.9001\t validation accuracy: 0.9156\n",
      "iteration number: 606\t training loss: 867.6621\tvalidation loss: 313.5940\t validation accuracy: 0.9156\n",
      "iteration number: 607\t training loss: 871.9329\tvalidation loss: 333.1019\t validation accuracy: 0.9111\n",
      "iteration number: 608\t training loss: 876.5713\tvalidation loss: 347.5988\t validation accuracy: 0.9111\n",
      "iteration number: 609\t training loss: 883.3440\tvalidation loss: 365.7872\t validation accuracy: 0.8978\n",
      "iteration number: 610\t training loss: 877.2978\tvalidation loss: 370.5070\t validation accuracy: 0.8911\n",
      "iteration number: 611\t training loss: 888.0762\tvalidation loss: 389.0014\t validation accuracy: 0.8800\n",
      "iteration number: 612\t training loss: 908.6592\tvalidation loss: 393.6843\t validation accuracy: 0.8622\n",
      "iteration number: 613\t training loss: 914.1685\tvalidation loss: 396.6955\t validation accuracy: 0.8578\n",
      "iteration number: 614\t training loss: 912.5931\tvalidation loss: 396.3424\t validation accuracy: 0.8556\n",
      "iteration number: 615\t training loss: 897.2845\tvalidation loss: 390.1761\t validation accuracy: 0.8644\n",
      "iteration number: 616\t training loss: 870.6514\tvalidation loss: 370.2598\t validation accuracy: 0.8800\n",
      "iteration number: 617\t training loss: 854.8650\tvalidation loss: 361.9813\t validation accuracy: 0.8956\n",
      "iteration number: 618\t training loss: 850.6232\tvalidation loss: 338.9081\t validation accuracy: 0.9133\n",
      "iteration number: 619\t training loss: 836.4189\tvalidation loss: 302.1857\t validation accuracy: 0.9222\n",
      "iteration number: 620\t training loss: 830.5466\tvalidation loss: 297.3878\t validation accuracy: 0.9244\n",
      "iteration number: 621\t training loss: 828.4812\tvalidation loss: 295.6744\t validation accuracy: 0.9267\n",
      "iteration number: 622\t training loss: 827.1139\tvalidation loss: 294.8471\t validation accuracy: 0.9311\n",
      "iteration number: 623\t training loss: 826.5901\tvalidation loss: 295.0877\t validation accuracy: 0.9356\n",
      "iteration number: 624\t training loss: 828.9149\tvalidation loss: 297.0780\t validation accuracy: 0.9333\n",
      "iteration number: 625\t training loss: 831.8813\tvalidation loss: 299.7951\t validation accuracy: 0.9311\n",
      "iteration number: 626\t training loss: 838.7146\tvalidation loss: 306.9302\t validation accuracy: 0.9267\n",
      "iteration number: 627\t training loss: 845.3273\tvalidation loss: 336.8788\t validation accuracy: 0.9178\n",
      "iteration number: 628\t training loss: 850.9675\tvalidation loss: 340.3506\t validation accuracy: 0.9133\n",
      "iteration number: 629\t training loss: 856.2066\tvalidation loss: 344.7884\t validation accuracy: 0.9156\n",
      "iteration number: 630\t training loss: 860.6027\tvalidation loss: 358.7080\t validation accuracy: 0.9089\n",
      "iteration number: 631\t training loss: 865.9871\tvalidation loss: 361.5155\t validation accuracy: 0.9067\n",
      "iteration number: 632\t training loss: 871.3025\tvalidation loss: 364.0538\t validation accuracy: 0.8978\n",
      "iteration number: 633\t training loss: 861.3314\tvalidation loss: 364.7210\t validation accuracy: 0.8889\n",
      "iteration number: 634\t training loss: 862.7526\tvalidation loss: 364.5365\t validation accuracy: 0.8889\n",
      "iteration number: 635\t training loss: 863.9262\tvalidation loss: 341.7528\t validation accuracy: 0.8889\n",
      "iteration number: 636\t training loss: 861.5212\tvalidation loss: 333.0517\t validation accuracy: 0.8911\n",
      "iteration number: 637\t training loss: 861.7886\tvalidation loss: 317.4583\t validation accuracy: 0.8956\n",
      "iteration number: 638\t training loss: 871.1445\tvalidation loss: 313.0621\t validation accuracy: 0.8978\n",
      "iteration number: 639\t training loss: 867.5643\tvalidation loss: 310.0895\t validation accuracy: 0.9022\n",
      "iteration number: 640\t training loss: 860.4039\tvalidation loss: 306.2533\t validation accuracy: 0.9067\n",
      "iteration number: 641\t training loss: 855.4968\tvalidation loss: 304.1927\t validation accuracy: 0.9089\n",
      "iteration number: 642\t training loss: 851.6573\tvalidation loss: 303.2647\t validation accuracy: 0.9089\n",
      "iteration number: 643\t training loss: 848.0768\tvalidation loss: 302.5651\t validation accuracy: 0.9044\n",
      "iteration number: 644\t training loss: 846.8747\tvalidation loss: 303.6179\t validation accuracy: 0.9022\n",
      "iteration number: 645\t training loss: 833.9918\tvalidation loss: 305.3882\t validation accuracy: 0.8956\n",
      "iteration number: 646\t training loss: 834.1654\tvalidation loss: 308.3648\t validation accuracy: 0.8956\n",
      "iteration number: 647\t training loss: 837.7895\tvalidation loss: 327.6629\t validation accuracy: 0.8911\n",
      "iteration number: 648\t training loss: 843.4005\tvalidation loss: 345.3777\t validation accuracy: 0.8867\n",
      "iteration number: 649\t training loss: 850.0994\tvalidation loss: 361.4901\t validation accuracy: 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 650\t training loss: 852.3307\tvalidation loss: 362.5043\t validation accuracy: 0.8778\n",
      "iteration number: 651\t training loss: 852.3853\tvalidation loss: 362.0178\t validation accuracy: 0.8867\n",
      "iteration number: 652\t training loss: 856.4101\tvalidation loss: 363.5360\t validation accuracy: 0.8822\n",
      "iteration number: 653\t training loss: 860.6014\tvalidation loss: 365.2046\t validation accuracy: 0.8756\n",
      "iteration number: 654\t training loss: 861.3492\tvalidation loss: 351.5262\t validation accuracy: 0.8756\n",
      "iteration number: 655\t training loss: 862.8325\tvalidation loss: 349.3599\t validation accuracy: 0.8822\n",
      "iteration number: 656\t training loss: 867.9788\tvalidation loss: 332.0970\t validation accuracy: 0.8889\n",
      "iteration number: 657\t training loss: 862.5805\tvalidation loss: 314.4170\t validation accuracy: 0.8911\n",
      "iteration number: 658\t training loss: 854.9526\tvalidation loss: 309.3791\t validation accuracy: 0.9000\n",
      "iteration number: 659\t training loss: 850.5209\tvalidation loss: 307.4610\t validation accuracy: 0.8978\n",
      "iteration number: 660\t training loss: 845.1898\tvalidation loss: 305.4263\t validation accuracy: 0.9000\n",
      "iteration number: 661\t training loss: 835.7603\tvalidation loss: 302.1133\t validation accuracy: 0.9111\n",
      "iteration number: 662\t training loss: 826.3877\tvalidation loss: 298.0058\t validation accuracy: 0.9200\n",
      "iteration number: 663\t training loss: 818.2021\tvalidation loss: 293.2500\t validation accuracy: 0.9244\n",
      "iteration number: 664\t training loss: 813.8985\tvalidation loss: 291.3001\t validation accuracy: 0.9267\n",
      "iteration number: 665\t training loss: 811.1244\tvalidation loss: 290.6486\t validation accuracy: 0.9244\n",
      "iteration number: 666\t training loss: 810.1251\tvalidation loss: 290.9610\t validation accuracy: 0.9244\n",
      "iteration number: 667\t training loss: 813.5525\tvalidation loss: 294.8154\t validation accuracy: 0.9244\n",
      "iteration number: 668\t training loss: 818.8049\tvalidation loss: 312.3161\t validation accuracy: 0.9200\n",
      "iteration number: 669\t training loss: 828.1126\tvalidation loss: 329.7392\t validation accuracy: 0.9133\n",
      "iteration number: 670\t training loss: 823.5340\tvalidation loss: 333.8194\t validation accuracy: 0.9133\n",
      "iteration number: 671\t training loss: 832.3494\tvalidation loss: 338.3795\t validation accuracy: 0.9067\n",
      "iteration number: 672\t training loss: 838.3108\tvalidation loss: 340.9942\t validation accuracy: 0.9067\n",
      "iteration number: 673\t training loss: 837.6823\tvalidation loss: 339.6513\t validation accuracy: 0.9089\n",
      "iteration number: 674\t training loss: 834.4141\tvalidation loss: 323.9568\t validation accuracy: 0.9133\n",
      "iteration number: 675\t training loss: 831.2058\tvalidation loss: 308.2680\t validation accuracy: 0.9089\n",
      "iteration number: 676\t training loss: 832.6345\tvalidation loss: 307.0559\t validation accuracy: 0.9022\n",
      "iteration number: 677\t training loss: 832.2274\tvalidation loss: 305.3530\t validation accuracy: 0.9067\n",
      "iteration number: 678\t training loss: 833.5891\tvalidation loss: 305.4775\t validation accuracy: 0.9067\n",
      "iteration number: 679\t training loss: 835.4686\tvalidation loss: 306.0111\t validation accuracy: 0.9022\n",
      "iteration number: 680\t training loss: 838.2611\tvalidation loss: 306.1018\t validation accuracy: 0.9044\n",
      "iteration number: 681\t training loss: 851.0045\tvalidation loss: 305.6252\t validation accuracy: 0.9111\n",
      "iteration number: 682\t training loss: 837.4593\tvalidation loss: 304.1506\t validation accuracy: 0.9111\n",
      "iteration number: 683\t training loss: 835.9394\tvalidation loss: 303.2671\t validation accuracy: 0.9089\n",
      "iteration number: 684\t training loss: 834.3360\tvalidation loss: 304.8073\t validation accuracy: 0.9044\n",
      "iteration number: 685\t training loss: 832.3970\tvalidation loss: 319.5322\t validation accuracy: 0.8978\n",
      "iteration number: 686\t training loss: 835.5030\tvalidation loss: 323.3110\t validation accuracy: 0.8800\n",
      "iteration number: 687\t training loss: 837.8540\tvalidation loss: 338.9464\t validation accuracy: 0.8778\n",
      "iteration number: 688\t training loss: 836.7295\tvalidation loss: 338.5736\t validation accuracy: 0.8800\n",
      "iteration number: 689\t training loss: 834.1696\tvalidation loss: 337.5132\t validation accuracy: 0.8844\n",
      "iteration number: 690\t training loss: 831.2954\tvalidation loss: 336.5536\t validation accuracy: 0.8844\n",
      "iteration number: 691\t training loss: 831.0718\tvalidation loss: 336.8032\t validation accuracy: 0.8867\n",
      "iteration number: 692\t training loss: 830.7391\tvalidation loss: 336.9851\t validation accuracy: 0.8844\n",
      "iteration number: 693\t training loss: 825.2138\tvalidation loss: 322.5849\t validation accuracy: 0.8933\n",
      "iteration number: 694\t training loss: 820.4795\tvalidation loss: 318.1872\t validation accuracy: 0.8978\n",
      "iteration number: 695\t training loss: 815.7671\tvalidation loss: 314.7405\t validation accuracy: 0.9000\n",
      "iteration number: 696\t training loss: 813.2145\tvalidation loss: 312.9725\t validation accuracy: 0.9022\n",
      "iteration number: 697\t training loss: 812.9638\tvalidation loss: 312.7113\t validation accuracy: 0.9022\n",
      "iteration number: 698\t training loss: 813.8133\tvalidation loss: 313.3384\t validation accuracy: 0.9044\n",
      "iteration number: 699\t training loss: 816.3269\tvalidation loss: 314.7402\t validation accuracy: 0.8978\n",
      "iteration number: 700\t training loss: 821.0651\tvalidation loss: 317.1572\t validation accuracy: 0.8911\n",
      "iteration number: 701\t training loss: 819.7020\tvalidation loss: 316.4441\t validation accuracy: 0.8911\n",
      "iteration number: 702\t training loss: 817.4411\tvalidation loss: 305.0980\t validation accuracy: 0.8911\n",
      "iteration number: 703\t training loss: 817.8027\tvalidation loss: 315.7352\t validation accuracy: 0.8933\n",
      "iteration number: 704\t training loss: 819.3259\tvalidation loss: 316.6748\t validation accuracy: 0.8889\n",
      "iteration number: 705\t training loss: 819.9063\tvalidation loss: 316.9340\t validation accuracy: 0.8911\n",
      "iteration number: 706\t training loss: 820.5394\tvalidation loss: 317.0948\t validation accuracy: 0.8911\n",
      "iteration number: 707\t training loss: 822.3933\tvalidation loss: 318.0004\t validation accuracy: 0.8867\n",
      "iteration number: 708\t training loss: 824.3075\tvalidation loss: 319.1153\t validation accuracy: 0.8822\n",
      "iteration number: 709\t training loss: 826.3968\tvalidation loss: 320.2881\t validation accuracy: 0.8800\n",
      "iteration number: 710\t training loss: 825.9467\tvalidation loss: 320.2825\t validation accuracy: 0.8822\n",
      "iteration number: 711\t training loss: 818.4573\tvalidation loss: 316.6055\t validation accuracy: 0.8956\n",
      "iteration number: 712\t training loss: 811.2256\tvalidation loss: 313.5260\t validation accuracy: 0.9000\n",
      "iteration number: 713\t training loss: 799.9837\tvalidation loss: 308.1273\t validation accuracy: 0.9133\n",
      "iteration number: 714\t training loss: 793.6320\tvalidation loss: 305.1117\t validation accuracy: 0.9178\n",
      "iteration number: 715\t training loss: 790.5501\tvalidation loss: 303.4367\t validation accuracy: 0.9200\n",
      "iteration number: 716\t training loss: 786.8113\tvalidation loss: 301.4831\t validation accuracy: 0.9244\n",
      "iteration number: 717\t training loss: 786.4077\tvalidation loss: 301.2318\t validation accuracy: 0.9311\n",
      "iteration number: 718\t training loss: 788.7154\tvalidation loss: 302.4561\t validation accuracy: 0.9244\n",
      "iteration number: 719\t training loss: 793.1365\tvalidation loss: 304.6511\t validation accuracy: 0.9222\n",
      "iteration number: 720\t training loss: 794.2988\tvalidation loss: 305.3266\t validation accuracy: 0.9289\n",
      "iteration number: 721\t training loss: 796.7134\tvalidation loss: 306.5257\t validation accuracy: 0.9289\n",
      "iteration number: 722\t training loss: 800.6664\tvalidation loss: 308.6684\t validation accuracy: 0.9289\n",
      "iteration number: 723\t training loss: 804.8014\tvalidation loss: 311.0776\t validation accuracy: 0.9267\n",
      "iteration number: 724\t training loss: 808.7880\tvalidation loss: 313.0567\t validation accuracy: 0.9311\n",
      "iteration number: 725\t training loss: 814.2235\tvalidation loss: 315.5758\t validation accuracy: 0.9267\n",
      "iteration number: 726\t training loss: 820.3837\tvalidation loss: 330.9562\t validation accuracy: 0.9222\n",
      "iteration number: 727\t training loss: 825.6776\tvalidation loss: 332.9854\t validation accuracy: 0.9178\n",
      "iteration number: 728\t training loss: 829.8847\tvalidation loss: 334.9754\t validation accuracy: 0.9200\n",
      "iteration number: 729\t training loss: 833.3886\tvalidation loss: 336.8328\t validation accuracy: 0.9156\n",
      "iteration number: 730\t training loss: 835.9104\tvalidation loss: 325.2925\t validation accuracy: 0.9133\n",
      "iteration number: 731\t training loss: 837.3773\tvalidation loss: 325.2707\t validation accuracy: 0.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 732\t training loss: 839.3501\tvalidation loss: 325.7563\t validation accuracy: 0.9089\n",
      "iteration number: 733\t training loss: 839.3118\tvalidation loss: 325.8342\t validation accuracy: 0.9067\n",
      "iteration number: 734\t training loss: 834.0927\tvalidation loss: 323.2771\t validation accuracy: 0.9089\n",
      "iteration number: 735\t training loss: 826.5579\tvalidation loss: 319.7467\t validation accuracy: 0.9133\n",
      "iteration number: 736\t training loss: 820.8717\tvalidation loss: 317.3259\t validation accuracy: 0.9133\n",
      "iteration number: 737\t training loss: 818.9413\tvalidation loss: 316.7402\t validation accuracy: 0.9089\n",
      "iteration number: 738\t training loss: 816.5514\tvalidation loss: 316.1468\t validation accuracy: 0.9044\n",
      "iteration number: 739\t training loss: 814.8603\tvalidation loss: 315.9053\t validation accuracy: 0.9000\n",
      "iteration number: 740\t training loss: 814.0900\tvalidation loss: 316.5767\t validation accuracy: 0.8867\n",
      "iteration number: 741\t training loss: 810.9183\tvalidation loss: 316.0460\t validation accuracy: 0.8844\n",
      "iteration number: 742\t training loss: 805.6174\tvalidation loss: 314.4614\t validation accuracy: 0.8889\n",
      "iteration number: 743\t training loss: 795.2670\tvalidation loss: 309.8389\t validation accuracy: 0.9000\n",
      "iteration number: 744\t training loss: 783.4132\tvalidation loss: 293.0334\t validation accuracy: 0.9022\n",
      "iteration number: 745\t training loss: 774.3928\tvalidation loss: 286.7073\t validation accuracy: 0.9089\n",
      "iteration number: 746\t training loss: 768.9041\tvalidation loss: 284.2453\t validation accuracy: 0.9156\n",
      "iteration number: 747\t training loss: 764.4714\tvalidation loss: 282.4796\t validation accuracy: 0.9156\n",
      "iteration number: 748\t training loss: 762.1610\tvalidation loss: 281.9267\t validation accuracy: 0.9200\n",
      "iteration number: 749\t training loss: 762.0016\tvalidation loss: 282.2794\t validation accuracy: 0.9222\n",
      "iteration number: 750\t training loss: 764.4955\tvalidation loss: 284.0814\t validation accuracy: 0.9244\n",
      "iteration number: 751\t training loss: 766.7998\tvalidation loss: 285.6394\t validation accuracy: 0.9200\n",
      "iteration number: 752\t training loss: 770.6598\tvalidation loss: 288.6991\t validation accuracy: 0.9200\n",
      "iteration number: 753\t training loss: 772.2106\tvalidation loss: 289.4711\t validation accuracy: 0.9222\n",
      "iteration number: 754\t training loss: 774.4098\tvalidation loss: 290.4654\t validation accuracy: 0.9244\n",
      "iteration number: 755\t training loss: 778.1282\tvalidation loss: 291.1868\t validation accuracy: 0.9267\n",
      "iteration number: 756\t training loss: 798.6973\tvalidation loss: 294.7200\t validation accuracy: 0.9244\n",
      "iteration number: 757\t training loss: 804.4721\tvalidation loss: 296.1703\t validation accuracy: 0.9289\n",
      "iteration number: 758\t training loss: 812.9976\tvalidation loss: 299.2563\t validation accuracy: 0.9267\n",
      "iteration number: 759\t training loss: 819.4628\tvalidation loss: 301.2385\t validation accuracy: 0.9267\n",
      "iteration number: 760\t training loss: 827.5712\tvalidation loss: 304.3758\t validation accuracy: 0.9178\n",
      "iteration number: 761\t training loss: 832.1354\tvalidation loss: 305.8330\t validation accuracy: 0.9111\n",
      "iteration number: 762\t training loss: 833.8182\tvalidation loss: 306.3543\t validation accuracy: 0.9111\n",
      "iteration number: 763\t training loss: 834.4687\tvalidation loss: 307.4816\t validation accuracy: 0.9111\n",
      "iteration number: 764\t training loss: 837.1210\tvalidation loss: 323.8684\t validation accuracy: 0.8978\n",
      "iteration number: 765\t training loss: 841.8444\tvalidation loss: 330.4524\t validation accuracy: 0.8844\n",
      "iteration number: 766\t training loss: 833.0234\tvalidation loss: 348.5330\t validation accuracy: 0.8800\n",
      "iteration number: 767\t training loss: 835.6029\tvalidation loss: 362.2182\t validation accuracy: 0.8711\n",
      "iteration number: 768\t training loss: 830.2663\tvalidation loss: 360.0771\t validation accuracy: 0.8711\n",
      "iteration number: 769\t training loss: 821.8605\tvalidation loss: 356.3616\t validation accuracy: 0.8711\n",
      "iteration number: 770\t training loss: 811.0731\tvalidation loss: 326.0564\t validation accuracy: 0.8778\n",
      "iteration number: 771\t training loss: 796.7061\tvalidation loss: 316.4272\t validation accuracy: 0.8822\n",
      "iteration number: 772\t training loss: 784.8679\tvalidation loss: 297.7971\t validation accuracy: 0.8844\n",
      "iteration number: 773\t training loss: 776.2066\tvalidation loss: 292.7624\t validation accuracy: 0.8889\n",
      "iteration number: 774\t training loss: 767.0378\tvalidation loss: 287.2620\t validation accuracy: 0.8911\n",
      "iteration number: 775\t training loss: 758.7398\tvalidation loss: 283.1035\t validation accuracy: 0.8911\n",
      "iteration number: 776\t training loss: 754.8767\tvalidation loss: 280.9535\t validation accuracy: 0.8978\n",
      "iteration number: 777\t training loss: 752.7188\tvalidation loss: 278.9165\t validation accuracy: 0.9044\n",
      "iteration number: 778\t training loss: 752.4275\tvalidation loss: 278.2456\t validation accuracy: 0.9089\n",
      "iteration number: 779\t training loss: 755.4699\tvalidation loss: 279.5526\t validation accuracy: 0.9089\n",
      "iteration number: 780\t training loss: 762.3228\tvalidation loss: 282.3399\t validation accuracy: 0.9000\n",
      "iteration number: 781\t training loss: 778.9289\tvalidation loss: 283.1942\t validation accuracy: 0.9022\n",
      "iteration number: 782\t training loss: 786.2851\tvalidation loss: 286.4421\t validation accuracy: 0.9044\n",
      "iteration number: 783\t training loss: 794.8896\tvalidation loss: 291.3724\t validation accuracy: 0.9000\n",
      "iteration number: 784\t training loss: 801.8974\tvalidation loss: 308.5340\t validation accuracy: 0.9044\n",
      "iteration number: 785\t training loss: 807.5251\tvalidation loss: 311.4188\t validation accuracy: 0.9067\n",
      "iteration number: 786\t training loss: 813.8365\tvalidation loss: 315.1470\t validation accuracy: 0.9067\n",
      "iteration number: 787\t training loss: 820.0753\tvalidation loss: 319.5921\t validation accuracy: 0.9044\n",
      "iteration number: 788\t training loss: 826.1332\tvalidation loss: 334.3605\t validation accuracy: 0.9000\n",
      "iteration number: 789\t training loss: 830.6552\tvalidation loss: 324.3101\t validation accuracy: 0.8956\n",
      "iteration number: 790\t training loss: 832.1380\tvalidation loss: 324.1844\t validation accuracy: 0.8889\n",
      "iteration number: 791\t training loss: 834.7362\tvalidation loss: 324.6502\t validation accuracy: 0.8867\n",
      "iteration number: 792\t training loss: 830.7888\tvalidation loss: 321.8843\t validation accuracy: 0.8867\n",
      "iteration number: 793\t training loss: 815.6062\tvalidation loss: 306.9800\t validation accuracy: 0.8889\n",
      "iteration number: 794\t training loss: 811.9865\tvalidation loss: 304.4963\t validation accuracy: 0.8844\n",
      "iteration number: 795\t training loss: 811.6631\tvalidation loss: 304.2837\t validation accuracy: 0.8800\n",
      "iteration number: 796\t training loss: 808.1924\tvalidation loss: 302.6457\t validation accuracy: 0.8756\n",
      "iteration number: 797\t training loss: 804.7665\tvalidation loss: 301.5529\t validation accuracy: 0.8778\n",
      "iteration number: 798\t training loss: 799.2112\tvalidation loss: 299.8034\t validation accuracy: 0.8778\n",
      "iteration number: 799\t training loss: 790.2297\tvalidation loss: 296.8924\t validation accuracy: 0.8822\n",
      "iteration number: 800\t training loss: 779.7625\tvalidation loss: 293.0014\t validation accuracy: 0.8844\n",
      "iteration number: 801\t training loss: 765.2020\tvalidation loss: 285.9742\t validation accuracy: 0.8933\n",
      "iteration number: 802\t training loss: 756.4499\tvalidation loss: 282.6348\t validation accuracy: 0.9000\n",
      "iteration number: 803\t training loss: 743.5288\tvalidation loss: 276.6045\t validation accuracy: 0.9111\n",
      "iteration number: 804\t training loss: 734.1986\tvalidation loss: 271.9074\t validation accuracy: 0.9178\n",
      "iteration number: 805\t training loss: 731.3033\tvalidation loss: 270.6032\t validation accuracy: 0.9156\n",
      "iteration number: 806\t training loss: 728.9099\tvalidation loss: 269.2726\t validation accuracy: 0.9200\n",
      "iteration number: 807\t training loss: 730.7018\tvalidation loss: 269.7222\t validation accuracy: 0.9289\n",
      "iteration number: 808\t training loss: 733.2132\tvalidation loss: 269.4038\t validation accuracy: 0.9289\n",
      "iteration number: 809\t training loss: 746.5016\tvalidation loss: 270.0359\t validation accuracy: 0.9222\n",
      "iteration number: 810\t training loss: 753.4569\tvalidation loss: 273.7571\t validation accuracy: 0.9178\n",
      "iteration number: 811\t training loss: 767.1052\tvalidation loss: 281.6609\t validation accuracy: 0.9133\n",
      "iteration number: 812\t training loss: 768.7755\tvalidation loss: 302.2409\t validation accuracy: 0.9156\n",
      "iteration number: 813\t training loss: 779.5957\tvalidation loss: 307.4623\t validation accuracy: 0.9022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 814\t training loss: 789.1631\tvalidation loss: 312.0281\t validation accuracy: 0.8933\n",
      "iteration number: 815\t training loss: 796.1146\tvalidation loss: 313.5732\t validation accuracy: 0.8889\n",
      "iteration number: 816\t training loss: 805.0395\tvalidation loss: 317.6527\t validation accuracy: 0.8800\n",
      "iteration number: 817\t training loss: 814.5356\tvalidation loss: 334.4752\t validation accuracy: 0.8778\n",
      "iteration number: 818\t training loss: 818.3957\tvalidation loss: 323.3868\t validation accuracy: 0.8711\n",
      "iteration number: 819\t training loss: 814.4147\tvalidation loss: 319.6157\t validation accuracy: 0.8733\n",
      "iteration number: 820\t training loss: 804.0462\tvalidation loss: 313.7734\t validation accuracy: 0.8933\n",
      "iteration number: 821\t training loss: 793.9860\tvalidation loss: 295.1595\t validation accuracy: 0.8956\n",
      "iteration number: 822\t training loss: 782.6915\tvalidation loss: 289.1948\t validation accuracy: 0.9044\n",
      "iteration number: 823\t training loss: 772.2445\tvalidation loss: 284.1587\t validation accuracy: 0.9111\n",
      "iteration number: 824\t training loss: 760.8897\tvalidation loss: 279.1096\t validation accuracy: 0.9156\n",
      "iteration number: 825\t training loss: 752.6792\tvalidation loss: 275.6418\t validation accuracy: 0.9200\n",
      "iteration number: 826\t training loss: 750.3341\tvalidation loss: 275.0016\t validation accuracy: 0.9244\n",
      "iteration number: 827\t training loss: 749.1586\tvalidation loss: 274.8713\t validation accuracy: 0.9222\n",
      "iteration number: 828\t training loss: 749.3094\tvalidation loss: 275.2836\t validation accuracy: 0.9178\n",
      "iteration number: 829\t training loss: 750.3165\tvalidation loss: 275.9651\t validation accuracy: 0.9089\n",
      "iteration number: 830\t training loss: 753.2727\tvalidation loss: 277.8435\t validation accuracy: 0.9044\n",
      "iteration number: 831\t training loss: 758.4095\tvalidation loss: 280.6051\t validation accuracy: 0.9000\n",
      "iteration number: 832\t training loss: 765.5412\tvalidation loss: 284.7502\t validation accuracy: 0.8867\n",
      "iteration number: 833\t training loss: 772.2026\tvalidation loss: 288.2304\t validation accuracy: 0.8822\n",
      "iteration number: 834\t training loss: 776.7250\tvalidation loss: 291.0503\t validation accuracy: 0.8778\n",
      "iteration number: 835\t training loss: 776.5023\tvalidation loss: 290.8639\t validation accuracy: 0.8756\n",
      "iteration number: 836\t training loss: 772.2285\tvalidation loss: 288.0694\t validation accuracy: 0.8756\n",
      "iteration number: 837\t training loss: 764.5493\tvalidation loss: 283.9095\t validation accuracy: 0.8844\n",
      "iteration number: 838\t training loss: 757.8331\tvalidation loss: 280.7090\t validation accuracy: 0.8933\n",
      "iteration number: 839\t training loss: 751.0382\tvalidation loss: 278.0532\t validation accuracy: 0.8956\n",
      "iteration number: 840\t training loss: 747.0065\tvalidation loss: 276.8793\t validation accuracy: 0.9022\n",
      "iteration number: 841\t training loss: 741.7496\tvalidation loss: 274.4868\t validation accuracy: 0.9044\n",
      "iteration number: 842\t training loss: 736.7520\tvalidation loss: 272.7133\t validation accuracy: 0.9089\n",
      "iteration number: 843\t training loss: 735.3919\tvalidation loss: 272.3892\t validation accuracy: 0.9089\n",
      "iteration number: 844\t training loss: 738.4597\tvalidation loss: 274.5378\t validation accuracy: 0.9067\n",
      "iteration number: 845\t training loss: 743.1491\tvalidation loss: 277.7157\t validation accuracy: 0.9044\n",
      "iteration number: 846\t training loss: 748.6943\tvalidation loss: 281.6223\t validation accuracy: 0.9044\n",
      "iteration number: 847\t training loss: 756.0716\tvalidation loss: 288.1825\t validation accuracy: 0.8933\n",
      "iteration number: 848\t training loss: 763.2158\tvalidation loss: 303.9607\t validation accuracy: 0.8911\n",
      "iteration number: 849\t training loss: 767.3238\tvalidation loss: 305.4175\t validation accuracy: 0.8889\n",
      "iteration number: 850\t training loss: 770.2295\tvalidation loss: 305.6442\t validation accuracy: 0.8867\n",
      "iteration number: 851\t training loss: 771.7856\tvalidation loss: 292.8868\t validation accuracy: 0.8867\n",
      "iteration number: 852\t training loss: 771.2526\tvalidation loss: 289.4279\t validation accuracy: 0.8867\n",
      "iteration number: 853\t training loss: 770.5375\tvalidation loss: 286.8180\t validation accuracy: 0.8933\n",
      "iteration number: 854\t training loss: 770.1629\tvalidation loss: 285.6278\t validation accuracy: 0.8933\n",
      "iteration number: 855\t training loss: 771.6204\tvalidation loss: 298.1486\t validation accuracy: 0.8956\n",
      "iteration number: 856\t training loss: 770.5616\tvalidation loss: 296.6444\t validation accuracy: 0.8978\n",
      "iteration number: 857\t training loss: 770.1019\tvalidation loss: 295.9998\t validation accuracy: 0.9000\n",
      "iteration number: 858\t training loss: 769.3527\tvalidation loss: 296.6757\t validation accuracy: 0.8978\n",
      "iteration number: 859\t training loss: 769.1255\tvalidation loss: 284.3541\t validation accuracy: 0.8978\n",
      "iteration number: 860\t training loss: 771.1265\tvalidation loss: 285.2520\t validation accuracy: 0.8956\n",
      "iteration number: 861\t training loss: 772.1332\tvalidation loss: 286.6728\t validation accuracy: 0.8978\n",
      "iteration number: 862\t training loss: 774.6540\tvalidation loss: 289.3933\t validation accuracy: 0.8956\n",
      "iteration number: 863\t training loss: 779.2364\tvalidation loss: 307.2345\t validation accuracy: 0.8911\n",
      "iteration number: 864\t training loss: 783.6296\tvalidation loss: 311.6083\t validation accuracy: 0.8800\n",
      "iteration number: 865\t training loss: 788.7425\tvalidation loss: 319.0348\t validation accuracy: 0.8778\n",
      "iteration number: 866\t training loss: 791.0403\tvalidation loss: 360.9185\t validation accuracy: 0.8778\n",
      "iteration number: 867\t training loss: 793.4284\tvalidation loss: 363.0554\t validation accuracy: 0.8778\n",
      "iteration number: 868\t training loss: 796.2771\tvalidation loss: 365.0549\t validation accuracy: 0.8711\n",
      "iteration number: 869\t training loss: 787.6349\tvalidation loss: 361.1952\t validation accuracy: 0.8756\n",
      "iteration number: 870\t training loss: 777.4566\tvalidation loss: 356.4766\t validation accuracy: 0.8867\n",
      "iteration number: 871\t training loss: 760.7343\tvalidation loss: 308.4260\t validation accuracy: 0.8933\n",
      "iteration number: 872\t training loss: 745.5296\tvalidation loss: 295.7373\t validation accuracy: 0.9000\n",
      "iteration number: 873\t training loss: 735.8878\tvalidation loss: 274.6566\t validation accuracy: 0.9089\n",
      "iteration number: 874\t training loss: 729.8688\tvalidation loss: 269.9252\t validation accuracy: 0.9178\n",
      "iteration number: 875\t training loss: 723.8725\tvalidation loss: 265.7948\t validation accuracy: 0.9178\n",
      "iteration number: 876\t training loss: 722.3846\tvalidation loss: 264.2074\t validation accuracy: 0.9244\n",
      "iteration number: 877\t training loss: 722.7378\tvalidation loss: 264.0209\t validation accuracy: 0.9267\n",
      "iteration number: 878\t training loss: 723.4177\tvalidation loss: 263.8820\t validation accuracy: 0.9244\n",
      "iteration number: 879\t training loss: 727.0520\tvalidation loss: 265.3614\t validation accuracy: 0.9244\n",
      "iteration number: 880\t training loss: 730.4968\tvalidation loss: 267.2441\t validation accuracy: 0.9244\n",
      "iteration number: 881\t training loss: 735.7627\tvalidation loss: 269.8631\t validation accuracy: 0.9178\n",
      "iteration number: 882\t training loss: 742.6054\tvalidation loss: 273.3436\t validation accuracy: 0.9133\n",
      "iteration number: 883\t training loss: 752.4857\tvalidation loss: 278.5445\t validation accuracy: 0.8978\n",
      "iteration number: 884\t training loss: 764.0494\tvalidation loss: 285.8538\t validation accuracy: 0.8822\n",
      "iteration number: 885\t training loss: 772.7072\tvalidation loss: 303.8693\t validation accuracy: 0.8756\n",
      "iteration number: 886\t training loss: 780.2716\tvalidation loss: 308.2186\t validation accuracy: 0.8711\n",
      "iteration number: 887\t training loss: 781.4153\tvalidation loss: 309.2939\t validation accuracy: 0.8667\n",
      "iteration number: 888\t training loss: 775.3251\tvalidation loss: 306.1194\t validation accuracy: 0.8711\n",
      "iteration number: 889\t training loss: 767.5982\tvalidation loss: 301.9823\t validation accuracy: 0.8733\n",
      "iteration number: 890\t training loss: 754.4226\tvalidation loss: 295.5292\t validation accuracy: 0.8822\n",
      "iteration number: 891\t training loss: 743.6570\tvalidation loss: 278.6481\t validation accuracy: 0.8978\n",
      "iteration number: 892\t training loss: 733.6319\tvalidation loss: 272.5140\t validation accuracy: 0.9044\n",
      "iteration number: 893\t training loss: 728.5700\tvalidation loss: 269.6183\t validation accuracy: 0.9089\n",
      "iteration number: 894\t training loss: 726.4067\tvalidation loss: 268.0848\t validation accuracy: 0.9089\n",
      "iteration number: 895\t training loss: 722.1828\tvalidation loss: 265.7103\t validation accuracy: 0.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 896\t training loss: 720.3773\tvalidation loss: 264.3453\t validation accuracy: 0.9133\n",
      "iteration number: 897\t training loss: 724.3820\tvalidation loss: 266.0998\t validation accuracy: 0.9133\n",
      "iteration number: 898\t training loss: 729.3250\tvalidation loss: 268.8674\t validation accuracy: 0.9067\n",
      "iteration number: 899\t training loss: 740.2111\tvalidation loss: 275.5624\t validation accuracy: 0.8889\n",
      "iteration number: 900\t training loss: 749.9493\tvalidation loss: 295.2387\t validation accuracy: 0.8800\n",
      "iteration number: 901\t training loss: 753.2504\tvalidation loss: 297.8984\t validation accuracy: 0.8778\n",
      "iteration number: 902\t training loss: 753.1618\tvalidation loss: 298.7022\t validation accuracy: 0.8844\n",
      "iteration number: 903\t training loss: 756.4562\tvalidation loss: 301.1259\t validation accuracy: 0.8889\n",
      "iteration number: 904\t training loss: 759.2911\tvalidation loss: 306.6726\t validation accuracy: 0.8933\n",
      "iteration number: 905\t training loss: 759.0745\tvalidation loss: 303.5086\t validation accuracy: 0.8956\n",
      "iteration number: 906\t training loss: 758.2421\tvalidation loss: 300.1531\t validation accuracy: 0.9044\n",
      "iteration number: 907\t training loss: 757.0649\tvalidation loss: 298.8250\t validation accuracy: 0.9022\n",
      "iteration number: 908\t training loss: 754.6429\tvalidation loss: 297.1605\t validation accuracy: 0.9044\n",
      "iteration number: 909\t training loss: 754.6452\tvalidation loss: 296.9327\t validation accuracy: 0.9044\n",
      "iteration number: 910\t training loss: 754.6768\tvalidation loss: 297.2474\t validation accuracy: 0.9044\n",
      "iteration number: 911\t training loss: 754.0846\tvalidation loss: 297.6682\t validation accuracy: 0.9044\n",
      "iteration number: 912\t training loss: 752.2587\tvalidation loss: 297.4599\t validation accuracy: 0.9044\n",
      "iteration number: 913\t training loss: 753.5525\tvalidation loss: 299.7289\t validation accuracy: 0.9000\n",
      "iteration number: 914\t training loss: 752.7142\tvalidation loss: 300.7128\t validation accuracy: 0.8956\n",
      "iteration number: 915\t training loss: 749.9280\tvalidation loss: 310.8953\t validation accuracy: 0.8956\n",
      "iteration number: 916\t training loss: 746.2506\tvalidation loss: 297.9213\t validation accuracy: 0.8933\n",
      "iteration number: 917\t training loss: 738.8664\tvalidation loss: 293.2726\t validation accuracy: 0.9000\n",
      "iteration number: 918\t training loss: 734.5212\tvalidation loss: 291.4911\t validation accuracy: 0.9000\n",
      "iteration number: 919\t training loss: 729.3809\tvalidation loss: 288.9528\t validation accuracy: 0.9000\n",
      "iteration number: 920\t training loss: 725.1707\tvalidation loss: 286.9394\t validation accuracy: 0.8956\n",
      "iteration number: 921\t training loss: 721.6594\tvalidation loss: 274.7064\t validation accuracy: 0.9000\n",
      "iteration number: 922\t training loss: 715.9596\tvalidation loss: 268.9413\t validation accuracy: 0.9000\n",
      "iteration number: 923\t training loss: 712.3986\tvalidation loss: 266.2044\t validation accuracy: 0.9067\n",
      "iteration number: 924\t training loss: 711.7619\tvalidation loss: 265.3655\t validation accuracy: 0.9111\n",
      "iteration number: 925\t training loss: 709.2445\tvalidation loss: 263.6642\t validation accuracy: 0.9133\n",
      "iteration number: 926\t training loss: 707.8844\tvalidation loss: 262.9227\t validation accuracy: 0.9133\n",
      "iteration number: 927\t training loss: 709.5188\tvalidation loss: 264.1836\t validation accuracy: 0.9089\n",
      "iteration number: 928\t training loss: 711.6370\tvalidation loss: 266.4988\t validation accuracy: 0.9111\n",
      "iteration number: 929\t training loss: 713.5578\tvalidation loss: 269.3714\t validation accuracy: 0.9111\n",
      "iteration number: 930\t training loss: 715.9964\tvalidation loss: 272.4763\t validation accuracy: 0.9044\n",
      "iteration number: 931\t training loss: 717.2497\tvalidation loss: 285.7163\t validation accuracy: 0.9022\n",
      "iteration number: 932\t training loss: 717.9674\tvalidation loss: 285.7121\t validation accuracy: 0.9044\n",
      "iteration number: 933\t training loss: 720.8265\tvalidation loss: 287.0461\t validation accuracy: 0.9044\n",
      "iteration number: 934\t training loss: 720.4325\tvalidation loss: 286.6059\t validation accuracy: 0.9044\n",
      "iteration number: 935\t training loss: 717.0999\tvalidation loss: 270.9330\t validation accuracy: 0.9133\n",
      "iteration number: 936\t training loss: 711.8990\tvalidation loss: 266.5885\t validation accuracy: 0.9156\n",
      "iteration number: 937\t training loss: 707.8096\tvalidation loss: 263.8901\t validation accuracy: 0.9222\n",
      "iteration number: 938\t training loss: 709.2570\tvalidation loss: 264.7125\t validation accuracy: 0.9244\n",
      "iteration number: 939\t training loss: 713.3388\tvalidation loss: 267.0068\t validation accuracy: 0.9200\n",
      "iteration number: 940\t training loss: 716.8538\tvalidation loss: 269.1437\t validation accuracy: 0.9156\n",
      "iteration number: 941\t training loss: 718.4426\tvalidation loss: 270.4650\t validation accuracy: 0.9178\n",
      "iteration number: 942\t training loss: 718.9134\tvalidation loss: 270.9890\t validation accuracy: 0.9156\n",
      "iteration number: 943\t training loss: 719.4271\tvalidation loss: 271.1365\t validation accuracy: 0.9156\n",
      "iteration number: 944\t training loss: 720.4496\tvalidation loss: 271.3055\t validation accuracy: 0.9178\n",
      "iteration number: 945\t training loss: 723.3197\tvalidation loss: 272.5528\t validation accuracy: 0.9133\n",
      "iteration number: 946\t training loss: 726.8029\tvalidation loss: 274.5170\t validation accuracy: 0.9156\n",
      "iteration number: 947\t training loss: 729.8915\tvalidation loss: 277.8262\t validation accuracy: 0.9178\n",
      "iteration number: 948\t training loss: 733.9316\tvalidation loss: 291.4413\t validation accuracy: 0.9089\n",
      "iteration number: 949\t training loss: 733.2985\tvalidation loss: 291.1622\t validation accuracy: 0.9067\n",
      "iteration number: 950\t training loss: 731.8253\tvalidation loss: 289.9331\t validation accuracy: 0.9089\n",
      "iteration number: 951\t training loss: 732.4996\tvalidation loss: 290.3122\t validation accuracy: 0.9067\n",
      "iteration number: 952\t training loss: 727.6034\tvalidation loss: 274.9749\t validation accuracy: 0.9067\n",
      "iteration number: 953\t training loss: 721.2546\tvalidation loss: 270.4743\t validation accuracy: 0.9089\n",
      "iteration number: 954\t training loss: 715.1755\tvalidation loss: 267.0659\t validation accuracy: 0.9156\n",
      "iteration number: 955\t training loss: 707.0567\tvalidation loss: 263.0390\t validation accuracy: 0.9178\n",
      "iteration number: 956\t training loss: 700.5315\tvalidation loss: 260.0619\t validation accuracy: 0.9244\n",
      "iteration number: 957\t training loss: 696.0121\tvalidation loss: 257.7192\t validation accuracy: 0.9244\n",
      "iteration number: 958\t training loss: 694.5562\tvalidation loss: 257.1826\t validation accuracy: 0.9289\n",
      "iteration number: 959\t training loss: 694.4287\tvalidation loss: 257.6859\t validation accuracy: 0.9267\n",
      "iteration number: 960\t training loss: 695.1055\tvalidation loss: 258.4498\t validation accuracy: 0.9222\n",
      "iteration number: 961\t training loss: 695.9772\tvalidation loss: 259.4168\t validation accuracy: 0.9200\n",
      "iteration number: 962\t training loss: 698.6291\tvalidation loss: 261.3502\t validation accuracy: 0.9178\n",
      "iteration number: 963\t training loss: 702.8048\tvalidation loss: 264.0576\t validation accuracy: 0.9089\n",
      "iteration number: 964\t training loss: 707.9567\tvalidation loss: 267.6963\t validation accuracy: 0.9089\n",
      "iteration number: 965\t training loss: 713.1840\tvalidation loss: 271.9639\t validation accuracy: 0.9044\n",
      "iteration number: 966\t training loss: 717.2509\tvalidation loss: 288.7093\t validation accuracy: 0.8978\n",
      "iteration number: 967\t training loss: 721.4385\tvalidation loss: 304.4759\t validation accuracy: 0.8956\n",
      "iteration number: 968\t training loss: 723.9199\tvalidation loss: 305.6930\t validation accuracy: 0.8978\n",
      "iteration number: 969\t training loss: 722.7359\tvalidation loss: 304.6610\t validation accuracy: 0.9000\n",
      "iteration number: 970\t training loss: 718.6316\tvalidation loss: 275.2309\t validation accuracy: 0.9044\n",
      "iteration number: 971\t training loss: 714.1431\tvalidation loss: 269.3513\t validation accuracy: 0.9067\n",
      "iteration number: 972\t training loss: 711.1539\tvalidation loss: 266.1965\t validation accuracy: 0.9089\n",
      "iteration number: 973\t training loss: 709.1592\tvalidation loss: 263.7471\t validation accuracy: 0.9111\n",
      "iteration number: 974\t training loss: 706.7579\tvalidation loss: 261.3345\t validation accuracy: 0.9200\n",
      "iteration number: 975\t training loss: 704.2407\tvalidation loss: 259.0114\t validation accuracy: 0.9311\n",
      "iteration number: 976\t training loss: 702.4256\tvalidation loss: 257.7045\t validation accuracy: 0.9267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 977\t training loss: 703.3877\tvalidation loss: 257.9350\t validation accuracy: 0.9267\n",
      "iteration number: 978\t training loss: 704.6643\tvalidation loss: 258.6807\t validation accuracy: 0.9289\n",
      "iteration number: 979\t training loss: 707.7593\tvalidation loss: 260.7168\t validation accuracy: 0.9267\n",
      "iteration number: 980\t training loss: 710.1569\tvalidation loss: 262.8652\t validation accuracy: 0.9156\n",
      "iteration number: 981\t training loss: 714.7643\tvalidation loss: 266.3948\t validation accuracy: 0.9000\n",
      "iteration number: 982\t training loss: 721.3360\tvalidation loss: 272.3669\t validation accuracy: 0.9000\n",
      "iteration number: 983\t training loss: 729.5530\tvalidation loss: 290.8843\t validation accuracy: 0.8978\n",
      "iteration number: 984\t training loss: 736.2282\tvalidation loss: 308.9293\t validation accuracy: 0.8889\n",
      "iteration number: 985\t training loss: 742.4381\tvalidation loss: 313.1109\t validation accuracy: 0.8800\n",
      "iteration number: 986\t training loss: 738.2173\tvalidation loss: 310.9203\t validation accuracy: 0.8844\n",
      "iteration number: 987\t training loss: 726.5800\tvalidation loss: 292.6008\t validation accuracy: 0.8911\n",
      "iteration number: 988\t training loss: 716.3186\tvalidation loss: 285.7156\t validation accuracy: 0.8956\n",
      "iteration number: 989\t training loss: 702.9863\tvalidation loss: 278.9151\t validation accuracy: 0.9000\n",
      "iteration number: 990\t training loss: 692.2447\tvalidation loss: 274.0099\t validation accuracy: 0.9089\n",
      "iteration number: 991\t training loss: 679.2378\tvalidation loss: 254.4190\t validation accuracy: 0.9200\n",
      "iteration number: 992\t training loss: 668.8827\tvalidation loss: 249.0244\t validation accuracy: 0.9267\n",
      "iteration number: 993\t training loss: 660.5488\tvalidation loss: 244.5805\t validation accuracy: 0.9400\n",
      "iteration number: 994\t training loss: 655.8279\tvalidation loss: 242.1453\t validation accuracy: 0.9422\n",
      "iteration number: 995\t training loss: 654.7181\tvalidation loss: 241.5494\t validation accuracy: 0.9422\n",
      "iteration number: 996\t training loss: 659.3250\tvalidation loss: 244.1174\t validation accuracy: 0.9378\n",
      "iteration number: 997\t training loss: 667.9046\tvalidation loss: 248.4283\t validation accuracy: 0.9333\n",
      "iteration number: 998\t training loss: 678.7097\tvalidation loss: 254.4881\t validation accuracy: 0.9289\n",
      "iteration number: 999\t training loss: 690.2021\tvalidation loss: 273.9591\t validation accuracy: 0.9267\n",
      "iteration number: 1000\t training loss: 699.0932\tvalidation loss: 278.8584\t validation accuracy: 0.9244\n",
      "iteration number: 1001\t training loss: 710.1345\tvalidation loss: 297.0551\t validation accuracy: 0.9222\n",
      "iteration number: 1002\t training loss: 718.2121\tvalidation loss: 300.4296\t validation accuracy: 0.9200\n",
      "iteration number: 1003\t training loss: 724.2491\tvalidation loss: 302.6057\t validation accuracy: 0.9178\n",
      "iteration number: 1004\t training loss: 731.8883\tvalidation loss: 305.8658\t validation accuracy: 0.9133\n",
      "iteration number: 1005\t training loss: 739.5247\tvalidation loss: 308.9814\t validation accuracy: 0.9089\n",
      "iteration number: 1006\t training loss: 743.7260\tvalidation loss: 297.7902\t validation accuracy: 0.9022\n",
      "iteration number: 1007\t training loss: 748.0315\tvalidation loss: 299.4872\t validation accuracy: 0.9022\n",
      "iteration number: 1008\t training loss: 751.1351\tvalidation loss: 300.8610\t validation accuracy: 0.9022\n",
      "iteration number: 1009\t training loss: 752.9122\tvalidation loss: 301.7860\t validation accuracy: 0.8978\n",
      "iteration number: 1010\t training loss: 751.2362\tvalidation loss: 288.1851\t validation accuracy: 0.8889\n",
      "iteration number: 1011\t training loss: 745.2822\tvalidation loss: 282.5286\t validation accuracy: 0.8956\n",
      "iteration number: 1012\t training loss: 733.4720\tvalidation loss: 274.8747\t validation accuracy: 0.8978\n",
      "iteration number: 1013\t training loss: 721.1976\tvalidation loss: 268.2326\t validation accuracy: 0.9000\n",
      "iteration number: 1014\t training loss: 706.2946\tvalidation loss: 261.7217\t validation accuracy: 0.9067\n",
      "iteration number: 1015\t training loss: 693.1025\tvalidation loss: 256.1645\t validation accuracy: 0.9111\n",
      "iteration number: 1016\t training loss: 680.3174\tvalidation loss: 251.1109\t validation accuracy: 0.9111\n",
      "iteration number: 1017\t training loss: 671.3413\tvalidation loss: 248.2517\t validation accuracy: 0.9156\n",
      "iteration number: 1018\t training loss: 665.3273\tvalidation loss: 246.6896\t validation accuracy: 0.9133\n",
      "iteration number: 1019\t training loss: 661.4276\tvalidation loss: 245.9595\t validation accuracy: 0.9133\n",
      "iteration number: 1020\t training loss: 661.0954\tvalidation loss: 246.5648\t validation accuracy: 0.9133\n",
      "iteration number: 1021\t training loss: 663.7206\tvalidation loss: 248.6522\t validation accuracy: 0.9089\n",
      "iteration number: 1022\t training loss: 666.8718\tvalidation loss: 250.7138\t validation accuracy: 0.9000\n",
      "iteration number: 1023\t training loss: 670.8411\tvalidation loss: 252.9400\t validation accuracy: 0.8956\n",
      "iteration number: 1024\t training loss: 676.9478\tvalidation loss: 255.9306\t validation accuracy: 0.8933\n",
      "iteration number: 1025\t training loss: 680.0211\tvalidation loss: 256.8442\t validation accuracy: 0.9000\n",
      "iteration number: 1026\t training loss: 684.8079\tvalidation loss: 258.5723\t validation accuracy: 0.8978\n",
      "iteration number: 1027\t training loss: 689.7551\tvalidation loss: 260.4191\t validation accuracy: 0.9022\n",
      "iteration number: 1028\t training loss: 696.2961\tvalidation loss: 263.2512\t validation accuracy: 0.9000\n",
      "iteration number: 1029\t training loss: 700.2241\tvalidation loss: 264.6530\t validation accuracy: 0.9044\n",
      "iteration number: 1030\t training loss: 702.0899\tvalidation loss: 264.7161\t validation accuracy: 0.9067\n",
      "iteration number: 1031\t training loss: 701.5006\tvalidation loss: 264.1701\t validation accuracy: 0.9156\n",
      "iteration number: 1032\t training loss: 700.8048\tvalidation loss: 263.3572\t validation accuracy: 0.9222\n",
      "iteration number: 1033\t training loss: 699.2556\tvalidation loss: 262.4280\t validation accuracy: 0.9200\n",
      "iteration number: 1034\t training loss: 695.2076\tvalidation loss: 260.7347\t validation accuracy: 0.9222\n",
      "iteration number: 1035\t training loss: 692.7196\tvalidation loss: 259.5360\t validation accuracy: 0.9222\n",
      "iteration number: 1036\t training loss: 688.7951\tvalidation loss: 257.6671\t validation accuracy: 0.9222\n",
      "iteration number: 1037\t training loss: 688.8473\tvalidation loss: 257.8206\t validation accuracy: 0.9244\n",
      "iteration number: 1038\t training loss: 688.4621\tvalidation loss: 257.9875\t validation accuracy: 0.9111\n",
      "iteration number: 1039\t training loss: 688.8414\tvalidation loss: 258.6317\t validation accuracy: 0.9067\n",
      "iteration number: 1040\t training loss: 689.5371\tvalidation loss: 259.7526\t validation accuracy: 0.9067\n",
      "iteration number: 1041\t training loss: 686.9108\tvalidation loss: 259.3626\t validation accuracy: 0.9000\n",
      "iteration number: 1042\t training loss: 686.5283\tvalidation loss: 260.0555\t validation accuracy: 0.8933\n",
      "iteration number: 1043\t training loss: 687.5231\tvalidation loss: 261.7443\t validation accuracy: 0.8867\n",
      "iteration number: 1044\t training loss: 688.9614\tvalidation loss: 264.3913\t validation accuracy: 0.8778\n",
      "iteration number: 1045\t training loss: 691.5322\tvalidation loss: 280.9600\t validation accuracy: 0.8756\n",
      "iteration number: 1046\t training loss: 693.1875\tvalidation loss: 283.1600\t validation accuracy: 0.8800\n",
      "iteration number: 1047\t training loss: 690.5601\tvalidation loss: 282.6056\t validation accuracy: 0.8800\n",
      "iteration number: 1048\t training loss: 685.8232\tvalidation loss: 280.6723\t validation accuracy: 0.8778\n",
      "iteration number: 1049\t training loss: 679.5750\tvalidation loss: 276.8075\t validation accuracy: 0.8756\n",
      "iteration number: 1050\t training loss: 671.7375\tvalidation loss: 272.2725\t validation accuracy: 0.8822\n",
      "iteration number: 1051\t training loss: 665.2971\tvalidation loss: 268.7481\t validation accuracy: 0.8867\n",
      "iteration number: 1052\t training loss: 657.6581\tvalidation loss: 264.7692\t validation accuracy: 0.8933\n",
      "iteration number: 1053\t training loss: 652.8411\tvalidation loss: 248.0336\t validation accuracy: 0.9000\n",
      "iteration number: 1054\t training loss: 648.0514\tvalidation loss: 243.9033\t validation accuracy: 0.9111\n",
      "iteration number: 1055\t training loss: 645.3592\tvalidation loss: 241.4179\t validation accuracy: 0.9156\n",
      "iteration number: 1056\t training loss: 646.1489\tvalidation loss: 241.4337\t validation accuracy: 0.9222\n",
      "iteration number: 1057\t training loss: 648.1147\tvalidation loss: 242.4669\t validation accuracy: 0.9311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1058\t training loss: 650.9620\tvalidation loss: 243.9228\t validation accuracy: 0.9356\n",
      "iteration number: 1059\t training loss: 655.2137\tvalidation loss: 246.4597\t validation accuracy: 0.9356\n",
      "iteration number: 1060\t training loss: 663.8042\tvalidation loss: 249.9624\t validation accuracy: 0.9311\n",
      "iteration number: 1061\t training loss: 673.8676\tvalidation loss: 254.2513\t validation accuracy: 0.9244\n",
      "iteration number: 1062\t training loss: 686.5943\tvalidation loss: 260.4196\t validation accuracy: 0.9178\n",
      "iteration number: 1063\t training loss: 697.8050\tvalidation loss: 266.3418\t validation accuracy: 0.9178\n",
      "iteration number: 1064\t training loss: 708.8130\tvalidation loss: 287.0166\t validation accuracy: 0.9111\n",
      "iteration number: 1065\t training loss: 716.2843\tvalidation loss: 304.1725\t validation accuracy: 0.8978\n",
      "iteration number: 1066\t training loss: 722.4870\tvalidation loss: 307.9354\t validation accuracy: 0.8911\n",
      "iteration number: 1067\t training loss: 729.1560\tvalidation loss: 312.0413\t validation accuracy: 0.8844\n",
      "iteration number: 1068\t training loss: 732.0781\tvalidation loss: 313.7055\t validation accuracy: 0.8711\n",
      "iteration number: 1069\t training loss: 731.5496\tvalidation loss: 313.4357\t validation accuracy: 0.8644\n",
      "iteration number: 1070\t training loss: 726.1910\tvalidation loss: 310.9835\t validation accuracy: 0.8622\n",
      "iteration number: 1071\t training loss: 716.9763\tvalidation loss: 294.3571\t validation accuracy: 0.8622\n",
      "iteration number: 1072\t training loss: 704.2466\tvalidation loss: 286.7240\t validation accuracy: 0.8644\n",
      "iteration number: 1073\t training loss: 693.7576\tvalidation loss: 281.2828\t validation accuracy: 0.8689\n",
      "iteration number: 1074\t training loss: 680.6944\tvalidation loss: 274.7602\t validation accuracy: 0.8711\n",
      "iteration number: 1075\t training loss: 670.5007\tvalidation loss: 269.9959\t validation accuracy: 0.8778\n",
      "iteration number: 1076\t training loss: 659.6396\tvalidation loss: 265.0647\t validation accuracy: 0.8822\n",
      "iteration number: 1077\t training loss: 651.2855\tvalidation loss: 261.0826\t validation accuracy: 0.8889\n",
      "iteration number: 1078\t training loss: 647.3465\tvalidation loss: 259.1213\t validation accuracy: 0.8889\n",
      "iteration number: 1079\t training loss: 646.3616\tvalidation loss: 258.6582\t validation accuracy: 0.8933\n",
      "iteration number: 1080\t training loss: 644.9550\tvalidation loss: 257.5378\t validation accuracy: 0.9000\n",
      "iteration number: 1081\t training loss: 645.7983\tvalidation loss: 257.6162\t validation accuracy: 0.9089\n",
      "iteration number: 1082\t training loss: 648.9790\tvalidation loss: 258.7570\t validation accuracy: 0.9111\n",
      "iteration number: 1083\t training loss: 653.3068\tvalidation loss: 260.2646\t validation accuracy: 0.9111\n",
      "iteration number: 1084\t training loss: 656.4684\tvalidation loss: 260.8076\t validation accuracy: 0.9111\n",
      "iteration number: 1085\t training loss: 659.1971\tvalidation loss: 261.3006\t validation accuracy: 0.9111\n",
      "iteration number: 1086\t training loss: 661.0711\tvalidation loss: 248.4623\t validation accuracy: 0.9089\n",
      "iteration number: 1087\t training loss: 663.3126\tvalidation loss: 247.3190\t validation accuracy: 0.9222\n",
      "iteration number: 1088\t training loss: 665.5256\tvalidation loss: 247.4061\t validation accuracy: 0.9244\n",
      "iteration number: 1089\t training loss: 667.9247\tvalidation loss: 247.5462\t validation accuracy: 0.9267\n",
      "iteration number: 1090\t training loss: 667.0025\tvalidation loss: 246.5288\t validation accuracy: 0.9244\n",
      "iteration number: 1091\t training loss: 671.5845\tvalidation loss: 248.7011\t validation accuracy: 0.9200\n",
      "iteration number: 1092\t training loss: 675.0363\tvalidation loss: 250.4405\t validation accuracy: 0.9178\n",
      "iteration number: 1093\t training loss: 679.7719\tvalidation loss: 252.7523\t validation accuracy: 0.9089\n",
      "iteration number: 1094\t training loss: 683.4007\tvalidation loss: 254.8900\t validation accuracy: 0.9022\n",
      "iteration number: 1095\t training loss: 687.3245\tvalidation loss: 257.5001\t validation accuracy: 0.9000\n",
      "iteration number: 1096\t training loss: 689.4478\tvalidation loss: 259.7789\t validation accuracy: 0.8867\n",
      "iteration number: 1097\t training loss: 691.0390\tvalidation loss: 263.3767\t validation accuracy: 0.8844\n",
      "iteration number: 1098\t training loss: 691.2847\tvalidation loss: 275.8633\t validation accuracy: 0.8756\n",
      "iteration number: 1099\t training loss: 687.3127\tvalidation loss: 275.0313\t validation accuracy: 0.8733\n",
      "iteration number: 1100\t training loss: 680.7840\tvalidation loss: 272.8459\t validation accuracy: 0.8756\n",
      "iteration number: 1101\t training loss: 669.2391\tvalidation loss: 267.8419\t validation accuracy: 0.8800\n",
      "iteration number: 1102\t training loss: 656.3531\tvalidation loss: 247.7606\t validation accuracy: 0.8956\n",
      "iteration number: 1103\t training loss: 649.1416\tvalidation loss: 243.1849\t validation accuracy: 0.9044\n",
      "iteration number: 1104\t training loss: 642.2891\tvalidation loss: 238.8365\t validation accuracy: 0.9044\n",
      "iteration number: 1105\t training loss: 635.8106\tvalidation loss: 234.5398\t validation accuracy: 0.9200\n",
      "iteration number: 1106\t training loss: 632.1876\tvalidation loss: 231.9685\t validation accuracy: 0.9289\n",
      "iteration number: 1107\t training loss: 631.7537\tvalidation loss: 231.1428\t validation accuracy: 0.9444\n",
      "iteration number: 1108\t training loss: 635.9401\tvalidation loss: 232.6020\t validation accuracy: 0.9467\n",
      "iteration number: 1109\t training loss: 642.6518\tvalidation loss: 248.9498\t validation accuracy: 0.9489\n",
      "iteration number: 1110\t training loss: 652.3604\tvalidation loss: 252.8333\t validation accuracy: 0.9467\n",
      "iteration number: 1111\t training loss: 665.6656\tvalidation loss: 258.9235\t validation accuracy: 0.9422\n",
      "iteration number: 1112\t training loss: 679.8421\tvalidation loss: 253.9997\t validation accuracy: 0.9333\n",
      "iteration number: 1113\t training loss: 692.2887\tvalidation loss: 259.5718\t validation accuracy: 0.9200\n",
      "iteration number: 1114\t training loss: 706.2751\tvalidation loss: 269.2326\t validation accuracy: 0.9089\n",
      "iteration number: 1115\t training loss: 721.2058\tvalidation loss: 305.1741\t validation accuracy: 0.9044\n",
      "iteration number: 1116\t training loss: 734.5879\tvalidation loss: 314.5074\t validation accuracy: 0.9044\n",
      "iteration number: 1117\t training loss: 747.3525\tvalidation loss: 334.4491\t validation accuracy: 0.8800\n",
      "iteration number: 1118\t training loss: 758.9739\tvalidation loss: 340.7099\t validation accuracy: 0.8756\n",
      "iteration number: 1119\t training loss: 768.9514\tvalidation loss: 353.8715\t validation accuracy: 0.8689\n",
      "iteration number: 1120\t training loss: 739.8465\tvalidation loss: 332.7704\t validation accuracy: 0.8667\n",
      "iteration number: 1121\t training loss: 722.3870\tvalidation loss: 309.6824\t validation accuracy: 0.8733\n",
      "iteration number: 1122\t training loss: 706.9512\tvalidation loss: 286.8051\t validation accuracy: 0.8733\n",
      "iteration number: 1123\t training loss: 691.9925\tvalidation loss: 278.0934\t validation accuracy: 0.8844\n",
      "iteration number: 1124\t training loss: 678.8107\tvalidation loss: 256.4541\t validation accuracy: 0.8889\n",
      "iteration number: 1125\t training loss: 665.0318\tvalidation loss: 248.7595\t validation accuracy: 0.8911\n",
      "iteration number: 1126\t training loss: 652.5175\tvalidation loss: 242.4605\t validation accuracy: 0.8978\n",
      "iteration number: 1127\t training loss: 644.7983\tvalidation loss: 238.5819\t validation accuracy: 0.8956\n",
      "iteration number: 1128\t training loss: 638.7060\tvalidation loss: 235.6390\t validation accuracy: 0.8978\n",
      "iteration number: 1129\t training loss: 634.2021\tvalidation loss: 233.5514\t validation accuracy: 0.8978\n",
      "iteration number: 1130\t training loss: 631.8639\tvalidation loss: 232.5215\t validation accuracy: 0.9022\n",
      "iteration number: 1131\t training loss: 633.5699\tvalidation loss: 233.4207\t validation accuracy: 0.9067\n",
      "iteration number: 1132\t training loss: 638.1638\tvalidation loss: 235.8367\t validation accuracy: 0.9044\n",
      "iteration number: 1133\t training loss: 641.8497\tvalidation loss: 238.0673\t validation accuracy: 0.9044\n",
      "iteration number: 1134\t training loss: 647.5447\tvalidation loss: 241.1054\t validation accuracy: 0.9089\n",
      "iteration number: 1135\t training loss: 656.3410\tvalidation loss: 246.0815\t validation accuracy: 0.9044\n",
      "iteration number: 1136\t training loss: 666.1267\tvalidation loss: 251.6552\t validation accuracy: 0.9022\n",
      "iteration number: 1137\t training loss: 677.9653\tvalidation loss: 259.1503\t validation accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1138\t training loss: 685.3083\tvalidation loss: 263.8032\t validation accuracy: 0.8978\n",
      "iteration number: 1139\t training loss: 693.9867\tvalidation loss: 268.5183\t validation accuracy: 0.8978\n",
      "iteration number: 1140\t training loss: 699.2000\tvalidation loss: 268.7558\t validation accuracy: 0.8956\n",
      "iteration number: 1141\t training loss: 702.5260\tvalidation loss: 269.4409\t validation accuracy: 0.8956\n",
      "iteration number: 1142\t training loss: 703.3166\tvalidation loss: 269.4607\t validation accuracy: 0.8933\n",
      "iteration number: 1143\t training loss: 699.8087\tvalidation loss: 266.7190\t validation accuracy: 0.8978\n",
      "iteration number: 1144\t training loss: 694.3190\tvalidation loss: 263.7045\t validation accuracy: 0.8933\n",
      "iteration number: 1145\t training loss: 682.4774\tvalidation loss: 256.8150\t validation accuracy: 0.8933\n",
      "iteration number: 1146\t training loss: 670.5651\tvalidation loss: 250.6413\t validation accuracy: 0.9000\n",
      "iteration number: 1147\t training loss: 660.5823\tvalidation loss: 245.8237\t validation accuracy: 0.9022\n",
      "iteration number: 1148\t training loss: 654.9465\tvalidation loss: 243.2992\t validation accuracy: 0.9067\n",
      "iteration number: 1149\t training loss: 652.6945\tvalidation loss: 242.3638\t validation accuracy: 0.9067\n",
      "iteration number: 1150\t training loss: 652.5415\tvalidation loss: 242.6108\t validation accuracy: 0.9000\n",
      "iteration number: 1151\t training loss: 651.2992\tvalidation loss: 242.2576\t validation accuracy: 0.9000\n",
      "iteration number: 1152\t training loss: 650.5554\tvalidation loss: 241.9978\t validation accuracy: 0.8978\n",
      "iteration number: 1153\t training loss: 650.3007\tvalidation loss: 242.0242\t validation accuracy: 0.9000\n",
      "iteration number: 1154\t training loss: 650.0883\tvalidation loss: 242.4305\t validation accuracy: 0.9022\n",
      "iteration number: 1155\t training loss: 647.2916\tvalidation loss: 241.6923\t validation accuracy: 0.9067\n",
      "iteration number: 1156\t training loss: 645.0224\tvalidation loss: 240.8881\t validation accuracy: 0.9044\n",
      "iteration number: 1157\t training loss: 641.3032\tvalidation loss: 239.2912\t validation accuracy: 0.9044\n",
      "iteration number: 1158\t training loss: 639.8688\tvalidation loss: 238.8306\t validation accuracy: 0.9022\n",
      "iteration number: 1159\t training loss: 639.0987\tvalidation loss: 238.8125\t validation accuracy: 0.8978\n",
      "iteration number: 1160\t training loss: 636.6316\tvalidation loss: 237.8850\t validation accuracy: 0.8978\n",
      "iteration number: 1161\t training loss: 635.6584\tvalidation loss: 237.4203\t validation accuracy: 0.9000\n",
      "iteration number: 1162\t training loss: 637.9081\tvalidation loss: 238.7625\t validation accuracy: 0.9000\n",
      "iteration number: 1163\t training loss: 640.6082\tvalidation loss: 240.6247\t validation accuracy: 0.9000\n",
      "iteration number: 1164\t training loss: 645.0574\tvalidation loss: 242.9385\t validation accuracy: 0.9000\n",
      "iteration number: 1165\t training loss: 648.2944\tvalidation loss: 244.8009\t validation accuracy: 0.9022\n",
      "iteration number: 1166\t training loss: 647.8344\tvalidation loss: 244.3169\t validation accuracy: 0.9000\n",
      "iteration number: 1167\t training loss: 647.7821\tvalidation loss: 244.3713\t validation accuracy: 0.9022\n",
      "iteration number: 1168\t training loss: 647.3655\tvalidation loss: 244.1106\t validation accuracy: 0.9044\n",
      "iteration number: 1169\t training loss: 646.9220\tvalidation loss: 243.5320\t validation accuracy: 0.9044\n",
      "iteration number: 1170\t training loss: 649.0047\tvalidation loss: 244.2023\t validation accuracy: 0.9044\n",
      "iteration number: 1171\t training loss: 653.2936\tvalidation loss: 245.2595\t validation accuracy: 0.9089\n",
      "iteration number: 1172\t training loss: 659.1222\tvalidation loss: 246.8847\t validation accuracy: 0.9067\n",
      "iteration number: 1173\t training loss: 664.6989\tvalidation loss: 248.5498\t validation accuracy: 0.9111\n",
      "iteration number: 1174\t training loss: 668.8649\tvalidation loss: 250.1790\t validation accuracy: 0.9089\n",
      "iteration number: 1175\t training loss: 672.1296\tvalidation loss: 251.8508\t validation accuracy: 0.9044\n",
      "iteration number: 1176\t training loss: 674.8267\tvalidation loss: 253.5952\t validation accuracy: 0.9000\n",
      "iteration number: 1177\t training loss: 677.5474\tvalidation loss: 255.6060\t validation accuracy: 0.8978\n",
      "iteration number: 1178\t training loss: 681.2625\tvalidation loss: 258.1803\t validation accuracy: 0.8956\n",
      "iteration number: 1179\t training loss: 683.5770\tvalidation loss: 259.7214\t validation accuracy: 0.8933\n",
      "iteration number: 1180\t training loss: 680.1457\tvalidation loss: 258.7784\t validation accuracy: 0.8911\n",
      "iteration number: 1181\t training loss: 674.2495\tvalidation loss: 256.9903\t validation accuracy: 0.8911\n",
      "iteration number: 1182\t training loss: 662.1143\tvalidation loss: 251.7647\t validation accuracy: 0.8956\n",
      "iteration number: 1183\t training loss: 649.7940\tvalidation loss: 246.9625\t validation accuracy: 0.8956\n",
      "iteration number: 1184\t training loss: 637.6361\tvalidation loss: 241.9193\t validation accuracy: 0.9000\n",
      "iteration number: 1185\t training loss: 625.6572\tvalidation loss: 237.1096\t validation accuracy: 0.9000\n",
      "iteration number: 1186\t training loss: 616.6065\tvalidation loss: 233.7122\t validation accuracy: 0.9000\n",
      "iteration number: 1187\t training loss: 607.8434\tvalidation loss: 229.7462\t validation accuracy: 0.9044\n",
      "iteration number: 1188\t training loss: 604.6123\tvalidation loss: 228.1674\t validation accuracy: 0.9044\n",
      "iteration number: 1189\t training loss: 602.0931\tvalidation loss: 226.5862\t validation accuracy: 0.9089\n",
      "iteration number: 1190\t training loss: 600.4506\tvalidation loss: 225.5087\t validation accuracy: 0.9111\n",
      "iteration number: 1191\t training loss: 602.9655\tvalidation loss: 226.0528\t validation accuracy: 0.9111\n",
      "iteration number: 1192\t training loss: 607.1939\tvalidation loss: 227.1648\t validation accuracy: 0.9133\n",
      "iteration number: 1193\t training loss: 611.7808\tvalidation loss: 228.3367\t validation accuracy: 0.9178\n",
      "iteration number: 1194\t training loss: 617.1726\tvalidation loss: 229.5578\t validation accuracy: 0.9178\n",
      "iteration number: 1195\t training loss: 623.3616\tvalidation loss: 231.1618\t validation accuracy: 0.9178\n",
      "iteration number: 1196\t training loss: 628.8101\tvalidation loss: 232.7624\t validation accuracy: 0.9178\n",
      "iteration number: 1197\t training loss: 633.4079\tvalidation loss: 234.4610\t validation accuracy: 0.9156\n",
      "iteration number: 1198\t training loss: 639.5112\tvalidation loss: 236.9662\t validation accuracy: 0.9156\n",
      "iteration number: 1199\t training loss: 647.3986\tvalidation loss: 240.5685\t validation accuracy: 0.9089\n",
      "iteration number: 1200\t training loss: 655.8843\tvalidation loss: 244.5172\t validation accuracy: 0.9111\n",
      "iteration number: 1201\t training loss: 663.3771\tvalidation loss: 248.5424\t validation accuracy: 0.9089\n",
      "iteration number: 1202\t training loss: 668.7213\tvalidation loss: 251.7761\t validation accuracy: 0.9089\n",
      "iteration number: 1203\t training loss: 670.0167\tvalidation loss: 252.9627\t validation accuracy: 0.9089\n",
      "iteration number: 1204\t training loss: 669.6315\tvalidation loss: 253.7508\t validation accuracy: 0.9089\n",
      "iteration number: 1205\t training loss: 665.0125\tvalidation loss: 252.1587\t validation accuracy: 0.9067\n",
      "iteration number: 1206\t training loss: 660.7969\tvalidation loss: 250.5500\t validation accuracy: 0.9022\n",
      "iteration number: 1207\t training loss: 656.9724\tvalidation loss: 248.8510\t validation accuracy: 0.9044\n",
      "iteration number: 1208\t training loss: 655.8164\tvalidation loss: 248.1346\t validation accuracy: 0.9022\n",
      "iteration number: 1209\t training loss: 650.2788\tvalidation loss: 245.1924\t validation accuracy: 0.8978\n",
      "iteration number: 1210\t training loss: 646.4433\tvalidation loss: 242.9806\t validation accuracy: 0.8956\n",
      "iteration number: 1211\t training loss: 644.5521\tvalidation loss: 241.9944\t validation accuracy: 0.8978\n",
      "iteration number: 1212\t training loss: 643.1869\tvalidation loss: 241.5513\t validation accuracy: 0.8978\n",
      "iteration number: 1213\t training loss: 640.0601\tvalidation loss: 240.5580\t validation accuracy: 0.9000\n",
      "iteration number: 1214\t training loss: 636.5611\tvalidation loss: 252.3513\t validation accuracy: 0.9022\n",
      "iteration number: 1215\t training loss: 633.7625\tvalidation loss: 251.3161\t validation accuracy: 0.9044\n",
      "iteration number: 1216\t training loss: 629.4651\tvalidation loss: 235.8313\t validation accuracy: 0.9000\n",
      "iteration number: 1217\t training loss: 626.4151\tvalidation loss: 234.2809\t validation accuracy: 0.8956\n",
      "iteration number: 1218\t training loss: 624.7939\tvalidation loss: 234.2300\t validation accuracy: 0.8956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1219\t training loss: 626.2250\tvalidation loss: 235.8960\t validation accuracy: 0.9022\n",
      "iteration number: 1220\t training loss: 623.4879\tvalidation loss: 235.5240\t validation accuracy: 0.9111\n",
      "iteration number: 1221\t training loss: 622.5295\tvalidation loss: 235.7220\t validation accuracy: 0.9111\n",
      "iteration number: 1222\t training loss: 624.0347\tvalidation loss: 236.9710\t validation accuracy: 0.9111\n",
      "iteration number: 1223\t training loss: 624.1173\tvalidation loss: 237.4881\t validation accuracy: 0.9156\n",
      "iteration number: 1224\t training loss: 625.1141\tvalidation loss: 238.3005\t validation accuracy: 0.9178\n",
      "iteration number: 1225\t training loss: 625.5183\tvalidation loss: 238.6459\t validation accuracy: 0.9178\n",
      "iteration number: 1226\t training loss: 627.3557\tvalidation loss: 239.0689\t validation accuracy: 0.9156\n",
      "iteration number: 1227\t training loss: 629.0459\tvalidation loss: 238.7735\t validation accuracy: 0.9156\n",
      "iteration number: 1228\t training loss: 632.2537\tvalidation loss: 239.5301\t validation accuracy: 0.9178\n",
      "iteration number: 1229\t training loss: 636.2386\tvalidation loss: 240.7430\t validation accuracy: 0.9133\n",
      "iteration number: 1230\t training loss: 640.5422\tvalidation loss: 242.0289\t validation accuracy: 0.9067\n",
      "iteration number: 1231\t training loss: 643.9142\tvalidation loss: 243.0790\t validation accuracy: 0.9044\n",
      "iteration number: 1232\t training loss: 647.4564\tvalidation loss: 244.2876\t validation accuracy: 0.9000\n",
      "iteration number: 1233\t training loss: 651.5243\tvalidation loss: 246.5503\t validation accuracy: 0.9000\n",
      "iteration number: 1234\t training loss: 655.8895\tvalidation loss: 248.7576\t validation accuracy: 0.8956\n",
      "iteration number: 1235\t training loss: 658.8426\tvalidation loss: 263.2139\t validation accuracy: 0.8933\n",
      "iteration number: 1236\t training loss: 661.1646\tvalidation loss: 263.8173\t validation accuracy: 0.8933\n",
      "iteration number: 1237\t training loss: 662.1167\tvalidation loss: 264.1115\t validation accuracy: 0.8933\n",
      "iteration number: 1238\t training loss: 656.4663\tvalidation loss: 249.4398\t validation accuracy: 0.8933\n",
      "iteration number: 1239\t training loss: 649.9072\tvalidation loss: 245.5233\t validation accuracy: 0.8911\n",
      "iteration number: 1240\t training loss: 639.9794\tvalidation loss: 241.3383\t validation accuracy: 0.8933\n",
      "iteration number: 1241\t training loss: 629.4971\tvalidation loss: 237.4277\t validation accuracy: 0.8956\n",
      "iteration number: 1242\t training loss: 620.0905\tvalidation loss: 233.9409\t validation accuracy: 0.8978\n",
      "iteration number: 1243\t training loss: 609.9973\tvalidation loss: 229.6943\t validation accuracy: 0.9022\n",
      "iteration number: 1244\t training loss: 603.2254\tvalidation loss: 227.2135\t validation accuracy: 0.9000\n",
      "iteration number: 1245\t training loss: 598.3800\tvalidation loss: 225.4470\t validation accuracy: 0.9022\n",
      "iteration number: 1246\t training loss: 596.8622\tvalidation loss: 224.6115\t validation accuracy: 0.9044\n",
      "iteration number: 1247\t training loss: 598.6324\tvalidation loss: 224.9545\t validation accuracy: 0.9089\n",
      "iteration number: 1248\t training loss: 602.1799\tvalidation loss: 225.9438\t validation accuracy: 0.9111\n",
      "iteration number: 1249\t training loss: 609.0204\tvalidation loss: 228.7016\t validation accuracy: 0.9133\n",
      "iteration number: 1250\t training loss: 617.3320\tvalidation loss: 232.3912\t validation accuracy: 0.9133\n",
      "iteration number: 1251\t training loss: 628.1680\tvalidation loss: 237.8698\t validation accuracy: 0.9133\n",
      "iteration number: 1252\t training loss: 636.8549\tvalidation loss: 242.5148\t validation accuracy: 0.9067\n",
      "iteration number: 1253\t training loss: 645.5159\tvalidation loss: 246.5637\t validation accuracy: 0.9044\n",
      "iteration number: 1254\t training loss: 649.1105\tvalidation loss: 247.9520\t validation accuracy: 0.9000\n",
      "iteration number: 1255\t training loss: 651.0948\tvalidation loss: 248.7455\t validation accuracy: 0.9000\n",
      "iteration number: 1256\t training loss: 650.3085\tvalidation loss: 248.0247\t validation accuracy: 0.8978\n",
      "iteration number: 1257\t training loss: 649.1858\tvalidation loss: 247.4810\t validation accuracy: 0.8933\n",
      "iteration number: 1258\t training loss: 647.4292\tvalidation loss: 259.4065\t validation accuracy: 0.8978\n",
      "iteration number: 1259\t training loss: 646.7826\tvalidation loss: 258.5411\t validation accuracy: 0.9000\n",
      "iteration number: 1260\t training loss: 645.1198\tvalidation loss: 257.3250\t validation accuracy: 0.8978\n",
      "iteration number: 1261\t training loss: 644.7009\tvalidation loss: 256.7036\t validation accuracy: 0.9000\n",
      "iteration number: 1262\t training loss: 644.6565\tvalidation loss: 257.0631\t validation accuracy: 0.9000\n",
      "iteration number: 1263\t training loss: 643.5894\tvalidation loss: 244.9725\t validation accuracy: 0.9000\n",
      "iteration number: 1264\t training loss: 641.1906\tvalidation loss: 243.6879\t validation accuracy: 0.9000\n",
      "iteration number: 1265\t training loss: 635.0980\tvalidation loss: 241.9976\t validation accuracy: 0.8956\n",
      "iteration number: 1266\t training loss: 630.9822\tvalidation loss: 241.0567\t validation accuracy: 0.8978\n",
      "iteration number: 1267\t training loss: 626.8085\tvalidation loss: 240.3680\t validation accuracy: 0.8956\n",
      "iteration number: 1268\t training loss: 620.9474\tvalidation loss: 239.1022\t validation accuracy: 0.8956\n",
      "iteration number: 1269\t training loss: 618.2492\tvalidation loss: 238.7766\t validation accuracy: 0.8933\n",
      "iteration number: 1270\t training loss: 617.2971\tvalidation loss: 239.7493\t validation accuracy: 0.8911\n",
      "iteration number: 1271\t training loss: 614.9289\tvalidation loss: 239.7187\t validation accuracy: 0.8911\n",
      "iteration number: 1272\t training loss: 612.3907\tvalidation loss: 239.0201\t validation accuracy: 0.8911\n",
      "iteration number: 1273\t training loss: 610.6702\tvalidation loss: 238.3736\t validation accuracy: 0.8911\n",
      "iteration number: 1274\t training loss: 610.2530\tvalidation loss: 237.4521\t validation accuracy: 0.8889\n",
      "iteration number: 1275\t training loss: 611.0330\tvalidation loss: 236.9050\t validation accuracy: 0.8956\n",
      "iteration number: 1276\t training loss: 612.2519\tvalidation loss: 235.6460\t validation accuracy: 0.9022\n",
      "iteration number: 1277\t training loss: 613.0370\tvalidation loss: 233.5943\t validation accuracy: 0.9044\n",
      "iteration number: 1278\t training loss: 614.8632\tvalidation loss: 232.6213\t validation accuracy: 0.9067\n",
      "iteration number: 1279\t training loss: 614.5019\tvalidation loss: 231.4456\t validation accuracy: 0.9089\n",
      "iteration number: 1280\t training loss: 615.2053\tvalidation loss: 230.9749\t validation accuracy: 0.9156\n",
      "iteration number: 1281\t training loss: 617.1003\tvalidation loss: 231.7375\t validation accuracy: 0.9156\n",
      "iteration number: 1282\t training loss: 617.5418\tvalidation loss: 231.7728\t validation accuracy: 0.9133\n",
      "iteration number: 1283\t training loss: 614.2896\tvalidation loss: 230.7310\t validation accuracy: 0.9089\n",
      "iteration number: 1284\t training loss: 615.4458\tvalidation loss: 231.5505\t validation accuracy: 0.9022\n",
      "iteration number: 1285\t training loss: 618.2847\tvalidation loss: 233.3691\t validation accuracy: 0.9000\n",
      "iteration number: 1286\t training loss: 622.3805\tvalidation loss: 235.6861\t validation accuracy: 0.9000\n",
      "iteration number: 1287\t training loss: 626.1261\tvalidation loss: 238.0418\t validation accuracy: 0.8956\n",
      "iteration number: 1288\t training loss: 625.8211\tvalidation loss: 237.9817\t validation accuracy: 0.8933\n",
      "iteration number: 1289\t training loss: 623.1283\tvalidation loss: 237.0040\t validation accuracy: 0.8911\n",
      "iteration number: 1290\t training loss: 618.9542\tvalidation loss: 235.4849\t validation accuracy: 0.8889\n",
      "iteration number: 1291\t training loss: 612.5796\tvalidation loss: 233.0275\t validation accuracy: 0.8933\n",
      "iteration number: 1292\t training loss: 607.7954\tvalidation loss: 231.4353\t validation accuracy: 0.8911\n",
      "iteration number: 1293\t training loss: 604.2237\tvalidation loss: 230.0571\t validation accuracy: 0.8911\n",
      "iteration number: 1294\t training loss: 601.5541\tvalidation loss: 229.3905\t validation accuracy: 0.8889\n",
      "iteration number: 1295\t training loss: 600.1718\tvalidation loss: 229.3927\t validation accuracy: 0.8889\n",
      "iteration number: 1296\t training loss: 596.7469\tvalidation loss: 228.4894\t validation accuracy: 0.8911\n",
      "iteration number: 1297\t training loss: 595.9212\tvalidation loss: 228.7644\t validation accuracy: 0.8911\n",
      "iteration number: 1298\t training loss: 594.3401\tvalidation loss: 228.5082\t validation accuracy: 0.8956\n",
      "iteration number: 1299\t training loss: 593.8634\tvalidation loss: 228.0235\t validation accuracy: 0.9000\n",
      "iteration number: 1300\t training loss: 595.2646\tvalidation loss: 228.7013\t validation accuracy: 0.9044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1301\t training loss: 600.4985\tvalidation loss: 230.4721\t validation accuracy: 0.9111\n",
      "iteration number: 1302\t training loss: 604.6972\tvalidation loss: 231.4276\t validation accuracy: 0.9156\n",
      "iteration number: 1303\t training loss: 610.7284\tvalidation loss: 232.9363\t validation accuracy: 0.9244\n",
      "iteration number: 1304\t training loss: 617.3840\tvalidation loss: 234.3581\t validation accuracy: 0.9267\n",
      "iteration number: 1305\t training loss: 625.8282\tvalidation loss: 237.1825\t validation accuracy: 0.9244\n",
      "iteration number: 1306\t training loss: 634.4489\tvalidation loss: 240.6931\t validation accuracy: 0.9156\n",
      "iteration number: 1307\t training loss: 644.6888\tvalidation loss: 245.6372\t validation accuracy: 0.9111\n",
      "iteration number: 1308\t training loss: 650.1460\tvalidation loss: 248.4439\t validation accuracy: 0.9000\n",
      "iteration number: 1309\t training loss: 655.7559\tvalidation loss: 251.5236\t validation accuracy: 0.8911\n",
      "iteration number: 1310\t training loss: 655.0627\tvalidation loss: 251.0009\t validation accuracy: 0.8867\n",
      "iteration number: 1311\t training loss: 654.3562\tvalidation loss: 251.0205\t validation accuracy: 0.8822\n",
      "iteration number: 1312\t training loss: 650.3159\tvalidation loss: 249.0133\t validation accuracy: 0.8689\n",
      "iteration number: 1313\t training loss: 643.3254\tvalidation loss: 245.6870\t validation accuracy: 0.8689\n",
      "iteration number: 1314\t training loss: 634.4429\tvalidation loss: 242.0460\t validation accuracy: 0.8667\n",
      "iteration number: 1315\t training loss: 618.6718\tvalidation loss: 234.9292\t validation accuracy: 0.8733\n",
      "iteration number: 1316\t training loss: 601.7686\tvalidation loss: 227.6718\t validation accuracy: 0.8844\n",
      "iteration number: 1317\t training loss: 588.2215\tvalidation loss: 221.8248\t validation accuracy: 0.8933\n",
      "iteration number: 1318\t training loss: 577.6160\tvalidation loss: 217.4071\t validation accuracy: 0.8956\n",
      "iteration number: 1319\t training loss: 566.7759\tvalidation loss: 212.9253\t validation accuracy: 0.9044\n",
      "iteration number: 1320\t training loss: 559.4991\tvalidation loss: 209.9982\t validation accuracy: 0.9222\n",
      "iteration number: 1321\t training loss: 554.7622\tvalidation loss: 208.1509\t validation accuracy: 0.9267\n",
      "iteration number: 1322\t training loss: 549.7501\tvalidation loss: 206.0125\t validation accuracy: 0.9356\n",
      "iteration number: 1323\t training loss: 547.0499\tvalidation loss: 204.8465\t validation accuracy: 0.9356\n",
      "iteration number: 1324\t training loss: 548.8736\tvalidation loss: 205.7652\t validation accuracy: 0.9400\n",
      "iteration number: 1325\t training loss: 553.3229\tvalidation loss: 208.2203\t validation accuracy: 0.9333\n",
      "iteration number: 1326\t training loss: 559.8970\tvalidation loss: 211.2967\t validation accuracy: 0.9311\n",
      "iteration number: 1327\t training loss: 569.1833\tvalidation loss: 215.2385\t validation accuracy: 0.9289\n",
      "iteration number: 1328\t training loss: 580.8768\tvalidation loss: 219.8256\t validation accuracy: 0.9244\n",
      "iteration number: 1329\t training loss: 593.2622\tvalidation loss: 225.0047\t validation accuracy: 0.9222\n",
      "iteration number: 1330\t training loss: 607.3272\tvalidation loss: 232.0567\t validation accuracy: 0.9111\n",
      "iteration number: 1331\t training loss: 621.0321\tvalidation loss: 251.1861\t validation accuracy: 0.9089\n",
      "iteration number: 1332\t training loss: 634.4156\tvalidation loss: 257.1662\t validation accuracy: 0.9089\n",
      "iteration number: 1333\t training loss: 641.9234\tvalidation loss: 249.0715\t validation accuracy: 0.9000\n",
      "iteration number: 1334\t training loss: 645.8397\tvalidation loss: 250.2483\t validation accuracy: 0.9022\n",
      "iteration number: 1335\t training loss: 647.8477\tvalidation loss: 251.5313\t validation accuracy: 0.8978\n",
      "iteration number: 1336\t training loss: 647.6216\tvalidation loss: 251.7853\t validation accuracy: 0.8956\n",
      "iteration number: 1337\t training loss: 645.0526\tvalidation loss: 250.4443\t validation accuracy: 0.8911\n",
      "iteration number: 1338\t training loss: 636.1834\tvalidation loss: 246.3635\t validation accuracy: 0.8956\n",
      "iteration number: 1339\t training loss: 626.0616\tvalidation loss: 242.3884\t validation accuracy: 0.8933\n",
      "iteration number: 1340\t training loss: 612.6446\tvalidation loss: 237.0426\t validation accuracy: 0.8956\n",
      "iteration number: 1341\t training loss: 599.6310\tvalidation loss: 232.2215\t validation accuracy: 0.8956\n",
      "iteration number: 1342\t training loss: 586.4904\tvalidation loss: 227.6288\t validation accuracy: 0.8956\n",
      "iteration number: 1343\t training loss: 575.0866\tvalidation loss: 224.6544\t validation accuracy: 0.8956\n",
      "iteration number: 1344\t training loss: 568.5343\tvalidation loss: 232.0795\t validation accuracy: 0.8978\n",
      "iteration number: 1345\t training loss: 564.1246\tvalidation loss: 218.9845\t validation accuracy: 0.9000\n",
      "iteration number: 1346\t training loss: 559.4053\tvalidation loss: 215.3040\t validation accuracy: 0.9000\n",
      "iteration number: 1347\t training loss: 556.1397\tvalidation loss: 213.4165\t validation accuracy: 0.9044\n",
      "iteration number: 1348\t training loss: 553.9107\tvalidation loss: 211.5397\t validation accuracy: 0.9178\n",
      "iteration number: 1349\t training loss: 554.6013\tvalidation loss: 211.1876\t validation accuracy: 0.9244\n",
      "iteration number: 1350\t training loss: 560.2335\tvalidation loss: 213.0809\t validation accuracy: 0.9311\n",
      "iteration number: 1351\t training loss: 570.5564\tvalidation loss: 216.8835\t validation accuracy: 0.9333\n",
      "iteration number: 1352\t training loss: 585.4215\tvalidation loss: 223.2795\t validation accuracy: 0.9311\n",
      "iteration number: 1353\t training loss: 599.4581\tvalidation loss: 229.5014\t validation accuracy: 0.9311\n",
      "iteration number: 1354\t training loss: 611.2643\tvalidation loss: 235.3864\t validation accuracy: 0.9200\n",
      "iteration number: 1355\t training loss: 619.5240\tvalidation loss: 240.6864\t validation accuracy: 0.9178\n",
      "iteration number: 1356\t training loss: 624.4029\tvalidation loss: 256.1534\t validation accuracy: 0.9156\n",
      "iteration number: 1357\t training loss: 621.3246\tvalidation loss: 255.3448\t validation accuracy: 0.9111\n",
      "iteration number: 1358\t training loss: 615.6190\tvalidation loss: 253.4332\t validation accuracy: 0.9111\n",
      "iteration number: 1359\t training loss: 610.7092\tvalidation loss: 251.7572\t validation accuracy: 0.9111\n",
      "iteration number: 1360\t training loss: 603.6941\tvalidation loss: 234.6065\t validation accuracy: 0.9089\n",
      "iteration number: 1361\t training loss: 596.2908\tvalidation loss: 230.7548\t validation accuracy: 0.9067\n",
      "iteration number: 1362\t training loss: 585.9190\tvalidation loss: 225.9063\t validation accuracy: 0.9022\n",
      "iteration number: 1363\t training loss: 577.2742\tvalidation loss: 221.7869\t validation accuracy: 0.9044\n",
      "iteration number: 1364\t training loss: 573.7489\tvalidation loss: 220.0440\t validation accuracy: 0.9044\n",
      "iteration number: 1365\t training loss: 572.1881\tvalidation loss: 218.8552\t validation accuracy: 0.9067\n",
      "iteration number: 1366\t training loss: 572.0594\tvalidation loss: 218.5006\t validation accuracy: 0.9067\n",
      "iteration number: 1367\t training loss: 571.9279\tvalidation loss: 217.6870\t validation accuracy: 0.9067\n",
      "iteration number: 1368\t training loss: 570.3432\tvalidation loss: 216.5503\t validation accuracy: 0.9067\n",
      "iteration number: 1369\t training loss: 568.8360\tvalidation loss: 215.5262\t validation accuracy: 0.9044\n",
      "iteration number: 1370\t training loss: 569.9378\tvalidation loss: 215.8203\t validation accuracy: 0.9089\n",
      "iteration number: 1371\t training loss: 572.9063\tvalidation loss: 217.5735\t validation accuracy: 0.9067\n",
      "iteration number: 1372\t training loss: 577.3442\tvalidation loss: 220.1998\t validation accuracy: 0.9067\n",
      "iteration number: 1373\t training loss: 584.0787\tvalidation loss: 223.7729\t validation accuracy: 0.9067\n",
      "iteration number: 1374\t training loss: 592.5052\tvalidation loss: 228.0121\t validation accuracy: 0.9089\n",
      "iteration number: 1375\t training loss: 597.5927\tvalidation loss: 230.7081\t validation accuracy: 0.9089\n",
      "iteration number: 1376\t training loss: 599.5783\tvalidation loss: 231.5164\t validation accuracy: 0.9111\n",
      "iteration number: 1377\t training loss: 604.4619\tvalidation loss: 233.3767\t validation accuracy: 0.9111\n",
      "iteration number: 1378\t training loss: 607.4436\tvalidation loss: 234.5300\t validation accuracy: 0.9089\n",
      "iteration number: 1379\t training loss: 612.3963\tvalidation loss: 236.2859\t validation accuracy: 0.9067\n",
      "iteration number: 1380\t training loss: 614.1902\tvalidation loss: 236.2644\t validation accuracy: 0.9044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 1381\t training loss: 615.4439\tvalidation loss: 236.2104\t validation accuracy: 0.9044\n",
      "iteration number: 1382\t training loss: 614.2721\tvalidation loss: 235.2756\t validation accuracy: 0.9089\n",
      "iteration number: 1383\t training loss: 612.5663\tvalidation loss: 234.2723\t validation accuracy: 0.9089\n",
      "iteration number: 1384\t training loss: 608.5653\tvalidation loss: 232.4750\t validation accuracy: 0.9067\n",
      "iteration number: 1385\t training loss: 603.2117\tvalidation loss: 230.4073\t validation accuracy: 0.9044\n",
      "iteration number: 1386\t training loss: 598.1760\tvalidation loss: 228.4566\t validation accuracy: 0.9044\n",
      "iteration number: 1387\t training loss: 590.5720\tvalidation loss: 225.5588\t validation accuracy: 0.9044\n",
      "iteration number: 1388\t training loss: 585.9572\tvalidation loss: 224.1767\t validation accuracy: 0.9044\n",
      "iteration number: 1389\t training loss: 581.6768\tvalidation loss: 223.0140\t validation accuracy: 0.9067\n",
      "iteration number: 1390\t training loss: 575.9139\tvalidation loss: 221.2819\t validation accuracy: 0.9022\n",
      "iteration number: 1391\t training loss: 571.9928\tvalidation loss: 220.6002\t validation accuracy: 0.9000\n",
      "iteration number: 1392\t training loss: 566.8606\tvalidation loss: 219.3263\t validation accuracy: 0.8978\n",
      "iteration number: 1393\t training loss: 561.7437\tvalidation loss: 217.8887\t validation accuracy: 0.8978\n",
      "iteration number: 1394\t training loss: 558.1834\tvalidation loss: 218.9727\t validation accuracy: 0.8978\n",
      "iteration number: 1395\t training loss: 554.5167\tvalidation loss: 229.7424\t validation accuracy: 0.8978\n",
      "iteration number: 1396\t training loss: 552.2584\tvalidation loss: 229.0280\t validation accuracy: 0.8978\n",
      "iteration number: 1397\t training loss: 552.5498\tvalidation loss: 229.2073\t validation accuracy: 0.8978\n",
      "iteration number: 1398\t training loss: 555.0427\tvalidation loss: 230.4628\t validation accuracy: 0.8978\n",
      "iteration number: 1399\t training loss: 557.0059\tvalidation loss: 231.0354\t validation accuracy: 0.9022\n",
      "iteration number: 1400\t training loss: 561.0153\tvalidation loss: 231.6430\t validation accuracy: 0.9044\n",
      "iteration number: 1401\t training loss: 565.8963\tvalidation loss: 232.1782\t validation accuracy: 0.9067\n",
      "iteration number: 1402\t training loss: 570.6045\tvalidation loss: 232.3643\t validation accuracy: 0.9044\n",
      "iteration number: 1403\t training loss: 575.6290\tvalidation loss: 233.0188\t validation accuracy: 0.9111\n",
      "iteration number: 1404\t training loss: 584.8482\tvalidation loss: 235.9957\t validation accuracy: 0.9044\n",
      "iteration number: 1405\t training loss: 590.6384\tvalidation loss: 237.5388\t validation accuracy: 0.9089\n",
      "iteration number: 1406\t training loss: 597.1060\tvalidation loss: 240.3103\t validation accuracy: 0.9067\n",
      "iteration number: 1407\t training loss: 601.8468\tvalidation loss: 242.8068\t validation accuracy: 0.9044\n",
      "iteration number: 1408\t training loss: 602.1702\tvalidation loss: 243.6117\t validation accuracy: 0.9022\n",
      "iteration number: 1409\t training loss: 602.3880\tvalidation loss: 244.7691\t validation accuracy: 0.8978\n",
      "iteration number: 1410\t training loss: 602.1778\tvalidation loss: 232.1752\t validation accuracy: 0.8978\n",
      "iteration number: 1411\t training loss: 602.4664\tvalidation loss: 233.5126\t validation accuracy: 0.9000\n",
      "iteration number: 1412\t training loss: 601.1645\tvalidation loss: 235.2319\t validation accuracy: 0.9000\n",
      "iteration number: 1413\t training loss: 597.4904\tvalidation loss: 237.0834\t validation accuracy: 0.8911\n",
      "iteration number: 1414\t training loss: 591.3963\tvalidation loss: 247.9286\t validation accuracy: 0.8933\n",
      "iteration number: 1415\t training loss: 585.8288\tvalidation loss: 246.7606\t validation accuracy: 0.9044\n",
      "iteration number: 1416\t training loss: 580.4316\tvalidation loss: 245.2883\t validation accuracy: 0.9089\n",
      "iteration number: 1417\t training loss: 577.6767\tvalidation loss: 244.7015\t validation accuracy: 0.9111\n",
      "iteration number: 1418\t training loss: 573.0970\tvalidation loss: 242.5227\t validation accuracy: 0.9111\n",
      "iteration number: 1419\t training loss: 570.0559\tvalidation loss: 240.8629\t validation accuracy: 0.9111\n",
      "iteration number: 1420\t training loss: 566.6411\tvalidation loss: 228.1303\t validation accuracy: 0.9111\n",
      "iteration number: 1421\t training loss: 564.0060\tvalidation loss: 222.2493\t validation accuracy: 0.9111\n",
      "iteration number: 1422\t training loss: 562.2069\tvalidation loss: 219.7997\t validation accuracy: 0.9133\n",
      "iteration number: 1423\t training loss: 559.5961\tvalidation loss: 217.1554\t validation accuracy: 0.9156\n"
     ]
    }
   ],
   "source": [
    "mlp = MultiLayerPerceptron(X, Y, hidden_size=200, activation='relu',dropout=True, dropout_rate=0.35)\n",
    "mlp.train(momentum = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.plot_loss_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "#### - Did you succeed to train the MLP and get a high validation accuracy? <br> Display available metrics (training and validation accuracies, training and validation losses)\n",
    "\n",
    "Yes, we are able to train the network with a validation accuracy of up to 97%. We have tested a few different models with varying hyperparameters and optimizers and all of them seem to converge to around the same accuracy. You can see these models above and the various metrics that we are able to display. We notice that the validation loss looks considerably lower than the training loss which can be a sign of undefitting but this is due to the fact that there are less validation samples than training examples. We still see that the curves follow the same trend so they should converge at the same rate.\n",
    "\n",
    "#### - Plot the prediction for a given validation sample. Is it accurate?\n",
    "\n",
    "After training, we can plot the model predictions for a given sample after passing through the softmax activation function. This gives us the probabilities that our model assigns to each label. A lot of the time this prediction is accurate but we can see that with certain samples, our model has a hard time giving a very confident prediction and will hesitate between a few labels. This is due to the fact that some samples in the MNIST dataset are quite difficult to guess even for a human and that we have also reduced the dimension of the data\n",
    "\n",
    "#### - Compare the full gradient descent with the SGD.\n",
    "\n",
    "Standard gradient descent is a lot slower to train than SGD but it is a lot smoother. It also seemed to take more iterations until the algorithm stopped. However, we found that because GD is so smooth in the training loss, instead of stopping early the training function until the loss levels out to 1e-4 delta. We found that this resulted almost in overfitting where the train loss became much lower than the validation loss which we established earlier to be the opposite normally. To fight this overfitting we could add dropout to fight this overfitting but it wouldnt change the fact that standard gradient descent is very slow and ressource intensive. \n",
    "\n",
    "#### - Play with the hyper parameters you have: the hidden size, the activation function, the initial step and the batch size. <br> Comment. Don't hesitate to visualize results.\n",
    "\n",
    "After experimenting with all of the hyperparameters, it seems that they all have some influence over the model performance and it is possible that they could even interact with one another but here we will consider them seperately\n",
    "\n",
    "- hidden size: The hidden size is directly proportional to our model complexity. We can have multiple layers of hidden neurons and each layer can have a different number of neurons. In our example, we are only considering a single hidden layer to make the calculations of gradients easier. From testing we noticed that having very few neurons (less than 20) in our hidden layer negatively impacted on accuracy as our model is not complex enough to model the data. on the other hand having a lot of hidden neurons tends to marginally increase validation accuracy and requires some dropout so that we dont overfit.\n",
    "\n",
    "- activation function: We have tested two different activation functions: ReLU and sigmoid, from testing it seems like ReLU was better than the sigmoid because the model validation accuracy increassed faster. This is most likely due to the fact that the sigmoid's value range is not very big and it can easily saturate at 1 or 0 and cause some issues with the gradients. On the other hand, the derivative of the ReLU is much better at propagating the gradients and increassing training speed\n",
    "\n",
    "- initial step: The initial step or learning rate is one of the most important hyperparameters in our model as it controls how fast or slow the model will 'learn'. The initial step is set to 0.1 which is quite high for neural networks but since our model is not very deep and the problem type is relatively simple, we can get away with such a high learning rate. if we turn it down to 1e-3 then the model takes considerably longer to converge\n",
    "\n",
    "- batch size: when doing SGD, batch size is the number of samples that we will use to update our model parameters. The idea with SGD is that a smaller number of samples can still give a good representation of the data distribution in general. When performing backpropagation the step may not be in the right direction but overall we will still converge. A decent batch size is of around 64, we could go as low as 32 or even 16 without too much of a decrease in performance. Usually, there is no disadvantage with a high batch size only that it will slow down the time per epoch of our model. However, too small a batch size will result in poor training\n",
    "\n",
    "#### - Once properly implemented, compare the training using early stopping, dropout, or both of them. <br> Why are these methods useful here?\n",
    "\n",
    "Early stopping is both used to prevent overfitting and to know when to stop training when the loss evolution could be noisy. When we use SGD or dropout, ou training loss is very likely to be noisy which means that we cant rely on the delta between training loss at different steps as our stop parameter. Instead, early stopping looks at when the loss begins to slowly level out and stops it once it is not changing very much overall. \n",
    "\n",
    "#### - Once properly implemented, compare the training using momentum.\n",
    "\n",
    "With momentum, training is much faster in almost any scenario. Without it and using SGD we converge in around 1500 iterations while we converge in 800 when using momentum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.plot_validation_prediction(sample_id=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAH6CAYAAACtTEJqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd5hU1f3H8ffZvgsssFRZOkhVqQpYEURNpARQilHRRDRqYkxMxIItlhiNseWnBjViAUEEFARLNBJFkSKKotjodVFA+rLt/P44d4bZ2ZndmWWW2fJ5Pc8+s3Pb+d4799753jPnnmustYiIiIiIyNGXEO8ARERERERqKiXjIiIiIiJxomRcRERERCROlIyLiIiIiMSJknERERERkThRMi4iIiIiEidKxqXGMcYsMMaoT88jYIy51BhjjTGXVnA5/b1y7qjIcmLFGNPai3fyUSjrDq+s/hVdVmUWq+1Q1fa1yswYs84Ysy7ecUh8hDsmvWEL4hNVSZUpF6iSybgxppMx5jFjzEpjzG5jTJ4xZosxZp4x5tfGmNR4x1iV6EtI4uVoJq9S8fR5ilS+pLOmMsZM9j6L1vGOpSxJ8Q4gWsaY24DbcRcSi4DngH1AE6A/8DRwFdA7TiGKSOwsAToDP8Y7kEron8A0YEO8A4mzWG0H7WsiFaszcCDeQQS4BMiIdxBQxZJxY8zNwJ3ARuACa+3iENMMBq4/2rGJSOxZaw8AX8c7jsrIWvsjShxjth20r4lULGttpTq+rLWVpyLDWlsl/oDWQJ73d1wZ06YGzWeByUAHYDqwHSgC+gdMdyzwPLDZK2OL9/7YEMuvA9wKrAT2AHuB1d6yewVNOxR4F9gKHPKW+z/g6ijXfyzwHvATkAusAiYGrmvAtBZYADQEJgWU/SVwWdC0k73pQ/3196a51Ht/KXCut+zdbvcptqyBwJvATq+8b4H7gLohYlzgLTMVuBtY682zGvfLR0rAtPVxV9OrARNm+8z1ltc7gm25IDh2b3gC8BtgKe7Xlv3e/1cBCSGmP80rd5MX+zbgY+D2oOmaAH8HvvGW+ZP3/2SgbRT7QHNcLeAar7wdwBzgxKDpnvS2xbAwy+njjX8laPgxwP8B63DHwA/ALIL26eB9ItS+F6Zc377W2nt/Ryn73qXeNP2993eEWF40x6yvrP7A+bha0APevjoNyI7yeKwD/MP77HNxSdwfgbZeOZMj2efK2JbrvL9Mr6x1QL5vWwSuU3mP/4B5Ur3l+fattbjjMrW0zzTMNo7o8wROAuZ5n0HgfnGmF/dXuPPrQdy59nYgrbTP9ki2Q7h9jcPnqiTgZuA7bzkbgb8RcK4Kmu+XwHIv/u3AC0Cz0vaFKPdB/3oTxT5NFMdNGeUb4Lfe9sz1lvdPoC7evhtuPycO3yNHUEaJdQm37wWsY6i/EuewGK5PJ9z5daP3meYAU4GOIaad7JXRGrgS+ML7/HJwx0mobRDTYzLEMVfaX/+A6X8BvOh9Xvu9v0+Aawn6ji5leeuCt3eI+KPNBaI+5wb/VaWa8cuAZGCatXZlaRNaaw+FGNwOWIz7EKcA6bidCmPMicA7uC/YObgdrhNwETDMGHOWtXapN63BHcQn45rJPA0U4BKlM4EPcDsHxpgrgH/hkrS5uNqbxsAJ3vo8HsmKG2P+7U2/CZiJS+b6AncBA40xg6y1BUGz1QM+xB2Yr+AO7guAfxtjiqy1z3nTveq9jsNdJCwIWMa6oGWejzuJvoFL+FoFxHgl8ARup52B+/LpD0wAhhhjTrHW/hRi9V4GTvRizAeG4Q7k3saYodbZZYyZ5m2Ds4D/BG2fFsDPgE+stctClBGpF4ALcSe0p3EH2HDc53Qq7svVV+a5uERiD26f2Qxk4X6Guxr3Cw7GmAzc59DOi3su7kuslbeur+ASoFIZY3oCb3tlvIVLkhviTk4LjTHDrbXzvcmfw51kLwFeC7G4cd7r5IDltwEW4pKF/wIvAS1w+8x5xpiR1trXy4ozSgtw++nvgRUc3hcBPittxmiO2SBX4y6Q5+D29z7AaKCbMaZ7mHNHcNmpuAvsE724p3jrcStwRlnzRykF93lk4T7/Pbgv6LJEevz7zmkzgfNwieY/cefaS4GuUcS6gMg/z37ATbh97t+4fTnPGzcB91l+hDvG0oBTcOeF/t5nWxhhTBFvhwhMxV2Av4H7HH4O3IA7p18WOKEx5gZcor4LdzzuBgZ5seyOosxIRLxPH8FxE8rDuCRoKy4B8Z2/++D227ww88XleyQGZUTiM9y5/3ZgPQHnWIp/t5YlmvU5F/d9kIz7fvkel4+MwJ27z7TWLg9Rxv3AOd48b+Pyl/FAe2BA0LSxPCYDrcP7rgySjKvcSKN4s5b7cBWpi3HfuXW9WB/Bba+LA6a9E/f92M0b7/tMI/lsI84FAhzZuSaaK+F4/uG+/CxweZTztebwFdG9IcYbXC2zBX4ZNG60N/xrvKsh4Hhv2OwwV1P1A95/grs6ahxi2oYRxn+pV94sID1o3B3euN+HuEqz3k6UGDC8C+7C4aug6ftTypV7QAxFwLkhxrfy1nMP0Clo3OPevJOChi/whn8btM3ScBc5Frg4YHhvQtTmBm2H8RFu0wWUrI0Z6y1jOVA7YHgtYJk37sKA4TO9Yd1K+2yBId50D4WYLgWoE0G8SbgTbC5wRtC4ZriT0laK/yL0jfeZZAVNn4qrDcoBkgKGv+XFeUvQ9Cd7+8yOoO3i2ycuDbHvLQizHpMJqAENOj4nh5mnxL5JlMds0D6yBzg+aJ6p3rhREe4/N3vTzwwqow2Ha3knB81TYp+LYFuu84a/A9QqZb/vH+IziOb4v9ib/n2K/yJVz9uOYT/TEDFF+nla4Mow07QlxC9guMoHC4yuoO1QYl8L/Oxw5/OsgOG1cMdlIdA0KP583C9LLYL225d8cUWyPcvY1lHt05TjuCml7JO96b8P2iaB5+91YfbzeH6PlKeMdcHrEuG+F9Exc4TrUx93wfcj0CVoWcfhanWXBw2f7C1nA9AyYHgS7hxggZMq8Jgsc7sExPhQ0PB2IaZNwF3wWqBPmOW0Lm17Bw2LKhcIWK+IzzWh/qpSbyrHeK+byjl/DqGvwE7GXfEtstZOCRxhrZ2Oq7npiLsaCnQweEHW2iJr7a6gwQW4E3PwtJG2cfy9t4xfWWuDy7wLlySFuko7APzRBlytWmu/wl25dTbG1I6w/ECvWWvfDDH8Ilxi+U9bsk3YLbhmPBeH6eXmrsBtZq3NxdWYAfwqYPgy3IEwzBjT1DfcGJMI/Nor46XoV8nPV9aN1tp9AeXux9UKAFweYr5Q+0GozzbUdHnW2r0RxHYermb9MWvt/4KWsQVXw9EU99Orz3O4z2Rs0LKG4E7gU6z3a4oxpjlwNu7kfH/Q8j/CbdcsXE1LZVDeYxbgUWvtF0HDnvJeT4qw/MtwCcUN1tqigLLXAo9GuIxoXO/th9GI5vgf571OtNbmBUz/E+4cUxE+s9b+K9QIa+0a632TBXnIez0ninJieR6cYK3dGbCc/bhfRRIo3mHAhbjE5jFr7caA6S1wIy55j6VI9+kjOW6C+X4JuCdomwSev8OJ2/fIEZZxNEW6PpfgLppv9/ZrAuZZidsPehhjuoQo4y82oM20933wrPe22LkwxsdkqbxOOsbhftUtdv+ftXZ18PTeOfiRGMZR3lzgiM41VSkZP1IrbOifoHt6r/8NM59veA/v9SvcT1FjjTEfGmNuMMacbIxJCTHvFNydul8ZYx4yxvzCGNMo0oC9Jg7dcFe+13l9d/r/cD+LH8I1jQj2nbV2T4jhvi+H+pHGEWBJmOFht6F3QvkUd2XfKcS8/wsxbCHuC6tH0PDHcV9ygSejn+N+knsx8MAph564BGtBmBiD4/F9mS02xjxpjBntJbWh5t0M3GiMedMYc60xppd3ERGpft5rq+B9wNsPfCfOwP3geW99xlGc7/3kgGG+9frAWlviwpGSx0C8RXvMBgrVjCniY8IYUwf3M+7mUF8MRPdTdCRygc/LMV80x38P3L7yUYjpF5aj7EiEO5dgjKlljLnZGLPU67q2yOsLeIc3SXYU5cTyPBjpvuPb70psO2vt+oB5YiXSuI7kuAnmW1Zp5+9w4vk9ciRlHE2Rro/vu6FbmO+GDt74UDlCxOfCGB+TYRljfomrNF2Gq30uChrfwBhznzHmc2PMPq/bQt+vVrGKI9pcwOeIzjVVqc34VtwOVd6NvS3M8LoByw9XLrirT6y1hcaYAcBtuLZvf/PG7zXGPAfc5EsKrbX/MMb8iGvTdy1wHWCNMf8D/mzLbt9cH/fTYiNcG7RohGsX5WtbHk0y6BOTbRgkJ3iAtbbA226Ng0ZNAx4Exhtj7vMO1Cu8cSFr2aJQF9gZWDNYWjzW2lkBPff8CtdGG2PMJ7h94D/edHuMMX1xJ5ihHL5y/9EY8zhwd5gEOFAD7/WCMqbzX3lbazcZY94FBhljOltrVxljGuPaan5mrQ1M8I7k84uHI4k31HERzTHhK7vEfusJd4yU1/YwNVJlieb49+37wfedQPj1PFIht5MxJhmXKJ2Eu0FsOq65h+8YuR3X1CpSMTsP2tDtiMNtTwi/7XJwzXliJdq4YnGch13HgPNlOPH8Hqkq57pI18f33TC+jOWFqpWNaL+pgGMyJGPMGbj7R9YDg63r3ShwfD3cTZRtcBd0z+OaBRZw+F6VWPyiEVUuEOCIzjVVqWbcV8swsNSpwgv3hea7maZpmPHHBE2HtXaXtfYP1toWuDvTL8e1tfst7sYQAqZ93lrbF3fQnAc8A5wOvBVBLbmvzE+ttaa0vzKWEysx24YBmgQPMMYk4W7oKnaV6TXTmYz7Ijs74MbNxdbaFaUFHoHdQJZ34ok0nnnW2gG4i6aBuJ/sugKvB/4saK3dZK39Ne4APg53YbYDd0F3W4SxgesdpbT9ILgZlu+GEV9t+C9xF+DBN5IcyecXzBL+Ij9WX3CxjLe8ZZfYbz3hYioC/74UrLTtUp5EPFp7cPt+qNjCreeRCrdew3Bf+pOttcdba6+w1t5irb2DI7/gPlp854lw266itmlZYnnchD0OAs6X4cTze6Q8ZRRR8ee0YNGuT7cyvhuiuVE5WIUfk8aYTsBsXHPOn1trQ13IXo5LxO+01vax1l5trZ3oxTE9FnF4os4FYqEqJePP4q7ERoZp/+QXZXuvT73X/mHGn+m9hrobGWvt99baZ3C9KOzD7bihpvvJWjvfWjsel1Bm4ZLysLwa9i+BrsaYrNKmPUK+nxTLU1sOpWxD72q2O4e7Ywx2Rohhp3qxfBpi3BN4N3/h2oonEpsTwqe44yHUZ3K6V064fWC/tfa/1to/Avfi2iT+LMR01lr7pbX2MVzPCuDu9i7Lx97raRFMG2gW7qRxkTEmAZeUF+Bu7grk286nhknISj0GguzC9cJSjNcsp3uI6cuz7x3RMXskrGvj/z2QbYxpF2KScDH52n+W2DbE/wFlvn3/5BDjImk/HOhIzyXtvddZIcaFOldURv7jKXiEMaYVofeBoyGWx41vmtLO39E6Gt8j5SljF9AkVHJG+GO3iPIfAxD5+pT3uyEaFXpMepWS83C19yOD276HiGNmFHGU9/ulXLnAkagyybi1dh3uDt0UYJ4xJuRB4HXz80YUi/4Q1/PEqcaY84OWdT5uJ/8Wr2beGNPGGNM2xHLq434iORgw/5nGmFC11r6fOCJ5EtU/cOv8b+9kUYwxpr5x3d4dCV+7r5blnP9F3IXS74wx7YPG3YXrJ/nFMG32bzXG+NtSGWPSgL96b58Nntha+x2uZ53BuH5Af8I1XzlS//Ze/+q11ffFk4HrTgncrxq+4aeXUZN4wJuuqzEmVE1YsenK8Bqun9lrjDE/DzWBMaZfYNzg/yXhZVzTrj/g7j+Yb63dHjTdJly3i61xTakCl9sHd0PaLlzNRVmWAC2NMWcHDZ9IQBdmAXbhLq6i2feiOmYrwLO4c+ffvIscX9ltcL96hOJrJ1vs52RjzEBK3mR7tD3vvd4deO+LMaYu7r6UaJTn8wy0znvtHzjQO+f+LXjiSmoq7qL3d96vd4C/C8m/EiYxMMYs8NrA9q+guGJ53Ez2Xm8JrCgKOn9H62h8j5SnjCW4mvHg7isvxXXvF8oOjuyiK9L1eRb3HXi7MabEDejGmIQY7E/rvNdiy4nFMemt1xxcby1XWmvfLUccPQh/03B5cpuocoFYqUptxrHW3uslQLcDS40xH+Ea+u/DJTen45qNRNzXtLXWGmPG4ZKR6caY13BNTjriai33ApcE3EjQDZhljFmKu3regmvTPQzXN2bgzjkb2GeM+Ri3IxncCe9E3A0H70QQ37+NMb1w7c5XG2PewvV6kYX7yeZ03AH5m0jXOYRvcDcZjjHG5OPabFngBe+Go7JiXGeMuQ73wJjlxpiXcW3KzsDdYPI1h+9CDrYK+NIYE9ifajvclfILYeZ5HNffeBNcjwUleiqJlrV2qjFmGDDKi+dV3Db4BW47T7fFeyB4FFc7+iGHH5LTC9fn6XoOXyAMAh4wxizCfdFtx91wOgxXe/JABLHlG2NG4LofnOft95/hEvkWuP2pLe4n1uDk/jncz3t/DXgfym9wX9YPeIn0Mg73M16Ee3BBJD2//B3XLv41Y8x0XJu+k3HbcAFBJ1Jr7T5jzGLgNGPMFNw2KgTmBLVrD5wn2mM21h70yhmJ29/fwv1cPQrXNdjQEPM8C/wZuMkY0w13I3gH3C8os71lxcvzwBjc/QQrjTFzcOeykbg2mh3xmtmUpTyfZxBfP8l/NMYcj6ulaom7+J5H+ZP8o8Zau9q4HiHuBVZ4x4Gvn/EsXB/sJ4SY1XdhF6rtfiziitlxY6390BjzGPA73D4TeP7eRfg22aUts8K/R8pZxmO4RPwJ7+J5I64GvR/wOm7fDPYu7vt0Lq4WNR9431r7foSbI9L12eFdSM0GPjbuPqEvcd9dLbwYG+BuSi2vijwmr8U9M2UNXgcFIaaZ7FXGPo87hz5sjDkT90yEY704ZuG65wz2rjfPU8aYmbh9/Cdr7T/DBVSOXCA2bJT9YFaGP9yNnI9x+AmYebiD/w1c04WQT+AsY5kdcTv5VtzOvxV3Fd0xaLrmuJPsh7gbUQ7hult8A/hZ0LS/wR0kazj8ZLRPcQ+KKLN/6aBlDcYd+Nu99d2Gu2K/m5L9pYbty5Mw/W7iErp3cV8aRQT0EUqYfpBDLPts3MMDdnnb5XtcV3n1Qky7wFtm8JPG1uDdEFJKOYm4E6gFupZj/1lAiH5+cV+GV+MS0QPe3yfANZR8utcoXJd/3+EuBvd4++M9QKOgffUf3jJ/8NZxHe6hACdHGXdj3JX5Si+2fV75r+C67EoKM9933rbaQZgnuHnTZeOaAa339rEfcQ9uOTHEtGH3CVwyugz3c+8O3IVJq1L2vfa4E/6OgH3vUm9cf+/9HeU9Zr1p7wjcp4PGtSaCc0TQPL6nYm7m8BM4ryfMEzi9eboC83FfCPu8/fCMcNuSUvo3Lm2dKN/xnwb8hcPH4TpvX872pn81im1Trs8zYP4WuN6KNuN+afwSd85MCrVusdoO4WKjHH3Ee+Muxp3vc3HH/ou45wKsxCUEgdMab3utJcxxHKt9miiOmzLK9z2BcxWHny79f0TwBM4yllvh3yPRlOFNfyruQvsA7lw/D3dBFW7fa4z7hSQHdzFa6j4fg/VpjXtY13fe/rYHd056AfhFJOeAMo6BCjkmA6Yr7a9/wPRdcDXp2zn89M3LKX1//yOH91FL5E/gjCgXKM+5JtSf8SYWOaqMMQtwD7CJ+uZT7+ex74EPrbUV2VZOpEYzxgzCJS33WWvL6j9aymCMycQlaJ9Za/sFDD8BV2N+jbU2oiczy5F9j1RG1W19JHJVps24SIA/4Wplwv7UJCKRM8Y0CzGsAYfbSEZyv4B4jDGNgm/485pYPoj7FSJ4e56BS9L/jYjUOFWqzbjUXMaYlrgbCY/Ftd9bAcyIa1Ai1cc/vLbsH+GaVDTHtWfPAv5lrQ37kB4JaSTwF2PMO7g2xr7eszrg7vd4LHBi63pYeix4ISJSMygZl6qiLe4mxAO4G5CushV3g55ITTMLd0P0ENzNqLm4dqHPUAE9B9QAi3G9kpzO4QezrMW1w/+bjcFN5yJSfajNuIiIiIhInKjNuIiIiIhInFS7ZioNGza0rVu3jncYIiIiIlLNffLJJz9aaxsdyTKqXTLeunVrli2L+Jk/IiIiIiLlYowp8+GIZVEzFRERERGROFEyLiIiIiISJ0rGRURERETiRMm4iIiIiEicKBkXEREREYmTatebioiISGW0Z88etm/fTn5+frxDEZEyJCcn07hxYzIzMyu8LCXjIiIiFWzPnj3k5OSQnZ1Neno6xph4hyQiYVhrOXjwIJs3bwao8IRczVREREQq2Pbt28nOziYjI0OJuEglZ4whIyOD7Oxstm/fXuHlVZtk3BgzxBgzaffu3fEORUREpJj8/HzS09PjHYaIRCE9Pf2oNCurNsm4tXautfaKunXrxjsUERGRElQjLlK1HK1jttok4yIiIiIiVY2ScRERERGROFEyLiIiIqUyxpT5t2DBgiMup2nTpkycODGqeXJzczHG8PTTTx9x+ZHq27cvF1100VErrzJ48sknMcZQUFAQ1XxTp07lxRdfLDG8Jm7DcNS1oYiIiJRq0aJF/v8PHjzIgAEDmDhxIuedd55/eJcuXY64nPnz59O4ceOo5klNTWXRokW0a9fuiMuX2Js6dSoFBQUlEu9nnnmGtLS0OEVVuSgZFxERkVL17dvX//++ffsAaNeuXbHh4eTm5kacdPXs2TPq2IwxEcUhlUvXrl3jHUKloWYqIiIiEhO+pgzLly/ntNNOIz09ncceewxrLddffz3HHXcctWrVokWLFowbN44ffvih2PzBzVTGjBnDqaeeyvz58+natSu1a9fmjDPO4JtvvvFPE6qZiq8JxHPPPUfbtm3JzMxkyJAhbNu2rVh5a9asYdCgQaSnp9OuXTumTp3K4MGDOffcc6Ne97fffpsTTzyRtLQ0mjZtyrXXXsvBgweLxXndddfRokULUlNTyc7OZuTIkRQVFQGwY8cOLr30Uo455hjS0tJo1aoV11xzTZnlvvLKK/Ts2ZO0tDSaNWvGLbfcQmFhIQBvvvkmxhhWr15dbJ7t27eTlJRUrPnIlClT6Nq1K6mpqbRs2ZI77rjDv5xQfMv+/vvviw0PbH4yZswY5s2bx1tvveVvznTfffeVmC7Sbegr88MPP2T48OHUqlWLdu3aHdUmShVByXgMFBQWsftAPoVFNt6hiIiIxN3o0aMZOXIk8+fP5+yzz6aoqIidO3cyceJE5s+fz4MPPshXX33FoEGDsLb0787vv/+eiRMncscdd/Diiy+yceNGLrzwwjJjeP/993nmmWd4+OGHefzxx1m0aBFXX321f3xRURGDBw9m7dq1TJ48mfvvv5/77ruPzz77LOr1/fTTTznvvPPIzs5m1qxZ3HrrrTz77LOMHTvWP81f/vIXZs6cyb333st//vMf/vGPf5CRkeFf/9/97ncsW7aMRx99lLfeeou77767zG3z/PPPM3r0aE477TTmzJnDTTfdxKOPPsrtt98OwFlnnUWDBg14+eWXi833yiuvkJKSwrBhwwCYO3cuF110Ef369WPOnDn85je/4Z577uH666+PelsEuvvuuznllFPo27cvixYtYtGiRVxyySUhp41kG/r86le/ok+fPrz66qv069eP8ePHs2LFiiOKNZ7UTCUGXv1sC3+asYIPbjiTFlkZ8Q5HRESqgDvnfslXW/bEpewuzTK5fUjFNRP405/+xJVXXlls2LPPPuv/v7CwkF69etG+fXuWLl3KSSedFHZZO3fuZPHixbRq1QpwNcxjx45l3bp1tG7dOux8+/fvZ968edSpUweATZs2MXHiRAoKCkhKSmL27NmsWrWKFStWcMIJJwCumUz79u057rjjolrfO++8kw4dOjBr1iwSElw9Z506dRg3bhyffvopPXr0YMmSJVxyySVcfPHF/vlGjx7t/3/JkiVMmDCBCy64wD8scNpghYWFTJgwgSuuuIJHHnkEgLPPPpvExERuuOEGbrjhBjIzMxk5ciTTp0/npptu8s87ffp0fv7zn/u3za233sq5557rr2E+55xzKCgo4K677uLmm2+Ouh2/T/v27alXrx4FBQVlNiWKZBv6jBs3jhtvvBGA0047jddff53Zs2fTrVu3csUZb6oZj4H05EQADuaH/zlHRESkpgi8sdNnzpw59O3bl7p165KUlET79u0B+Pbbb0tdVocOHfyJOBy+UXTTpk2lztevXz9/sumbr7Cw0N9UZenSpbRu3dqfiAO0adOG448/voy1K2nJkiWMHDnSn0QCjBo1CmMMCxcuBKB79+489dRTPPjgg6xcubLEMrp3785f//pXnnzyyRJNP0JZuXIl27Zt44ILLqCgoMD/N2DAAPbv38+qVasAl/CvWLHC37Rny5YtLFy40H8hcOjQIT7//PNiFwG++QoKCli8eHHU26M8ItmGPmeffbb//7S0NNq2bVvm/lCZqWY8BtKS3Y5zME/JuIiIRKYia6bjrUmTJsXe+9r4jhkzhltuuYVGjRqRn5/P6aefTm5ubqnLqlevXrH3KSkpAEc837Zt22jUqFGJ+UINK421lpycnBLrnJaWRmZmJjt37gTgrrvuIiUlhUceeYQ//elPtGjRgptuuomrrroKgEmTJjFx4kRuu+02rrrqKjp27Mi9997LiBEjQpb7448/AjBw4MCQ4zdu3EifPn3o378/TZs2Zfr06dx2223MmDGDjIwMBg8e7N8O1toS8fve++KvSJFuQ59Qn21Z+0NlpprxGFDNuIiIyGHBjxGfOXMmLVu2ZMqUKQwZMoS+ffuWu+lDrDRt2rTEDaRAyGGlMcbQpEkTtm/fXmx4bm4ue/bsISsrC4D09HTuvfdeNmzYwNdff82wYcO4+uqr/f2zZ2Vl8fjjj5OTk8Onn35Kt27dGDVqVNhact9yn3vuOZYuXVriz5ekJ10o4ncAACAASURBVCQkcP755zN9+nTANVEZMmQI6enp/u1gjCkRf05OTrFygvl6yMnLyys2fNeuXWVvtCCRbsPqqtok48aYIcaYSbt37z7qZaelKBkXEREJ5+DBg/6aaZ8pU6bEKRrnxBNPZN26dXz++ef+YWvXruWLL76Iell9+vRh5syZxW64nDFjBtZaTj311BLTd+zYkYceeoiEhAS++uqrYuOMMXTv3p377ruPwsLCsM14jj/+eBo1asT69evp3bt3ib/69ev7px0zZgxfffUV8+bN4+OPP2bMmDH+campqXTr1o0ZM2YUW/7LL79McnIyffr0CVl+8+bNAfzNYQBWr15doueWSGuto92G1Um1aaZirZ0LzO3du/f4o122r2Y8V81UREREShg0aBBPPvkkf/7znzn33HN5//33mTZtWlxjGj58OJ06dWLEiBHce++9JCUlcccdd9C0adNi7ZYjcdttt3HiiScycuRIxo8fz9q1a7nxxhsZNmyY/8bD8847j1NOOYXu3buTmprKtGnTSExM5LTTTgNcMjpmzBi6du2KtZYnnniCzMxMevXqFbLMpKQkHnjgAcaPH8/OnTs5++yzSUpKYvXq1cyePZv58+eTmOjyk5NPPpkWLVowfvx4MjMzS3TdeOeddzJs2DCuuOIKzj//fJYvX85dd93F1VdfHfYXjPbt23P88cdz0003kZSURF5eHvfeey8NGjQoNl2nTp345z//yZw5c2jWrBnNmzenadOm5dqG1VW1qRmPJzVTERERCW/EiBHcddddTJkyhaFDh7J48WJeffXVuMaUkJDAvHnzaN26NZdccgl//OMf+cMf/kC7du3IzMyMalk9evRg3rx5bNiwgV/84hfceeedXHrppUydOtU/zSmnnMIrr7zCmDFjGD58OCtXruTVV1/13zDar18/nnnmGUaMGMGYMWPYu3cvb731Vol21IHGjRvHzJkzWbx4MSNHjmTkyJFMmjSJvn37FrugMMYwatQotm7dyvDhw0v8SjF06FBeeOEFFi5cyODBg/m///s/br75Zh588MFS13v69Ok0adKECy+8kNtvv5177rmHNm3aFJvm97//Pf3792fcuHGceOKJTJ48udzbsLoyZfVhWdX07t3bLlu27KiWmbMnlz73vss9w4/jl31alT2DiIjUKKtWraJz587xDkPKsGPHDtq2bcuNN95YrCtAqbnKOnaNMZ9Ya3sfSRnVpplKPKX5asbVTEVERKTK+Oc//0laWhrt27cnJyeHBx54AHA1ziJHi5LxGPA1UzlUUBTnSERERCRSKSkpPPDAA2zYsIHExET69OnDu+++S7NmzeIdmtQgSsZjIDnRkJhgVDMuIiJShVxxxRVcccUV8Q5DajjdwBkDxhjSkxN1A6eIiIiIREXJeIykJScoGRcRERGRqCgZj5G05ET1My4iIiIiUVEyHiNqpiIiIiIi0VIyHiPpKUrGRURERCQ6SsZjJC05Ub2piIiIiEhUlIzHSHpyIrmqGRcRkWpoyJAh/se2h/Lb3/6WevXqcejQoYiW9/3332OM4c033/QPa968OTfeeGOp83322WcYY1i4cGFkgXuefPJJ5syZU2J4JGXGSkFBAcYYnnzyyaNSXmVx0UUX0bdv36jnu++++3j//feLDauu21DJeIyozbiIiFRXY8eOZeXKlXz11VclxhUWFvLKK68wYsQIUlNTy13G3Llzueaaa44kzLDCJeMVWaYcmVDJeFJSEosWLWLEiBFxiqpiKBmPkfSURHLz9QROERGpfoYNG0ZGRgYvvfRSiXHvvfceOTk5jB079ojK6NGjBy1atDiiZVSFMuXI9O3bl8aNG8c7jJiqNsm4MWaIMWbS7t2741J+mmrGRUSkmqpVqxZDhgxh+vTpJcZNmzaNxo0bM2DAAAA2b97MZZddRps2bUhPT6dDhw7cfvvt5Ofnl1pGqCYjjz32GC1atKBWrVoMGzaMbdu2lZjvgQceoHfv3mRmZtKkSROGDRvG6tWr/eNPPfVUVqxYwTPPPIMxBmMML774Ytgyp02bxnHHHUdqaiotW7bktttuo7Dw8Pf7008/jTGGL7/8krPOOotatWrRuXNnXnvttTK2YmiPPvoo7du3JzU1lWOPPZZHH3202PgNGzZw/vnn06hRI9LT02nfvj133HGHf/wXX3zBOeecQ/369alduzZdunQpsxlHYWEh99xzD+3atSM1NZWOHTvywgsv+MdPnDiR7OxsrLXF5nvttdcwxrBu3Tr/cm699VZatGhBamoqxx13HNOmTSu17IkTJ9K0adNiw4KbnzRv3pzdu3dz6623+j+zhQsXhm2mUtY29JW5bNky+vTpQ0ZGBj179uSjjz4qNdajpdok49baudbaK+rWrRuX8tOSE9TPuIiIVFtjx47lu+++45NPPvEPy8/PZ9asWYwaNYrExEQAfvjhBxo2bMjDDz/Mm2++yfXXX89TTz3FddddF1V5M2fO5Nprr2XYsGHMmjWLzp07M378+BLTbdq0iWuvvZY5c+YwadIkDh06xCmnnMLevXsBmDRpEsceeyxDhw5l0aJFLFq0iHPPPTdkmfPnz2fs2LGcdNJJvPbaa1x99dXcd999/P73vw+5PX7xi18we/Zs2rRpw+jRo9m6dWtU6/jEE09w3XXXMXz4cObOncuIESO47rrr+Pvf/+6f5qKLLmLr1q08/fTTzJ8/n5tuuonc3FwArLUMHjyY1NRUpk6dymuvvcY111zDnj17Si3Xt15XXXUV8+bNY+jQoYwbN87fhn/06NFs2bKlRNv86dOn06dPH1q3bg3AzTffzN/+9jeuuuoq5syZQ58+fRg7diwzZsyIajsEmzt3LrVr1+bKK6/0f2bdunULOW0k2xBg3759XHbZZVx11VXMnDmTpKQkhg8f7t+WcWWtrVZ/vXr1svFw/5urbJsbX7dFRUVxKV9ERCqvr776Kt4hHLFDhw7ZevXq2T/96U/+YXPnzrWA/fDDD8POl5+fb5977jmbnp5u8/PzrbXWfvfddxawb7zxhn+67OxsO2HCBP/7Hj162MGDBxdb1qWXXmoB+8EHH4Qsq6CgwO7fv99mZGTYKVOm+Id369bN/vrXvy4xfXCZvXr1smeddVaxae655x6bmJhot2zZYq219qmnnrKAfe655/zT5OTkWGOMfeqpp0rdDoB94okn/O+bNGliL7/88mLTjR8/3tarV88eOnTIWmttamqqnT9/fshlbt261QJR7V9ff/21BeyLL75YbPjYsWNt3759/e+7dOlir7nmGv/7AwcO2Nq1a9uHHnrIWmvtDz/8YNPS0uzdd99dbDmDBg2yXbp08b//5S9/afv06eN/f8stt9gmTZoUmyd421hrbd26de1dd91V6nSRbsNbbrnFAvZ///uff5qlS5dawP7nP/8Jt6mstWUfu8Aye4S5a1J8LgGqn1qpSRRZyM0vIj0lMd7hiIhIZffGjbDti/iU3fR4+Nl9Uc2SkpLCiBEjePnll7n//vsxxjB9+nRatWpFv379/NMVFRXx0EMP8fTTT7Nu3bpiNY+bNm3y16qWJi8vjxUrVnD11VcXGz5ixAgmT55cbNhHH33EbbfdxqeffsrOnTv9w7/99tuo1i8/P5/PPvuMxx9/vNjw0aNHc8stt/Dxxx8zfPhw//Czzz7b/3/jxo1p2LAhmzZtiri8DRs2kJOTwwUXXFCivKeeeoovv/ySHj160L17dyZMmMD27dsZMGBAsTbujRo1Ijs7myuvvJLf/va39O/fv8z21O+88w7JyckMGzaMgoIC//CBAwdyzTXXUFRUREJCAqNHj+bxxx/nkUceITExkXnz5nHgwAF/vJ9//jm5ubkh47/88svZuXMnWVlZEW+P8oh0GwKkpaVx2mmn+afp0qULQFSfWUWpNs1U4q12qruu2XeooIwpRUREqqaxY8eyYcMGFi1aRG5uLq+99hpjxozBGOOf5sEHH2TChAlccMEFzJkzhyVLlvjb8EbaJGD79u0UFRWVSCyD369du5ZzzjmHxMREJk2axIcffsjSpUvJysqKuvnB9u3bKSwspEmTJsWG+94HJvoA9erVK/Y+JSUlqjJ9TVrKKu+VV16he/fu/P73v6dly5b07NmT9957D4DExETefvttGjZsyGWXXcYxxxzD6aefzooVK8KW++OPP5Kfn0+dOnVITk72/11++eUcOnSI7du3AzBmzBhycnL43//+B7gmKqeeeirZ2dkRxb9r166It0V5RboNAerWrVtsP01JSQEi3ycrkmrGY6RWituU+w8V0KhO+bt2EhGRGiLKmunK4Mwzz6RJkyZMmzaNrVu3snfv3hK9qMyYMYMxY8bwl7/8xT/s888/j6qcxo0bk5CQ4E8MfYLfv/HGGxw6dIhXX32V9PR0wNWq//TTT1GV5yszMTGxRBk5OTkAMa/lPeaYY4CS6xRcXvPmzXn++ecpLCxkyZIl3HbbbQwdOpSNGzdSr149unTpwqxZs8jLy+ODDz7ghhtuYPDgwWzcuDFkuVlZWaSkpLBw4cJiyalPgwYNAOjQoQPdu3dn+vTpnHTSScybN69YO+zA+APv1/PFX79+/ZDlp6WlkZeXV2xYeRP3SLdhZaea8RippZpxERGp5hITExk1ahQzZsxg6tSpdO7cucSNdQcPHizR3/iUKVOiKiclJYUTTjihRA8ls2bNKlFWYmIiSUmH6xanTZtGUVHxroYjqbVOTk6mR48eJW4+fPnll0lMTCzXg2tK06pVK5o0aRKyvPr169O1a9diwxMTE+nXrx+33XYb+/btY8OGDcXGp6SkMHDgQK677jo2bdoU9ibOAQMGkJeXx759++jdu3eJv+TkZP+0Y8aMYdasWcyePZu8vDzOP/98/7gTTjiBtLS0kPF36dIlbCLcvHlzdu3a5U+YAd5+++0S00XymUW7DSsr1YzHiK+Zyn4l4yIiUo2NHTuWxx57jNmzZ3PnnXeWGD9o0CCeeOIJevfuTdu2bXn++ef9XeFF4+abb2bUqFH89re/ZejQofz3v//lnXfeKTbNwIEDueGGG7jsssu47LLL+OKLL3jooYfIzMwsNl2nTp147733ePvtt8nKyqJt27Yhk8U777yT8847j8svv5wLLriAFStWcMcdd/Cb3/zGXwsbK4mJidx+++1cc8011K9fn4EDB/Lee+/x1FNPcf/995OSksKOHTsYMmQIF198MR06dODgwYP8/e9/p1mzZnTs2JHly5dz0003MXr0aNq0acPOnTt54IEH6NWrV4lt4NO1a1fGjx/PBRdcwA033ECvXr04ePAgX375JWvWrOFf//qXf9rRo0dz4403MmHCBM4888xizYQaNmzItddey5133klCQgI9e/ZkxowZvP3227z88sth1/tnP/sZaWlpXHrppfzhD39g9erVIbti7NSpE6+//jpnnXUWtWvXplOnTqSlpUW9DauEI70DtLL9xas3leXrd9pWE163767aFpfyRUSk8qoOvakEat26tQXsd999V2Lcnj177CWXXGLr1atn69evb8ePH29fffVVC9hVq1ZZayPrTcVaax9++GHbrFkzm56ebs877zz7xhtvlOhN5dlnn7Vt2rSxaWlptl+/fnbp0qUllvXdd9/ZAQMG2MzMTAvYF154IWyZU6dOtV27drXJyck2OzvbTpw40RYUFPjH+3pTOXjwYLH5Qi0rUKgeQ3zr2LZtW5ucnGzbtWtnH374Yf+4AwcO2F//+te2Q4cONj093TZs2NAOGTLErly50lrrelP55S9/adu0aWNTU1Nt06ZN7YUXXmg3btwYNg5rrS0sLLQPPvig7dy5s01JSbENGza0Z5xxhn+7BOrTp48F7NNPPx1ynSZOnGizs7NtcnKy7dq1q506dWqxaYJ7U7HW9cLTuXNnm5aWZk8//XS7cuXKEttmyZIl9qSTTrIZGRn+z7w829DayHtwCeVo9KZi3HKqj969e9tly5Yd9XK/y9nLoIfe59GxPRjardlRL19ERCqvVatW0blz53iHISJRKuvYNcZ8Yq3tfSRlqM14jNRSMxURERERiZKS8RhRMi4iIiIi0VIyHiO1vAf9qDcVEREREYmUkvEYSUpMIC05QTXjIiIiIhIxJeMxVDs1iX2HCuMdhoiIiIhUEUrGY6h2apJqxkVEJKTq1nuZSHV3tI5ZJeMxVEvJuIiIhJCcnMzBgwfjHYaIROHgwYPFnkhaUZSMx1Ct1CTdwCkiIiU0btyYzZs3c+DAAdWQi1Ry1loOHDjA5s2biz11tKIkVXgJNUid1CS27cmNdxgiIlLJ+B5NvmXLFvLz8+McjYiUJTk5mSZNmviP3YqkZDyGMtOT+Xb73niHISIilVBmZuZR+WIXkaql2jRTMcYMMcZM2r17d9xiyExLYs9BNVMRERERkchUm2TcWjvXWntF3bp14xZD3fRk9uTmU1Sk9oAiIiIiUrZqk4xXBpnpyVgL+/JUOy4iIiIiZVMyHkOZaa77mz0HdXOOiIiIiJRNyXgMZaa7ZHy3knERERERiYCS8RjKTHed00R6E+fyDbvo/pe3Of+Jjzigpi0iIiIiNY6S8RiqG2XN+OPvreanA/ksW7+Lfy9cW5GhiYiIiEglpGQ8hvxtxnPLTsa37c7l3a9zuHZAewZ0asyzH66jUL2wiIiIiNQoSsZjqG5G5DdwfrZxF9bCgM5NGN4jmx3781i+YVdFhygiIiIilYiS8RiqnZKEMZEl459v2k1SgqFT0zr079iIlMQE3v5y21GIUkREREQqi6R4B1CdJCQY6qQmRdRm/IvNu+nYtA5pyYmkJSfSu3V9Plq94yhEKSIiIiKVhWrGY6xeRgo/lZGMW2v5YvNujs8+/LTQ3q3qs2rrHvYfUq8qIiIiIjWFkvEYq18rhV0HSk/GfzqQz08H8mnfuLZ/WM9W9SmysGLjTxUdooiIiIhUEkrGYywrI5ld+/NKnWbDzgMAtMzK8A/r0bI+xsAn63UTp4iIiEhNoWQ8xurXSmFnGcn4ei8Zb9Wgln9Y3fRkOjSuwzIl4yIiIiI1hpLxGMvKSGHXgTJqxnfsB6BFVnqx4T1b1Wf5hl0Uqb9xERERkRpByXiM1a+VwoG8QnLzC8NOs2HnARrVSSUjpXhnNr1b1WdvbgHf/7CvosMUERERkUpAyXiMZdVKASi1dnz9jgO0Cmgv7tO7dX0AlqzdGVFZuw/m89HqH9ldxg2jIiIiIlI5KRmPMV8yXlq78Q07DxS7edOnZVYGTTJTWRxBMr5x5wHOe/QDLnxqMafe/1/e+GJr+YMWERERkbhQMh5j/prx/aFrq3PzC9m2J5eWDUom48YY+rRpwJK1O7C29Hbj98xbxa79eTwypjvtGtXmdy99yv++/eHIV0BEREREjhol4zFWP8OrGQ/TTGXTroNYC61CJOMAJ7XJImfPIdbvOBC2jJWbd/Pml9sYf3pbhnXP5sXL+9C+cW2ufelTtu4+eOQrISIiIiJHhZLxGPM3U9l3KOT4DTtdTyqhmqkA9G2bBcDitTvClvGv99dQOzWJX53aBoDaqUk8cVEvcvMLuev1r8odu4iIiIgcXUrGY6xeejJJCYYfwiXjO3wP/KkVcny7RrVpWDuFxWtCtxvfuPMA87/YyoV9WpKZluwf3qZhLX57Znvmf7GNj9eET+RFREREpPJQMh5jCQmGRnVSydkTOhlfv/MAGSmJNKydEnK8MYaT2mTx8ZrQ7cafWbgWA1x2SusS48af3pZj6qbx1/mr1Fe5iIiISBWgZLwCNM5MI2dPbshxG3a4nlSMMWHnP6V9Q7bszuWbnL3Fhu/cn8f0pRsZ2q0Zx9RNLzFfWnIi15/dkRWbdjNPvauIiIiIVHrVJhk3xgwxxkzavXt3vEOhSZ1UtpdSMx6uvbjPoC5NMAbeXLmt2PB/L1xLbkEhV/VvF3be4T2y6dS0Dve/9TWHCsI/eEhERERE4q/aJOPW2rnW2ivq1q0b71BokplGzt6SNeNFRZaNOw+E7UnFp3GdNHq3qs/cFVv8TVX25Obz3KJ1nNu1Kcc2qRN23sQEw80/78zGnQd5+oO1R7QeIiIiIlKxqk0yXpk0yUzlpwP55OYXr5nevvcQhwqKyqwZBxjVuwWrf9jPR6vdzZhPf7CWvbkFXHNm+zLnPb1DI35+fFP+8Z9vWbYusqd5ioiIiMjRp2S8AjSukwbAD3uLN1VZv8Pr1rBB6J5UAg3p1owGtVK4e94q5n2+lScWfM/Qbs04Ljuymv/7Rp5Adr10fjv1U7b8pL7HRURERCojJeMVoHFmKgDbgm7i3LDTdWvYKoKa8bTkRB4c1Y1vc/ZyzdTltMzK4M6hXSOOITMtmScu6sn+QwUMf/xDHl/wPYtW7yCvoCiKNRERERGRipQU7wCqo+x6rqeTzbsOcmLrw8NX/7Cf5ERDdv2SPaGE0r9jY/7zh9P5NmcfZ3RoRHpKYlRxdG1Wl5eu6Mutr63k/je/AaBh7RTGnNiSMSe1oHn9si8KRERERKTiKBmvAC2yMjAG1nnNUny+376XNg1rkZwY+Q8SbRvVpm2j2uWO5bjsusy++hR27DvEJ+t38fKyjfzfgu/5vwXfc0aHRlx1Rjv6tG1Q7uWLiIiISPkpGa8AacmJNM1M8z9t0+fbnH0c3zw+vb00qJ3K2V2bcnbXpmzadYCXl25k2tKNjJ70MTf9rBNXnhG+u0QRERERqRhqM15BWmZlsH7n4WT8YF4hG3cd4NjG5a/ljpXm9TP449kdWfDn/px3wjH89Y2vS/RpLiIiIiIVT8l4BWndoJa/9xSA1T/sw1roUEof4UdbRkoSD4/uTtdmmUx8dSV7c/PjHZKIiIhIjaJkvIK0bJDBj/vy/Anu55vck0G7HJMZz7BKSE5M4J7hx/PjvkO88PH6eIcjIiIiUqMoGa8gnZq6GvCvtuwBYPmGXWTVSinz6Zvx0L1FPfp3bMTTH6xl/6GCeIcjIiIiUmMoGa8g3VvUA+CzjT8BsHz9Lnq2rIcxJp5hhfW7Aceyc38eUxardlxERETkaFEyXkEa1E6lZVYGn274ie17c1nz4356tKwf77DC6tWqPqcd25BJ76/hYF5hvMMRERERqRGUjFegHi3rsWz9TmYs2wTAOV2bxjmi0l078Fh+3JfHS0s2xDsUERERkRpByXgFGt4jmx/35fHAW9/Qo2U92leCbg1Lc2LrLE5qncW/P1xLYZGNdzgiIiIi1Z6S8Qp0RodG9GvbgEZ1UrnpZ53jHU5EfnVqazbtOsg7q3LiHYqIiIhItacncFYgYwzP/eokEgwkJVaN655BXZqSXS+dZz9cW+mb1YiIiIhUdVUjQ6zCUpISqkwiDpCYYBh3cis+XrOTL7fsjnc4IiIiItVa1ckS5agZ3bsl6cmJTP5wXbxDEREREanWlIxLCXUzkhnZK5vXVmxhx75D8Q5HREREpNpSMi4hXXpyG/IKipi6WN0cioiIiFQUJeMSUvvGtTm9QyNe+Hg9eQVF8Q5HREREpFpSMi5hXXZKa7bvPcQbK7fGOxQRERGRaknJuIR1xrGNaNuwFv/WjZwiIiIiFULJuISVkGC49JTWrNj4E8s37Ip3OCIiIiLVjpJxKdXIns2pk5bEs6odFxEREYk5JeNSqlqpSYzu3YI3vtjKtt258Q5HREREpFpRMi5lGndya4qs5YWP18U7FBEREZFqRcl4LFgLBXlQVD27AGyRlcFZnZswdfEGcvML4x2OiIiISLWhZDwWVrwEdzeC3dX3ATmXndKGXQfyee2zzfEORURERKTaUDIeC8np7jX/YHzjqEB922bR+ZhMnv1wHdbaeIcjIiIiUi0oGY+F5Az3mn8gvnFUIGMMl53Smq+37WXRmh3xDkdERESkWlAyHgu+mvG86puMAwzt1owGtVLUzaGIiIhIjCgZjwV/zXj1baYCkJacyJiTWvDuqhy2/FS911VERETkaKg2ybgxZogxZtLu3buPfuH+NuPVu2YcYMyJLbHA9KUb4x2KiIiISJVXbZJxa+1ca+0VdevWPfqF14AbOH1aZGVw+rGNeHnZRgoKq2dXjiIiIiJHS7VJxuMquZZ7rQE14wBjT2rJ1t25LPjmh3iHIiIiIlKlKRmPhRrUTAVgYOfGNK6TyktLqm+/6iIiIiJHg5LxWKhBzVQAkhMTGNW7Be99s103coqIiIgcASXjsZCYDAnJNaZmHGD0iS2wwDTdyCkiIiJSbkrGYyU5o8bUjEPAjZxLdSOniIiISHkpGY+V5PQaVTMO8Ms+Ldm2J5e3vsyJdygiIiIiVZKS8VhJqVk14wADOzehdYMMJr2/GmttvMMRERERqXKUjMdKcgbk1aya8cQEw+WntWXFpt0sWbsz3uGIiIiIVDlKxmOlBjZTATi/V3OyaqXwj/98S16B2o6LiIiIREPJeKwkp9e4ZioAacmJTDi3I4vX7uTy55cx+9NNHCoojHdYIiIiIlVCUrwDqDaSM+DgT/GOIi5Gn9gSa2Hiqyt5/9sf+C5nHzec2yneYYmIiIhUeqoZj5UaWjPuM+akliy+eSBndW7CUx+sYbMeBiQiIiJSJiXjsZJcq0Yn4wANaqdyx9AuFBRZpi3ZEO9wRERERCo9JeOxkpwO+fvjHUXcNa+fQf8OjXh52UZ1dygiIiJSBiXjsZKcXuO6NgxnUJem5Ow5xLod2h4iIiIipVEyHiupdaDwEBTmxzuSuOvVqj4An6zfFedIRERERCo3JeOxklLbvR7aG984KoFjG9emTmoSyzcoGRcREREpjZLxWEn1kvG8ffGNoxJISDB0b1mP5aoZFxERESmVkvFYSa3jXg8pGQfXVOWbnL3szVWzHREREZFwlIzHSoqXjKtmHICeLetjLXy2sWY+CElEREQkEkrGY8XXTOXQxfYB3AAAIABJREFUnvjGUUl0b1kPY3QTp4iIiEhplIzHiv8GTtWMA2SmJXN8dl0WfPNDvEMRERERqbSUjMdKqpqpBPvZccfw2caf2LRL/Y2LiIiIhKJkPFZ0A2cJ5x1/DACvfbYlzpGIiIiIVE5KxmPF10wlT/2M+7RskMHJ7RowdfEGCgqL4h2OiIiISKWjZDxWklIgMVUP/QlySb/WbP7pIG+s3BbvUEREREQqHSXjsZRaW81Uggzq0oT2jWvz6LvfUVhk4x2OiIiISKWiZDyWUmrrBs4giQmGPw7qwHfb9/H8onXxDkdERESkUokoGTfGJBljUoOGnW2Muc4Y07NiQquCUuuoZjyEnx3XlDM6NOLOuV9x3qMfMGPZxniHJCIiIlIpRFozPh14wvfGGHMt8CbwV+BjY8zgCoit6kmto4f+hGCM4aHR3Tm2cW2+3LKHP7/yOYvX7Ih3WCIiIiJxF2ky3heYH/D+z8CD1tp04GngllgHViWl1tENnGFk1Urh9WtP5bPbBpFdL51756/CWrUhFxERkZot0mS8AbANwBhzPNAMeNIbNwPoEvvQqqC0upC7O95RVFqpSYnUy0jh2oHtWbFpN4tWq3ZcREREarZIk/EcoLX3/7nAemvtau99OqBOpMFLxn+KdxSV3tBu2aQnJ/L6F1vjHYqIiIhIXEWajM8A/maMeQCYADwfMK4H8F2sA6uS0uq5mvEiXZuUJj0lkQGdG/PWym3k62FAIiIiUoNFmozfCPwL6IS7kfPegHG9cDd4Sno9sEV6CmcERvTIZsf+PD0MSERERGq0pEgmstYWAH8JM25ETCOqytLqudfc3a7JioR1ZsfGtG1Ui0nvr2bICcdgjIl3SCIiIiJHXaT9jDc2xrQJeG+MMVcYYx42xgypuPCqmHQvGT+oduNlSUgwjD+tLSs37+HjNTvjHY6IiIhIXETaTGUy8IeA938BHsfdzDnbGHNpbMOqovw140rGIzG8RzYNa6fw1Adr4h2KiIiISFxEmoz3BP4LYIxJAH4D3Gyt7QTcA1xXMeFVMb6mKZHWjB/aC+//Hb58teJiqsTSkhO5pF9r/vv1dr7NUTt7ERERqXkiTcbrAr5OoXsBWcAU7/1/gfYxjqtqSo+yZnzp0/Dfu2DGOFj9XsXFVYld1LcVtVISGfn4R6zcrD7aRUREpGaJNBnfxOEH+5wHfG2t3ey9rwvkxjqwKiktijbj1sLy56FZT6jXEt65o0JDq6yyaqUw8+qTKbKWKYvXxzscERERkaMq0mT838D9xpgZwA3ApIBxfYFVsQ6sSkqtAyYxsprx7atg5xrofRn0uQq2fgY7Vpc9XzXUqWkmZ3ZqzFtf5lCgfsdFRESkBokoGbfW/hX4HbDNe300YHQW8HTsQ6uCjPGewhlBc4ttn7vX5idBZ69Dmq9eq7jYKrnBJzRj5/48nvpgbbxDERERETlqIq0Zx1r7vLX2d9baZ6y1NmD4b6y1z1VMeFVQen04EEFXfVs/h6Q0aNAe6rWAY7rBd/+p+PgqqXO6NuG8E47hgbe+5vvt++IdjoiIiMhREXEyboxJMsaMNsY8ZoyZ4r2OMsZE9OCgGiOjARzYUfZ02z6HJl0h0dt8rU+Dzcsg/2DFxldJGWO4c2hX0pITeeTd7+IdjoiIiMhREfFDf4BlwEu4Gzjbeq/TgKXGmEYVFmFVU6th2TXj1sK2L6Dp8YeHtT4VCvNg07KKja8Sa1g7lZE9m/POVznkq+24iIiI1ACR1oz/A2gA9LXWtrXW9rPWtgX6eMP/UVEBVjkZWWXXjB/Y6W7ybNjx8LCW/QAD6z+s0PAqu75tG3Awv1DdHIqIiEiNEGky/nNggrV2SeBAa+1S4CZcLbnA4WYqh5vVl7TTe+JkVtvDw9LrQdPjYN3Cio2vkjuxTX0Alq6LoN29iIiISBUXaTKeCoR7ROJeICU24VQDGQ2g8BDk7Q8/TahkHKDVqbBpKRQcqrj4KrnGddI4tnFtnlm4Vk/lFBERkWov0mT8Y2CCMaZW4EDv/QRvvIBLxqH0pio71wAG6rcqPrz1KVCQC5uXV1h4VcGjY3tQWATXvvQpeQVqOy4iIiLVV6TJ+PVAV2CjMWaaMeYRY8xLwEbckzmvr6gAq5yMhu71wI/hp9m5Buo2h6TU4sNbnuxe19fspiqdj8nkryOO5+ttezn/yY94+oM12NKa/YiIiIhUUZE+9Ocz4FjckzcbAYOAxsCTwLHW2hUVFmFV468ZL6XN8841UL91yeG1GkDjLrAuwps4V70O0y+Gjx6DgryoQ63MBnVpwh/O6sDnm3Zz97xVzFy+Od4hiYiIiMRcNA/9+dFae6O1dqC1tov3erO1tpQq4BooI8u9ltVMpUG70ONanQIbl0BhfunlfPs2vHwxrP8I3v5/9u47Oq7yePj499mVVqvee5clS+7GDVdsjME0x6H3DgYCIRAI8EsgCbwphARCCL23gOm9Y4yxca+4y7Ikq/feyz7vH1eSJautbEkryfM5Z8/V3rYjDrZHo7nz3AevnwP1I6vH+jeLEtjz4GKmx/jyl8/3UF7by38TIYQQQohhxu5kXNiptTJe3c3PKLWlUFvS+eHNVjFzoLEacnv4ZUNjLXxxpzEa8fadcO7zkLkeXlsKdRXHFv8Q42Zx4s+/GEd5bSPP/XjQ0eEIIYQQQvSrblfPVEptAuxu1NVaz+iXiDrGMAb4DRAArNBaP93fn9HvrN7g5ApVeV0fL0kztn49VMbBGHEYMa3rc356HMoy4KpPweIGEy8Eiwe8fTl8fAtc+BoodWzfxxAyLsyb08YG89bGTG47JQEXJ7OjQxJCCCGE6Bc9VcZ39/FlF6XUS0qpAqXUriP2n66U2q+USlFK3Qugtd6rtb4JuBCYY/+35UBKgWcIVOR2fby7sYatPIIgYHT3i/+UZcCaR2HsLyH2pMP7k86ERX+CvZ/ArvePPv4h6pIZUZRUN/DtnnxHhyKEEEII0W+6rYxrra8eoM98BXgCeK11h1LKDDyJ8WBoFrBJKfWJ1nqPUuoXwM3A6wMUT//zDIXK7irjLcl4Vw9wtoqeAzvfMx7KdDpihPs39wMKTvt/na+bdSvs+Ri+vAdGLTzcvz4CzEsIJNzHleUbMzl7YpijwxFCCCGE6BeD3jOutf4ROHLUyAwgRWudqrVuAJYDS1vO/0RrfQZw2eBGegw8Q6Cyh8q4Z5jRXtKd0adDQyWk/tBxf9qPsOcjmHsH+ER1vs5khiX/MfrSv73/qMMfiswmxUXTI1mTUkRGcY2jwxFCCCGE6BdD5QHOcIyZ5a2ygHCl1AKl1ONKqWeBL7q7WCm1TCm1WSm1ubCwcKBj7Z1nqJGMdzUbuyS1+xaVVqMWgos37P7g8L7mJqPi7RMFc27r/tqQCTD717DtDUhbfXTxD1HnTY0A4Itd3fygI4QQQggxzAyVZLxLWusftNa3aa1v1Fo/2cN5z2mtp2mtpwUGBg5miF3zDIHGGqjvYrJJSSr4xfZ8vZMFxi2F3R9BdcuIxI3PQsEeWPw3cHbt+fr594BPNHx2OzTWHd33MASF+7gyPtxL+saFEEIIMWIMlWQ8G4hs9z6iZd/w5NXS03xk33hdBVQX9l4ZB5h5CzTVwg9/h0PrYMWDkLAYks7u/VqLG5z9byhOga/u7Xv8Q9ipY0LYmlFKafXIWuRICCGEEMenoZKMbwISlFKxSikLcDHwiYNjOnqeIca24oifJ0pbxxrakYwHJcH062HT8/Dy6caUlV/81/6RhfGnwJzbYcvL8OW9xhQWm83+72GImhbji9awJ3dkzVMXQgghxPGp22kq7Sml3gdeBL7SWh9TRqeUegtYAAQopbKAP2mtX1RK3Qp8DZiBl7TWdo9LHHJ8oo1taXrH/a2TVLpbffNIZ/4LomYZCwhNughcffsWxyl/MtplNjxtvAJGw6kPGg+IDtM55KODPQHYl1fJnPgAB0cjhBBCCHFs7ErGAX/gUyBfKfUa8LLWev/RfKDW+pJu9n9BDw9pDiteYWC2HF7gp1XRAWPr20vPeCulYML5Rx+HyQRn/hOmXAWH1hp9529dDDHz4LS/QNjko7+3gwR6uuDvbiE5r7LL41pr1h4sZkKEN15W50GOTgghhBCib+xqU9FaLwASgBeAi4A9Sqm1SqnrlVKeAxjf8GQyG3PEWyvhrfJ3GYm4i8fgxhMyHk5cBr9ab1TbC/bAc/Phgxu7X5xoCBsd7Mm+/K6T8Q+3ZXPZCxtY9MgqDhVXD3JkQgghhBB9Y3fPeMsM8D9qrWOB04AU4N9ArlLqVaXUggGKcXjyje3cppK/G4LHOSQcAMzOMOMGuG2bMat894dGP3p3CxQNUWPDvNiXW0FFXWOH/Tsyy7j/o12YFNQ1NnPJc+vZllHqoCiFEEIIIXp3tA9wrgNWAvsBN2Ah8L1SartS6oT+Cm5Y84sz2lRaZ4031EDxQQge79i4AKzesOjPcO2XUFUAH97U9Uz0IWrp5DDqm2xc+vx6vtqVx8p9BRRU1HH3ez/j625h7b2n8OYNM1FKcd2rm6lvanZ0yEIIIYQQXepTMq6Umq+UehnIAx4BNgLTtdaRwHigmHbL3A8mpdQSpdRz5eXljvj4zvzioLH68EqcBXsB7djK+JHCpxq946krYcdbjo7GbhMjfJgU4c2u7ApuemML17yyiRl/W8H+/EqWnRRHiLeV8eHe/OWc8ZRUN7ByX4GjQxZCCCGE6JJdybhS6o9KqRSMangscAsQprX+ldZ6C4DWeg9wPzB2oILtidb6U631Mm9vb0d8fGehE41tznZjm7ne2IZPdUw83Zl6jRHTdw9AfZWjo7HbS1dP57vfzmf5spm8ecOJbftPHx/S9vVJCYEEebrw8fYcR4QohBBCCNEreyvjNwLvAKO11gu01q9rrbta2nEfcG2/RTechU4CZYbszcb79J+Mhzq9wx0aVicmE5z+D6jKgzX/dnQ0dvP3cCE+yIOZcf7MHhXAG9edyH1njSHI09p2jtmkmJsQwKb0EvQwasMRQgghxPHD3mQ8Umv9e611Sk8naa1LtNav9kNcw5+zq9GSkr3FWGwnYy3EzHV0VF2LnA4TLoC1/4XSQ46O5qjMTQjg+nmdF1OaGu1LUVUDmSW1DohKCCGEEKJn9o42tAEopRKVUpcrpX7Xsk0a2PCGucgZkLkJdn8AtaUwaqGjI+reoj+DMsE39zk6kn41JcpYKGlLRomDIxFCCCGE6MzennEvpdTbwG6MBzTvb9nuUkq9o5TyGsAYh68TrjAe4nz/OvAKh6Qljo6oe94RMO9O2PsJJH/j6Gj6zehgT/zcLXy5c3iNbxRCCCHE8cHeNpWnMGaLXwm4a629AHfgKuDUluPiSGGTYfQZxjL2i/8KThZHR9SzOb8B/3hY8cCwGnXYE7NJccmMSL7dmy+LAAkhhBBiyLE3GV8K/E5r/abWuhZAa12rtf4fcHfLcdGVS96C36XCuHMcHUnvnCxGdTx/FxwYOdXxK2fF4GRSvLI2vW1fY7NNHuoUQgghhMPZm4xXAd2tm54DSMmxO0oZE0uGiwkXgHck/PivEVMdD/aycvbEMN7ZlElhZT2f7MjhhAe/5byn1/Lvb5NparY5OkQhhBBCHKfszRKfBO5SSrm236mUcgPuQtpURg6zs9GukrURMtY5Opp+c/OCUTRrzZyHvue2t7YRF+jOgYIq/rPiAKuSC7n8hQ28sDrV0WEKIYQQ4jhjbzLuDSQAmUqpt5RS/1FKvQVkAPGAp1Lq4ZbXPwYqWDFIJl8GVm/Y+LyjI+k3o4M9ef7Kafh7WIgLdOeN609kw+9PweJk4va3t7MmpYivd8tDnkIIIYQYXE52nnc+0Njymtluf2W74600cM+xh9Y3SqklwJL4+PjB/uiRx+IGky+Hjc9CZR54hvR+zTAwLyGQNfcspMlmw8XJDMCsOH9WJRfiZXVib24lNpvGZFIOjlQIIYQQxwt754zH9uHVeeWVQaC1/lRrvczb29sRHz/yTL8ObE2w5RVHR9KvzCbVlogD3HhSHFfOiuZ3pydRVd9EVqksDiSEEEKIwTOMniwUg8p/FIw6BTa/DM2Njo5mwMyOD+DBpeOZEG78ELcnt9zBEQkhhBDieGJ3Mq6UilNKPa2U2qmUym7ZPqWUckglXAyCGTdAVR7s+8zRkQy4pBBPLE4m1qfKSp1CCCGEGDz2rsA5FdgOnAdswlh9c1PL+21KqSkDFqFwnITTwDsKNr7g6EgGnNXZzILRgXy5KxebbWSMdBRCCCHE0GdvZfxfwDYgRmt9rdb6/7TW1wKxLfv/NVABCgcymWH6tXBoDeTvcXQ0A+6siaHkV9Rz/WubqWtsdnQ4QgghhDgO2JuMzwAe1lrXtN/Z8v5fwIn9HZgYIk64EswusO5JR0cy4M6aEMr1c2P5fl8Baw4UOTocIYQQQhwH7E3GawH/bo75AXX9E44Yctz9Ydq1sONNKEx2dDQDysls4u7Tk/C0OvFVLzPHv9uTz+mP/cj5T6/l0x05gxShEEIIIUYae5Pxz4GHlFJz2+9sef934NP+DkwMIfPuBGc3WPkXR0cy4CxOJhaNCeab3XlU1Td1eU5Dk40HPttNeW0jhVX13PnODrYcKkFr6TUXQgghRN/Ym4z/FkgFVimlcpVSO5RSucAqIA24c6ACFEOARyDMugX2fAx5uxwdzYC7anYMFXVNvLg6rdOx6vom3lh/iMySWv5+7gSeuXwqDc02znt6Hd/tLXBAtEIIIYQYzuxd9KdYaz0XOAt4CvipZXuG1nqu1rp4AGMUQ8HMm8HJFTaN/MkqkyN9OHNCCI+tSOb19Yfa9tc1NjP/nz/w4Gd7ODHWj/mjAxkT6sWzV0wFYGtGqaNCFkIIIcQw5dTbCUopF+Au4DOt9VfAVwMe1VFQSi0BlsTHxzs6lJHJ1RcmnAc/vwOnPgDWkb3S6aMXTqahaSv3f7SLQ0XVLEwK4l/f7Keoqh4vqxN//sU4lFIALB4XwthQL3bnVDg4aiGEEEIMN71WxrXW9cAfAJ+BD+foaa0/1Vov8/Ye2UmiQ027DhqrYcfbjo5kwFmdzTx9+VSunBXNC2vSuPSFDWzNKMPb1ZntfzyNMaFeHc4fG+bFHknGhRBCCNFHvVbGW2wApmD0iIvjVfgUCJsCm18yVudsqQyPVM5mEw8uHc+MWD++25PPqWNDiPB1xWTq/H2PDfXivS1ZFFTWEeRpdUC0QgghhBiO7E3G7wbeVEo1Al8A+UCH0RFHziAXI9SUK+CzOyB3B4RNdnQ0g+LsiWGcPTGsx3PGhRmV8t05FQQlSjIuhBBCCPvYO01lAzAKeBw4AFQAlUe8xPFg7C/BbDF6x0WbMS3JuLSqCCGEEKIv7K2MX8sRlXBxnHLzg4TTYOe7cOqDYLb3f6GRzcvqTKSfK9szy6isa8TT6uzokIQQQggxDNiVSWmtXxngOMRwMvEi2PcZpP0A8Ys6HitMhoCEEd9P3pUYf3e+3ZPP5S9u5ONb5jg6HCGEEEIMA3a1qSilUpVSk7o5Nl4pldq/YYkhbfRisPp0nqqSuwOenA47ljsmLgdbMsnoK9+RWUZZTYODoxFCCCHEcGBvz3gM4NLNMTcgol+iEcODkwuMOwd2vQ+VeYf3Z6w3tuuegONwafgLpkbw1g0zAdhySBYAEkIIIUTvuk3GlVJeSqkopVRUy66Q1vftXqOBi4HsQYlWDB2TLwXdDP8eBwV7jX3ZW4xt/i5IX+242BxEKcUJUT44mxUb00scHY4QQgghhoGeesbvAP6E8eCmBj7s5jwF3NnPcYmhLnIGXP4+LL8M3r8BnF0hayPEzjeS8XVPQexJjo5y0FmdzSQEeZKcJwOGhBBCCNG7npLxN4HNGMn2J8BdwP4jzmkA9mutMwYmPDGkxS+CRQ/AV/cYPeQAY5ZA+FT46TGoLgL3AMfG6ACRfq4cLKx2dBhCCCGEGAa6Tca11gcwZoqjlDoZ2Kq1lnKf6GjmTTDxQqMy3twIFg+jMr7mUdj/BUy50tERDrpIXzdWJReitUYdh1NlhBBCCGE/ux7g1Fqvak3ElVJmpZTbka+BDVMMaW5+RjJu9QKTCUImgE807P3M0ZE5RKSfG3WNNgqr6h0dihBCCCGGOHtHG3oppZ5QSuUA9XRefdPhFXOl1BKl1HPl5eWODkUoBXHzIWvTcTlVJdLPFYDMkloHRyKEEEKIoc7e5ROfBc4GXgD2YPSKDyla60+BT6dNm3aDo2MRQMhE2PoaVGSD9/E1+TLS1/hFUVZpDVOjfTsc01pTXttIUVUDJgVxgR6OCFEIIYQQQ4S9yfhi4A6t9QsDGYwYQUJb1ojK3XH8JeN+bpgUpBRUdTr24po0/vL5XjxcnLA4mfjq9nkEeVp7veeG1GIOFlZz8fRITCbpQxdCCCFGCnsX/akGsgYyEDHCBI8DFOT+7OhIBp3V2czECB/WHizusL+usZn/fHcAMCrk1fVN/Onj3b3eb2dWORc9t57ff7iTu9//mSdXptDUbBuQ2IUQQggxuOxNxh8BfqWUsvd8cbyzuBvV8eQvHR2JQ8yJ92d7ZhmVdY1t+35KKaKyvolnr5jKijsX8OuF8Xy5K4+vd+f1cCdYub+g7ev3tmTxz6/3E/+HL3l21cEBi18IIYQQg8Pe5DocmATsV0o9p5R6+IjXPwYwRjFcnXC50aaSs93RkQy6OfEBNNs0G9MOr8S5LaMMs0lxUkIgId5Wrp8Xx4Rwb257axvZZd0/7LnmQBHjw70I9nIB4JSkIDytTjzyTTJpRTLPXAghhBjO7E3GzwdsGD3mpwIXdPESoqMJ54OzO6x+xNGRDLopUb64OJlYk1IEwC1vbuWJlSkkhXjiajEDRjvLQ+dNoL7Jxub0ki7vU1XfxNaMUubGB/LiVdO594wkXrx6Oit+O59mrXl3c+agfU9CCCGE6H/2zhmP7eUVN9CBimHI1Rfm/Ab2fgKpPzg6mkFldTYzI9aPtSnFHCys4vOfc4HDk1ZaxQd5YDYptmeWUVjZeS75xrRimmyaeQkBjA/35qb5owAI8rIye5Q/n/6cgz4Ox0cKIYQQI4X0gIuBNfvX4J8AH94EZcdXFXdOfAD78yt5dW06AOE+rlwxK7rDOS5OZmL83Xj5p3Sm//U7quqbOhxffaAIFydTpxGJAL+YFEZmSS3bMssG7HsQQgghxMCyOxlXSk1USr2tlDqolKpXSk1p2f9XpdQZAxeiGNYsbnDBy9BQA6+eDcUHYeXfoTTd0ZENuDmjAgB4Y/0hpkX78tO9C5kTH9DpvEBPl7avz396LbuyjYWrvt2Tz7ubs5gZ54/V2dzpusXjQ7A4mfhke07bvoamY5uysiu7nK0Zpcd0DyGEEELYz94VOM8AtgAhwGuAc7vD9cCv+z80MWKETIArPoSaEvjvFFj1kFEpH+HGhnnh4+aMTcMZE0K7Pa91zvjJiYHsy6vksZbxh49+m0yQlwt/+eX4Lq/zsjqzMDGI/204xJMrU3j0m/0k3v9lWzJ/NO56dwe3/G/rMbW+/LC/gIWP/EB5TWPvJwshhBDHOXsr438HXtFazwf+esSx7cDkfo1KjDwRU+GaLyF8Grj5Q8Y6SFnh6KgGlNmkmD3KH4Azxod0e96ffzGOZy6fysvXzODaObH8mFxISkEle3MrOH9qBJF+bt1e+8DScUyN9uWx75J5/PsUtIaV+wq6Pb8nWaU17MurJLe8jr25lUd1D601V7+8idTCag4UHN09hBBCiOOJvcl4EvB2y9dHlswqAL9+i0iMXCHj4YYV8Nu94BMN3/4RbCN78ZpbT07gb+dMIMzHtdtz/NwtnN6SrC+ZFEpDs43TH1sNwMmJQT3eP9jLyq8XJtDYrHFxMhHu48q61OIer+nO9+2S+Kte3kjKUSTT97x/eJGn4uqGo4pDCCGEOJ7Ym4wXAN1NTBkHZPRPOOK44OQCc++A/F1QtN/R0QyosWFeXHpilN3nnxDly8tXT+fSE6O4clY0SSGevV5zYqwfod5Wzp0SweJxIWw5VEp9U3OfY92dXUGAh4WrZkVTWFnPyz+l9+n62oZm3tmcxcmJgQBdTocRQgghREdOdp63HHhQKbUHWNeyTyulRgP3AC8ORHBiBIubb2wPrYWgMY6NZYg5OSmIk5N6roi352Q28dVvTsJqMfHtnnxe+imNlIIqxoV59+lzs8tqifB144Gl48kpr2PlvgK01iil7Lq+qMpIvk8dG8LK/YWSjAshhBB2sLcyfj+wGVjF4Sr4x8Au4Gfgb/0fmhjRfGPBI8ToHRfHzNvNGRcnM0khXgBH1fOdXVZLuK/RTrMwKYic8jqS86vsvr41GQ/xdsHP3dL2XgghhBDds6syrrWuB85WSp0CnAIEACXACq31twMYn92UUkuAJfHx8Y4ORdhDKYieBamroKkBnCyOjmhEiA1wx8XJxL7cij5dZ7NpsstqOW1sMACTI30ASCmoItGOVhmAoiqjRzzAw4UAD4tUxoUQQgg79GnRH631Cq3177XWy7TW9w6VRBxAa/2p1nqZt3fffjUvHGjSpVBdAHs+cnQkI4bZpEgM8WRfXt8q40VV9TQ02doq4yFexrjFvIq6Pt0DjGQ80NOFQqmMCyGEEL2SFTiF48QvgoDRsPoRaG7q/Xxhl7GhXuzOKe9yVnhmSQ11jc002zTltYfngGeV1QLGKqEAPm7OWJxM5PchGS9uSb793C0EerhIm4oQQghhB0nGheOYTHDKH6FwH+x4y9HRjBgTI3worWkko6Smw/7y2kZO+/ePPPzVfp5amcJJD6+kqt74IWhvS1tLa2VcKUWot5Xc8r5UxhvwtDphdTYT6OlCfkU997z3M+9uzuyn70wIIYQYeSQZF46VdDZ4R8HBkb0A0GBq7ffenlnWYf93e/KpbWzmg217D5H4AAAgAElEQVRZvLMlk/LaRr7ZnUdJdQP//Ho/EyO8SQg63B8e7GUlvw/JeGFVPQEeLoCx4mhDk423N2fyu/d+7uXKgVPX2EyJzDsXQggxhEkyLhxLKQidCLmOS9hGmtHBHgD8Zvl23tp4eAmAz37OwWI2UVbTSGaJ0ZbywdZs3t2cSVlNI/84byJm0+ExhiFeVnIrjPP+8OFOPv85t8fPLa6qJ8DDeBB3SpQvV86KBsDqbKLZ1rllZjD8v8/2sPTJNV227AghhBBDgSTjwvFCJ0HJQajr2wQQ0TUns4mzJ4YCh1fVLKis48cDRVwzN4a7T09kSpQP18+NZU1KEX//ch/TY3wZE+rV4T6h3lbyy+vJK6/jfxsyuOXNrT1+bk5ZHUGe1rb3Dy4dzyMXTKKu0UZqof0jEvuLzaZZua+AzJJa0oqqB/3zhRBCCHvYlYwrpc5TSl3X7n2sUmqtUqpMKfW+Uspn4EIUI17oJGObv8uxcYwgT1w6hXkJAeS1tJl8uDWbZpvmwmmR/GpBPB/8ag6/PW00wV4uOJsVty5M6HSPUG8rDc02/rfhUNu+jOKaTueBMUklo6SGCREdpxm1vt+ZXd5f35pd9uZWEPf7L8hp+f43pJUM6ucLIYQQ9rK3Mn4f0L5s9l+MWeMPAVOAv/ZzXOJ4EjLR2EqrSr+K9nfjUHE1Wmve2ZzJtGhfRgV6tB13szjx2a/nsfkPpzJ/dGCn68+cEIq7xcx/v09p2/fpzzldfta2DKM/fWq0b4f9cQHumE2K1MLBrUz/lFLU9rXFycRGScaFEEIMUfYm43HATgCllDdwGnCH1voh4A/AkoEJTxwXPEPAPRDyJBnvT9F+7lTUNfHFzjwOFlZz4bTITucEerrg7ebc5fVBXlb+3y/HE+nnyo3z45gZ58c7mzOxddH/vflQCc5mxYTwjpVxJ7OJYE8Xcspr++ebstOelukwD58/kRkxfqRKm4oQQoghqi89463/As8HmoHvWt5nAZ3LakLYSymjOi6V8X4V6ecGwC1vbiXQ04UzW/rI++LcKRGsvnsh/3fGGC6aHsmh4hq2HTGlpaHJxsfbcpge44fV2dzpHmE+ruSUDW4yvju7gpMTA7lwWiTBXlYK+jAvXQghhBhM9ibjO4DLlFLuwPXASq1164oeUUDBQAQnjiOhE6FwLzTJQjH9Jdrfre3rr28/CQ8Xp2O638mJQSgFa9u1gAB8siOHvIo6bpw/qsvrQn1c+zSvHKDZptmYVkLuUVTU6xqbSSmsYnxLlT7E24WCyvo+T3R5/sdUHvsuuc+fL4QQQvSFvcn474FzgAqMyvif2x37JbChf8MSx53QyWBrguwtjo5kxBgd7MntixJYfffJ+Llbjvl+Pm4WkkK8WJ9W3GH/6gOFBHm6cFJCQJfXhXlbyS2r67K9pTu3Ld/Ghc+uY94/VrIpvW/93oeKa2i2aRKCjZnpIV5Wmm26bYVQe721KYP/bcjo/UQhhBDiGNiVjGut12BUwGcA0Vrrje0Ov4TxgKcQRy/+FHByhZ3vOjqSEcNsUty+aHRbu0p/mBnnx+b0Uuoam6mub+LWN7fy8fYcpkT5opTq8powH1camm0Ud7P4zoH8Sg62G33Y0GTj2z35LJkUhpvFzAXPrOOXT/5kd2U7vdjoD49u+b6DvYxxi3l9aFWpbWgmvaiawsp6ivqYxAshhBB9YXfPuNa6Umu9RWvd1jCqlPLRWn+htZbf5Ypj4+IJY86GXe9DQ9fj84TjzUsIoL7JxvrUYr7clcdnLQsBnRDV/XTTUG8jGe6u5eSu937m9x/sbHu/P6+ShiYbp40NZk68UW3fnllGcn6lXTG2jl+M8XcHIKTl8/P60CqzP7+S1tx/b67MvxdCCDFw7J0zfrNS6u527ycrpbKAYqXUFqVUxIBFKI4f066DunLY+lrH/Y11xn7hcLNHBWB1NvH9vgI+2XF4zOGUI0Yathfu6wpARknnH7K01qQWVrVVswG2Z5YCMDnSh2vmxLbt33Ko1K4Y04ur8XZ1bpsS01oZz6+0v8K9r10CLsm4EEKIgWRvZfzXGP3irR4HcoDLWu7xUD/HJY5H0bMgajas/S+8uBjWPAbNjfDSYnj2JKmYDwFWZzPzEgL5eHsOqw8UcsvJo1i+bCbTekjG4wI8UApSCjqvwlla00hlXRP5FfXUNTZT19jM+1uzCfR0IcLXlRmxfqT9/UwCPFzYamcynlFS0+Hh1QAPF8wm1aeJLhvTS/C0OhHu48pPKcUcyK/k2z35dl8vhBBC2Mve8QpRwH4ApVQgMAc4RWv9g1KqAXhigOITx5t5v4X/nQ8VWZC5HjY+b3wNRpK+4B7Hxie49eR4ztn7E+4WJ66fG4dvLw+HulrMhPu4dpmMt6+IZ5bU8OKaNLZnlvHfS05o60FXSjE12octGb0n40alvbpDpd5sUowP82J9anEPVx5WXd/EV7vy+MWkMIK8rDy+4gCrkgsBWHnXAmID3O26jxBCCGEPeyvj9UDrv7gnAzXA6pb3JUD3DaNC9EX8IqM6PuFCWPw3CJkAZz0KSWfDuieg1r7qqBg4kyJ9+PdFk3n8ksm9JuKt4oM8ukzGD7VLxt/bmsXyTZn8asEolkwK63De1GhfDhXXUNhLq8lXu/LILqtl3hGTXU5OCmJ7ZpldE1U+3ZFDTUMz502N4OLpkVidTYT7GK029lbnhRBCCHvZm4xvBG5RSo0DbgO+0lo3txyLw2hZcSil1BKl1HPl5dJbPKwpBdd+Cec9D7NugUuXw/TrYMG9UF8BG551dIQCWDo5nIVJwXafHx/oQWpRdaeJKOlFh1uPXlydhsVs4taF8Z2unxJlVLq39lIdf3ltOnEB7px7QniH/QuTgtAaVuzteUmEZpvm2R9TGRfmxbRoX8J8XNn4h0X8ePfJeLo49fr5QgghRF/Zm4zfCYwDdgKRwB/aHbsI+Kmf4+ozrfWnWutl3t7evZ8shp+QCUZ1fP1T8jDnMJQY4klDk40dWWXUNDS17U8pqCLSzxUfN2eabJppMb64WTp3z40P98bZrNiQ2v3McZtNsyengrkJATiZO/7VNiHcm7hAd5Zv6nlu+M7sctKKqrl+Xmxbm4yX1RmzSTEp0odN6SVo3bfFg4QQQoie2DtnfI/WehTGsvcxR4wyvKvlJcTAmn2bkYinrHB0JKKPFiQGAXDuU2u55Ln1bft355QzLtSbuxcnAbSNMjyS1dnMwqQgXl+fzuct4xSPlFlaQ1V9E2NDvTodU0pxyfQotmaUkV5U3cXVhtaHPBODO9/jjAkhJOdXMfHP3/DRtuxu7yGEEEL0hd1zxgG01sWAn1IqQSnl37Jvp9a6cECiE6K90ImAgiIZaz/cBHq64NsyanBHVjlaayrrGkkvrmF8uBeXzIjkrRtmct3c2G7v8fB5k0gM8eSWN7eyNqWo0/HWEYRjukjGAaZEG4+2tH9o9Ei5LbPIW2ejt3fpjCgumhZJZX0Tr6xN7/YeQgghRF/YnYwrpS5SSu0FCoB9QIFSaq9S6oIBi06I9pxdwScKCvc7OhJxFJ68bAqeVqMFJa+ijj05RvI8LswbpRSzRvljdTZ3e723mzNvL5uFUrAhrWO7SrNN8/XufEzKaInpStu88R5W4syvqMPiZMKn5QeH9pRS/OP8idyxaDQ7sspkZU4hhBD9wt5Ffy4B3gJSgWuAM1u2qcBypdTFAxahEO0FJkplfJiaPSqA56+cBkByfhW725LxrivZXXF3cWJUoEfbta0+3ZHDh9uyuXJWTLcJfaCnCwD5Fd0n0bnldYR6W9v6xbvS+jDoT11U54UQQoi+snfO+B+A57TWNx2x/zWl1DPAfcDyfo1MiK4EjIbUVWBrBlP3VVQxNI0ONqrWT3x/gAAPFwI9XQjy6twS0pNxYV5sPKIyvjevAovZxP1nj+32OhcnM37uFvJ6qoyX17VV0LszKsiYM55T1vV9NqWX8Nq6QywaE8TSycZUl8LKet7amIGn1Qk3i5nTx4W2rRB6tNanFnOouJozJ4TiaT22ewkhhHAce5PxeOCObo69D1zdL9EI0ZvARGiuh7JD4Bfn6GhEH/m5W4jwdWVTujEicEFiYJ/vMS7Mi4+355BXXkdIS293ZkkNEb6umE3dV7QBgjxdKOghGc+tqG0bo9gdN4sTrs7mLmeWf78vn+tf3YxNQ3ZpTVsyfte7O9oWDgJ49NtkXrlmRrf97b2prGvkshc20GzTvL7+EB/cPAeLU58eARJCCDFE2Pu3dz4wrZtj01qOCzHwAhKNbaG0qgxXH98yp20Rnb60qLQ6bWwITibFf1Yc/n8go6SGSD+3Xq8N8bZ226aitSa/or4twe+Jv4eF4uqGTvs/+zkXXzcLv5wcxsHCarTW1DU2sy61mOvmxrLyrgW8vWwmCsUVL26gqr6pi7v3Ljm/imabZl5CALuyK9idI+M+hRBiuLI3GX8Z+LNS6j6lVJJSylcplaiUug/4E/DSwIUoRDuBo41tkTzEOVz5e7hw7hSjYhzh23sCfaSYAHeunh3DWxszeW9LFgAZxTVE2ZGMB3tau21TKaysp6HJ1vaDQk/8PVy6TMZ3ZZczKdKHyZE+lNc2UlhZz9aMUhqabMyJ9yc2wJ0T4/x55oqpFFU18OLqtF4/qyvJ+ZUA3DDP+O3QgS5WNxVCCDE82Num8iDgDNwLPNBufy3wr5bjQgw8V19wD5LK+DB3y8nxeFqdOOeIlTLtdffpSWw+VMqTK1NYNCaIirom+5JxLxeKquppbLbhfMTCQGkt88dj/N17vY+/u6XTVJbq+iZSCqo4Y3xoW298cn4VH23PxsmkmB7j13bu5EgfzhgfwlM/pHDWxBDig7qeANOd/XmVuFnMzBrlj8XJRIok40IIMWzZu+iPTWv9B4zVNxcAl7RsI7XW92lZkk4MpsBEqYwPc1ZnM8tOGtXjKMOeWJxMLEgMJL24mn15RpXYnjaVMB9XtIa88s7V8UPFNYD9yXhxVcfK+J7cCmwaJkZ4Ex/sAcDlL27gvS1ZXD8vrtNDlg8sHYebxczFz20gtbBvyXRyfiUJwZ44m02MCvTgQEulXAghxPDTazKulLIqpb5RSi3QWpdqrVdrrd9p2ZYORpBCdBCYCAV7ofGIhGr7W/DNfbDhWTi4EuRnxBEtKcQTrWlrVRkf3nv/eWvCnlla0+lYWnE1zmZFmI89PeMulFQ30L4OsTPL6NueEO5NoIcLv14Yz3VzY7nvrDH89tTRne4R5Gll+bJZFFXV81k3q4p2ZXdOORvSSpgWbTxomhDkQXK+VMaFEGK46rVNRWtdp5SaDsgcOTE0JJ0Nm16AfZ/BhPMP71/5NyjPOPx+zu1w6gOdrxcjQlKIkXy/tyWLYC8Xu3q9I3yNc7JKazsdSy+qJtLXDSdz778w9He30NBso7K+Ca+WivfO7HKCvQ6ParzztMRe75MY4kmYt7WtRcYeT/9wEC+rE79eGA8YP4R8sqPjdBkhhBDDh70PcH4C/HIgAxHCbrHzjZU4dxwx2r6uDCZdCncdgClXwk+PyWqdI1iUnxuuLW0uU6N9e1yop1Wotysm1XUynlpYTUxA7y0qYExTATq0qvycVcaEcB+7rm8vNtCd1D4k45klNYwP98bHzYhhbrwxHnL1gcKeLhNCCDFE2ZuMfw2cq5R6Tyl1rVLqLKXUme1fAxmkEB2YTBB3MmRtOtyKUlcB9RUQlAQeQbDwflBm2P6mY2MVA8ZkUty+KAGAkxOD7LrG4mQixMtKVknHNpW0omr251cyI9avmys7al0Y6FCxkUSX1zaSWlTNhHBve8NvExvgTlphFb09epNRXMNd7+4graia0HYV8KQQTwI8XFh9QFYEFUKI4cjeaSpvtGzPbXkdSSNtLGIwhU6Cra9CWQb4RkNFtrHfq2U6h0cQxJ8Cez+RVpUR7Mb5o7h6TgwWO1pLWkX4unWqjH+4NQuTwu7pLlOifLE6m1i5r4AFiUH89fM9KGBhkn0/FLQXF+BBRV0TJdUN+Hu4dHveJc+vJ7vMiDuk3SqhJpNiarSPzBoXQohhyt5/wWJ7eclSiGJwhU4ytnk/G9vylmTcO+LwOSETofQQNB/dwipieHBxMtvVotIqJsCN5IJKbLbDlei1B4s5Icq3reLdG1eLmbnxgXy7J5/S6gbe3ZLF1bNjmRBxFJXxQKM1pqe+8YOFVW2JOECId8f++AhfN7LLanutrgshhBh67B1teKi310AHKkQHQWNBmSBrs/G+wpio0VYZB6NirpsPHxMCmB7jR1lNY9tCOVpr9uVV9nk10IVJQeSU1/HO5ky0hjMnhBxVPHEtfeo99Y2/uja9Q/U/xLtjBT3cx5W6RhslXSxEJIQQYmjrNhlXSoUqpd5XSi3u4ZzFLef0/XezQhwLixvEn2qMMVz/DOTtNJJzz9DD5/hEG9vSdIeEKIammXH+AGxIKwaMhzmr6pvaprPY64Qo42HNp1cdxNXZzMSIvj+8CUYi7WxWpBZ2nYxX1DXy3pYslkwKa9t3ZAU/vGVKTPvqeU9255Rz0bPrKK6qP6qYhRBC9J+eKuN3YbSffNPDOd9gtKnc2Z9BCWGXXzwOPpHw1T3GqMPQyWBu9xiEb2syLr+4EYdF+LoS5m1lfaqRjO/NrQAgKbRvq2CODvbEbFKU1TQyI9YPi5P9fevtOZlNRPu7k1bU9azwdzdnUdPQzNWzY9r2hR7RptI61jG7iykxR7LZNBc/t54NaSV8v6/gqGIWQgjRf3r61+Ns4JmeVtdsOfYssLS/AxOiV54hcOsmuHktLH0Srviw43GvCGOiSpkk4+IwpRQz4/zZmFbC1oxSlr2+BYDE4L4l42aTorml7/zG+cf22ExsgHu3PePvb8nihCgfJkR48+DScfi7W/B167iaZ0QfKuPJBZVU1hnPUWxKLzmmuIUQQhy7nqapRAN77LjHXiCmX6IR4mgEjzNeRzI7gXe4VMZFJyfG+fHBtmyeW5UKwL8umIS7i73DpQ575vKp7MouZ/aogGOKJy7AnVXJhTTbNGbT4YdRG5psJOdXcsNJRrJ/5awYrpwV0+l6b1dn3C3mLuenH+lggZH0h/u4siFNknEhhHC0nirjtYA9TZQeLecKMfR4R0G5PMApOjox1ugb/2p3HhPCvTl/akQvV3Tt9PEh3LW495U2ezMu3JuGJhsbWlpnWh0srKLJpkkK6blqr5RicpQPP+wv6HWiysFCox3m/KkRHCquoby28diCPwo2m+avn+9hf17loH+2EEIMNT0l41uBX9hxj6Ut5wox9HiHH55BLkSLaH+3traU8eF9e3BzIJw2NhhvV2f+tzGjw/7WZHVMaO8xLp0UTnpxDTuyep43frCwinAfV8a09MhnHrEA0mBILarm+dVpvLs5s1/u12zTvL7+ECkFktwLIYafnpLxp4DrlFJXdXeCUupK4Brgif4OrK+UUkuUUs+Vl8vCF6Idr3CoyAFbs6MjEUOIUor/OzMJgHkJgQ6OBqzOZi6aHsmXO3NZm1LElS9tZFd2OXtzK7CYTcS2jD/syekTQnC3mHni+5QezztYWMWoIA8i/dyA7pPxqvomymsGpmreukDR7pyKY7pPcn4le3Iq+PFAIfd/tItFj/7IJzty+iNEIYQYNN02SWqt31dK/Qd4WSl1K/AVkIGx2mYUsBiYBvxba/1hd/cZLFrrT4FPp02bdoOjYxFDiHe4MWu8qgC8Qns/Xxw3FiQGseH3pxDk2f2ql4Pp5vmjWL4xg0tf2ACAj6szm9NLOCHKB2c7Vhj1sjrz61MSeOjLfVz83Dp8XC1MiPDmurmxWJ2NBZJtNs3Bgmqmz/AjqiUZP9RFMl7f1MzMv62gqr6J926axbQYv378TmFXtpGM78opR2vdtmhTfkUdD3+1n3UHi/jLOeNZmBTc7T1WHyjkihc3YnEycf3cWADGhnrxf+//zFkTQjv03gshxFDW49/wWus7MdpQKjBGHT4LPAf8DqgElmqt7xroIIU4al4tvcDSqiK6EOxl7dPqnQPJ193CC1dN56wJxg+Nn+zIIae8jltOjrf7HtfNjeWORaOprGviQEEl//x6P9e+sonGZhsAeRV11DY2MyrQA0+rM37uFjK6SMYLKuqpqjcmrqw4ivGHKQVVLH1iDWf+ZzXXvLyxU/V9Z0syXlnX1LbY0de78zjlkVV8uiMHpRR3vrOjx/73j7cbFfCGJhsfb89hcqQP186NpbqhmfTi7hdQ6ovCynpy7JzdLoQQR6vXcovW+lOt9SmAJxDa8vLUWi/SWn820AEKcUy8W1bklIc4xTAwI9aPJy+bwsPnTQSMXvJ5CfZPanE2m/jNogQ+v20eK+5cwMPnT2TtwWLe32L8/9/68OaoQA8AIv3cumxTKaisa/t63cHiTsd78/2+fHZklWN1NrE5vZTTH/uRR7/ZT2OzjW0ZpWxMK2HRmGCcTIoLnlnHRc+u48bXtxAT4MY3d5zEspPiKK1pJL+i+0WJ9uZWEOBh/FYju6yW6TG+bQ+69teDoXe/t4Nlr2/ul3sJIUR37F6lQmvdpLXOb3k1DWRQQvQbr5ZkvKKLPtKSVPjwZvjst9JTLoaU86ZG8NLV03jysinHVLm/YGoEvm7ObM8sA+BgQUsyHmT0oMf4u5FS0HmxodYk+JSkIHZml1NQUdfpnJ7syq4gzNvKB7+aw1d3nMSsUQE8/n0KH2/P4cHP9hDsZeXRiybx8a1ziA/yIK2omvvOGsP7N88mJsCdxNakOr/rpLqx2caB/CrOnRLetu+KmTHEB3lgUrCvH5JxrTVbM8rYn1fZ9psFIYQYCEe3ZJwQw4WrL7gHwqGfDu/LWA/rn4FXlsCON2Hzi7DmUcfFKMQRzCbFwqRgu3rFe6KUYny4N7taHpg8WFiNp9WJwJaK8uRIH3LL68gpq+WDrVnUNRo/lLYm3zfOH4XFbOK25du6/YwD+ZUsfOQHfs4qa9u3O6ecceHegDHP/LkrpuJldeKVtWlsyyhj2UlxeFmdGRfmzTs3zmLjHxZx/bw4XJyM3vbWSTfJ3STVBwuraGi2MS7Mi+evnMaHv5pNlL8bVmczMQHu7Ms9ugdDtdY8s+ogyfmVZJbUUl7bSGOzJr2bBZmEEKI/SDIuRjalYPJlsP8LKG/pG3/nKvjqHnCywI0/wtil8P1fYN1Tjo1ViAEwLsyb/XmVZJfVsvZgEaMCPdqq7VOjfQF4+oeD/PadHfz5k90AFFTW42RSTIv25Y5TE1ifWtLtCqHf7MkntbCai59bT155HaXVDaQWVTMu7PA4RpNJMTXal13ZFbhZzJzXy1x3X3cLQZ4u3Va49+Ua+5NCvDh1bDAnRPm2HZsV58/K/QVdVvx78/XufB76ch8vrE7l5+zDP1x0V6EXQoj+IMm4GPmmXQNaw9ZXoTIPqvJg1q1w62YInQTnvQTBE4yEXYgRZkK4N43NmkWPrCKrtJYb5sW1HRsT6oWrs5nPd+YC8N3efMBoUwn0dMFkUpzZ8kDpt3vyurz/tgwjaTUpxZIn1nDm46sxK8WCxKAO57X2qV89OwYvq3OvcSeGeJLcTRKcWlSNSUFMgFunY7cvGo3FbOLFNWm9fkZ7jc02Hv5qHwDvbM7in1/vx8PFCZPqvkIvhBD9QZJxMfL5xkDCqbDlFcjaZOxLOgtMxq/EMTtB+AmQv9tI2u3V3Aj1fa++CTGYThsXzE3zR3FyUiCf3zaXsyYeHvHpbDYxKdKbkuoGAIqqGsgsqaGgso4gLysAEb5ujAn14vsupqp8tSuP7/bmc96UCJYvm8nYUC/igzx4a9lMJkf6dDj3mrmxXDUrmlsX2jcdZnSwkYw3Nds6PZCZVlRNhK9bW1tLe4GeLiSGeJJW1Lc/m6+vO0RqUTXzRxtz5w8V1/DyNdOJ8XcnOV/+nAshBo4k4+L4MPNmqMqHty833odM6Hg8aBzUlhjn9ERrWPtfeG0pPBQFfw+Hb/80MDEL0Q+czSbuPSOJpy6bSnyQZ6fj06KNGeLuFjOuzmbu+2gXqYXVHeavT432YXdOBWU1Dfz5k92U1zZS29DMTW9sAWBOvD/jw7159doZvH7diUzvYi55uI8rDywdj5ul2+UtOkgM8aS+ycZ/v09h8WM/8tWuw5X51MKqHhdCivJzI7Ok95GE5TWNZJbU8Oi3yfz1i72cNDqQB34xDoC/nzuB6TF+bT8UCCHEQJFkXBwfRi2EM/5pfB08AVyOSEqCxxrbHx6CB3yhtowu5e6Ab+4zprOccAUoM6SvHri4hRhgrX3js+MD+N3iRFYlF5JXUcfSyWFt5ySFeFFZ18Ttb2/nlbXpfLQtu+2h0D+ePZZfTg7v8t7HovUhztfXHwLgzY0ZgPGQZVpRNXGB3SfjkX5u5JbX9jgF5fcf7mTSg98w7+GVPL7iAIvGBPHUZVOICXBn/19O55IZUQCMDvEkvbiausZmtmWU8sLq1H75/rTWPP9jKq+vS++X+/W3j7Zl8+XO3B5nvQsh+od9JQohRoITl8H4c7tuRQkeb2y3vGxs83dDzJzO57W2uVz2HvhGQ3MD7Pl4YOIVYhBMifLFpCAhyINr58YyM84fm9aMb5mGAkZvOcAP+wsBY9Ge+iZj8sqSSWGYBmC1y4RgD5SirYXmx+RCNqeX4OXqTE1DM3E9VMYj/dywacgpqyXav+vzfkopwt/dwi0nxzM/MbCtpx3o0P6SGOyJTRsTXH71v63kltcxJdqXKe0eGj0ab2zI4K9f7AXg4hlRxzw5pz9tzyzj9re3A/C3cyZw6YlRDo5IiJFt6PzpF2IwuAeAR2Dn/W5+EDjm8PvilK6vz95ijEr0afnHyS/WaG+pK+//WIUYBN5uzixfNqvtwc6xYV4dEnGgbe43gJfVife2ZPH5zjwi/VwJbNfO0p/cLE6cPdGozjIIUgMAACAASURBVN8wL5ZwH1d+s3w7V7y4AR83504PiLYX6Ws82NlTq0pJVQNLJoVx7dzYDon4kRJDjGM7s8qpqG0E4Pkfj706vjalqO3rL3bm8th3ydQ0DI0lPP674gD+7hYifF15f6ssmCbEQJNkXIhW0bMOf12U3Pn4lldhx1sQPs0YmQjgG2tsS9Igc5PRwtI8NP5BFcJeM2L98HW3dHvcw8WJhUlB3HLyKH53ehIAu7PLuW5O7IDG9a8LJnLvGUksO2kUT18+hfomG1ZnM8uXzSTSr/MklVZR/sax9OKuxzHWNzVTWd+Efw/fc6sYf3fiAt350ye7qW4wfhuwO+fo5pi3l5xfydz4AMwmxW+Wb+ex7w7w7Z5enlkZBHWNzfx0sIglk8K4YGokWzNKO6zIKoTof9KmIkSrqFmw+SXj68L9nY//8JCxnXjh4X1+LclIaRpsfN5YXMjiAQvuHdhYhRhkL109HYCmZhvTon0J9bbi49Z7MnssXJzM3DR/FGBMSfnx7gU4mUxYnHquI4V6WQnydGHdwWIunxnd6Xhr64ufR+/xO5lNLL9hJle8uJH9+ZUsHhfMd3sLaGq24XSUrSX1Tc2kF9dwxvhQTh8fwvbMMt7bktX2oGhNQxNXv7SJ209NYPaogKP6jKO1Ma2EukYb8xMDCfW28u/vkvluT4G0qggxgKQyLkSrCRfAFR/CuHMh72doaFdVqy6Gyhw49f8ZfeetWivj6546vMrntjcGL2YhBpmT2cSYUK8BT8S74mZx6jURB2ORoYVJQfyYXEhDU+eHOIurjGTc392+FpsgLyvv3DSLN68/kVOSgmm2aXLLj75anFZUTbNNkxDsweUzo/nXBZNICPJgf54xQnFDagkb00t46Mt9g/4A5Q/7C7E4mZgZ609isCfR/m58vbvrGfNCiP4hybgQrZQypq6ccBlUF8LLZ0D+HuNY3g5jGzqx4zUuHrD475C10XjvFQ7lmdBQM3hxCyE6WTQmmMr6pi7no7dWxv3tqIy38nZ1ZnZ8QFt7TEbJ0f8ZP9Aytzyh3ajJ0SGe7M2toLq+ibUHjX7yn7PKWX2gqMt7DJQfkguYGeePq8WMUorF40JYe7CIyrrGQY1DiOOJJONCHCl+EVz4ujG+8I3zIGM97P3MOBYysfP5s34FZ/7L+HrGMmP703+gqnMSIIQYHAsSA4kLcOfRb/dTUdfYoUJeXF0PYFfP+JFa+9EPFfecjB8srOKCZ9by7ubMTsfSi4zfurWflZ4Y7El2WS3j/vQ1r647xNRoX0K8rDyxspuHyQdAZkkNqYXVLBh9+CH3+aMDaWzWbM3oZtwrxpjGN9Yf4rpXNlFeI0m7EH0lybgQXRlzttGyUl8JLy2GzS8aCwO5dV7MBIAZN8B9hRB/ivF+1UPwxe8GL14hRAdOZhP/d+YYkvOrmPjnb/jN8m1tx/raptJeiJcVZ7Pih/0FVNV3/bC21pplr21mU3op936wk8yWKnpGcQ3bMkpJLaomxMuKq+XwCMVzTgjnmjkx3HZKArNH+bPspDhunB/HxrQSvhmkNpEfko3RlfMTDyfjkyJ9UAq2ZZR2e90XO/O476NdrNhXwO8/2jngcQox0sgDnEJ0J2QC/GYHpK0yRhkGj+v5fCcL+I06/L5JJhAI4Uinjg3m3xdN4o63d7CmXbtHcXUDTiaFl2vf/wk0mxSXz4zm5Z/Smf/wSq6eHcOy+XEdZpPvyCrnYGE1ty9K4KmVB3lhdSoPLB3PlS9tIL2lon5ibMcf7CP93PjTko5/xzQ223h7Uyb3vP8z/h4WpkZ3UwzoJ6v2FxLp59phhruHixOJwZ5szSijocmG2aQwt5srb7Np/rMimfggD05ODOTFNWmU1zbi7eo8oLEKMZJIZVyInrj7Gw9sRkwDZ9fez7e0G7fW3DBwcQkh7HLOCRHcfXoilfVNVNQ1kl9Rx67scvw9LCh1dIsV/WnJOD66ZQ4TI7x55Ntkznt6LYWV9W3HP9qWjcXJxLVzYzl7UijvbckitbCqLREHY2Rib5zNJp65fCpWZzP//LrzhCebTbM1oxSb7dgf8qxvambtwSLmjw7s9N/lhChftmWUcubjq7n2lU0dHirdfKiU5Pwqbp4/ikVjgrFpWJ9afMzxDEVNzTb++fU+fvnkT20rwwrRHyQZF6K/3bEbYuZBebajIxFCQNuiPss3ZnDi31aw+kARV82OOaZ7To704eVrZvD8ldNIKajiomfXkVNWS2OzjU935HDqmGC8rM4sOymO2sZmrn3FWL13dLARi70Pj8YEuDM3PoCDhR1npmutufj59Zz71Fo+2Hbsf9d8sDWbmoZmFo8L6XRsbnwAlXVNpBRUsSq5kBV7Dz8P8+mOHKzOJk4fH8IJUb64WcwdfgtxtGpbZroPJZ/vzOXJlQepqG3k/o928eTKFN7bksWDn+6hqbnz1B4h7CXJuBD9zTvCaGmpyIZBHksmhOgsPshIgF/5KR2A35+ZxM3zR/Vwhf1OHRvMG9edSEFlPX/8eBdrUooorm5g6WRj9dCkEC8unxndVhVfdpLxueG+dvymrUVcoAeFlfUdJpqkF9ewMa0E/j975x3mRnX14Xe2975rr73uvXcDxja4gE0xJJjQO4SSkNBJQgnJlwAhJAQILRQDhkDohBK6bVwBdxv33r2996Lvj6O7GkkjabTe7vs+jx9JoxnN1Wos/e65v3MO8M2WY2sWtO5AEX//cjtjeiYxub93XfMpA9MIM1lTVjgj3+XVdXyy4TDTB2cQGyllJ0/sm8rSnccmxl9dvpdxf/6KgvIa6hscrD9QxKq9BT49+q3F5iMlhIcafHbrFM4akcmjX2zjznfWM2/ZHtYflATXw0WVzFu6pzFJt7U4VFTJA//9kee+3dWq59U0D9ozrtG0BAndoaYMqoohOkm2Fe6D18+DS991NQtqCg0N8MU9Yp/pMbF5xqvRdGJ6pcQQHmpwuLiK4d0TGgVxczG+dwrXT+3LY19tp8EBYSGGWxLkb2YPZv6KfcRHhXH+uCx6JEczobd9/7equrInr5yRWfJ9snqfJFSO65XMkh151NQ12KrBDuJFDzUMQkIMskuquHLeD8RHhfHweSMsrTsJUVLWMc9pxdmZI6UZX1m+l8KKWn4+pW/jvif3T2PB1hwOFlaQley7S6oviitqeeyr7VTU1PP15mxeWLKbHc7zhRhS3eWxC0b77RjbUuzJLadXaiyRYaE8dckYzt+WRXVdPTe+vobvdhfw46ES/vr5Vspr6nn0i218dfvUJv0NmsL85Xt5dYVYZ/qnxzFzaJdWOa+medCRcY2mJUjsLrclh13bDvwA+Tth/wrrYw6tgYLd1s/VVIiYByg5CN8/Cy+d5v76Go3GkrDQEM4YnglAn7S4FjmH6vS5YGsOPVJi3BI6YyPDWHv/aXxx61QATuibSkiIfb96v3QR47tNVpXV+wqJjwrjusl9KKuu48O1h9h4sNjv6zgcDp5dtItRf/ySkx9ZwKq9Bdz97gaq6+p57doTGNw1weexT140mlevmUj/jDh25ZZxtLiKZxbu5LShXRjTM7lxvykDJLK+rInR8acX7aSkqpawEIO739vA3vxy/nr+SOZdNZ4bT+nHsl35XPPqyjaxhezOK29MbjUMg2mDM5g9PJMBGXE88fUOHvhoE+N6p/DGz0+g3uHg8a93tNrYduaU0Tc9lqzkaN74YX+rnVfTPGgxrtG0BIk95LZwr2ubEtp5Fl/Qa+bDC9Pg/eu9n1v+T/hrH3hiJLx3nfvxK19qtiFrNJ2Ze88awpDMBC6Z2DJt3VNiI+iSIKUSe6V6R0OTYyPolmTfmmKmZ2oMIQa8/t0+bn9rHeXVdazaW8DYnsmc0DcVgLvf28Ccp5aSX1bt83Ve+24fj3y+lUn9UgkLNTj/uRV8uz2X350xxK3muRVJMRGkx0fSLz2OQ0WV3Pfhj9Q2OLj/rKFu+w3IiCMtLpLF2/N4a+V+aoMQzQu2ZvPKsr3MHZtFWKhMVu48fRAXjO/B9MFduHv2YP72s1Gs3V/Evxb7CFy0EHX1DezLL6dvuvdk7tRB6WDA/507jFevnsCkfmn8bFwWH68/TFVty3nfS03183fmljGkawLDuiWwL791LTKaY0fbVDSalqDrCAiNhH3LYPCZsk2J8XyLJh6b/+t8zsPvV1kEX94HfadJjfON70DaIHmu2xhY+xqc+lsI1WXENBp/dEmI4rNbprToOQZ2iSe7pNpWpZRgiAwL5Z4zh/DnT7ewal8hE/qksCOnjLnjskiJjSA81KC2XvJTrn9tNc9eNpaM+CgAFm3LoXdqLMmxEfz9y+1MGZDG85ePZ/3BIn7z3gZmD+vK5c6ovh36Z8ThcMDXW7K5deaAxiZICsMwGN0jiU83HuHTjUcorarjOpONxReF5TX86o21DOoaz71nDmFC72S+2JTNNZPdLX3njOrGF5uO8vjX2xmVlcTkAd4e95Zgb345tfUO+qZ7f7Z3zhrEL6f1JynGZZ2ZPjiDf3+/nzX7Cplk4cNvKt/tzuepBTs5XFTJ7rxyuiREcv64LPblV3Du6O5U1dazcFsuDQ2OoFZfNG2LjoxrNC1BeDT0PBF2L3Jt8yfG1XOVBVBjimqoKPgJN8DwuXJ/++cQEQ8Tb4CybG8Br9Fo2gTV3t4qMn6sXDelL+t/fzoALy3dA9CYbDk0U+wld80axNr9hby+Yh8HCir4/X9/5KqXV3L72+t484f9FFfW8pvZgwkJMRjTM5kvbzuF208fFJRom9AnmVFZicwdm8WNPpJgx/RMarw/f8U+KmoCJ16+tHQPFbX1/P2CUSTHRnDhhJ7Mu2oC4aHeMuXP5w6nV2osV8z7nsXORkUtzUtL9xAeanCyhbCODAt1E+IgVqTQEINlu469soxid24Zl734PXvyyumfEcdtMwfSOzWWpxfKb0C/9Fh6pMRQU9dAdmnn6XNRXFFLdV37q67TnGgxrtG0FH1PhewfofigPC6UH1Dyd0lnTyW662uhaL+rYZBZXOdtl9u0gZDaX+4fWgWp/SC5tzwuPihifsGDupyiRtOGDHCWLWzuyLgiMSacnikx7MwpIykmvFGE/+vy8bx05Xh+Oa0/PVNi2JVbzrPf7mK+M6Fvf0EF764+yPheyQzvnnhMY8iIj+K/N0/m7xeMIio81HIf8zkOFlYw559LufU/a3lv9UG3GuWKoooaXlm+lzOHZzKwS3zAMSTHRvDhL09mQEY8t/xnLYeLKm2Pv66+gXdWHaDEVJnGH0UVNTy9cCdvrTzApSf0ortNq1FcZBijshL5bneB7bEF4uVlewkxDD745SSev2I8t8wcwFs3nMRVzjKdw7ol0CtFJoL7TDXtOzpznlrK0N9/we7csrYeSouhxbhG01IMnwtGCHz/L/j2r1CeCz1PgvpqeLgHPJwFix6B4gPQUAcDJOrlFjnP2w4h4ZDUC5JNy7VpAyDJ6Usv3g+vnA2L/wrr32y996fRaNyYMTiDs0dmMq53cuCdm0hyjFjSfjqme2NEu2tiFDOGSPWMvumSYLkzu4zBXeP5zezB5JXVsNNpa2kNTuiTwtkjM/nqtqk8cdEY0uIiWbE7nzveWc9Xm73LML75wwHKquv41Yz+ts8RFxnGM5eNpaaugdvfXmcp8q1YuC2Xu97dwOS/LGDLkZLG7ct35XHDa6v417e73KKwN72+hke/2MZJ/VL5zezBtscHUulm46HiRl+3wuFw2B6vora+gffXHOTsUZmNFiTFA3OGsviuafTPiG9cldnfScR4eXUd+wsqqG9wcN38VW7NtToTWoxrNC1Fci8YMgeWPwkLHxRxfsnbcMFrMOlXMOhMWPQQfPRr2b//TMCAw2tcr5G3Q6LgoWEQZloGHX4+xGdCSBgcWS81zcF3NRaNRtPiZCRE8dQlY0mIarkcjvHOkojXnGxdHrVvWix788vZkVPK6B5JbpYRVfu8pYkKD+WpS8YyoEs8c0Z1460bTmLRndMA2J5d6rX/1qMlZCVH+63mYkW/9DjumjWI73YXsHJvoa1j1Pmr6ho444klXPfqKr7enM3181fzxaZsHv5sK3/4aDMgpSRX7M7nusl9eO2aE4iOsF4J8MWYnsnU1DW4if6jxVVMfOgbZj2+OKha5BsOFlNeU8/MId4lCw3DaPTud0uKJjIshC1HS7z280VeWTVbg9i/NTlQKJOKy0/sxaHCSs58ckmnmWiY0WJco2lJ5jwBMx6AuS/Jv6gEGHoOnP4nOH+eiPW9S2TfLsPkue+fh+1fiBDftxQyhrheL2OY3A44HUJCIaEb7Frgel6LcY2mU3PXrEF8e9ep9Eix9qX3TY+jqraBwopa+qXHMTIrkb5psfzjwlHERLRdzYboiFDS4iI5UOBtKTlUWGnb/uHJhRN6khobwbOLLHJxnDgcDurqG8guqWLDwSK6JUax4rfTuW3mQBZty+G6+atIjYtgxe+mM3NIBj/skaZGLyzZTYgBP5/at0nJkGoitHZ/ITtzyrjng41c+uJ35JZWsz27jCVBlH/8ztlo6YQ+/uvTh4eGMLFPCkuC6II69a8Lmf34Etv7tybKbvOz8Vn89+aTqa1v4KLnV7C8Gb347QFdTUWjaUmik2HK7dbPhUVKlHznN1C0FxIy4cy/QfYmeOMC5/EpMP1+1zFX/08sLSHOeXRiD6nYAtB7CuRua7G3otFo2p6o8FB6+fGkq26j6n5MRBgL7jy1FUYWmJ4p0Y2RTjOHiio5qV9qk14zOiKUq0/uzd++3M6WIyUMyfSOrv/qzbWs3V/EIae3fOrAdFLjIrll5gDmjMrkx8MlnDIgncSYcIZkJrBwWy7Ld+Xxxvf7uXZyH7okRHm9ph0yE6PJTIxizf4iDhRW8sb3+xnWLYF5V43nF/9ew74gIuPf7c5nUJd4UuMiA+57ysB0/vzpFg4VBZ7kVNTUUVEjtpyy6jriIptPFpZU1fLikj384tR+PvMLAnGgQK6XXimxJMaE88rVE7np9dU89uV2Jt3UOpV0WgMdGddo2hLDgAEzYcJ18jguA25aDuc+DVPvgusXiU1FEZ0EsaYvIFXPHCRhtDwHqtrncqNGo2l5xvVKbhSkA7sGToZsTXqkxLC/wF2M1zoj1llNjIwDXH5ib2IjQnlmkXdlqdX7Cvlkw5FGIQ4QaepU2jc9jnNGdSPR6cUf2CWe+gYH189fTUZ8JHecPrDJ4wKJjq89UMi2o6WMzErk019PYfrgLvROFTsRQHGl72ohH68/zPAHvmDJjjxO7Guva+u0wRkAfLTuMKv3FbhFkStq6twSXr/d5qpGc6Cgee0f76w6yJPf7GCFM6rfFPblV5AQFdb4+YzukcTJ/dM4WGg/abcjoMW4RtPeCIuEMZfB9PvEd+6PYT9x3jEkqRO0VUWjOY4JDTH46OaT+eyWKU22frQUPVNiOFJc5dY982hxFQ0O6J7c9LEmxoRz2Um9+HTDYS8f9uNfb/fa/9ITfDd+UtVcyqrr+PWMAcds7RnTI5kDBZUs25XHIFOlmF6pMezNr6C4spZZ/1jMnz/ZYnn826skuRWwvXrQLz2Ok/un8sjnW5n77AoueeH7xufufncDk/6ygOJKqSazyCTGPSdKx8rnPx6R182vIKekioLymqBfY9vRUq9a9t2ToskurfJKjO3IdBoxbhjGHMMwni8u9t8OWKPpVAw6Ay56Ay59B5KcPzCqlKJGozkuCQ8NsbRrtDU9UmKob3Cw2ZTQqCKc3ZOOrTb7tZP7EBYawnPfuqLjC7flsGRHHlef3Ltx25K7p3HqoAyfr6M6kXZPim6Wbq3KN+5wwCDTSkXv1Fj251fw4KebOVpSxY4c78TWwvIalu9yRZUn9rFv5bl15kDiTZYTFXlf6vSpv7VyPw6HgyU7chsj7s0ZGc8pqWLVPkmq3ZtfzvWvrebG11YH9RpbjpTww94CZg/r6ra9e3I0DgccKe480fFOI8YdDsfHDofj+sTEY6uhqtF0OAafBQNOg3hnpYTSI207Ho1Go7Fg+uAMUmMjuPmNtTz46WbeXnmAD9dKJahjbZSUER/FRRN68N6agxwuqiS3tJrb31rH4K7x3D1rMPGRYUSFhwRcLYgIC2HBHafwzR2nNEsHy9E9khp92GYx3ictlpr6Bt5edZCwEIOjxd5NetYdLKK+wcFVk3pz7eQ+pMRGeO3jiwm9U1j3wOn8de5IQCrDAMQ4vdv/+nY3q/YVcri4irNHdiM+KqwxMl5VW8/OHHs1vRdvz2Xh1hyv7V9sOorDAQlRYezKLWfzYRHWdl8X4IXFu4mJCOUyjw6xWc5VlEOdyKrSacS4RnPcE5supQ5L/DT+WfkS5Hov22o0Gk1LkxYXydOXjiUmIpRXV+zj7vc28NaqA1w1qbfP6jDBcP3Uvjgc8K9vd/H7//5IeXU9T10yhuiIUAZ1jWdARrwtgd03Pa7JCYeehIWKuP/1jAFMNFVCmTOqG+eM6saJfVO4eGJPjhRXedUez3YK9Oum9OH+s4cGfe7QEINh3WWFZGdOmfjFi6s4Y3hXCitq+NlzK4iNCOX0oV3olRrDxkPiLHj0i23MfOzbgKUXDxZWcMW8H7j6lZVez/1v41H6Z8QxqV8ai7fnUuO0Jr2z+oCtsR8pruSj9Ye5YHwPr+6mWc5VlINBNHtq7+hqKhpNZyEkRGqPl/iIjB/9ET69HbqNkcTQ1sLhgD2LodckCG25+ssajab9c2LfVD6/dSoOh4Nt2aXU1DUw4hi7giqykmP46ZjuvOrsPPrbMwbTP0Oi0Q+fN4L6IBvtNBcZCVHcfpp7ImhsZBhPXjwGgHlL91BdJ+UozdHv7BJpcOPZ5CcY+qXHYRjwnx8O8NG6wwCcNTKT04Z24aH/beHu2YPJSIjivDFZ/N8nm1m+K4+1+8Ve8vjX2/n7BaMJtZjA5JdVc92rq9y2NTQ4yCuvpqyqju/25HPLjAFU1rgSU/ukxfLe6kPcefogwkN9x4Jr6xu47a11hBgG1072rqffNTEKw2j+hNO2RItxjaYzkdDNd2R8zXy5bajz/xo7v4alj0N9LSR2lyotKf2gxwnSfChYDq6C+edAr8lw1SdSQUaj0RzXGIYRdJMfO/zx3GFS0jEyjMtMiZoDurSvyjJmuiWJ2D5SXOkmxo+WVJEaG0FEWNNNDFHhoYzontjoFQfomxbH0G4JnDfW1ZH1khN68ty3u3j8qx3kOLtcfrjuMDml1bx45Xi3RNb8smouffF79uSVM2VAGkt25FFSVcuXm7K58531RISFEB4SwqUn9GLr0RL+tViKCtw1axC/+Pca/rfxCOeO7u5zzE98vYPvdhfwjwtHWa6YRISFMLZnMu+vOcTN0/sTGdY8qxhtiRbjGk1nIj4Tsn+0fk41Byr30yzh41tg9SuQ2FMquexdCj++J88NPRcumB/8mHK3yu2+pVC4F1KsOwdqNBrNsRITEcYNp/QLvGM7omuieKCPFFUxrJtrlSC7pKrJNc7NvHfTJOobHPx4qJh3Vx9kQJc4r32iwkP55bT+PPDRJkCEc1pcBL97fyNXv7ySl6+eQHS4lI984/v95JdXM++qCeSX17BkRx5HiqoaI+o1dQ3cNnMg6fGRpMenc8dpA9mTX87pQ7swvHsC//fxZk4ZmO5lPwFYva+AZxbt5GfjsvjpmCyv5xW3zBjAFfN+4N3VB7n0hABVxzoAWoxrNJ2JhO6w40uxhpgj0A4HlMgSJaVHpBZ5lEdUatMHIsRP/AXM/IOUWGyoFwG95lVY9gTs+EqSRYMh39QZr/SIFuMajUZjIjPRFRlvaHBQU99AVHioU4wHbvITiPDQEMJDYXzvFMb39l2r/KKJPfjLZ1uprK1naGYC0wZnEBUeym1vreOKl35gbK9knl+8m3G9knnsglGc0DeV1fsKADhcXEl2STXdEqOYf+3ERnsQwK9mDGi8/9e5ozjzySW8uGQPd84a5Hb+hgYHd7+7ge7J0TxwzjC/72nKgDRGdE/kxSV7uGhCT0srTUdCJ3BqNJ2JxCyorXAXwADVJVBbDj1Pksd5HkmctVXw5e+h60g47U8ixAFCQqXp0PT7JVq+9B/Bj6nA1IhDV3rRaDQaN9LjIkmLi2TZznwe+2o7g+//nLLqOrJLquiaeOyRcbtEhoWy6K5TuXla/8aa5ueO7s4TF41h0+ESnl+8m3NHd+OdG07ihL7yfKYzqn+4qJJ9+eUM657oJsQ9GdotgTNHdOWV5Xsprqh1e27hthx25ZZz16zBATuBGobB9VP7sievnK82Zx/L224XaDGu0XQmRpwP4bGw4E/u21VUfOBsqbjyn0vghxdcz2/7FIr3w8wHrH3hoeFwwg2wbxnkbgtuTPm7oceJcr/0aHDHajQaTScnJMTg7JGZLNiaw1MLJZDy3KJd5JXVHFPyZlPokhDFnbMGuVWTmTOqG9/fO4Nv7zqVJy4a41aRJiM+EsOA5xfvZkdOGb1tlKj89YwBlFXX8dJS9wZ1r67YR2ZiFGcM7+rjSHfOGN6VrORonl/s3Xm1o6HFuEbTmYjLgJN/DZv/CwdM5aaUGO8xEa7+DJJ6wf/uhFJnREF17ex1su/XVlH1gj2+96mpgC/vg7wdsGoeLHtSIuPdx0FYlI6MazQajQU/GdO9sfwf0CjKJ/ixlbQmCVHh9EqN9doeFhrC0MwE9uVLZZOeNkpUDu6awFkjMnlm0S6+2SK/QTmlVSzdkcvcsVl+K614nvvKk3qzZn8R+/M7dmUVLcY1ms7GSTdDbAYsfNC1TYnghG4iyM94RB7vXSK3JYchOgXC/TTEiEuX23LvBg+NrJkPy/8JL58Jn9wGX90PEbHSKTS+q46MazQajQWjshIbo8p/mDOUn47pzp/OHcbkAWltPLLAvP+LSdzoTJodZLNCzl/mjqB/rArM1QAAIABJREFURhwPfLSJuvoGPlp3mAaHTEqC4dRB8ru0YrefwgQdAC3GNZrORmQcTLgOdi+U5EtwRcbjM+W260iITJBqKer5hABfgjHOH4XyXOvnG+rhu2ec++TI6/1mL9yxHfpMkXNrMa7RaDReGIbRWO7vpH5p/OPC0Vx+Uu+2HZRNIsNC+e0Zg1l81zQm9E62dUx8VDi3nzaQg4WVfLjuMG98v58xPZPon+Fd6cUf/TPiSIuLZMWu/KYMvd2gxbhG0xkZfQlgwOpX5XHJIYhJdSVmhoZJE57di6TSSvEhiZr7IyIGIuJ8l0bc8jEU7ZPzAnQZDtHJLg96fFdtU9FoNBofXD+1L89cOpZBXdtvTXR/9EyNwQiij8TMIV0Y1SOJO99Zz+68cq44KfgShYZhcFK/VJbvyvfqYNqR0GJco+mMJPWAIXNg5YtQWQg7F0DmaPd9BpwGhXvE311ySBr8BCI23XdkfMVTkNwHek+Wx54lDBOzoOgA1PhvsazRaDTHI7GRYZw5IrOth9FqhIQYPHfZWKYNSufnU/pw1ogAASEf3DpzAO/dNCmoiUB7Q4txjaazMvUuqC6Ff46TSimjLnZ/fuBsud30AVQWBI6Mg4jxMgvP+P7v4eBKOOmXkNxbtiV7iPH+p0F9tXT41Gg0Gs1xT2ZiNC9fPZF7zxra5E6j/dLjLDt1diS0GNdoOiuZI+Gcf0oN8dT+MPgs9+cTs6D7eFj0kDwO5BkHZ2Tcwqay9jWITBR7TLJzqdEzMt7rZLHKbPog+Pei0Wg0Gk0nRYtxjaYzM/ZyuOcQ/Gq1eL49Oe2PzjuGy17ijzgfNpXSo5DaVyqndB0ptcwzhrjvExoGw86Drf+DioKg34pGo9FoNJ0RLcY1ms6OPx9d78lwxX/h9i2Q1DPwa8WmQ0WeVE4xU10Ckc6kowGnw22brV9v3JViVdnwlv3xazQajUbTidFiXKM53ul7KiTYTBpK6gmOBsj36HhWXSqlEkHEf3wX6+O7joCsCfDds1Bf19QRazQajUbTadBiXKPR2Ed16Ny72H17VQlEJdp7jZNvlRKImz9s3rFpNBqNRtMB0WJco9HYJ6WvJHruWeK+vbrEFRkPxKAzIW0gLH1capxrNBqNRnMco8W4RqOxj2GIrWXXArGmADQ0OG0qNhtVhITApF9D9kY4tLqlRqrRaDQaTYdAi3GNRhMc46+VSPjqV+RxTSnggCibkXEQ3zhA4d5mHpxGo9FogiJ3G+z4qq1HcVyjxbhGowmOrHESHV/0F8jbKX5xsG9TAVeCZ+nR5h6dRqPRaILh6Ynw7/PbehTHNVqMazSa4Dn3aWiog1XzXHaVYCLjUUkQGgllLSzG170BH/7SulGRRqPRdCZqqyRA4ll61vbxlc07Ho1twtp6ABqNpgOSmCVt74v2iWUF7HvGwVX+sDS7RYYHwMHV8OFNcr+uEs6f13Ln0hyf1FZCeHRbj0KjgaID8OocKNwjnZUvfQdiUoJ7jZLDkNqvZcan8YuOjGs0mqaR2AOK9ptsKjZLGyriurZcZLyhHj65FeK7iT+9YE/LnEdz/PLV7+HBrpC9qa1HotHA2tclB2f6/XBoFax5NfjXKD3S7MPS2EOLcY1G0zSSekDxAVdkPBibCkB816ZFxuuqA++zbzkc3QAzfg/JfaAiP/jzaDS+KMuFZU/I/bwdbTsWjQagqljydqbeCaERUFkU/GuUaDHeVmgxrtFomkZiD6gslKVNCC6BE5xiPMjIeNF++HMGfPec//3U63YfJ0u1lYXBnUej8UfJQdf9BX+Gty5ru7FoNOAsLxsn98Ojm+b/Lj3cvGPS2EaLcY1G0zSSesqtWqYPxjMOENcFqotdNhc75GyR289/4z/yU+FM2IxJlX/VJVBXE9z42gO7v4X3roMf32vrkWjMmFd08nfAlo/bbiwaDTgbrzm/g8NjoLbC3nFm0a4j422GFuMajaZpJPaQ200fSFfOiNjgju9zitwuftT+MWZPY8Eu3/tV5IMRAtHJ8g86XnR804fw2k9g4zuw6uW2Ho3GjFWuQ21Vy5xrz2J47+ew7fOWeX1N58DceC08GupsXo/moEbJoeYfl8YWWoxrNJqmkTZABG99NQw4TSqkBEOPCTDsp7Du3/aPKTEto5bl+N6vPA+iU6TbZ0yqbOtIvvGCPfDfm6UqQv/TdD329oaKjKcPdm2rLGiZc616GTa+DcufbJnX13QO3MR4jH2bSpVTjIdFwc6vW7bClcYnWoxrNJqmEZMCg86U+/2mN+010gZBRYH9urjmyI0/gVqRB7FprnFCy4ml5qa+Ft7/uUx0zn8JUvvrKgftjbJsmeyZrVktNdkry3a/1Wis8IyM27WpqBXDWQ9BfQ0se7xlxqfxixbjGo2m6Zz7FMz8Iww8o2nHx6YBDhHkdig5DF1HyH1PcbL8KXhhhtyvKHBFxDtaZPyLe+HgSpjzuPjyEzKhpiw4b73m2KkukwYqVpRlS86DubJPi4txPytBGo1ZjIdF2Y+MK5tKtzEwfC6smd+0SiyaY0KLcY1G03Sik2HyrRAW0bTjVdS6wk+HzKpi1/2Sw9JsKDrFW4x/ea/U162vE5uKEuHR6hwmwb/lY9izpGljbkkcDlj9Coy6GIafJ9viu8mtjo63Lsv/CS9Mk8/Ek9Kj0rSq3pQU3FJiXNkGqkugxma0U3P8UVPmqmgVTAKnsqlEJ8PE6+V1dnzZMmPU+ESLcY1G03bEOK0kvoTMVw/AX3pKMwsQMZ7Q3X+N8vJca5uK+Rxf3gef/876+LaMQFYViQdfRf9BIuOgxXhrUXIY5p8LuxaIADZPBhVl2dK0qvdk1za7qzvBUFMONaViVVLn1Wg8aWiwsKnYjIyrayom1VUhy+qa17QoWoxrNJq2Q0Wvyy0i46vmufyLudtEmFSXiBCP6+JbmJQeFh+kEvrh0RCVBDmb5bHDISW8sje6J4QCHFwNfxsAG9899vfWFNREIK6La1u8U4wHU3Zs/Vvw+T32vfgaF+9eC7sXwcEf5LHVRLEiXyZ7sx6CG5f53u9YUddD15HujzUaM7XlgKNpCZyH10FSL2naFhYl2+xWYtE0G1qMazSatkNFrz1tKt8+Cp/cBpmj5HHRfol4A8RmeItxs8cxexM4GlxCH8T2sfm/UHxIhHq90+u74yv38+ZuldvtX7hvry6Dwn3Bv79gUWIrNt21TYlxuw05di+CD66H754OrmykJ6XZ8vc6nsjeBPuXu2/zFNm1VWIBiE6GsEjoOlwmey0ixp3XeOZI98ea5qXkCCx8GD653bXiZmVPaq9Ul8pthLnpj02byuG14hdXx0HTynSuf0tPFo8BLcY1Gk3bofzc5SYhk70JFj0Ew8+H676R1s7FB6QFOYhQTe4lUW0lFotMQnnLJ3KrBAzAiTfJ7eJH3aPhnt7IUKf33fxDtuNreLQ/PDGq5Zu7KLFljoxHxEjEym5SlWqM1HeaJLWqH+pg+OEFeGwI/GMovDTLeuWiM7L0HyJolKgBb5Ft9tgqYlKDE+PZm2SyufFdOLrRewXj6EYpb6muB19Jy83F5o9kArxncfsXoZs+gP9cCt//q3lWfqqK4dmTYPFfYe1r8Owk+EOiJDJ2FNT/8WBtKhUF8t3Zfaw8Dg2HkDD7Ql5RlisBgH+OC+64prDyJfjHCEl0b0qX0XaKFuMajabtCIuAyESXkGlogE/vkESkMx+VH4fELI/IeBqMvlTuL/m73CpPOcCOL0S8djf9MCT3ggnXwZpXYdP7si1jmHS4NHfmrHZ6JWvK5XbNa9LqPLmXJI5+cGPLRn/Ue4zLcN8ezLKz2m/qneI33vB28ONY8hhkjYfT/gRH1sF71wb/Gh2RA9/DwFnQZbhrm6fIVqXgzGI8rgvk+6i84kneTnj5DLFhvXctPDcZvvmj+z4vTIcnR8PbV8jjLsOl1KWnrao52PguvH05LPwzvDoHtn3W/OdoThY9Als/gc/uhgV/PvbXK9gjn+l5L8ANi10rUUc3HvtrtxaNYtwjgTPQxEp1T+5qClyEBdEwSFHu/E6sLnG9ZkuxexEU74cVT8GbF0kp2E6AFuMajaZtiUlx2VTWzof9K2D2w67Ey8QeUHTAJMadkfHx18Cql6T6yP7vIDTS5XnMmiAWAjOn/g5S+rkE/LgrRawe+F4e5+0Qbzq4fsi+uAe6DIMrPoJL35UfqW//2mJ/CspyJDIVleS+PWgxbkCvkyF9iEQSg8HhkM+j50lw8q+lwsKeJTJR6uxUFsn1lZjl2ua5KmAlxgefBUfWQ85W/69fXQYf3AAY8Ks1TvHXzd0OVFfjqtIy8AyZEMV3FcG0twUqAC39h0Teb1gsj6vaeVm7ijwYeyWMuVzGbhZ/DfViuwgG9b2S1BMyhsCNS+QacHSgfItqZ9lTc2QcAotqdS0ru6A6NtiIs/obgntgpCUoy4HeU2DOkyLMN/+3Zc/XSmgxrtFo2pb4rpC7XUTgimfEvzjqYtfzST3FpmIW4yCCve80qYry3TPQf4brx2f4XO/zRCdJ7W5F/5lyW7RPRNhT4+GH52VbWY4s4VaXyGvFd4G0/mKd2fi2ezS9OSnLEU98iMdXc3i0M0nLBnWVsr9hwOAzYd9y14+uHWrKRAwqz31CNxEm7V2kHSv1tfJ5Rye7i3E7kfGRF8okyl832aM/SsT78Fo450lI7Sc5ETGp7uJHNac66+9wyX9kQgQw+Gw4uMpeh8Q9S+DL+wNXeMndDtk/wujLXP+v6lvo2m4OGhrkPcWmwWn/J5Pv759zPb/oL/D8qcFFtT3zNAxD/v90pDKSasVEXZPhMXIbSFQ3ivgE17bwIGqUK8wT1pbuh1B2VH4zhv1UHrfEalEboMW4RqNpW4bPlcom718Pedtg4g3yg6hI6Ste2Zwt8qMR7ox+h4bDnCdcy5RDfwKTfg1Dz4VxV1mfq+ck133141tZKP5TM4V7pMY0QEof1/ZhPxWP6d7FTX67finLhrh07+3BRKtqq1wrBAPPECG9a4H9MSjx2RZNkwr3SoS5LXzLqpxbdEoAMW7hGY9LhwGzYMNbUufeikUPy+d72btyjSo8J1pK2MSkuR8/+CzAAStf8P8+1r0Br54Ny5+EebN8jwdg1zdyO+RsV75Ee172ryqS6zkmTVbORl0oNixVaWifM/k2mBwHZbEwW8OCqdPdHtj2maywpA2Ux42JmAHeg6fXHJw2lWOIjNsti7jhbfjwl8HZ/hwO2T+ui4zZCO00QQItxjUaTdsy+hKp2bzxbbFWeEa1+zlF8Y/vui+ngthV7tgGF70BI86H0/8EF8x3F/NmQkLgZ6/K0r/6Mq8shAPfee+rkkKTTWK83zSIiG+ZpdEdX4tozhjm/VxErH1xUFvp+jHOGCy3RQfsj0NFUz3FeEsnce5ZLEmy/5oKRze07LmsMEe8B50J46+F9MH2IuMg13FZtiydW1GWA91GQ7/p7ts9J1qekyFFl6Ew8iLx8/uqcpOzFT6+BfpMhZ88C3nbYfvn1vs2nsuQ2v2h4bKtPUfGPa/Nk2+FhjpY8jd5rERkMImdZbkQHiv/xxT+Jr8VBXBodXDjbklqymHn1zBkjmtFzW5kvMoqMh4dfDUV83dDtc3I+MoXYd3r8PUf7J+nulS+B+O6yHd8dFJwq37tGC3GNRpN2xIRCzcuFfFw0b+9u3l2HSViHbwFCkBsqkQNQ0LtnW/YT2Tp3zBEUFUWuguuxB7ugim5l+t+WCQMmi0VW/xFHJvChv/I+zvjEe/nglk2rzOJ8Yg4CAl3WR/s0Ch4nJ792ACNmZqD+lr48Beux21RvUW97+hkSOwOZz8myXyeFUwqC2USZ44mgnjswXciZ2WBq3qQGc+Jlvo7e048AUb8TCLDvpbmP/+tvN7ceTDiAomWfves75WG6lIRYoYh1wm078i4yi1R3wMpfcQ/vvoVScRU4jOYaKnVapSvHI36OnjjAnhlTvupOlOwR+x5vU5ybWuMjNuwqYTHQGiY+7HBrgqU54q9LjzGfmS8wfn9WRJE+VT1fzHe+Xugvr87AVqMazSaticuXSKLntFGkGjPmMvkvor4NBeNYrzAfdul77keqx82xdBzRVjtW9a8YynLFnERleD9XLAJnGHOMRuGM0E2GDHuy6bSggJ566eSF3DKb+VxXXXLncsXVhHvbmPgyAb3spKVhbKP5+pLdJL763hSkW89mfScaPmKjIMrKdmXjSD7Rxhyjvx/Cg2DybfCvqW+o+Pmro3twaZycDW8eYlYlaxonKiY/jZT7xK//uJHTWI8iA6S5c48DTO+BOmSv8HBlWIrshsBbmnU9Wa+XoIR45Ee3zdhUU2oppIntr+oRPt/e/WdFMxn1Vj61fl5RSXZL/naztFiXKPRtH+m3wcXvQlnNHMlk+hk+TKvyHfVcq4plwlAv+mSte9JvxkijpvbqlKW413SUBGMh7W20uWrB4nGBhM9ahSDzihua9hUVr4IiT1dXupgPavNQaOoMYnxgbO9PfdKjHsSEipixGoVor5OrjNfYtzKpmJ1Dn9NWRwOOYf5uPHXyDl91cevLnGJ8ZBQwGh9m0pFAXz1ADw/DV6cAds+9W31KfeIjAMkZEqOyIa3JNcDghR4ufZKiRYdkEpKSri3l9r7ahXAXIGp0aZiwzPuucITHtMEm0qurOREJrSsGC89KrdxOjKu0Wg0rY+qDKI80M1FdJIs+ddWuLp91pTJ7eUfwFWfeB8TEQMDTheBY8ebmrsNFjwoZdg+/IVUfLCqOFCW7d7sx0wwCZx1Ve7R/JgmiHEjVOq/q3OHx7acTSVni5Tsm3CN/G2haR0AjxWryHjWeBF+3z0j0fqGevk8rUS1Otbqb11VBDh8iHEPm0p5nggr5eE2469deW0lNNS6IvQgrxHfzffnbxZjhiHR8dYU42W58M+xsOwJifqf9EvZ7suS1ThR9LDwnPgL6bqrsCvwtnwMuVvcO96C9eS3cK9MzEZd5D6WtsbqulWT8UBivKrEeyUuPKqJNhVnZNzOikF9raunQzBi/PBaqbef4KwFH52sEzg1Go2mwxOdDAW75H5Xpxgfe2Xg44aeK8vbqka5orYSvv6jJNkpVr8q3f2+/gPs+ErE+JsXuZdHrKuWH1WfYjyYyHiFy6YC8h6DtanEpLiXV4wNssNkMGx4W2wGY67wLzZBygMW7GmZcVQWAoZrEgISLT7zUbEmvHwGvHs15GySiLMVvlYhPFcbzHhaInzZWcD/38cqQgoizn19/p6R0dBwl5e3NcjZLH+vC16Faz6HWQ/KteurjGdFvjwf4WFXS+4FPU5wPbYr8BY7Ez+VDU5hNflVn2tqf7ltL5HxRjFu+twjnJ9pTYByqFaR8aY0/anId4pxm5FxdT1GJcn+dvz3VcXyXTrspyL6QSdwajQaTacgOtklPhK6wX05MO2ewMcNOF2Ekdmq4nBIQ5elj7l3VFQ/VL/ZB3ftgLkvit98oal7oK/Om4pgkqpqq9xtKjEp9hI466qlQdDeJd5iMCbNtUQcLHsWw7InXeXnPFHiMzY1sBh/7mTpTNkSVBbIj7tnjffhc+Fnr8j73/4FTL4NRl5g/Rq+Jj6eSbFmwmMkGq0SgivyrZM3wRTxtFglUd7ZqET37f5WRqzEeGtGxj0FLojQ9hcZ9zVRGXae675dMV5ZKDXis8a7b7ea/KrJjiof2JI5FMFQWSST2Yg41zb1mQb6O1h5xoNt+lNbJa8Tm+r0jNuIjKvJaUof+f618912cKU0aRt7hWtbdLK8x2Cq57RTtBjXaDTHL+al3ZhUWSr3VRbRTGScNA3a/JErqrNqnkucmyPTFflSOk5FrkacLwJv5TzXPqrWrq/IeESM/GjZSa6rrXRPdI12JnAGij5t/QTeuUqqgZx4k/tzWeNhz7ew9vXA5zez/QuYfy58dT98eZ/1PnXVLhFuN/HMLtVlUvbNDvm7vO0PimE/hds3wz2HYeYffF8jvoSvv6TMxm6Jla59fUbG/XRWVGIx2jMy7sdX6yXGW9mmUmmqYKPwtO2YqSr2fn+KCdfCOf+EjKH2rQuVhdYVbtTk1/x/xisynut9XFtQWSgRZvM1qawnqo64L1Q1HTPBNv1Rk5LYdPuecfX/QZWNtXOMmmzGZ7q2qVWgYKwu7RQtxjUazfGLpxgPhl4nQ+lh+TEsz5dOoP1nwozfi7BS0b3KAu/XTh8sUR5lVWkU434SOCHwsjPIucPMCZzJ4iVWXnhfqMj1Ba95N02a9ZCUfAymeRDIsnJCd2ldvvlDKD7of7yhEYDRfNVU1r8Jr88N3LVy71LYvVCipP4IVD4zOtl6FcKfGFeWC3W9KJuQFY3VVCzEeKUvm4pTjFtNxjzFWGhEcNVUjqyHp0+Uz7kpWPmdI2J8X+dVJd6Rf0VIqERN47vaE2fmjquehEeLB908MakslAh0bJpMGMrbiWe8qsj7PYRFyVgDiXErz7hq+mO3dKO5M7LyjAc6Vv0fSenrHIcdMa6uFdP/DfW+O4FVRYtxjUZz/GIWR8GKcfVDUFUMRXuhvloaxahkMBUxsop0Nh7rFFCH18itZ4k1RTARY3PTH3AJu0C+8Yp8+QEfMsf7udBwiUgF65OtLITk3jD1Tonsr/+P9z511S6RaRjO0mrNFBlX1poyPxabQ6vhjQshqaf3ikCwRKe4L5tv/wI2fSiJZ+p5T8yVLxwO+Rv7itD7q6biMzKeYj0Za6iXbebIeEiYfTFeWQT/vkASIHcvtHeMJxUFIv7M16ulRaQYlj4uws8zkuuJ8iEHorHjqpUYt6hGUlnkikDHprYjm0qh92duGPK5+hPjDQ0SEPCqpqJWX2xOiMtNkfGoBJnABPKcN9pUmiLGTe+1sZxox0/i1GJco9Ecvww43XXf1/K3L1SErqrYJXRj07zbx1cUeEc6o0w/Ikc3wrePSMnEhO7W5wp3dge04630FONKAAbyjVfkydh9WTBi04MX41VF8ndK7g09ToRVL4t1xExdlXskPzwqcDUVu0JBCaYv7pU61J4sfAjeuEg+n2u+FPvRsdAYqSuSZjtvXADvXAmrX5aunp6Jh+A+0aouFeHsa2IYEirNeawmK/4i4+AdPVTivCk2FYdDGgypVvKGzYZbnlQWev/fiIj19oy/eQl8/QDkbfMdGVfYrXXtq5MqmKr6VLrvr/aNSXP9X2jrCLlnOUtFIDFe43zOyjMO9nNUGsV4miuYULDb/zFmzzjY/7wi4t2rDKmxt5ea78eAFuMajeb4JSoB7toNV39uv4On+VhwinGTDcEsxtVSuFdkXHkdi1wdG0//k3fyoMLuD2R9rZRfc6umYtNXWWFhpzHTlGigWcCMOB9KDsJTE9z3qat2Tzj11XSkwVS6zm5lF7Xf3iVSxabogOu5nK0yCTIMuPDfrnJpx4ISlvuWwZf3w6Cz4OcL4JK34UIffnvzRMtf901FWJT1ZER9vp5i1ZcYV0LNS4z7iYx/crvkADw5RixAU+8Sj3aw1TcUVjXbPSPje5dJ4yJFIDEekyrXcqCEY39i3KqdvNkOktJHcijeuw4e7SuJz22F8ox7EpnoX4xbff4QOInaE2VTiUmTuvxGKGx8J8CYi+RvrMS7XTHu+VlFaTGu0Wg0nYPYVPdW0nZRoqC6xEOMq/bxBb6raJgj442NTPwIMCtxYIUSMebIuIoeBapyUJ7nX4zHpMn7NIviQFQWuSYD466CXpPFZ28Wk7UeHndfYty8zTNC39AA696AFU/Dp3fAAmelGnPUsqEOVjzlerzxbalZfMMSyBxp/z35I7m33H5wg4icc56E7uNg4Czfkz3zRMuft7xxfx8JdlVFIsA8z+PLpmQpxgNUU1n1kjTkSR8Esx6GU34TfPUNMxUFFmLcVDmorkYEr1lsBhLjoy+RCda3j/jfz68Yt5j8mu0gp94jlh4lOr/6vXc0v77OXo6HLz64Ua5jf/5rq0ZPish4/yJVfR941Rm3+V2jKM+F0Eg5X1w69J8ReHKiLD/m1cVAWNlx7H63dQDC2noAGo1G0yGJ9IiMG84OjKr5SHmeqVqEhxg3Ryv91aBWRFh4WK1Q9g5zpNlu9KgiH7oM8/18bLoI2qoi/2NV1FWLnUIJqdBwGPYTiXJWFkF8F9d+yjMOvsWdWYx7RuiProcPPfze0+9z3y88RhINp94t49/4DvQ91TWO5qDHRDjxl7BmPlz0hv8It3lcIGJOvW9/YtxXHejKImuhGjAybk7gDBebjBUNDYAh0fDp9wYejx0qC0XYmzHbVLZ+IpO3i9+CN53JtZ7i0ZPUfmI/27ss8LnB2p6mxHiNhxhPdzYdS+sP134FOOT//6tz4K3LoOdJUHwAJt8Ki/8O616H+3IhLML/WKxY/6bcdhkm1Xw8cTjEZlVdDN0syn1GxvvPlVDfB16ecT/lM60oz5PvBmVvSx8s5Uz9UeWcpDeuLtrwfFtFxtXYAyWqdgDadWTcMIyfGIbxgmEYbxmGcXrgIzQajaaVcPOM57v81lFJEnGtyPcd6TTbVPx1XFRYiQMrlFgPa0JkvCLPv3hUz9m1iCgPs1vClUfiKjg946bxhkVa2zDM4sDTp6sen/V38ZUm9XJuN4nxybdJku3/7oT9K6BoP4zwUS/8WJj9ENy9y/5qi3miZdXu3ZOwSN+lDaOtxLjKGfAU4xZizJ9NpboYcFhEsoMshWem0iKfIjzG1fRn/X8ksdac2xEoMg5SlShQhQ1bNhWzGC923zdzpHTt7TNVKijtXyG9A9a8Clv/BxucycqbPww8Xk/MEfW8nd7P7/5WJgCL/wqjL4NRF3vvE8gz3jgZ86xL77z2ygJUIFKU58rqYuN5E+T6rPOzwqIi42GR8n+/qTYV7RlvOoZhzDMMI8cwjB89ts82DGObYRg7DcP4LYDD4fjQ4XD8HLgRCFBZ6fgRAAAgAElEQVRzSqPRaFqRyATAEJFrrpgSEiI+4CV/gx+el21eNhXnD2BlUWAR3HguAnu2lUhzs6nYiB7V18lY/Fll1Bjt1le2EjtW1Q88I+O+Iq1ukXEPMa7Efe8p0q68ulSqhZgFWb8ZMP1+2PS+dNMMi4YhZ9t7L8Fifj+BMCdw2rap+IqM+4nyegrmYG0qvsSrL1tReT58cBMcWGn9eg6HtcAyN/0pPQxdhrvnUtgR4/7KOSpUx1Wr1/P8m+Vul8mIVTUcgCl3wL1H4N5sSbAtz4WuI+S5lS8GHq8n5kmkZ9Q4exPMPwcK98GMB6S2ulXSdSAxrgSwZ2Q8zblSkbfd3liLD0rZU4WdlTgVGYfgEm49r5XQMPmu7QQ2lbaIjL8CzDZvMAwjFHgaOAMYClxsGMZQ0y73OZ/XaDSa9kFIiPyQqWoqZgGl7B5bP4XBZ7u69ilCw6VjXlWRU8gHEOPJfeSHaP/3/vdT4sEsxkPDJdLn78exshBwBPaMg/2KKlbt2aOsIuOVFtVULCKt5m2ek5LG5MUkl1e2LBswibHELImOz31JookX/dtbiLQFKgpbuBcWPiheZH/jUnWgPTELHLf9fdQm95nA6UuMq5UOK4+3xXj2L4f1b8BLM2UVwpOaMrE9eU4gwmNlBaOhXj5XNRFVFVvsivGGWv+e7VxnZRYrL796j7sWyITi6Qly/Y8KEBMMj5KofHmu6//Jge+h+FDgMZsx/x/zLNuXu01uL34TptzuO+k7KsFeZNzT9hOXLt8DOVsCj9PhkM82qadrm51otXniaEeMq4mblT0ukDe+g9DqnnGHw7HYMIzeHpsnAjsdDsduAMMw/gOcaxjGFuAvwGcOh2NNqw5Uo9FoAqF+SCry3QX35e/Lcn9Uou9SgSp6V57vKvHli5AQaTK0d4n//ZRH3bNcWaDOeHZ866p+euEe/2NoHIuVTUVFxk0Ra8tqKhbRd7OY9BQojcI/UcRFQx08NsR7/IYhVV1GnG/vPbQGUUliFVjyN8k3GPEz/11gw/1UU7GKjIc6/cqeIrvKwqYSEiarJFYEGxk3j3HJYzDnce/xgvcEIsLU4Kqq2CW+QyNkEhKozrh5jJUF3uUqayrgo1+JfeTEX1ofn9wbJlwHK1+Qx+Ougkm/diXo+iM2TZp4leXIRHzrJ7Du37J97JX2qjaZV588I+NKeAYqxRoZ77KLWHnWfXnGQXzfSvT7o6JALEVuYtz5ev6i1cFGxg98bz1xA+eko+OL8fbiGe8OmGpOcdC57VfATOB8wzBu9HWwYRjXG4axyjCMVbm57aRFrUaj6fxEOn8Iyj2sJhGx8mPjT1RFJblsKnYaDvWeDEX7rD2kChXNUolmjecK8IOlnrP6sVPEd4WsidJ8xU7HO8vIuIdNxeHwrjPuq+mPZ5k5t3MVS0WH8ChvcTH9Pph2n+8IYlsTFgHjrxYhfsJNMDeArSHMx8qBuXKNGcOQv42ngA86Mu5DjPuKjKttmaOlAosnvkoxNuZHlMsYVeRWTSpsRcZ9+OQBVs2DH9+VRN7T/+z7Nc54FH72itye/bgkhtohNkPqbNdXQ88TpZrOwgfhk9tg59f2XkOt/CT2sJh4KhEdYFKinvfVebe6FDBkhc6T9EHSzClQJ82ifXJrFuONNhUfUfn6OhmT3cj4imfEVpaQBYPP8n4+MsAKQAehnX47CQ6H40mHwzHO4XDc6HA4nvOz3/MOh2O8w+EYn56e3ppD1Gg0xzNRiVCwRyLLCd2COzY2FfJ3eAt5Xwz9iVgUvn4A8nbAh7+A/93lnsyYvQniuronVIGNZC4fZc7MGAZMu0eijYdWBx6vlXhrTHp1Coz6WhGhXtVUAnjGPQWKWYiaRcpZj8GUO+GUuwKPty2Z9CtJwjv5lsD7WkWiPSvXeB0T6S2yq0vFEmKO1NoS4x7nCFSKMr5rcHXRVd318hy5NtTzMc7rKCLWenxmfFWQaaiHH/4lq0zT7/U/QQsJkSomJ1zvf1LtSWw6FOxy3s+QCZZi/4rAxx9cJU2qAFL7+0i89SGizTRGqH0I3aoS+b9i9d6SespxgUozKvtRMDYVzxWRKD+rdqVH4Zs/Qv/T4BcrrCdEkfHaM96MHAJMGQBkObdpNBpN+yUqEXI2AQ7oc0pwx466WBr+OOpdzS/8kZAJU++QZe+nxsOP78PqV+Dty13WguwfrcsTRiYEWDb2s2RtJs5ZBvC75+D1uf4jZ0X7JZnNLLZCw2QsSkyrhkde1VQsxJ2KtMamW0fG1XnM76Hb6OCEVFsRmwY/fc5e46FwiwRXK0uQmdAIC894iffnHRruu5qKrw6fajye14I6n6qu4YkvMa5sKqppjxJ3l74ndc3jbJSiVGLcs7Z6WbZcl1alApsL88Q6Ll3KeU6/XwRroHKLICUS1fWd0M3iWneK6EArPRGmZlJWmFcdvI6N83+sQolxcwJnIJuK54qZr8h4fZ30DKivhTMe8T1WbVNpVlYCAwzD6GMYRgRwEfBRG49Jo9Fo/GOOQHcbG9yxw8+XusQDZsFImyX2ptwJV30qJfxuWgZznpBujxvfEW9o7jZrMR7QpuKjG5/V6wDs/EqW3Hd9Y71fQwNs/gj6z/T2yEYlyQ/ynsXwrLP8XzDVVOK7WnvGoywi44ESYzsiYZHeKwdWliDPYzxLzVWXWotxX3XGKwtFpHn6j311bFSPoxKto+3mpFszKjJeesR1PEht72n32Jtc+YqMq3PasYU1lTjTxDo2Q/6mU++U/++H10D+Lv/Hm69ZZWUzU11iz6qj/o6+ottWkzGFEvK+LC6K0iNyHvMksLEZmo+VOM+JY1SiCHfPydx3z0jgYdaD/nNqtE2laRiG8SawAhhkGMZBwzCudTgcdcDNwBfAFuBth8OxqbXHptFoNEEx+XboOhIm3iBR32AIDYNrPodL37bXRAdEiPSeLMllqf0kut5lBHz7F1g7X0SPVYQ+UGTcqgGMFZ7PL33cer89i6DkIAw/z/u56EQRSdmbXduCqaYSn2k/Mm7H/tPRsKqm4itq3XhMpHiYzVhFRgPZVPx2q/QYU22V1NuPjAvOpqI+v6ID1s/bIZAYb8pr2sUsps1R/InXi8j98Bdil/GFOeE0OkkSJM2rFVUlgRsfgXsirBXVJb7/v5sbUfnDamLQWErVlz3G+Zmo46ISZQJYWwmH1sgkvboMlj0B/abDiTdZv07j+QJ8t3UQWl2MOxyOix0OR6bD4Qh3OBxZDofjJef2/zkcjoEOh6Ofw+F4sLXHpdFoNEGT2g9uXAJn/rVtzm8YMPthES6f3iEVXfpN994vKtGeZzyQDzUiDjBFJvcugT3OCi+rXhahUVUMH90ijXesEq5UtM8cYTWXYgyLEuuOZ1UPz8i4OZJWVWzyjJvEuB1/cUfDqppKVSCbio8EzqBsKoXWYt9fZDwsSs7dUOvs4Gkes6pz7SEIVe5FtjMeZ0d4ehIeJYLSS4yr3IgWFOPKPz3oLLGpKBIyYfYjcOA7+PYR3xav8jzoNgZ+tcY0qTBNPs3lHv1h1bjITJWNyHggm4rVNRQWKZ+5r+8b9bmqxlzm5mn/vVlsOh/9SvJwTr3H//lBro/act9VgDoI7cWmotFoNJqm0GcKXPia1M4++3FrL2lkvP8frOpS6VwZyIcaEuISRwPPkCj1wodEWHxyq5Rw+9sgKDkk9bytxHB0sndk282motpxewgBc2S8odajO6KpFbwdodKRUQmTZnHry/LReEyETTHuJzJuXn0w4ysyrsR4mK/SisUiGD1tL/GZUlO8UYwHKOHni5hU78Y1rREZ7zUJblwmdew9GXWR2FW+fQSeOVGSvz2pyJMKLKn9XO/d/P+luthmZFxZTZriGQ9gcQn0GlF+otW7F0m1J5UfoT6Lw2sl/6aqWBpzTbsXekzwf35wBRACWWraOVqMazQaTUdn8Fnwk6eh98nWzwdqcW136Rtc7bPju0jnwf3LYcPbrufrKuG0//P9QxrtjIybf6zNNpXE7nJbuNf9OBV5VUv/5vKI5hrb7aGRT0uS4qwosfplWc4HGwmcPmwqnhOXkHCp52wVtfUlvBonTz7EeKhzouV5/qoia1EcGibXQLEzObCpk6vRl8KOL10rN+CyTrTkhM0woOtwa2+7YUjpylN/B7lbvasS1dc6m9s4rS7q88zd6tqnyo+9xExjZLwJnvHwABaXxtewmNCBq+QryKRRXRs1FbBvOfQ91bWvugbWzJfb1P4wZI58t9hB2XGsrG0dCC3GNRqNprPTZbjcHt3ovl0l9fn7YfZECbKoJBh7BaQPgQ+ul23nz4Pbt8Kkm/0cnySCo9qHGM8cLbdH1rkfV1spkVvlr69yWlVytoitJTHL+VoWDU46E8PPg8Se8Ont8Nndss3c9MiKYBI4wdqqUu3DHqGEm6dNpbZK7CKNHUA9xbiPJkUg70/RFJsKwORb5XbfcvdzQstGxgNhGBIhB++/iar+onIduo2F+G7w/g0u20d1sJ5xH5HxmnLftrRjsamAbPvxPXh1Djw+Ah7uAZ/9Vr4n6qqkTKtCXQPbP4Nek+EX38OFr9vvCxBuc6ztnE4jxg3DmGMYxvPFxQE6OWk0Gs3xRtfhgAFH1stjh0M85n/rL9usoqS+UPtFJ4vQumC+JLGm9IVBZwYuzxedJFHSshzXNrMYT+4jlhk1VkVdlSQvqh/vl8+Evw+Gf58v723w2fbG39EJDYcLXpH7qrScsnwoMe2JZwKnw+GjtKEPSwn4Xj0JDxAZ9yvGfYhi5bs2Hx8s4dHOMpom33hVibxHc8fXtsCXz141+1FiPDYVZv5Botul2c5VILuRcSVSLaLbDQ0iXn3lVARjU7ES4/1nyCpLaTZ0HyulJH94HrZ+CjMegF4nufZNH+zq7jv51uAT4QMlqnYQgnzX7ReHw/Ex8PH48eN/3tZj0Wg0mnZFZLx4UI9ukMcb3oaVL4q4fe86ed6uN1cJMrWEnj5QkljtopLSlJAEd8EVEgKZo+CwRWQ8PMp13qoiSBsEedukhKI5We7KjyGhu/0xdTS6j5P3rCKpvkSRwjOBs6YccNgX4w6H73OoGvFWjYjcbCoWnvG4rtbjVZ+lSvJrKmoVxnzOtoyKKzz/zhUFsHuhqfSiqSKLWgmqLIDaTFkFshMZD4uAkDDryLiKIqtVDU8CJX8qfE3iZ/zeu+vt7IcBw6IhWRz8eq1MvntP9n++YxlrO6fTiHGNRqPR+KHbGNjxlXTv/OaPYgcZd6W06Qb3pWN/RJpsKk1BHecmxj0ilT0mSmkzc3fS2krZL32IJKtOuEbew8GVEk0302dq08bWkYiMd/nqA4lxzwTOksPO1/AsbeiUBA0eib61FSICLW0qgSLjTuHpGRkvz5fP0or+p8GuBTB3nvXzdom2EOPtIcHXMzI+/xx3C5m5JKe5TGNlADuSJ+Gx1iJVbTuWyHhDg//rztNm4q/MaGR804Q42I/it3M6jU1Fo9FoNH6YcqeIrKfGS7WT2X+BwXOkFjTY9+Z6RsaDJdpCjHuKv+FzRfxt+sC1LWezRPfDoyRZtfs4aSjU80RJJj3eMNdXrikLHBk321SWPibbBpzmsZ8pYrvwIVj6DxFdjSUBrRI4fUXGq1xl7sD9/DXlUofeqr05SIWgG5fKqsux4Fm5x27DnJam0bpTA4X7RIhP+DlMv0+qraSY/i7mbqI5W+R+6gB754mIsRapqvKILzEeGi42E38Ct9bH6kpr01jNR0fGNRqNRtPeyRgMl70Pn90FIy5w+TYHzoZt//Pu9OeL5oqMq0hrYg/vDntdhkHGUPj+XzDmchF22ZtgyDlNO2dnJMrUebC61H+NeHMC57o3YP2bMPk2V9KrQonxLZ9I+T3FoDPlNpjIeG2VeIGtPOP5O+U27RjFdiCik2USp2gvNpWQULGQ1FVJrX6A8ddAl6He+5oj4yUH5X7mSHvnCY+xFqk1ASLj6jl/AldN0NpcjAco4dhB0GJco9Fojhd6ngA3LHbfdsYjIsbtLhNHmRI4m4I5oj5wNsx9wXsfw4DT/wyvnwdf3if74ZAouEaITJQykvW1Isb9+avDIqHsKDzYTSKavadYN1RRCaBf3itCOTYdfngRejonblZiPDpFVldKDrlvV5FxKzGe66z/nT7I3nttKtHJ3gmcqqlQWxMWJSsQe5aIRzzDh2UnKkn+vpXOyHhKP/sTiogYa5GqIt7hAcS4P4Hb2LW3jcV4RIASjh0ELcY1Go3meCapJ9xzxL0Lpj96nCjiLN5H8l0gzCLenzWm/ww46WZY8RRs+ViifN3HNe2cnRElgqpKApemVBHv2nKYepf8syoBmdhDbhvq4ORbJbnu7Stg80ey3erzioiRVYyDq9y3q+o3VgmcedtFYKb0Dfw+jwUlxlUt+tIj7pU82pLQCFdkvPdk67rk4Gy0lSQ2lcPrJJ/CLuGx1s1wlHD1FxkPj/EvcBvFeBuvNITrOuMajUaj6QxExPgWA570Ogmu+bzpJeciEwHnuQIl0532J5j0axEUc18UcagRlDCuLrGRwOn8rMJjxZfs67PrMRFOf1Ai5yPOlxWJiHhY97o87+sc3cdJAxtzs6DGyLhFAufRjZJ029RryC7RyTKxOLwW3rhAIsJjr2zZc9olLEoi3SWHAiccRyfDgR/EptJrkv1zRASyqfiopqKe8+cZr24nNpVAnUY7CFqMazQajab1CAkBnKItUBJoSAic/if47QHpMqpxEWkW42X+JyoqOm3H3jDpZrjqE5fFZMBprpJ7viZPWeMlUfL181wCrrZKVls8EziriqVSimfyaEugrq83L4bcbXDu01L3uj0QFgH7lsn9QGI8JgWyndVWBs62f47wADYVf3kGEXEdw6aikk07uE1Fi3GNRqPRtC6DzoKsCTDqEnv72+3GdzyhIuNludBQay8y7i8S6ouhpqRZX7aigbMlmr5rgasrqKdnvLYKVs2D1a+IMB/xs+DHEizKElV2FM57HkZf3PLntIsqbxgaKS3g/aEmUV2GQ1IP++eIiLUWqWqbrzrj6jl/Arc8V26bmjvSnPjyxncgOo1n3DCMOcCc/v0DXNQajUajaVsufqOtR9DxUeJbJU76s/w0inE/HmFfDJ7juh/hQ/DHZUg0/bPfSqfFGX+QCUJYtOvcRzfA98/J/cxRreP/V0Jx+FwYOKvlzxcMyscfGR/YIlbsrKIy+bbgzhEwMu4vgTMGivyI8dxtcs01NXekOQn3MenoQHSacIPD4fjY4XBcn5jYDsoWaTQajUbTkijx3djAx0YCp7/qGT6PDYNL34Xx1wZeoRh1kbM+/Pvy2FxnvCzbtd+cJ+3nKBwLWRPglN/CmX9r+XMFi4qM25kgzXoQJt8uk4pgiHAmcJq9/GCvtGFcV7m2PI9V5GyRCjCt8TkGQkfGNRqNRqPRtDrKuqBqTweqMw5Ni4yD+LvteLwzR0mJxQ1vOc9r6sBZnie3130D3UY3bRzBEhYJ037XOucKFvWZ2PFc958p/4IlfZDYhfJ2uDdQqimTzyYk1PexGYNlv+IDUnHJjMMh9duHtpO6/77qqXcgOk1kXKPRaDSa4wYVGV/vFL52IuNN8YwHg2HA0HOlsgpIQyAVGVce46Y2i+psHOsEyQ6qPvz+5e7bayv8+8UB0gfLbe427+fKcqTueYZFk6K2ICLWf+WXDoAW4xqNRqPRdDTCIuDEX4o3G/xXU1Gt6ptiUwmWoee67ncZ7mwkZLjEeFtX32gvqEmKvxWNYyW1vzQU2uchxmvKA59XifGcLd7Pqa6mvhoVtTY6Mq7RaDQajaZNmP0QTLlD7idk+d7Pjke4ueg+DgaeAbP/IiUPDUOiwBX58ry/Rk/HE60RGTcMGHA6bHwHNn3g2l5THniVJCYFYjMgd6v3c0qgp7cTMR4R0+Gb/mjPuEaj0Wg0HZUZvxdB7k/U1baiGDcMuOQ/7ttCIyU6HxLuSlw83gnGM34snPko5O+Aj2+BnpMgvotTjNu4FrqPg71LxSNuTtTM2SwR97j0lht3MIRrm4pGo9FoNJq2JJCwGn81DPspnHxL64zHE5XEGZXQPqpvtAdaIzIOYl/6ybNS5/0/l0BpNhxcBSl9Ax/bfwYU7YOC3e7bVSWV9sLMP0hpzQ6MFuMajUaj0XRmopPhZ6+I9aAtCG2lKHBHojU844q0AXD+PDi8Bv4+CKqLYeINgY9TFVx2fOXa1tAg1pX2krwJkJDpXfGlg6HFuEaj0Wg0mpaj0ZKh/eKNqBWC1rAOAQw5G37yHKQNlBWSHhMCH5PSRxI5t3zk2pazWUoeZo5qubEeh2jPuEaj0Wg0mpYjPFpuo3RTvkbqnVVwWiMyrhh1ofwLhuFzYeFD0gAooZt4yAH6TGn+8R3H6Mi4RqPRaDSaliNtgNxqm4oLVZJSrRq0V4bPBRyw3pmUu3eJNHbq4LaQ9kanEeOGYcwxDOP54uLith6KRqPRaDQaRbexcltf07bjaE801MttaHjbjiMQqf2g9xRY/TKU5cLObySxU9OsdBox7nA4PnY4HNcnJuplMI1Go9Fo2g3dx8lt/s62HUd7QtlUQtq5GAeYeD0U7Ycnx0BdpTzWNCudRoxrNBqNRqNph6hkv7SBbTuO9oSyqYR2gNS9IXOgxwlQUwqjL21fZQ07CR3gKtBoNBqNRtNhiYyD6xdBcp+2Hkn7oSNFxg0DLngNDq6EwWe19Wg6JVqMazQajUajaVm6jWnrEbQvZv9FupEOOK2tR2KP+C5SHlHTImgxrtFoNBqNRtOaJPWA819q61Fo2gnaM67RaDQajUaj0bQRWoxrNBqNRqPRaDRthBbjGo1Go9FoNBpNG6HFuEaj0Wg0Go1G00ZoMa7RaDQajUaj0bQRWoxrNBqNRqPRaDRthBbjGo1Go9H8f3v3Hm3HeMZx/PtbCU1cVty1hKKUpRShabKoKnUPQVHUamJpUwtd0VJVreVSqV5ciqoWiduqS6SkIWhSRKkKifslKghJSi5CEETJ0z/e98iY7CRnn71P5uT4fdba68z7zuyZZz97zznPmXlntplZRTpNMS5pP0mXzZ07t+pQzMzMzMxapdMU4xFxa0QM6tGjR9WhmJmZmZm1Sqcpxs3MzMzMljcuxs3MzMzMKuJi3MzMzMysIi7GzczMzMwq4mLczMzMzKwiLsbNzMzMzCriYtzMzMzMrCIuxs3MzMzMKuJi3MzMzMysIoqIqmNoKkmzgJcr2PRawOwKttsZOZfN41w2j3PZHM5j8ziXzeNcNsenMY+fj4i1G1lBpyvGqyJpQkTsUHUcnYFz2TzOZfM4l83hPDaPc9k8zmVzOI9t42EqZmZmZmYVcTFuZmZmZlYRF+PNc1nVAXQizmXzOJfN41w2h/PYPM5l8ziXzeE8toHHjJuZmZmZVcRHxs3MzMzMKuJivAkk7SXpOUmTJZ1SdTwdnaRhkmZKeqrQt4aksZKezz9Xz/2SdFHO7ROSelUXecciaQNJ90h6RtLTkgbnfueyTpK6SXpI0uM5l2fm/o0ljc85u1HSirn/M7k9Oc/fqMr4OxpJXSQ9Kum23HYe20DSFElPSnpM0oTc5/27DSStJmmEpEmSnpXU17msn6TN8+ex5fGWpBOcy8a4GG+QpC7AJcDewJbA4ZK2rDaqDu8qYK9S3ynAXRGxGXBXbkPK62b5MQi4dBnFuDz4EDgxIrYE+gDH5c+ec1m/+cCuEbENsC2wl6Q+wG+ACyJiU+AN4Oi8/NHAG7n/grycLTQYeLbQdh7b7hsRsW3hdnHev9vmQuDOiNgC2Ib0+XQu6xQRz+XP47bA9sC7wC04lw1xMd643sDkiHgxIj4AbgD6VxxThxYR/wTmlLr7A1fn6auBAwr910TyILCapM8tm0g7toh4NSIeydNvk/64rI9zWbeck3dyc4X8CGBXYETuL+eyJccjgN0kaRmF26FJ6gnsC1yR28J5bCbv33WS1APYGRgKEBEfRMSbOJeN2g14ISJexrlsiIvxxq0PTC20p+U+q8+6EfFqnn4NWDdPO7+tkE/vbweMx7lskzy04jFgJjAWeAF4MyI+zIsU8/VxLvP8ucCayzbiDuv3wMnAgtxeE+exrQIYI2mipEG5z/t3/TYGZgFX5uFTV0haGeeyUYcB1+dp57IBLsatw4l0ix/f5qeVJK0C/BU4ISLeKs5zLlsvIj7Kp157ks54bVFxSMsdSf2AmRExsepYOomdIqIX6VT/cZJ2Ls70/t1qXYFewKURsR0wj4XDKADnsl75uo/9gZvK85zL+rkYb9x0YINCu2fus/rMaDl1lX/OzP3O7xJIWoFUiP8lIm7O3c5lA/Lp63uAvqRTql3zrGK+Ps5lnt8DeH0Zh9oR7QjsL2kKacjerqSxus5jG0TE9PxzJmlcbm+8f7fFNGBaRIzP7RGk4ty5bLu9gUciYkZuO5cNcDHeuIeBzfLdAlYknbYZVXFMy6NRwIA8PQD4W6H/u/mK7D7A3MKpsE+1PLZ2KPBsRJxfmOVc1knS2pJWy9Pdgd1JY/DvAQ7Oi5Vz2ZLjg4G7w1/aQET8LCJ6RsRGpN+Fd0fEd3Ae6yZpZUmrtkwDewBP4f27bhHxGjBV0ua5azfgGZzLRhzOwiEq4Fw2xF/60wSS9iGNk+wCDIuIIRWH1KFJuh7YBVgLmAGcDowEhgMbAi8Dh0bEnFxw/oF095V3gaMiYkIVcXc0knYC7gOeZOH43FNJ48adyzpI+jLpoqMupIMUwyPiLEmbkI7wrgE8ChwZEfMldQOuJY3TnwMcFhEvVhN9xyRpF+CkiOjnPNYv5+yW3OwKXBcRQyStiffvuknalnRR8YrAi8BR5H0d57Iu+Z/DV4BNImJu7vPnsgEuxs3MzMzMKuJhKmZmZmZmFXExbmZmZmZWERfjZmZmZmYVcTFuZmZmZlYRF9IUdLEAAAWpSURBVONmZmZmZhVxMW5mlkm6StKEQru3pDMqimWQpANq9E+RdG4VMVVF0i6SQtJWVcdiZtZsXZe+iJnZp8Yvge6Fdm/SffDPqCCWQaQveRlZ6j8Qf0ulmVmn4WLczCyLiBfac/2SukfEe42sIyIebVY8lkjqFhHvVx2HmX06eZiKmVlWHKYiaSBwcZ6O/BhXWHYrSaMlvZ0fN0n6bGF+y9CKPSWNkvQO6ZvokHSipIclzZU0Q9KtkjYtPHccsD0woLDtgXneIsNUJB0q6UlJ8yVNlTREUtfC/IF5HVtLGitpnqRJkg5qRU5C0mBJv5I0S9JMSZdI+kxhmTMkzV7Mc48vtKdIOlfSKZJeza//vPxV2ftIejrncqSk1WuEs56k23L8r0g6psY2vybpXknvSnpd0uXKXytfykVvSeMkvQf8ZGl5MDNrLy7GzcxqGw2cl6f75sexALlw/hfQDTgSGAh8Cbg1f/1z0VDgcWD/PA3Qk1SY9we+D3QBHpDUI88/FpgE3F7Y9uhaQUraA7gReCSv72LgpLz+suuAUaShLs8DN0jqubREACcC6+XX+jvgB8DgVjyvlsNIw3+OAn4L/Bg4nzRE6DTgGODrwDk1njsUeAI4iJSbSyX1a5kpaUfgH8BrwMHACcA+wJU11nU9cGuef1sbX4uZWcM8TMXMrIaImCVpSp5+sDT7dFLBt3dEfAAg6QlSAb0Pnyycb4qI00rr/lHLtKQuwFhgJqmYviYinpE0D5hVY9tlZwHjImJAbt+Z/x84R9LZETGtsOwFETEsb3ciMAPoB/xpKduYEhED8/Tfc9F7EKmYrtf7wCER8VGOtT/wQ2CziHgpx7YNMIBUmBfdERGnFuL4AvALFhbTvwYeiIhvtzxB0nTgLklbRcRThXVdFBEXtiF+M7Om8pFxM7P6fRO4BVggqWseEvISMAXYobTsIke0JfXJw0VeBz4E3gVWAb5YTxC5kO8F3FSadSPp93vfUv+YlomIeJ30D0BrjoyPKbWfaeXzahmXC/EWk0nF/kulvrUlrVh67i2l9s3A9pK6SFqJ9HqHt7wn+X25H/gfadhPUc0zDWZmy5qLcTOz+q0F/JRU5BUfmwAblJadUWxI2pBU3Io03GNH4CukwrhbG+JYobyNQnuNUv+bpfYHrdxmW5/X2nXV6hNQLsZn1mh3JeVhddJwnz/yyfdkPilHS3xfzMyq4mEqZmb1m0M6SntFjXnlCxmj1N4LWAnoHxHzAPIR3HLh3BqzSQXnOqX+dQtxLgvvUyqcF3MBZqPKr3Md0pmF2aR/DoJ0G8rbazz3v6V2+X0xM6uEi3Ezs8VrGQ9evvXdXaQLNidGRL1FXXdgAamIbHEoi/4+XurR54j4KI/9PgS4tLS+BcC/64ytraYBq0paPyKm57492mE7BwJ3lNoT87CXeZIeBDaPiLPaYdtmZu3CxbiZ2eJNyj8HS7obeCsiniMdfX0IGC1pGOnI7PrA7sBVETFuCeu8mzSc4kpJQ0lF/UksOlRjErCnpD1JX/LzUh7nXXY66WLGK4EbgK1Jdya5vHTxZnu6E3gPGCbpPGBjFr34shn2ljQEuJd0AenupIteW5xMulhzATACeBvYENgX+HlE/KcdYjIza4jHjJuZLd59pFv5DQbGA38GyEVdH9KFl5eRjtaeSRqfPHlJK4yIJ0m3Qvwq6S4gR5CObM8tLXo28CwwHHgY2G8x6xtDul3gDqRb9Z1AuiXj8bWWbw8RMRv4FumizpGkWyAe0Q6b+h7pgtWRpLvAHBcRowpx3A/sDKwNXEvKx8nAVDxG3Mw6KNV/htXMzMzMzJrBR8bNzMzMzCriYtzMzMzMrCIuxs3MzMzMKuJi3MzMzMysIi7GzczMzMwq4mLczMzMzKwiLsbNzMzMzCriYtzMzMzMrCIuxs3MzMzMKvJ/frE69NwfDF0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.plot_loss_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III - Multiclass classification MLP with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Implement the same network architecture with Keras;\n",
    "    - First using the Sequential API\n",
    "    - Secondly using the functional API\n",
    "\n",
    "#### - Check that the Keras model can approximately reproduce the behavior of the Numpy model.\n",
    "\n",
    "#### - Compute the negative log likelihood of a sample 42 in the test set (can use `model.predict_proba`).\n",
    "\n",
    "#### - Compute the average negative log-likelihood on the full test set.\n",
    "\n",
    "#### - Compute the average negative log-likelihood  on the full training set and check that you can get the value of the loss reported by Keras.\n",
    "\n",
    "#### - Is the model overfitting or underfitting? (ensure that the model has fully converged by increasing the number of epochs to 500 or more if necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, Y_tr, Y_val = train_test_split(X, Y)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1), copy=False)\n",
    "X_tr = scaler.fit_transform(X_tr)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "n_features = X[0].shape[0]\n",
    "\n",
    "n_classes = len(np.unique(Y_tr))\n",
    "n_hidden = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with relu activation\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 3,760\n",
      "Trainable params: 3,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1347 samples, validate on 450 samples\n",
      "Epoch 1/30\n",
      "1347/1347 [==============================] - 0s 259us/sample - loss: 2.2111 - accuracy: 0.3935 - val_loss: 2.0843 - val_accuracy: 0.7044\n",
      "Epoch 2/30\n",
      "1347/1347 [==============================] - 0s 49us/sample - loss: 1.9525 - accuracy: 0.6281 - val_loss: 1.7424 - val_accuracy: 0.7933\n",
      "Epoch 3/30\n",
      "1347/1347 [==============================] - 0s 49us/sample - loss: 1.5927 - accuracy: 0.7379 - val_loss: 1.3342 - val_accuracy: 0.8444\n",
      "Epoch 4/30\n",
      "1347/1347 [==============================] - 0s 48us/sample - loss: 1.2517 - accuracy: 0.7550 - val_loss: 0.9958 - val_accuracy: 0.8778\n",
      "Epoch 5/30\n",
      "1347/1347 [==============================] - 0s 48us/sample - loss: 1.0032 - accuracy: 0.7944 - val_loss: 0.7748 - val_accuracy: 0.8956\n",
      "Epoch 6/30\n",
      "1347/1347 [==============================] - 0s 50us/sample - loss: 0.8258 - accuracy: 0.8189 - val_loss: 0.6282 - val_accuracy: 0.9067\n",
      "Epoch 7/30\n",
      "1347/1347 [==============================] - 0s 48us/sample - loss: 0.6986 - accuracy: 0.8419 - val_loss: 0.5265 - val_accuracy: 0.9156\n",
      "Epoch 8/30\n",
      "1347/1347 [==============================] - 0s 52us/sample - loss: 0.6260 - accuracy: 0.8619 - val_loss: 0.4541 - val_accuracy: 0.9267\n",
      "Epoch 9/30\n",
      "1347/1347 [==============================] - 0s 51us/sample - loss: 0.5758 - accuracy: 0.8500 - val_loss: 0.4043 - val_accuracy: 0.9356\n",
      "Epoch 10/30\n",
      "1347/1347 [==============================] - 0s 52us/sample - loss: 0.5323 - accuracy: 0.8545 - val_loss: 0.3583 - val_accuracy: 0.9444\n",
      "Epoch 11/30\n",
      "1347/1347 [==============================] - 0s 50us/sample - loss: 0.4990 - accuracy: 0.8760 - val_loss: 0.3376 - val_accuracy: 0.9400\n",
      "Epoch 12/30\n",
      "1347/1347 [==============================] - 0s 47us/sample - loss: 0.4455 - accuracy: 0.8916 - val_loss: 0.3043 - val_accuracy: 0.9400\n",
      "Epoch 13/30\n",
      "1347/1347 [==============================] - 0s 50us/sample - loss: 0.4197 - accuracy: 0.8886 - val_loss: 0.2776 - val_accuracy: 0.9600\n",
      "Epoch 14/30\n",
      "1347/1347 [==============================] - 0s 50us/sample - loss: 0.4020 - accuracy: 0.8998 - val_loss: 0.2585 - val_accuracy: 0.9556\n",
      "Epoch 15/30\n",
      "1347/1347 [==============================] - 0s 50us/sample - loss: 0.3625 - accuracy: 0.9072 - val_loss: 0.2445 - val_accuracy: 0.9511\n",
      "Epoch 16/30\n",
      "1347/1347 [==============================] - 0s 51us/sample - loss: 0.3542 - accuracy: 0.9027 - val_loss: 0.2258 - val_accuracy: 0.9578\n",
      "Epoch 17/30\n",
      "1347/1347 [==============================] - 0s 51us/sample - loss: 0.3451 - accuracy: 0.9094 - val_loss: 0.2135 - val_accuracy: 0.9622\n",
      "Epoch 18/30\n",
      "1347/1347 [==============================] - 0s 50us/sample - loss: 0.3242 - accuracy: 0.9146 - val_loss: 0.2034 - val_accuracy: 0.9622\n",
      "Epoch 19/30\n",
      "1347/1347 [==============================] - 0s 48us/sample - loss: 0.3375 - accuracy: 0.9065 - val_loss: 0.1945 - val_accuracy: 0.9644\n",
      "Epoch 20/30\n",
      "1347/1347 [==============================] - 0s 48us/sample - loss: 0.2996 - accuracy: 0.9228 - val_loss: 0.1839 - val_accuracy: 0.9667\n",
      "Epoch 21/30\n",
      "1347/1347 [==============================] - 0s 52us/sample - loss: 0.2865 - accuracy: 0.9258 - val_loss: 0.1767 - val_accuracy: 0.9644\n",
      "Epoch 22/30\n",
      "1347/1347 [==============================] - 0s 54us/sample - loss: 0.2691 - accuracy: 0.9243 - val_loss: 0.1714 - val_accuracy: 0.9622\n",
      "Epoch 23/30\n",
      "1347/1347 [==============================] - 0s 52us/sample - loss: 0.2729 - accuracy: 0.9317 - val_loss: 0.1627 - val_accuracy: 0.9756\n",
      "Epoch 24/30\n",
      "1347/1347 [==============================] - 0s 53us/sample - loss: 0.2636 - accuracy: 0.9302 - val_loss: 0.1602 - val_accuracy: 0.9622\n",
      "Epoch 25/30\n",
      "1347/1347 [==============================] - 0s 49us/sample - loss: 0.2460 - accuracy: 0.9369 - val_loss: 0.1500 - val_accuracy: 0.9689\n",
      "Epoch 26/30\n",
      "1347/1347 [==============================] - 0s 49us/sample - loss: 0.2356 - accuracy: 0.9376 - val_loss: 0.1448 - val_accuracy: 0.9711\n",
      "Epoch 27/30\n",
      "1347/1347 [==============================] - 0s 49us/sample - loss: 0.2387 - accuracy: 0.9339 - val_loss: 0.1429 - val_accuracy: 0.9733\n",
      "Epoch 28/30\n",
      "1347/1347 [==============================] - 0s 47us/sample - loss: 0.2362 - accuracy: 0.9347 - val_loss: 0.1372 - val_accuracy: 0.9711\n",
      "Epoch 29/30\n",
      "1347/1347 [==============================] - 0s 50us/sample - loss: 0.2295 - accuracy: 0.9391 - val_loss: 0.1338 - val_accuracy: 0.9733\n",
      "Epoch 30/30\n",
      "1347/1347 [==============================] - 0s 49us/sample - loss: 0.2207 - accuracy: 0.9414 - val_loss: 0.1303 - val_accuracy: 0.9711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffa8ad1d588>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "activation = \"relu\"\n",
    "# activation = \"sigmoid\"\n",
    "\n",
    "print('Model with {} activation'.format(activation))\n",
    "\n",
    "keras_model = Sequential()\n",
    "# TODO:\n",
    "keras_model.add(Dense(50 , input_dim = n_features , activation=activation, kernel_initializer=\"normal\" ) )\n",
    "keras_model.add(Dropout(0.3))\n",
    "                \n",
    "keras_model.add(Dense(n_classes ,kernel_initializer=\"normal\", activation=\"softmax\"))\n",
    "                \n",
    "keras_model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=\"adam\",\n",
    "            metrics=['accuracy'])\n",
    "                \n",
    "keras_model.summary()\n",
    "\n",
    "keras_model.fit(X_tr, to_categorical(Y_tr), validation_data=(X_val, to_categorical(Y_val) ), epochs=30,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with relu activation\n",
      "Train on 1347 samples, validate on 450 samples\n",
      "Epoch 1/20\n",
      "1347/1347 [==============================] - 0s 255us/sample - loss: 2.2533 - accuracy: 0.1774 - val_loss: 1.9958 - val_accuracy: 0.4644\n",
      "Epoch 2/20\n",
      "1347/1347 [==============================] - 0s 45us/sample - loss: 1.8683 - accuracy: 0.4477 - val_loss: 1.6248 - val_accuracy: 0.7244\n",
      "Epoch 3/20\n",
      "1347/1347 [==============================] - 0s 50us/sample - loss: 1.5618 - accuracy: 0.5939 - val_loss: 1.3064 - val_accuracy: 0.8289\n",
      "Epoch 4/20\n",
      "1347/1347 [==============================] - 0s 47us/sample - loss: 1.3033 - accuracy: 0.6897 - val_loss: 1.0380 - val_accuracy: 0.8778\n",
      "Epoch 5/20\n",
      "1347/1347 [==============================] - 0s 48us/sample - loss: 1.0863 - accuracy: 0.7365 - val_loss: 0.8271 - val_accuracy: 0.8956\n",
      "Epoch 6/20\n",
      "1347/1347 [==============================] - 0s 49us/sample - loss: 0.9452 - accuracy: 0.7647 - val_loss: 0.6795 - val_accuracy: 0.9178\n",
      "Epoch 7/20\n",
      "1347/1347 [==============================] - 0s 48us/sample - loss: 0.8050 - accuracy: 0.8018 - val_loss: 0.5714 - val_accuracy: 0.9178\n",
      "Epoch 8/20\n",
      "1347/1347 [==============================] - 0s 49us/sample - loss: 0.7251 - accuracy: 0.8099 - val_loss: 0.4937 - val_accuracy: 0.9222\n",
      "Epoch 9/20\n",
      "1347/1347 [==============================] - 0s 47us/sample - loss: 0.6508 - accuracy: 0.8278 - val_loss: 0.4315 - val_accuracy: 0.9333\n",
      "Epoch 10/20\n",
      "1347/1347 [==============================] - 0s 48us/sample - loss: 0.6140 - accuracy: 0.8330 - val_loss: 0.3931 - val_accuracy: 0.9356\n",
      "Epoch 11/20\n",
      "1347/1347 [==============================] - 0s 47us/sample - loss: 0.5509 - accuracy: 0.8515 - val_loss: 0.3474 - val_accuracy: 0.9422\n",
      "Epoch 12/20\n",
      "1347/1347 [==============================] - 0s 49us/sample - loss: 0.5191 - accuracy: 0.8612 - val_loss: 0.3172 - val_accuracy: 0.9511\n",
      "Epoch 13/20\n",
      "1347/1347 [==============================] - 0s 47us/sample - loss: 0.4759 - accuracy: 0.8760 - val_loss: 0.2896 - val_accuracy: 0.9533\n",
      "Epoch 14/20\n",
      "1347/1347 [==============================] - 0s 50us/sample - loss: 0.4407 - accuracy: 0.8738 - val_loss: 0.2664 - val_accuracy: 0.9489\n",
      "Epoch 15/20\n",
      "1347/1347 [==============================] - 0s 47us/sample - loss: 0.4193 - accuracy: 0.8924 - val_loss: 0.2482 - val_accuracy: 0.9600\n",
      "Epoch 16/20\n",
      "1347/1347 [==============================] - 0s 50us/sample - loss: 0.4129 - accuracy: 0.8879 - val_loss: 0.2335 - val_accuracy: 0.9556\n",
      "Epoch 17/20\n",
      "1347/1347 [==============================] - 0s 48us/sample - loss: 0.3924 - accuracy: 0.8998 - val_loss: 0.2198 - val_accuracy: 0.9622\n",
      "Epoch 18/20\n",
      "1347/1347 [==============================] - 0s 49us/sample - loss: 0.3618 - accuracy: 0.9042 - val_loss: 0.2093 - val_accuracy: 0.9667\n",
      "Epoch 19/20\n",
      "1347/1347 [==============================] - 0s 48us/sample - loss: 0.3607 - accuracy: 0.8968 - val_loss: 0.2008 - val_accuracy: 0.9689\n",
      "Epoch 20/20\n",
      "1347/1347 [==============================] - 0s 49us/sample - loss: 0.3334 - accuracy: 0.9102 - val_loss: 0.1864 - val_accuracy: 0.9689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffa88660780>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "activation = \"relu\"\n",
    "# activation = \"sigmoid\"\n",
    "\n",
    "print('Model with {} activation'.format(activation))\n",
    "\n",
    "inputs = Input(shape=(n_features,))\n",
    "# TODO:\n",
    "\n",
    "hidden_layer = Dense(50,activation=activation)(inputs)\n",
    "\n",
    "dropout_layer = Dropout(0.3)(hidden_layer)\n",
    "\n",
    "output_layer= Dense(n_classes,activation=\"softmax\")(dropout_layer)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = output_layer)\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss = \"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_tr,to_categorical(Y_tr), validation_data=(X_val, to_categorical(Y_val) ), epochs = 20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that you know if the model is underfitting or overfitting:\n",
    "\n",
    "It looks like the model is underfitting just a little because we get a higher validation accuracy than training accuracy.\n",
    "\n",
    "#### - In case of underfitting, can you explain why ? Also change the structure of the 2 previous networks to cancell underfitting\n",
    "If the model is undefitting, then that is a sign that our model complexity is not high enough and is not able to model that data distribution. If this is the case then we can increase our hidden layer size or simply add more hidden layers but not too many as this could lead to overfitting. \n",
    "\n",
    "\n",
    "#### - In case of overfitting, explain why and change the structure of the 2 previous networks to cancell the overfitting\n",
    "If our model is overfitting then there are two possible options:\n",
    "1) reduce the model size by removing some hidden layers if there are too many or by decreassing the number of hidden neurons\n",
    "2) add some dropout to the layers as a regularization technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
